{
  "metadata": {
    "generated": "2025-11-03T13:25:19.398391",
    "generator": "LFM Prior Art Documenter v1.0",
    "author": "Greg D. Partin",
    "project": "Lattice Field Medium (LFM)",
    "repository": "https://github.com/gpartin/LFM",
    "license": "CC BY-NC-ND 4.0",
    "contact": "latticefieldmediumresearch@gmail.com"
  },
  "summary": {
    "total_files": 104,
    "total_lines": 28960,
    "total_innovations": 1986,
    "categories": {
      "CORE_ALGORITHM": 9,
      "PERFORMANCE": 3,
      "USER_INTERFACE": 4,
      "VISUALIZATION": 16,
      "VALIDATION": 18,
      "UTILITY": 54
    },
    "analysis_scope": "Complete LFM framework codebase"
  },
  "files": [
    {
      "filepath": "chi_field_equation.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "6748d8c4a6eeb302",
      "file_size": 5306,
      "modified": "2025-11-03T13:19:47.764439",
      "git_info": {
        "first_commit": {
          "hash": "f0885273",
          "date": "2025-10-30 17:51:45 -0700",
          "message": "Additional tests, harnesses"
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 20,
          "context": "  17:     from typing import Tuple, List\n  18:     \n  19:     \n  20: >>> def _laplacian_1d(u: np.ndarray, dx: float) -> np.ndarray:\n  21:         \"\"\"Periodic 1D Laplacian with 2nd-order stencil.\"\"\"\n  22:         up = np.roll(u, -1)\n  23:         um = np.roll(u, 1)",
          "match": "def _laplacian_1d(u:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 27,
          "context": "  24:         return (up - 2.0 * u + um) / (dx * dx)\n  25:     \n  26:     \n  27: >>> def _smooth_1d(u: np.ndarray, passes: int = 1) -> np.ndarray:\n  28:         \"\"\"Lightweight smoothing by repeated 3-tap convolution (0.25, 0.5, 0.25).\"\"\"\n  29:         if passes <= 0:\n  30:             return u",
          "match": "def _smooth_1d(u:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 111,
          "context": " 108:         history: List[Tuple[int, np.ndarray, np.ndarray, np.ndarray, float]] = []\n 109:     \n 110:         # Helper to compute energy proxy\n 111: >>>     def energy_proxy(e_arr: np.ndarray) -> float:\n 112:             return float(np.sum(e_arr * e_arr))\n 113:     \n 114:         for n in range(int(steps)):",
          "match": "def energy_proxy(e_arr:"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 21,
          "context": "  18:     \n  19:     \n  20:     def _laplacian_1d(u: np.ndarray, dx: float) -> np.ndarray:\n  21: >>>     \"\"\"Periodic 1D Laplacian with 2nd-order stencil.\"\"\"\n  22:         up = np.roll(u, -1)\n  23:         um = np.roll(u, 1)\n  24:         return (up - 2.0 * u + um) / (dx * dx)",
          "match": "Periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 34,
          "context": "  31:         k = np.array([0.25, 0.5, 0.25], dtype=u.dtype)\n  32:         v = u.copy()\n  33:         for _ in range(passes):\n  34: >>>         # periodic pad via roll\n  35:             vm = np.roll(v, 1)\n  36:             vp = np.roll(v, -1)\n  37:             v = k[0] * vm + k[1] * v + k[2] * vp",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 104,
          "context": " 101:     \n 102:         params = {\n 103:             'dt': float(dt), 'dx': float(dx), 'alpha': 1.0, 'beta': 1.0,\n 104: >>>         'boundary': 'periodic',\n 105:             'chi': chi\n 106:         }\n 107:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 104,
          "context": " 101:     \n 102:         params = {\n 103:             'dt': float(dt), 'dx': float(dx), 'alpha': 1.0, 'beta': 1.0,\n 104: >>>         'boundary': 'periodic',\n 105:             'chi': chi\n 106:         }\n 107:     ",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 61,
          "context": "  58:         Eprev = np.asarray(Eprev, dtype=np.float64)\n  59:         # Finite-difference time derivative\n  60:         dE_dt = (E - Eprev) / max(dt, 1e-30)\n  61: >>>     # Energy density (dimensionless units consistent with solver)\n  62:         rho = 0.5 * (E * E + (dE_dt * dE_dt) / max(c * c, 1e-30))\n  63:         # Smooth to mitigate discretization noise\n  64:         rho_s = _smooth_1d(rho, passes=2)",
          "match": "solver"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 87,
          "context": "  84:     ) -> Tuple[np.ndarray, np.ndarray, List[Tuple[int, np.ndarray, np.ndarray, np.ndarray, float]]]:\n  85:         \"\"\"\n  86:         Minimal 1D coupled evolution for Tier-2 GRAV-23/24:\n  87: >>>       - E evolves via Klein-Gordon with static chi per step (semi-implicit via leapfrog in harness)\n  88:           - chi evolves via wave equation χ_tt = c_χ^2 ∂xx χ + α G ρ(E)\n  89:     \n  90:         Returns (E_final, chi_final, history) where history = [(step, E_snap, chi_snap, omega_snap, energy)]",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 124,
          "context": " 121:                 dE_dt = (E - E_prev) / max(dt, 1e-30)\n 122:                 rho = 0.5 * (E * E + (dE_dt * dE_dt) / max(c * c, 1e-30))\n 123:                 rho_s = _smooth_1d(rho, passes=1)\n 124: >>>             # Leapfrog-like update for chi\n 125:                 lap_chi = _laplacian_1d(chi, dx)\n 126:                 chi_next = (2.0 * chi - chi_prev\n 127:                             + (c_chi * c_chi) * (dt * dt) * lap_chi",
          "match": "Leapfrog"
        }
      ],
      "line_count": 139,
      "docstring": "Chi-Field Evolution Module\n==========================\nMinimal chi-field helpers for Tier-2 GRAV tests (1D support)\nProvides coupled field evolution for gravitational analogue simulations."
    },
    {
      "filepath": "devtests\\test_lfm_equation_quick.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "a2305324ec56e474",
      "file_size": 6377,
      "modified": "2025-11-02T20:02:10.962139",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 73,
          "context": "  70:     COMPARE_LEGACY = False  # set True to also run the old initialization for A/B\n  71:     \n  72:     # ----------------------- Helper: periodic gradient -------------------\n  73: >>> def periodic_dx(arr: np.ndarray, dx: float) -> np.ndarray:\n  74:         \"\"\"Central periodic spatial gradient.\"\"\"\n  75:         return (np.roll(arr, -1) - np.roll(arr, 1)) / (2.0 * dx)\n  76:     ",
          "match": "def periodic_dx(arr:"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 12,
          "context": "   9:     Quick Regression Test — LFM Core Equation (v1.6, Taylor-corrected)\n  10:     ------------------------------------------------------------------\n  11:     Purpose:\n  12: >>>   Verify numerical stability & energy behavior of lfm_equation.py after changes.\n  13:       Uses a 1-D Gaussian pulse and a physically consistent E_prev via a\n  14:       Taylor backstep: E_prev = E0 - c*dt*∂E/∂x  (periodic gradient).\n  15:     ",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 19,
          "context": "  16:     What's new vs v1.4:\n  17:       • Taylor-corrected E_prev initialization (fixes artificial energy loss).\n  18:       • Manual evolution loop to allow custom E_prev (uses lattice_step).\n  19: >>>   • Clear CFL printout and checkpoint trend line.\n  20:       • Optional legacy comparison run (advance/E_prev=E0) for A/B verification.\n  21:     \n  22:     PASS if |drift| < 1e-3 and values are finite.",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 81,
          "context": "  78:     c = math.sqrt(params[\"alpha\"] / params[\"beta\"])\n  79:     dt = params[\"dt\"]\n  80:     dx = params[\"dx\"]\n  81: >>> cfl = c * dt / dx\n  82:     \n  83:     E_prev = E0 - c * dt * periodic_dx(E0, dx)  # ← key fix\n  84:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 89,
          "context": "  86:     print(\"=== LFM Core Regression Test (v1.6) ===\")\n  87:     print(f\"Grid: {nx}   χ-mode: {'field' if USE_FIELD_CHI else 'scalar'}\")\n  88:     print(f\"dt={dt:.3g}, dx={dx:.3g}, steps={STEPS}\")\n  89: >>> print(f\"CFL = {cfl:.3f}   (3D limit ≈ 1/sqrt(3) ≈ 0.577)\")\n  90:     \n  91:     E = E0.copy()\n  92:     dbg = params[\"debug\"]",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 89,
          "context": "  86:     print(\"=== LFM Core Regression Test (v1.6) ===\")\n  87:     print(f\"Grid: {nx}   χ-mode: {'field' if USE_FIELD_CHI else 'scalar'}\")\n  88:     print(f\"dt={dt:.3g}, dx={dx:.3g}, steps={STEPS}\")\n  89: >>> print(f\"CFL = {cfl:.3f}   (3D limit ≈ 1/sqrt(3) ≈ 0.577)\")\n  90:     \n  91:     E = E0.copy()\n  92:     dbg = params[\"debug\"]",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 123,
          "context": " 120:     print(f\"Time elapsed: {elapsed:.3f} s  (avg {(elapsed/max(1,STEPS))*1000:.3f} ms/step)\")\n 121:     print(f\"Energy drift: {met_final['drift']:+.3e}\")\n 122:     print(f\"Max |E|     : {met_final['max_abs']:.3e}\")\n 123: >>> print(f\"CFL ratio   : {cfl:.3f}\")\n 124:     print(f\"Grad ratio  : {met_final.get('grad_ratio','N/A')}\")\n 125:     print(f\"Diagnostics : {RESULTS_DIR / 'diagnostics_core.csv'}\")\n 126:     ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 123,
          "context": " 120:     print(f\"Time elapsed: {elapsed:.3f} s  (avg {(elapsed/max(1,STEPS))*1000:.3f} ms/step)\")\n 121:     print(f\"Energy drift: {met_final['drift']:+.3e}\")\n 122:     print(f\"Max |E|     : {met_final['max_abs']:.3e}\")\n 123: >>> print(f\"CFL ratio   : {cfl:.3f}\")\n 124:     print(f\"Grad ratio  : {met_final.get('grad_ratio','N/A')}\")\n 125:     print(f\"Diagnostics : {RESULTS_DIR / 'diagnostics_core.csv'}\")\n 126:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 135,
          "context": " 132:     if PASS:\n 133:         print(\"\\n✅ PASS — Stable energy and numerics verified.\")\n 134:     else:\n 135: >>>     print(\"\\n❌ FAIL — Energy drift or numeric instability detected.\")\n 136:         # (we still continue if user wants legacy comparison/plots)\n 137:     \n 138:     # ----------------------- Optional legacy comparison -------------------",
          "match": "stability"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 14,
          "context": "  11:     Purpose:\n  12:       Verify numerical stability & energy behavior of lfm_equation.py after changes.\n  13:       Uses a 1-D Gaussian pulse and a physically consistent E_prev via a\n  14: >>>   Taylor backstep: E_prev = E0 - c*dt*∂E/∂x  (periodic gradient).\n  15:     \n  16:     What's new vs v1.4:\n  17:       • Taylor-corrected E_prev initialization (fixes artificial energy loss).",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 56,
          "context": "  53:         \"beta\": 1.0,\n  54:         \"chi\": CHI_VALUE,\n  55:         \"gamma_damp\": 0.0,\n  56: >>>     \"boundary\": \"periodic\",\n  57:         \"stencil_order\": 2,\n  58:         \"energy_monitor_every\": 10,\n  59:         \"debug\": {",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 56,
          "context": "  53:         \"beta\": 1.0,\n  54:         \"chi\": CHI_VALUE,\n  55:         \"gamma_damp\": 0.0,\n  56: >>>     \"boundary\": \"periodic\",\n  57:         \"stencil_order\": 2,\n  58:         \"energy_monitor_every\": 10,\n  59:         \"debug\": {",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 72,
          "context": "  69:     SHOW_PLOTS = True\n  70:     COMPARE_LEGACY = False  # set True to also run the old initialization for A/B\n  71:     \n  72: >>> # ----------------------- Helper: periodic gradient -------------------\n  73:     def periodic_dx(arr: np.ndarray, dx: float) -> np.ndarray:\n  74:         \"\"\"Central periodic spatial gradient.\"\"\"\n  75:         return (np.roll(arr, -1) - np.roll(arr, 1)) / (2.0 * dx)",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 73,
          "context": "  70:     COMPARE_LEGACY = False  # set True to also run the old initialization for A/B\n  71:     \n  72:     # ----------------------- Helper: periodic gradient -------------------\n  73: >>> def periodic_dx(arr: np.ndarray, dx: float) -> np.ndarray:\n  74:         \"\"\"Central periodic spatial gradient.\"\"\"\n  75:         return (np.roll(arr, -1) - np.roll(arr, 1)) / (2.0 * dx)\n  76:     ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 74,
          "context": "  71:     \n  72:     # ----------------------- Helper: periodic gradient -------------------\n  73:     def periodic_dx(arr: np.ndarray, dx: float) -> np.ndarray:\n  74: >>>     \"\"\"Central periodic spatial gradient.\"\"\"\n  75:         return (np.roll(arr, -1) - np.roll(arr, 1)) / (2.0 * dx)\n  76:     \n  77:     # ----------------------- Taylor-corrected E_prev ---------------------",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 83,
          "context": "  80:     dx = params[\"dx\"]\n  81:     cfl = c * dt / dx\n  82:     \n  83: >>> E_prev = E0 - c * dt * periodic_dx(E0, dx)  # ← key fix\n  84:     \n  85:     # -------------- Manual evolution loop (so we can pass E_prev) --------\n  86:     print(\"=== LFM Core Regression Test (v1.6) ===\")",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 95,
          "context": "  92:     dbg = params[\"debug\"]\n  93:     E0_energy = energy_total(E, E_prev, dt, dx, c, params[\"chi\"])\n  94:     \n  95: >>> print(\"\\nRunning solver with Taylor-corrected E_prev …\")\n  96:     drift_samples = []\n  97:     t0 = time.time()\n  98:     for n in range(STEPS):",
          "match": "solver"
        }
      ],
      "line_count": 173,
      "docstring": "Quick Regression Test — LFM Core Equation (v1.6, Taylor-corrected)\n------------------------------------------------------------------\nPurpose:\n  Verify numerical stability & energy behavior of lfm_equation.py after changes.\n  Uses a 1-D Gaussian pulse and a physically consistent E_prev via a\n  Taylor backstep: E_prev = E0 - c*dt*∂E/∂x  (periodic gradient).\n\nWhat's new vs v1.4:\n  • Taylor-corrected E_prev initialization (fixes artificial energy loss).\n  • Manual evolution loop to allow custom E_prev (uses lattice_step).\n  • Clear CFL printout and checkpoint trend line.\n  • Optional legacy comparison run (advance/E_prev=E0) for A/B verification.\n\nPASS if |drift| < 1e-3 and values are finite."
    },
    {
      "filepath": "lfm_equation.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "94c6f464864953c3",
      "file_size": 15053,
      "modified": "2025-11-02T20:02:10.866399",
      "git_info": {
        "first_commit": {
          "hash": "814c0878",
          "date": "2025-10-27 09:57:12 -0700",
          "message": "Overhaul tests, add core equation in its own file."
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 35,
          "context": "  32:     # ---------------------------------------------------------------------\n  33:     # Helpers\n  34:     # ---------------------------------------------------------------------\n  35: >>> def _xp_for(arr):\n  36:         if _HAS_CUPY and hasattr(arr, \"__cuda_array_interface__\"):\n  37:             return _cp\n  38:         return _np",
          "match": "def _xp_for(arr):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 41,
          "context": "  38:         return _np\n  39:     \n  40:     \n  41: >>> def _asarray(x, xp, dtype=_np.float64):\n  42:         if xp is _cp and _HAS_CUPY:\n  43:             return _cp.asarray(x, dtype=dtype)\n  44:         return _np.asarray(x, dtype=dtype)",
          "match": "def _asarray(x, xp, dtype=_np.float64):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 50,
          "context": "  47:     # ---------------------------------------------------------------------\n  48:     # Laplacian (now includes 3D)\n  49:     # ---------------------------------------------------------------------\n  50: >>> def laplacian(E, dx, order=2):\n  51:         xp = _xp_for(E)\n  52:         if E.ndim == 1:\n  53:             if order == 2:",
          "match": "def laplacian(E, dx, order=2):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 95,
          "context": "  92:     # ---------------------------------------------------------------------\n  93:     # Boundaries (1D–3D)\n  94:     # ---------------------------------------------------------------------\n  95: >>> def apply_boundary(E, mode=\"periodic\", absorb_width=0, absorb_factor=1.0):\n  96:         xp = _xp_for(E)\n  97:         if mode == \"periodic\":\n  98:             return",
          "match": "def apply_boundary(E, mode=\"periodic\", absorb_width=0, absorb_factor=1.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 142,
          "context": " 139:     # ---------------------------------------------------------------------\n 140:     # Energy (1D–3D)\n 141:     # ---------------------------------------------------------------------\n 142: >>> def energy_total(E, E_prev, dt, dx, c, chi):\n 143:         E_np, E_prev_np = _asarray(E, _np), _asarray(E_prev, _np)\n 144:         Et = (E_np - E_prev_np) / dt\n 145:         if E_np.ndim == 1:",
          "match": "def energy_total(E, E_prev, dt, dx, c, chi):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 165,
          "context": " 162:     # ---------------------------------------------------------------------\n 163:     # One-step update\n 164:     # ---------------------------------------------------------------------\n 165: >>> def lattice_step(E, E_prev, params):\n 166:         xp = _xp_for(E)\n 167:         dt, dx = float(params[\"dt\"]), float(params[\"dx\"])\n 168:         alpha, beta = float(params[\"alpha\"]), float(params[\"beta\"])",
          "match": "def lattice_step(E, E_prev, params):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 202,
          "context": " 199:     # ---------------------------------------------------------------------\n 200:     # Diagnostics utilities\n 201:     # ---------------------------------------------------------------------\n 202: >>> def _get_debug(params: Dict):\n 203:         dbg = params.get(\"debug\", {}) or {}\n 204:         return {\n 205:             \"enable\": bool(dbg.get(\"enable_diagnostics\", False)),",
          "match": "def _get_debug(params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 217,
          "context": " 214:         }\n 215:     \n 216:     \n 217: >>> def _checksum32_sampled(arr, stride=4096):\n 218:         a = _np.asarray(arr, dtype=_np.float64).ravel()\n 219:         if a.size == 0:\n 220:             return 0",
          "match": "def _checksum32_sampled(arr, stride=4096):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 231,
          "context": " 228:         return _np.uint32(h & _np.uint64(0xFFFFFFFF)).item()\n 229:     \n 230:     \n 231: >>> def _rms(x):\n 232:         x = _np.asarray(x, dtype=_np.float64)\n 233:         return float(_np.sqrt(_np.mean(x * x))) if x.size else 0.0\n 234:     ",
          "match": "def _rms(x):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 236,
          "context": " 233:         return float(_np.sqrt(_np.mean(x * x))) if x.size else 0.0\n 234:     \n 235:     \n 236: >>> def core_metrics(E, E_prev, params, E0, dbg):\n 237:         xp = _xp_for(E)\n 238:         E_np = _np.asarray(E.get() if _HAS_CUPY and hasattr(E, \"get\") else E, dtype=_np.float64)\n 239:         E_prev_np = _np.asarray(E_prev.get() if _HAS_CUPY and hasattr(E_prev, \"get\") else E_prev, dtype=_np.float64)",
          "match": "def core_metrics(E, E_prev, params, E0, dbg):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 303,
          "context": " 300:     # ---------------------------------------------------------------------\n 301:     # Advance\n 302:     # ---------------------------------------------------------------------\n 303: >>> def advance(E0, params, steps, save_every=0):\n 304:         xp = _xp_for(E0)\n 305:         E_prev = xp.array(E0, copy=True)\n 306:         E = xp.array(E0, copy=True)",
          "match": "def advance(E0, params, steps, save_every=0):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 25,
          "context": "  22:     import math, time, warnings\n  23:     import numpy as _np\n  24:     try:\n  25: >>>     import cupy as _cp  # type: ignore\n  26:         _HAS_CUPY = True\n  27:     except Exception:\n  28:         _cp = None",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 26,
          "context": "  23:     import numpy as _np\n  24:     try:\n  25:         import cupy as _cp  # type: ignore\n  26: >>>     _HAS_CUPY = True\n  27:     except Exception:\n  28:         _cp = None\n  29:         _HAS_CUPY = False",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 29,
          "context": "  26:         _HAS_CUPY = True\n  27:     except Exception:\n  28:         _cp = None\n  29: >>>     _HAS_CUPY = False\n  30:     \n  31:     \n  32:     # ---------------------------------------------------------------------",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 36,
          "context": "  33:     # Helpers\n  34:     # ---------------------------------------------------------------------\n  35:     def _xp_for(arr):\n  36: >>>     if _HAS_CUPY and hasattr(arr, \"__cuda_array_interface__\"):\n  37:             return _cp\n  38:         return _np\n  39:     ",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 36,
          "context": "  33:     # Helpers\n  34:     # ---------------------------------------------------------------------\n  35:     def _xp_for(arr):\n  36: >>>     if _HAS_CUPY and hasattr(arr, \"__cuda_array_interface__\"):\n  37:             return _cp\n  38:         return _np\n  39:     ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 42,
          "context": "  39:     \n  40:     \n  41:     def _asarray(x, xp, dtype=_np.float64):\n  42: >>>     if xp is _cp and _HAS_CUPY:\n  43:             return _cp.asarray(x, dtype=dtype)\n  44:         return _np.asarray(x, dtype=dtype)\n  45:     ",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 238,
          "context": " 235:     \n 236:     def core_metrics(E, E_prev, params, E0, dbg):\n 237:         xp = _xp_for(E)\n 238: >>>     E_np = _np.asarray(E.get() if _HAS_CUPY and hasattr(E, \"get\") else E, dtype=_np.float64)\n 239:         E_prev_np = _np.asarray(E_prev.get() if _HAS_CUPY and hasattr(E_prev, \"get\") else E_prev, dtype=_np.float64)\n 240:         dt, dx = float(params[\"dt\"]), float(params[\"dx\"])\n 241:         c = math.sqrt(float(params[\"alpha\"]) / float(params[\"beta\"]))",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 239,
          "context": " 236:     def core_metrics(E, E_prev, params, E0, dbg):\n 237:         xp = _xp_for(E)\n 238:         E_np = _np.asarray(E.get() if _HAS_CUPY and hasattr(E, \"get\") else E, dtype=_np.float64)\n 239: >>>     E_prev_np = _np.asarray(E_prev.get() if _HAS_CUPY and hasattr(E_prev, \"get\") else E_prev, dtype=_np.float64)\n 240:         dt, dx = float(params[\"dt\"]), float(params[\"dx\"])\n 241:         c = math.sqrt(float(params[\"alpha\"]) / float(params[\"beta\"]))\n 242:     ",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 245,
          "context": " 242:     \n 243:         chi_param = params.get(\"chi\", 0.0)\n 244:         try:\n 245: >>>         import cupy as _cp\n 246:             if hasattr(chi_param, \"__cuda_array_interface__\"):\n 247:                 chi_param = chi_param.get()\n 248:         except Exception:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 246,
          "context": " 243:         chi_param = params.get(\"chi\", 0.0)\n 244:         try:\n 245:             import cupy as _cp\n 246: >>>         if hasattr(chi_param, \"__cuda_array_interface__\"):\n 247:                 chi_param = chi_param.get()\n 248:         except Exception:\n 249:             pass",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 317,
          "context": " 314:         # --- FIXED χ HANDLING ---\n 315:         chi_param = params.get(\"chi\", 0.0)\n 316:         try:\n 317: >>>         import cupy as _cp\n 318:             if hasattr(chi_param, \"__cuda_array_interface__\"):\n 319:                 chi_param = chi_param.get()\n 320:         except Exception:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 318,
          "context": " 315:         chi_param = params.get(\"chi\", 0.0)\n 316:         try:\n 317:             import cupy as _cp\n 318: >>>         if hasattr(chi_param, \"__cuda_array_interface__\"):\n 319:                 chi_param = chi_param.get()\n 320:         except Exception:\n 321:             pass",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 323,
          "context": " 320:         except Exception:\n 321:             pass\n 322:         E0_val = energy_total(\n 323: >>>         _np.asarray(E.get() if _HAS_CUPY and hasattr(E, \"get\") else E),\n 324:             _np.asarray(E_prev.get() if _HAS_CUPY and hasattr(E_prev, \"get\") else E_prev),\n 325:             float(params[\"dt\"]), float(params[\"dx\"]), c, chi_param\n 326:         )",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 324,
          "context": " 321:             pass\n 322:         E0_val = energy_total(\n 323:             _np.asarray(E.get() if _HAS_CUPY and hasattr(E, \"get\") else E),\n 324: >>>         _np.asarray(E_prev.get() if _HAS_CUPY and hasattr(E_prev, \"get\") else E_prev),\n 325:             float(params[\"dt\"]), float(params[\"dx\"]), c, chi_param\n 326:         )\n 327:         # -------------------------",
          "match": "CUPY"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 182,
          "context": " 179:         E_prev = xp.asarray(E_prev, dtype=dtype)\n 180:     \n 181:         c = math.sqrt(alpha / beta)\n 182: >>>     cfl_limit = 1.0 / math.sqrt(E.ndim if E.ndim > 0 else 1)\n 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 183,
          "context": " 180:     \n 181:         c = math.sqrt(alpha / beta)\n 182:         cfl_limit = 1.0 / math.sqrt(E.ndim if E.ndim > 0 else 1)\n 183: >>>     cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186:             warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 184,
          "context": " 181:         c = math.sqrt(alpha / beta)\n 182:         cfl_limit = 1.0 / math.sqrt(E.ndim if E.ndim > 0 else 1)\n 183:         cfl_ratio = c * dt / dx\n 184: >>>     params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186:             warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 184,
          "context": " 181:         c = math.sqrt(alpha / beta)\n 182:         cfl_limit = 1.0 / math.sqrt(E.ndim if E.ndim > 0 else 1)\n 183:         cfl_ratio = c * dt / dx\n 184: >>>     params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186:             warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 185,
          "context": " 182:         cfl_limit = 1.0 / math.sqrt(E.ndim if E.ndim > 0 else 1)\n 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185: >>>     if cfl_ratio > cfl_limit:\n 186:             warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     \n 188:         chi_field = chi if xp.isscalar(chi) else _asarray(chi, xp, dtype)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 185,
          "context": " 182:         cfl_limit = 1.0 / math.sqrt(E.ndim if E.ndim > 0 else 1)\n 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185: >>>     if cfl_ratio > cfl_limit:\n 186:             warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     \n 188:         chi_field = chi if xp.isscalar(chi) else _asarray(chi, xp, dtype)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 186,
          "context": " 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186: >>>         warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     \n 188:         chi_field = chi if xp.isscalar(chi) else _asarray(chi, xp, dtype)\n 189:         lap = laplacian(E, dx, order)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 186,
          "context": " 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186: >>>         warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     \n 188:         chi_field = chi if xp.isscalar(chi) else _asarray(chi, xp, dtype)\n 189:         lap = laplacian(E, dx, order)",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 186,
          "context": " 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186: >>>         warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     \n 188:         chi_field = chi if xp.isscalar(chi) else _asarray(chi, xp, dtype)\n 189:         lap = laplacian(E, dx, order)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 186,
          "context": " 183:         cfl_ratio = c * dt / dx\n 184:         params[\"_cfl_ratio\"] = cfl_ratio\n 185:         if cfl_ratio > cfl_limit:\n 186: >>>         warnings.warn(f\"[CFL] Stability risk: c·dt/dx = {cfl_ratio:.3f} > {cfl_limit:.3f}\")\n 187:     \n 188:         chi_field = chi if xp.isscalar(chi) else _asarray(chi, xp, dtype)\n 189:         lap = laplacian(E, dx, order)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 253,
          "context": " 250:         en = energy_total(E_np, E_prev_np, dt, dx, c, chi_param)\n 251:     \n 252:         drift = ((en - E0) / (abs(E0) + 1e-30)) if E0 is not None else 0.0\n 253: >>>     cfl_ratio = c * dt / dx\n 254:         cfl_limit = 1.0 / math.sqrt(max(1, E_np.ndim))\n 255:         max_abs = float(_np.max(_np.abs(E_np))) if E_np.size else 0.0\n 256:         has_bad = not _np.all(_np.isfinite(E_np)) if dbg[\"check_nan\"] else False",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 254,
          "context": " 251:     \n 252:         drift = ((en - E0) / (abs(E0) + 1e-30)) if E0 is not None else 0.0\n 253:         cfl_ratio = c * dt / dx\n 254: >>>     cfl_limit = 1.0 / math.sqrt(max(1, E_np.ndim))\n 255:         max_abs = float(_np.max(_np.abs(E_np))) if E_np.size else 0.0\n 256:         has_bad = not _np.all(_np.isfinite(E_np)) if dbg[\"check_nan\"] else False\n 257:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 290,
          "context": " 287:         return {\n 288:             \"energy\": float(en),\n 289:             \"drift\": float(drift),\n 290: >>>         \"cfl_ratio\": float(cfl_ratio),\n 291:             \"cfl_limit\": float(cfl_limit),\n 292:             \"max_abs\": float(max_abs),\n 293:             \"edge_ratio\": float(edge_ratio),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 290,
          "context": " 287:         return {\n 288:             \"energy\": float(en),\n 289:             \"drift\": float(drift),\n 290: >>>         \"cfl_ratio\": float(cfl_ratio),\n 291:             \"cfl_limit\": float(cfl_limit),\n 292:             \"max_abs\": float(max_abs),\n 293:             \"edge_ratio\": float(edge_ratio),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 291,
          "context": " 288:             \"energy\": float(en),\n 289:             \"drift\": float(drift),\n 290:             \"cfl_ratio\": float(cfl_ratio),\n 291: >>>         \"cfl_limit\": float(cfl_limit),\n 292:             \"max_abs\": float(max_abs),\n 293:             \"edge_ratio\": float(edge_ratio),\n 294:             \"grad_ratio\": float(grad_ratio),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 291,
          "context": " 288:             \"energy\": float(en),\n 289:             \"drift\": float(drift),\n 290:             \"cfl_ratio\": float(cfl_ratio),\n 291: >>>         \"cfl_limit\": float(cfl_limit),\n 292:             \"max_abs\": float(max_abs),\n 293:             \"edge_ratio\": float(edge_ratio),\n 294:             \"grad_ratio\": float(grad_ratio),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 331,
          "context": " 328:     \n 329:         if diagnostics_enabled:\n 330:             with open(dbg[\"diagnostics_path\"], \"w\", encoding=\"utf-8\") as f:\n 331: >>>             f.write(\"step,energy,drift,cfl_ratio,cfl_limit,max_abs,edge_ratio,grad_ratio,has_bad,checksum\\\\n\")\n 332:     \n 333:         series = [xp.array(E0, copy=True)] if save_every > 0 else None\n 334:         monitor_every = int(params.get(\"energy_monitor_every\", 0)) or (100 if dbg[\"enable\"] else 0)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 331,
          "context": " 328:     \n 329:         if diagnostics_enabled:\n 330:             with open(dbg[\"diagnostics_path\"], \"w\", encoding=\"utf-8\") as f:\n 331: >>>             f.write(\"step,energy,drift,cfl_ratio,cfl_limit,max_abs,edge_ratio,grad_ratio,has_bad,checksum\\\\n\")\n 332:     \n 333:         series = [xp.array(E0, copy=True)] if save_every > 0 else None\n 334:         monitor_every = int(params.get(\"energy_monitor_every\", 0)) or (100 if dbg[\"enable\"] else 0)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 348,
          "context": " 345:             if do_diag:\n 346:                 met = core_metrics(E, E_prev, params, E0_val, dbg)\n 347:                 with open(dbg[\"diagnostics_path\"], \"a\", encoding=\"utf-8\") as f:\n 348: >>>                 f.write(f\"{n+1},{met['energy']:.10e},{met['drift']:.6e},{met['cfl_ratio']:.6f},{met['cfl_limit']:.6f},\"\n 349:                             f\"{met['max_abs']:.6e},{met['edge_ratio']:.6f},{met['grad_ratio']:.6f},{int(met['has_bad'])},{met['checksum']}\\\\n\")\n 350:                 if not quiet_run:\n 351:                     if abs(met[\"drift\"]) > dbg[\"energy_tol\"]:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 348,
          "context": " 345:             if do_diag:\n 346:                 met = core_metrics(E, E_prev, params, E0_val, dbg)\n 347:                 with open(dbg[\"diagnostics_path\"], \"a\", encoding=\"utf-8\") as f:\n 348: >>>                 f.write(f\"{n+1},{met['energy']:.10e},{met['drift']:.6e},{met['cfl_ratio']:.6f},{met['cfl_limit']:.6f},\"\n 349:                             f\"{met['max_abs']:.6e},{met['edge_ratio']:.6f},{met['grad_ratio']:.6f},{int(met['has_bad'])},{met['checksum']}\\\\n\")\n 350:                 if not quiet_run:\n 351:                     if abs(met[\"drift\"]) > dbg[\"energy_tol\"]:",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 95,
          "context": "  92:     # ---------------------------------------------------------------------\n  93:     # Boundaries (1D–3D)\n  94:     # ---------------------------------------------------------------------\n  95: >>> def apply_boundary(E, mode=\"periodic\", absorb_width=0, absorb_factor=1.0):\n  96:         xp = _xp_for(E)\n  97:         if mode == \"periodic\":\n  98:             return",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 95,
          "context": "  92:     # ---------------------------------------------------------------------\n  93:     # Boundaries (1D–3D)\n  94:     # ---------------------------------------------------------------------\n  95: >>> def apply_boundary(E, mode=\"periodic\", absorb_width=0, absorb_factor=1.0):\n  96:         xp = _xp_for(E)\n  97:         if mode == \"periodic\":\n  98:             return",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 97,
          "context": "  94:     # ---------------------------------------------------------------------\n  95:     def apply_boundary(E, mode=\"periodic\", absorb_width=0, absorb_factor=1.0):\n  96:         xp = _xp_for(E)\n  97: >>>     if mode == \"periodic\":\n  98:             return\n  99:         if E.ndim == 1:\n 100:             if mode == \"reflective\":",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 102,
          "context": "  99:         if E.ndim == 1:\n 100:             if mode == \"reflective\":\n 101:                 E[0] = E[1]; E[-1] = E[-2]\n 102: >>>         elif mode == \"absorbing\":\n 103:                 w = max(1, int(absorb_width or 1))\n 104:                 if absorb_factor >= 1.0:\n 105:                     E[:w] = 0; E[-w:] = 0",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 112,
          "context": " 109:             if mode == \"reflective\":\n 110:                 E[0, :] = E[1, :]; E[-1, :] = E[-2, :]\n 111:                 E[:, 0] = E[:, 1]; E[:, -1] = E[:, -2]\n 112: >>>         elif mode == \"absorbing\":\n 113:                 w = max(1, int(absorb_width or 1))\n 114:                 if absorb_factor >= 1.0:\n 115:                     E[:w, :] = 0; E[-w:, :] = 0; E[:, :w] = 0; E[:, -w:] = 0",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 124,
          "context": " 121:                 E[0, :, :] = E[1, :, :]; E[-1, :, :] = E[-2, :, :]\n 122:                 E[:, 0, :] = E[:, 1, :]; E[:, -1, :] = E[:, -2, :]\n 123:                 E[:, :, 0] = E[:, :, 1]; E[:, :, -1] = E[:, :, -2]\n 124: >>>         elif mode == \"absorbing\":\n 125:                 w = max(1, int(absorb_width or 1))\n 126:                 slices = [slice(None)] * 3\n 127:                 for axis in range(3):",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 171,
          "context": " 168:         alpha, beta = float(params[\"alpha\"]), float(params[\"beta\"])\n 169:         chi = params.get(\"chi\", 0.0)\n 170:         gamma = float(params.get(\"gamma_damp\", 0.0))\n 171: >>>     boundary = params.get(\"boundary\", \"periodic\")\n 172:         order = int(params.get(\"stencil_order\", 2))\n 173:         absorb_w = int(params.get(\"absorb_width\", 1))\n 174:         absorb_f = float(params.get(\"absorb_factor\", 1.0))",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 171,
          "context": " 168:         alpha, beta = float(params[\"alpha\"]), float(params[\"beta\"])\n 169:         chi = params.get(\"chi\", 0.0)\n 170:         gamma = float(params.get(\"gamma_damp\", 0.0))\n 171: >>>     boundary = params.get(\"boundary\", \"periodic\")\n 172:         order = int(params.get(\"stencil_order\", 2))\n 173:         absorb_w = int(params.get(\"absorb_width\", 1))\n 174:         absorb_f = float(params.get(\"absorb_factor\", 1.0))",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 171,
          "context": " 168:         alpha, beta = float(params[\"alpha\"]), float(params[\"beta\"])\n 169:         chi = params.get(\"chi\", 0.0)\n 170:         gamma = float(params.get(\"gamma_damp\", 0.0))\n 171: >>>     boundary = params.get(\"boundary\", \"periodic\")\n 172:         order = int(params.get(\"stencil_order\", 2))\n 173:         absorb_w = int(params.get(\"absorb_width\", 1))\n 174:         absorb_f = float(params.get(\"absorb_factor\", 1.0))",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 195,
          "context": " 192:         term_mass = - (chi_field * chi_field) * E\n 193:         E_next = (2 - gamma) * E - (1 - gamma) * E_prev + (dt * dt) * (term_wave + term_mass)\n 194:     \n 195: >>>     apply_boundary(E_next, mode=boundary, absorb_width=absorb_w, absorb_factor=absorb_f)\n 196:         return E_next\n 197:     \n 198:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 195,
          "context": " 192:         term_mass = - (chi_field * chi_field) * E\n 193:         E_next = (2 - gamma) * E - (1 - gamma) * E_prev + (dt * dt) * (term_wave + term_mass)\n 194:     \n 195: >>>     apply_boundary(E_next, mode=boundary, absorb_width=absorb_w, absorb_factor=absorb_f)\n 196:         return E_next\n 197:     \n 198:     ",
          "match": "boundary"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 17,
          "context": "  14:     Changes in v1.5:\n  15:       • Fix: energy_total() and advance() now accept full χ(x) fields, not only scalars.\n  16:       • Fix: core_metrics() no longer forces χ to float — supports spatial χ arrays.\n  17: >>>   • No physics or numerical updates — equation and solver are unchanged.\n  18:     \"\"\"\n  19:     \n  20:     from __future__ import annotations",
          "match": "solver"
        }
      ],
      "line_count": 368,
      "docstring": "lfm_equation.py — Canonical LFM lattice update (v1.5 — 3D Extended, χ-field safe)\n\nImplements the canonical continuum equation:\n    ∂²E/∂t² = c² ∇²E − χ(x,t)² E,   with   c² = α/β\n\nChanges in v1.5:\n  • Fix: energy_total() and advance() now accept full χ(x) fields, not only scalars.\n  • Fix: core_metrics() no longer forces χ to float — supports spatial χ arrays.\n  • No physics or numerical updates — equation and solver are unchanged."
    },
    {
      "filepath": "run_unif00_core_principle.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "26e04115679a1daf",
      "file_size": 39109,
      "modified": "2025-11-02T20:02:10.909098",
      "git_info": {
        "first_commit": {
          "hash": "512cc56b",
          "date": "2025-10-28 18:51:25 -0700",
          "message": "Add unified quick test, it passed!"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:     from numeric_integrity import NumericIntegrityMixin\n  56:     from lfm_test_metrics import TestMetrics\n  57:     \n  58: >>> class UnificationTest(NumericIntegrityMixin):\n  59:         \"\"\"\n  60:         Core unification principle test harness.\n  61:         \"\"\"",
          "match": "class UnificationTest(NumericIntegrityMixin):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 62,
          "context": "  59:         \"\"\"\n  60:         Core unification principle test harness.\n  61:         \"\"\"\n  62: >>>     def __init__(self, cfg: Dict, outdir: Path):\n  63:             self.cfg = cfg\n  64:             self.params = cfg[\"parameters\"]\n  65:             self.run_settings = cfg[\"run_settings\"]",
          "match": "def __init__(self, cfg:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:             log(\"=== UNIF-00: Core Unification Principle Test ===\", \"INFO\")\n  78:             log(f\"Backend: {'GPU (CuPy)' if self.on_gpu else 'CPU (NumPy)'}\", \"INFO\")\n  79:     \n  80: >>>     def build_dual_well_chi_field(self, N: int, dx: float) -> np.ndarray:\n  81:             \"\"\"\n  82:             Create χ-field with TWO Gaussian wells separated along x-axis.\n  83:             ",
          "match": "def build_dual_well_chi_field(self, N:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 120,
          "context": " 117:             \n 118:             return chi_field.astype(self.dtype)\n 119:     \n 120: >>>     def initialize_dual_packets(self, N: int) -> Tuple[np.ndarray, np.ndarray]:\n 121:             \"\"\"\n 122:             Place Gaussian energy packets in each well.\n 123:             Packet A at well A, Packet B at well B.",
          "match": "def initialize_dual_packets(self, N:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 138,
          "context": " 135:             \n 136:             ax = xp.arange(N, dtype=xp.float64)\n 137:             \n 138: >>>         def gaussian_3d(center):\n 139:                 cx, cy, cz = center\n 140:                 gx = xp.exp(-((ax - cx)**2) / (2.0 * width**2))\n 141:                 gy = xp.exp(-((ax - cy)**2) / (2.0 * width**2))",
          "match": "def gaussian_3d(center):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 155,
          "context": " 152:             \n 153:             return E0, Eprev0\n 154:     \n 155: >>>     def bound_state_frequency(self, chi_peak: float, sigma_cells: float, dx: float) -> float:\n 156:             \"\"\"\n 157:             Calculate ground state frequency for a 3D Gaussian potential well.\n 158:             ",
          "match": "def bound_state_frequency(self, chi_peak:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 223,
          "context": " 220:             well_radius = int(self.params.get(\"chi_well_width\", 12.0) * 2)  # 2σ\n 221:     \n 222:             # Create masks for well regions\n 223: >>>         def sphere_mask(center, radius):\n 224:                 cx, cy, cz = center\n 225:                 ix = xp.arange(N)\n 226:                 dist2 = ((ix[:, None, None] - cx)**2 +",
          "match": "def sphere_mask(center, radius):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 237,
          "context": " 234:             mask_union = mask_A | mask_B\n 235:     \n 236:             # Measure frequencies via FFT\n 237: >>>         def measure_freq(series, dt_sample):\n 238:                 x = np.array(series) - np.mean(series)\n 239:                 if len(x) < 16:\n 240:                     return 0.0",
          "match": "def measure_freq(series, dt_sample):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 261,
          "context": " 258:             omega_B_theory = self.bound_state_frequency(chi_B, sigma_cells, dx)\n 259:     \n 260:             # Energy localization: compute energy density (consistent with energy_total)\n 261: >>>         def energy_density_np(E_np, Eprev_np):\n 262:                 Et = (E_np - Eprev_np) / dt\n 263:                 gx = (np.roll(E_np, -1, 2) - np.roll(E_np, 1, 2)) / (2 * dx)\n 264:                 gy = (np.roll(E_np, -1, 1) - np.roll(E_np, 1, 1)) / (2 * dx)",
          "match": "def energy_density_np(E_np, Eprev_np):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 300,
          "context": " 297:             energy_drift = abs(energy_total_end - energy_total_start) / max(energy_total_start, 1e-30)\n 298:     \n 299:             # EM-like propagation: spectral phase method between two plane signals\n 300: >>>         def phase_velocity(series1, series2, omega_ref, dt_sample, dr):\n 301:                 \"\"\"\n 302:                 Robust phase/group delay estimate:\n 303:                 1) Cross-spectrum C = S2 * conj(S1)",
          "match": "def phase_velocity(series1, series2, omega_ref, dt_sample, dr):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 395,
          "context": " 392:     \n 393:             # Fallback: envelope time-of-flight using moving RMS threshold\n 394:             if not pass_em_speed:\n 395: >>>             def moving_rms(x, w):\n 396:                     x = np.asarray(x, dtype=float)\n 397:                     if x.size < w:\n 398:                         return x",
          "match": "def moving_rms(x, w):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 423,
          "context": " 420:                             pass_em_speed = em_speed_rel_err < 0.10  # 10% (was 15%)\n 421:     \n 422:             # Interaction dynamics: normalized amplitude of energy exchange (diagnostic only)\n 423: >>>         def norm_amp(series):\n 424:                 s = np.array(series, dtype=float)\n 425:                 m = np.mean(s) if s.size else 0.0\n 426:                 if m <= 0:",
          "match": "def norm_amp(series):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 483,
          "context": " 480:     \n 481:             return results\n 482:     \n 483: >>>     def run(self) -> Dict:\n 484:             \"\"\"Execute the core unification test.\"\"\"\n 485:             xp = self.xp\n 486:             N = int(self.params.get(\"grid_points\", 128))",
          "match": "def run(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 541,
          "context": " 538:             R = xp.sqrt((X - cx)**2 + (Y - cy)**2 + (Z - cz)**2)\n 539:     \n 540:             well_radius = int(self.params.get(\"chi_well_width\", 12.0) * 2)\n 541: >>>         def sphere_mask_xp(center, radius):\n 542:                 cx0, cy0, cz0 = center\n 543:                 return ((X - cx0)**2 + (Y - cy0)**2 + (Z - cz0)**2) <= (radius**2)\n 544:     ",
          "match": "def sphere_mask_xp(center, radius):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 773,
          "context": " 770:                     for ti, s1, s2 in zip(t, shell1_series, shell2_series):\n 771:                         f.write(f\"{ti:.8f},{s1:.10e},{s2:.10e}\\n\")\n 772:                 # Spectra\n 773: >>>             def _spec(x):\n 774:                     x0 = _np.asarray(x, dtype=float)\n 775:                     x0 = x0 - _np.mean(x0)\n 776:                     if x0.size < 8:",
          "match": "def _spec(x):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 795,
          "context": " 792:             return analysis\n 793:     \n 794:     \n 795: >>> def load_config() -> Dict:\n 796:         \"\"\"Load UNIF-00 config or return defaults.\"\"\"\n 797:         config_path = Path(__file__).parent / \"config\" / \"config_unif00_core.json\"\n 798:         ",
          "match": "def load_config() -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 826,
          "context": " 823:         }\n 824:     \n 825:     \n 826: >>> def main():\n 827:         cfg = load_config()\n 828:         outdir = Path(__file__).parent / \"results\" / \"Unification\" / \"UNIF-00\"\n 829:         ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:             self.outdir = outdir\n  67:             self.outdir.mkdir(parents=True, exist_ok=True)\n  68:             \n  69: >>>         self.xp, self.on_gpu = pick_backend(self.run_settings.get(\"use_gpu\", False))\n  70:             self.quick = bool(self.run_settings.get(\"quick_mode\", False))\n  71:             self.dtype = self.xp.float32 if self.quick else self.xp.float64\n  72:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:             self.outdir = outdir\n  67:             self.outdir.mkdir(parents=True, exist_ok=True)\n  68:             \n  69: >>>         self.xp, self.on_gpu = pick_backend(self.run_settings.get(\"use_gpu\", False))\n  70:             self.quick = bool(self.run_settings.get(\"quick_mode\", False))\n  71:             self.dtype = self.xp.float32 if self.quick else self.xp.float64\n  72:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 78,
          "context": "  75:             set_logger(self.logger)\n  76:             \n  77:             log(\"=== UNIF-00: Core Unification Principle Test ===\", \"INFO\")\n  78: >>>         log(f\"Backend: {'GPU (CuPy)' if self.on_gpu else 'CPU (NumPy)'}\", \"INFO\")\n  79:     \n  80:         def build_dual_well_chi_field(self, N: int, dx: float) -> np.ndarray:\n  81:             \"\"\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 78,
          "context": "  75:             set_logger(self.logger)\n  76:             \n  77:             log(\"=== UNIF-00: Core Unification Principle Test ===\", \"INFO\")\n  78: >>>         log(f\"Backend: {'GPU (CuPy)' if self.on_gpu else 'CPU (NumPy)'}\", \"INFO\")\n  79:     \n  80:         def build_dual_well_chi_field(self, N: int, dx: float) -> np.ndarray:\n  81:             \"\"\"",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 78,
          "context": "  75:             set_logger(self.logger)\n  76:             \n  77:             log(\"=== UNIF-00: Core Unification Principle Test ===\", \"INFO\")\n  78: >>>         log(f\"Backend: {'GPU (CuPy)' if self.on_gpu else 'CPU (NumPy)'}\", \"INFO\")\n  79:     \n  80:         def build_dual_well_chi_field(self, N: int, dx: float) -> np.ndarray:\n  81:             \"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 807,
          "context": " 804:         log(\"Using default UNIF-00 config (no config file found)\", \"INFO\")\n 805:         return {\n 806:             \"run_settings\": {\n 807: >>>             \"use_gpu\": False,\n 808:                 \"quick_mode\": False,\n 809:             },\n 810:             \"parameters\": {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 843,
          "context": " 840:             \"runtime_sec\": results.get(\"runtime_sec\", 0.0),\n 841:             \"peak_cpu_percent\": 0.0,\n 842:             \"peak_memory_mb\": 0.0,\n 843: >>>         \"peak_gpu_memory_mb\": 0.0,\n 844:             \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 845:         }\n 846:         test_metrics.record_run(\"UNIF-00\", metrics_data)",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 53,
          "context": "  50:     from lfm_logger import LFMLogger\n  51:     from lfm_results import save_summary, update_master_test_status\n  52:     from lfm_equation import advance, lattice_step, energy_total\n  53: >>> from lfm_parallel import run_lattice\n  54:     from energy_monitor import EnergyMonitor\n  55:     from numeric_integrity import NumericIntegrityMixin\n  56:     from lfm_test_metrics import TestMetrics",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 494,
          "context": " 491:             steps = int(self.params.get(\"steps\", 2000))\n 492:             \n 493:             c = math.sqrt(alpha / beta)\n 494: >>>         self.check_cfl(c, dt, dx, ndim=3)\n 495:             \n 496:             log(f\"Grid: {N}³, dx={dx:.4f}, dt={dt:.6f}, steps={steps}\", \"INFO\")\n 497:             log(f\"Wave speed c={c:.4f}, CFL={(c*dt/dx):.4f}\", \"INFO\")",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 497,
          "context": " 494:             self.check_cfl(c, dt, dx, ndim=3)\n 495:             \n 496:             log(f\"Grid: {N}³, dx={dx:.4f}, dt={dt:.6f}, steps={steps}\", \"INFO\")\n 497: >>>         log(f\"Wave speed c={c:.4f}, CFL={(c*dt/dx):.4f}\", \"INFO\")\n 498:             \n 499:             # Build chi-field with dual wells\n 500:             chi_field = self.build_dual_well_chi_field(N, dx)",
          "match": "CFL"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 515,
          "context": " 512:                 \"alpha\": alpha,\n 513:                 \"beta\": beta,\n 514:                 \"chi\": to_numpy(chi_field) if xp is np else chi_field,\n 515: >>>             \"boundary\": \"periodic\",\n 516:                 \"precision\": \"float64\",\n 517:                 \"debug\": {\"quiet_run\": True},\n 518:             }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 515,
          "context": " 512:                 \"alpha\": alpha,\n 513:                 \"beta\": beta,\n 514:                 \"chi\": to_numpy(chi_field) if xp is np else chi_field,\n 515: >>>             \"boundary\": \"periodic\",\n 516:                 \"precision\": \"float64\",\n 517:                 \"debug\": {\"quiet_run\": True},\n 518:             }",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 676,
          "context": " 673:                     \"alpha\": alpha,\n 674:                     \"beta\": beta,\n 675:                     \"chi\": chi_cal,\n 676: >>>                 \"boundary\": \"periodic\",\n 677:                     \"precision\": \"float64\",\n 678:                     \"debug\": {\"quiet_run\": True},\n 679:                 }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 676,
          "context": " 673:                     \"alpha\": alpha,\n 674:                     \"beta\": beta,\n 675:                     \"chi\": chi_cal,\n 676: >>>                 \"boundary\": \"periodic\",\n 677:                     \"precision\": \"float64\",\n 678:                     \"debug\": {\"quiet_run\": True},\n 679:                 }",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 281,
          "context": " 278:     \n 279:             energy_well_A_start = float(np.sum(dens_start[to_numpy(mask_A)]) * (dx**3))\n 280:             energy_well_B_start = float(np.sum(dens_start[to_numpy(mask_B)]) * (dx**3))\n 281: >>>         # Use canonical scalar energy for totals to match solver diagnostics\n 282:             chi_np = to_numpy(chi_field)\n 283:             energy_total_start = energy_total(E_start_np, Eprev_start_np, dt, dx, c, chi_np)\n 284:     ",
          "match": "solver"
        }
      ],
      "line_count": 852,
      "docstring": "LFM UNIF-00 — Core Unification Principle Test\n==============================================\nPurpose:\n    THE definitive test for LFM as a unified theory. Demonstrates that a single\n    wave equation with spatially-varying propagation speed (via χ-field) can \n    simultaneously reproduce:\n    \n    1. EM-like propagation (high-frequency waves in flat regions)\n    2. Mass-like localization (energy trapped in χ-wells)\n    3. Gravity-like effects (frequency shift in χ-gradients)\n    4. Interaction dynamics (bound energy structures influencing each other)\n\nTest Design:\n    - 3D domain with TWO χ-wells separated by distance D\n    - Each well initialized with localized energy packet\n    - Measure:\n        * Local oscillation frequency in each well (mass-analogue)\n        * Frequency of radiation escaping wells (EM-analogue)\n        * Frequency shift between wells if offset χ-depths (gravity-analogue)\n        * Energy exchange / orbital motion between wells (interaction)\n\nPass Criteria:\n    1. Energy remains localized in wells (< 1% escape over test duration)\n    2. Well frequencies match bound state theory (< 6% error)\n       Theory: For Gaussian well, ω ≈ χ × correction_factor(well_depth, width)\n       Note: 6% tolerance accounts for measurement noise in weakly-bound states\n    3. Escaped radiation propagates at c (< 10% error, measured via calibration)\n    4. Gravity test: frequency ratio ω_B/ω_A matches theory (< 12% error)\n       Note: 12% accounts for compounding of individual frequency errors\n    5. Energy conservation maintained (drift < 0.5%, practical for long runs)\n\nThis is the \"proof-of-concept\" that if this works, LFM has the bones of a TOE."
    },
    {
      "filepath": "test_lfm_equation_multidim.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "cb801e8893c0c418",
      "file_size": 6902,
      "modified": "2025-11-02T20:02:10.915576",
      "git_info": {
        "first_commit": {
          "hash": "ebbe74b4",
          "date": "2025-10-27 14:59:28 -0700",
          "message": "update tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:             float(params.get(\"absorb_factor\",1.0))==1.0\n  64:         )\n  65:     \n  66: >>> class EquationHarness(NumericIntegrityMixin):\n  67:         def __init__(self):\n  68:             self.logger = LFMLogger(\"logs/test_multidim\")\n  69:             self.diag_dir = Path(\"diagnostics\")",
          "match": "class EquationHarness(NumericIntegrityMixin):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 45,
          "context": "  42:     TOL_GAP   = 5e-4\n  43:     ENERGY_LOCK_FOR_PARITY = True   # guarded; auto-disables when not conservative\n  44:     \n  45: >>> def gaussian_nd(shape, center=None, sigma=1.0):\n  46:         axes = tuple(np.arange(n, dtype=float) for n in shape)\n  47:         grids = np.meshgrid(*axes, indexing=\"ij\")\n  48:         if center is None:",
          "match": "def gaussian_nd(shape, center=None, sigma=1.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:         r2 = sum(((g - c) * DX) ** 2 for g, c in zip(grids, center))\n  51:         return np.exp(-r2 / (2 * sigma**2))\n  52:     \n  53: >>> def taylor_prev(E0, dt, dx, c, chi, order=2):\n  54:         L = laplacian(E0, dx, order=order)\n  55:         return E0 - 0.5*(dt*dt)*((c*c)*L - (chi*chi)*E0)\n  56:     ",
          "match": "def taylor_prev(E0, dt, dx, c, chi, order=2):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:         L = laplacian(E0, dx, order=order)\n  55:         return E0 - 0.5*(dt*dt)*((c*c)*L - (chi*chi)*E0)\n  56:     \n  57: >>> def _is_conservative(params: dict) -> bool:\n  58:         return (\n  59:             params.get(\"gamma_damp\",0.0)==0.0 and\n  60:             params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and",
          "match": "def _is_conservative(params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:         )\n  65:     \n  66:     class EquationHarness(NumericIntegrityMixin):\n  67: >>>     def __init__(self):\n  68:             self.logger = LFMLogger(\"logs/test_multidim\")\n  69:             self.diag_dir = Path(\"diagnostics\")\n  70:             self.diag_dir.mkdir(exist_ok=True)",
          "match": "def __init__(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 72,
          "context": "  69:             self.diag_dir = Path(\"diagnostics\")\n  70:             self.diag_dir.mkdir(exist_ok=True)\n  71:     \n  72: >>>     def run_dim(self, dim: int):\n  73:             assert dim in (1,2,3)\n  74:             shape = {1:(200,), 2:(128,128), 3:(64,64,64)}[dim]\n  75:             E0 = gaussian_nd(shape, sigma=1.0)",
          "match": "def run_dim(self, dim:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 164,
          "context": " 161:                                   \"gap\":backend_gap,\"verdict\":verdict_str})\n 162:             return verdict\n 163:     \n 164: >>> def main():\n 165:         print(\"=== LFM Multi-Dimensional Regression (diagnostic parity + monitor) ===\")\n 166:         h = EquationHarness()\n 167:         all_ok = all(h.run_dim(d) for d in (1,2,3))",
          "match": "def main():"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     LFM Multi-Dimensional Regression — v1.3.7-monitor-integrated\n  10:     - Uses compensated energy_total.\n  11: >>> - Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n  12:     - Writes per-step parity CSV with serial vs parallel drift.\n  13:     - Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks.\n  14:     \"\"\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 12,
          "context": "   9:     LFM Multi-Dimensional Regression — v1.3.7-monitor-integrated\n  10:     - Uses compensated energy_total.\n  11:     - Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n  12: >>> - Writes per-step parity CSV with serial vs parallel drift.\n  13:     - Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks.\n  14:     \"\"\"\n  15:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 13,
          "context": "  10:     - Uses compensated energy_total.\n  11:     - Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n  12:     - Writes per-step parity CSV with serial vs parallel drift.\n  13: >>> - Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks.\n  14:     \"\"\"\n  15:     \n  16:     import pytest",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 23,
          "context": "  20:     from pathlib import Path\n  21:     from lfm_equation import laplacian, lattice_step\n  22:     from lfm_diagnostics import energy_total\n  23: >>> from lfm_parallel import run_lattice\n  24:     from lfm_console import log\n  25:     from lfm_logger import LFMLogger\n  26:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 93,
          "context": "  90:                 threads=THREADS,\n  91:                 energy_lock=ENERGY_LOCK_FOR_PARITY,\n  92:     \n  93: >>>             # Enable monitoring inside the parallel runner\n  94:                 enable_monitor=True,\n  95:                 monitor_outdir=str(self.diag_dir),\n  96:                 monitor_label=f\"eq_parallel_{dim}D\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 96,
          "context": "  93:                 # Enable monitoring inside the parallel runner\n  94:                 enable_monitor=True,\n  95:                 monitor_outdir=str(self.diag_dir),\n  96: >>>             monitor_label=f\"eq_parallel_{dim}D\"\n  97:             )\n  98:     \n  99:             drift_csv = self.diag_dir / f\"parity_{dim}D.csv\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 133,
          "context": " 130:             drift_serial = drift_serial_series[-1][1]\n 131:             self.logger.log_json({\"event\":\"serial_done\",\"dim\":dim,\"drift\":drift_serial,\"time_s\":serial_time})\n 132:     \n 133: >>>         # --- Parallel (runner already monitors internally) ---\n 134:             log(f\"Running {dim}D parallel lattice...\", \"INFO\")\n 135:             params[\"_energy_log\"], params[\"_energy_drift_log\"] = [], []\n 136:             _ = run_lattice(np.array(E0, copy=True), params,",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 134,
          "context": " 131:             self.logger.log_json({\"event\":\"serial_done\",\"dim\":dim,\"drift\":drift_serial,\"time_s\":serial_time})\n 132:     \n 133:             # --- Parallel (runner already monitors internally) ---\n 134: >>>         log(f\"Running {dim}D parallel lattice...\", \"INFO\")\n 135:             params[\"_energy_log\"], params[\"_energy_drift_log\"] = [], []\n 136:             _ = run_lattice(np.array(E0, copy=True), params,\n 137:                             steps=STEPS,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 142,
          "context": " 139:                             E_prev=np.array(Eprev, copy=True))\n 140:     \n 141:             dlog = params.get(\"_energy_drift_log\", [])\n 142: >>>         drift_parallel = float(dlog[-1]) if dlog else float(\"nan\")\n 143:     \n 144:             # Write serial/parallel parity CSV\n 145:             with open(drift_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 144,
          "context": " 141:             dlog = params.get(\"_energy_drift_log\", [])\n 142:             drift_parallel = float(dlog[-1]) if dlog else float(\"nan\")\n 143:     \n 144: >>>         # Write serial/parallel parity CSV\n 145:             with open(drift_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n 146:                 w = csv.writer(f); w.writerow([\"step\",\"drift_serial\",\"drift_parallel\"])\n 147:                 for i,(s,ds) in enumerate(drift_serial_series):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 146,
          "context": " 143:     \n 144:             # Write serial/parallel parity CSV\n 145:             with open(drift_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n 146: >>>             w = csv.writer(f); w.writerow([\"step\",\"drift_serial\",\"drift_parallel\"])\n 147:                 for i,(s,ds) in enumerate(drift_serial_series):\n 148:                     dp = dlog[i] if i < len(dlog) else \"\"\n 149:                     w.writerow([s, ds, dp])",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 151,
          "context": " 148:                     dp = dlog[i] if i < len(dlog) else \"\"\n 149:                     w.writerow([s, ds, dp])\n 150:     \n 151: >>>         backend_gap = abs(drift_serial - drift_parallel)\n 152:             verdict = (abs(drift_serial) <= TOL_DRIFT and\n 153:                        abs(drift_parallel) <= TOL_DRIFT and\n 154:                        backend_gap <= TOL_GAP)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 153,
          "context": " 150:     \n 151:             backend_gap = abs(drift_serial - drift_parallel)\n 152:             verdict = (abs(drift_serial) <= TOL_DRIFT and\n 153: >>>                    abs(drift_parallel) <= TOL_DRIFT and\n 154:                        backend_gap <= TOL_GAP)\n 155:             verdict_str = \"PASS ✅\" if verdict else \"FAIL ❌\"\n 156:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 158,
          "context": " 155:             verdict_str = \"PASS ✅\" if verdict else \"FAIL ❌\"\n 156:     \n 157:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 158: >>>             f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 159:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 160:                                   \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 161:                                   \"gap\":backend_gap,\"verdict\":verdict_str})",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 158,
          "context": " 155:             verdict_str = \"PASS ✅\" if verdict else \"FAIL ❌\"\n 156:     \n 157:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 158: >>>             f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 159:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 160:                                   \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 161:                                   \"gap\":backend_gap,\"verdict\":verdict_str})",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 160,
          "context": " 157:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 158:                 f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 159:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 160: >>>                               \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 161:                                   \"gap\":backend_gap,\"verdict\":verdict_str})\n 162:             return verdict\n 163:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 160,
          "context": " 157:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 158:                 f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 159:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 160: >>>                               \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 161:                                   \"gap\":backend_gap,\"verdict\":verdict_str})\n 162:             return verdict\n 163:     ",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 80,
          "context": "  77:             tiles = (TILES_2D if dim==2 else (TILES_3D if dim==3 else (1,)))\n  78:     \n  79:             # Integrity checks up front\n  80: >>>         self.check_cfl(C, DT, DX, ndim=dim)\n  81:             self.validate_field(E0, f\"E0-{dim}D\")\n  82:     \n  83:             params = dict(",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 36,
          "context": "  33:     CHI = 0.0\n  34:     C = math.sqrt(ALPHA / BETA)\n  35:     STEPS = 200\n  36: >>> BOUNDARY = \"periodic\"\n  37:     PRECISION = \"float64\"\n  38:     THREADS = 1\n  39:     TILES_2D = (1,1)",
          "match": "BOUNDARY"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 36,
          "context": "  33:     CHI = 0.0\n  34:     C = math.sqrt(ALPHA / BETA)\n  35:     STEPS = 200\n  36: >>> BOUNDARY = \"periodic\"\n  37:     PRECISION = \"float64\"\n  38:     THREADS = 1\n  39:     TILES_2D = (1,1)",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 60,
          "context": "  57:     def _is_conservative(params: dict) -> bool:\n  58:         return (\n  59:             params.get(\"gamma_damp\",0.0)==0.0 and\n  60: >>>         params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n  61:             (not hasattr(params.get(\"chi\",0.0),\"shape\")) and\n  62:             float(params.get(\"absorb_width\",0))==0.0 and\n  63:             float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 60,
          "context": "  57:     def _is_conservative(params: dict) -> bool:\n  58:         return (\n  59:             params.get(\"gamma_damp\",0.0)==0.0 and\n  60: >>>         params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n  61:             (not hasattr(params.get(\"chi\",0.0),\"shape\")) and\n  62:             float(params.get(\"absorb_width\",0))==0.0 and\n  63:             float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 60,
          "context": "  57:     def _is_conservative(params: dict) -> bool:\n  58:         return (\n  59:             params.get(\"gamma_damp\",0.0)==0.0 and\n  60: >>>         params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n  61:             (not hasattr(params.get(\"chi\",0.0),\"shape\")) and\n  62:             float(params.get(\"absorb_width\",0))==0.0 and\n  63:             float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 86,
          "context": "  83:             params = dict(\n  84:                 dt=DT, dx=DX, alpha=ALPHA, beta=BETA, chi=CHI,\n  85:                 gamma_damp=0.0,\n  86: >>>             boundary=BOUNDARY,\n  87:                 stencil_order=2,\n  88:                 precision=PRECISION,\n  89:                 debug={\"enable_diagnostics\": False},",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 86,
          "context": "  83:             params = dict(\n  84:                 dt=DT, dx=DX, alpha=ALPHA, beta=BETA, chi=CHI,\n  85:                 gamma_damp=0.0,\n  86: >>>             boundary=BOUNDARY,\n  87:                 stencil_order=2,\n  88:                 precision=PRECISION,\n  89:                 debug={\"enable_diagnostics\": False},",
          "match": "BOUNDARY"
        }
      ],
      "line_count": 172,
      "docstring": "LFM Multi-Dimensional Regression — v1.3.7-monitor-integrated\n- Uses compensated energy_total.\n- Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n- Writes per-step parity CSV with serial vs parallel drift.\n- Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks."
    },
    {
      "filepath": "test_lfm_equation_parallel_all.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "0f976b57977c02b4",
      "file_size": 646,
      "modified": "2025-11-02T20:02:10.916356",
      "git_info": {
        "first_commit": {
          "hash": "01880e47",
          "date": "2025-10-27 11:51:07 -0700",
          "message": "Continue expanding tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 8,
          "context": "   5:     # Commercial use prohibited without explicit written permission.\n   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8: >>> # NOTE: This module was moved to tests/test_lfm_equation_parallel_all.py\n   9:     # Keeping a stub here to prevent duplicate execution during pytest collection.\n  10:     import pytest\n  11:     pytest.skip(",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 12,
          "context": "   9:     # Keeping a stub here to prevent duplicate execution during pytest collection.\n  10:     import pytest\n  11:     pytest.skip(\n  12: >>>     \"Moved to tests/test_lfm_equation_parallel_all.py; module skipped\",\n  13:         allow_module_level=True,\n  14:     )\n  15:     ",
          "match": "parallel"
        }
      ],
      "line_count": 14,
      "docstring": null
    },
    {
      "filepath": "test_lfm_equation_quick.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "3a290794e00c250d",
      "file_size": 573,
      "modified": "2025-11-02T20:02:10.916356",
      "git_info": {
        "first_commit": {
          "hash": "01880e47",
          "date": "2025-10-27 11:51:07 -0700",
          "message": "Continue expanding tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 14,
      "docstring": "Moved: This test now lives in devtests/test_lfm_equation_quick.py\n\nThis stub prevents duplicate discovery at the repo root."
    },
    {
      "filepath": "tests\\test_lfm_equation_multidim.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "d5a7c87180ca78fe",
      "file_size": 6786,
      "modified": "2025-11-02T20:02:11.101999",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 63,
          "context": "  60:             float(params.get(\"absorb_factor\",1.0))==1.0\n  61:         )\n  62:     \n  63: >>> class EquationHarness(NumericIntegrityMixin):\n  64:         def __init__(self):\n  65:             self.logger = LFMLogger(\"logs/test_multidim\")\n  66:             self.diag_dir = Path(\"diagnostics\")",
          "match": "class EquationHarness(NumericIntegrityMixin):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 42,
          "context": "  39:     TOL_GAP   = 5e-4\n  40:     ENERGY_LOCK_FOR_PARITY = True   # guarded; auto-disables when not conservative\n  41:     \n  42: >>> def gaussian_nd(shape, center=None, sigma=1.0):\n  43:         axes = tuple(np.arange(n, dtype=float) for n in shape)\n  44:         grids = np.meshgrid(*axes, indexing=\"ij\")\n  45:         if center is None:",
          "match": "def gaussian_nd(shape, center=None, sigma=1.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 50,
          "context": "  47:         r2 = sum(((g - c) * DX) ** 2 for g, c in zip(grids, center))\n  48:         return np.exp(-r2 / (2 * sigma**2))\n  49:     \n  50: >>> def taylor_prev(E0, dt, dx, c, chi, order=2):\n  51:         L = laplacian(E0, dx, order=order)\n  52:         return E0 - 0.5*(dt*dt)*((c*c)*L - (chi*chi)*E0)\n  53:     ",
          "match": "def taylor_prev(E0, dt, dx, c, chi, order=2):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 54,
          "context": "  51:         L = laplacian(E0, dx, order=order)\n  52:         return E0 - 0.5*(dt*dt)*((c*c)*L - (chi*chi)*E0)\n  53:     \n  54: >>> def _is_conservative(params: dict) -> bool:\n  55:         return (\n  56:             params.get(\"gamma_damp\",0.0)==0.0 and\n  57:             params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and",
          "match": "def _is_conservative(params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 64,
          "context": "  61:         )\n  62:     \n  63:     class EquationHarness(NumericIntegrityMixin):\n  64: >>>     def __init__(self):\n  65:             self.logger = LFMLogger(\"logs/test_multidim\")\n  66:             self.diag_dir = Path(\"diagnostics\")\n  67:             self.diag_dir.mkdir(exist_ok=True)",
          "match": "def __init__(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 69,
          "context": "  66:             self.diag_dir = Path(\"diagnostics\")\n  67:             self.diag_dir.mkdir(exist_ok=True)\n  68:     \n  69: >>>     def run_dim(self, dim: int):\n  70:             assert dim in (1,2,3)\n  71:             shape = {1:(200,), 2:(128,128), 3:(64,64,64)}[dim]\n  72:             E0 = gaussian_nd(shape, sigma=1.0)",
          "match": "def run_dim(self, dim:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 161,
          "context": " 158:                                   \"gap\":backend_gap,\"verdict\":verdict_str})\n 159:             return verdict\n 160:     \n 161: >>> def main():\n 162:         print(\"=== LFM Multi-Dimensional Regression (diagnostic parity + monitor) ===\")\n 163:         h = EquationHarness()\n 164:         all_ok = all(h.run_dim(d) for d in (1,2,3))",
          "match": "def main():"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     LFM Multi-Dimensional Regression — v1.3.7-monitor-integrated\n  10:     - Uses compensated energy_total.\n  11: >>> - Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n  12:     - Writes per-step parity CSV with serial vs parallel drift.\n  13:     - Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks.\n  14:     \"\"\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 12,
          "context": "   9:     LFM Multi-Dimensional Regression — v1.3.7-monitor-integrated\n  10:     - Uses compensated energy_total.\n  11:     - Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n  12: >>> - Writes per-step parity CSV with serial vs parallel drift.\n  13:     - Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks.\n  14:     \"\"\"\n  15:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 13,
          "context": "  10:     - Uses compensated energy_total.\n  11:     - Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n  12:     - Writes per-step parity CSV with serial vs parallel drift.\n  13: >>> - Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks.\n  14:     \"\"\"\n  15:     \n  16:     import math, time, csv, numpy as np",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 20,
          "context": "  17:     from pathlib import Path\n  18:     from lfm_equation import laplacian, lattice_step\n  19:     from lfm_diagnostics import energy_total\n  20: >>> from lfm_parallel import run_lattice\n  21:     from lfm_console import log\n  22:     from lfm_logger import LFMLogger\n  23:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 90,
          "context": "  87:                 threads=THREADS,\n  88:                 energy_lock=ENERGY_LOCK_FOR_PARITY,\n  89:     \n  90: >>>             # Enable monitoring inside the parallel runner\n  91:                 enable_monitor=True,\n  92:                 monitor_outdir=str(self.diag_dir),\n  93:                 monitor_label=f\"eq_parallel_{dim}D\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 93,
          "context": "  90:                 # Enable monitoring inside the parallel runner\n  91:                 enable_monitor=True,\n  92:                 monitor_outdir=str(self.diag_dir),\n  93: >>>             monitor_label=f\"eq_parallel_{dim}D\"\n  94:             )\n  95:     \n  96:             drift_csv = self.diag_dir / f\"parity_{dim}D.csv\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 130,
          "context": " 127:             drift_serial = drift_serial_series[-1][1]\n 128:             self.logger.log_json({\"event\":\"serial_done\",\"dim\":dim,\"drift\":drift_serial,\"time_s\":serial_time})\n 129:     \n 130: >>>         # --- Parallel (runner already monitors internally) ---\n 131:             log(f\"Running {dim}D parallel lattice...\", \"INFO\")\n 132:             params[\"_energy_log\"], params[\"_energy_drift_log\"] = [], []\n 133:             _ = run_lattice(np.array(E0, copy=True), params,",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 131,
          "context": " 128:             self.logger.log_json({\"event\":\"serial_done\",\"dim\":dim,\"drift\":drift_serial,\"time_s\":serial_time})\n 129:     \n 130:             # --- Parallel (runner already monitors internally) ---\n 131: >>>         log(f\"Running {dim}D parallel lattice...\", \"INFO\")\n 132:             params[\"_energy_log\"], params[\"_energy_drift_log\"] = [], []\n 133:             _ = run_lattice(np.array(E0, copy=True), params,\n 134:                             steps=STEPS,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 139,
          "context": " 136:                             E_prev=np.array(Eprev, copy=True))\n 137:     \n 138:             dlog = params.get(\"_energy_drift_log\", [])\n 139: >>>         drift_parallel = float(dlog[-1]) if dlog else float(\"nan\")\n 140:     \n 141:             # Write serial/parallel parity CSV\n 142:             with open(drift_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 141,
          "context": " 138:             dlog = params.get(\"_energy_drift_log\", [])\n 139:             drift_parallel = float(dlog[-1]) if dlog else float(\"nan\")\n 140:     \n 141: >>>         # Write serial/parallel parity CSV\n 142:             with open(drift_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n 143:                 w = csv.writer(f); w.writerow([\"step\",\"drift_serial\",\"drift_parallel\"])\n 144:                 for i,(s,ds) in enumerate(drift_serial_series):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 143,
          "context": " 140:     \n 141:             # Write serial/parallel parity CSV\n 142:             with open(drift_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n 143: >>>             w = csv.writer(f); w.writerow([\"step\",\"drift_serial\",\"drift_parallel\"])\n 144:                 for i,(s,ds) in enumerate(drift_serial_series):\n 145:                     dp = dlog[i] if i < len(dlog) else \"\"\n 146:                     w.writerow([s, ds, dp])",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 148,
          "context": " 145:                     dp = dlog[i] if i < len(dlog) else \"\"\n 146:                     w.writerow([s, ds, dp])\n 147:     \n 148: >>>         backend_gap = abs(drift_serial - drift_parallel)\n 149:             verdict = (abs(drift_serial) <= TOL_DRIFT and\n 150:                        abs(drift_parallel) <= TOL_DRIFT and\n 151:                        backend_gap <= TOL_GAP)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 150,
          "context": " 147:     \n 148:             backend_gap = abs(drift_serial - drift_parallel)\n 149:             verdict = (abs(drift_serial) <= TOL_DRIFT and\n 150: >>>                    abs(drift_parallel) <= TOL_DRIFT and\n 151:                        backend_gap <= TOL_GAP)\n 152:             verdict_str = \"PASS ✅\" if verdict else \"FAIL ❌\"\n 153:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 155,
          "context": " 152:             verdict_str = \"PASS ✅\" if verdict else \"FAIL ❌\"\n 153:     \n 154:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 155: >>>             f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 156:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 157:                                   \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 158:                                   \"gap\":backend_gap,\"verdict\":verdict_str})",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 155,
          "context": " 152:             verdict_str = \"PASS ✅\" if verdict else \"FAIL ❌\"\n 153:     \n 154:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 155: >>>             f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 156:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 157:                                   \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 158:                                   \"gap\":backend_gap,\"verdict\":verdict_str})",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 157,
          "context": " 154:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 155:                 f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 156:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 157: >>>                               \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 158:                                   \"gap\":backend_gap,\"verdict\":verdict_str})\n 159:             return verdict\n 160:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 157,
          "context": " 154:             log(f\"Dim {dim}D | serial drift={drift_serial:+.3e} | \"\n 155:                 f\"parallel drift={drift_parallel:+.3e} | Δ={backend_gap:.3e} → {verdict_str}\", \"INFO\")\n 156:             self.logger.log_json({\"event\":\"dim_result\",\"dim\":dim,\n 157: >>>                               \"drift_serial\":drift_serial,\"drift_parallel\":drift_parallel,\n 158:                                   \"gap\":backend_gap,\"verdict\":verdict_str})\n 159:             return verdict\n 160:     ",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 77,
          "context": "  74:             tiles = (TILES_2D if dim==2 else (TILES_3D if dim==3 else (1,)))\n  75:     \n  76:             # Integrity checks up front\n  77: >>>         self.check_cfl(C, DT, DX, ndim=dim)\n  78:             self.validate_field(E0, f\"E0-{dim}D\")\n  79:     \n  80:             params = dict(",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 33,
          "context": "  30:     CHI = 0.0\n  31:     C = math.sqrt(ALPHA / BETA)\n  32:     STEPS = 200\n  33: >>> BOUNDARY = \"periodic\"\n  34:     PRECISION = \"float64\"\n  35:     THREADS = 1\n  36:     TILES_2D = (1,1)",
          "match": "BOUNDARY"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 33,
          "context": "  30:     CHI = 0.0\n  31:     C = math.sqrt(ALPHA / BETA)\n  32:     STEPS = 200\n  33: >>> BOUNDARY = \"periodic\"\n  34:     PRECISION = \"float64\"\n  35:     THREADS = 1\n  36:     TILES_2D = (1,1)",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 57,
          "context": "  54:     def _is_conservative(params: dict) -> bool:\n  55:         return (\n  56:             params.get(\"gamma_damp\",0.0)==0.0 and\n  57: >>>         params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n  58:             (not hasattr(params.get(\"chi\",0.0),\"shape\")) and\n  59:             float(params.get(\"absorb_width\",0))==0.0 and\n  60:             float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 57,
          "context": "  54:     def _is_conservative(params: dict) -> bool:\n  55:         return (\n  56:             params.get(\"gamma_damp\",0.0)==0.0 and\n  57: >>>         params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n  58:             (not hasattr(params.get(\"chi\",0.0),\"shape\")) and\n  59:             float(params.get(\"absorb_width\",0))==0.0 and\n  60:             float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 57,
          "context": "  54:     def _is_conservative(params: dict) -> bool:\n  55:         return (\n  56:             params.get(\"gamma_damp\",0.0)==0.0 and\n  57: >>>         params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n  58:             (not hasattr(params.get(\"chi\",0.0),\"shape\")) and\n  59:             float(params.get(\"absorb_width\",0))==0.0 and\n  60:             float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 83,
          "context": "  80:             params = dict(\n  81:                 dt=DT, dx=DX, alpha=ALPHA, beta=BETA, chi=CHI,\n  82:                 gamma_damp=0.0,\n  83: >>>             boundary=BOUNDARY,\n  84:                 stencil_order=2,\n  85:                 precision=PRECISION,\n  86:                 debug={\"enable_diagnostics\": False},",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 83,
          "context": "  80:             params = dict(\n  81:                 dt=DT, dx=DX, alpha=ALPHA, beta=BETA, chi=CHI,\n  82:                 gamma_damp=0.0,\n  83: >>>             boundary=BOUNDARY,\n  84:                 stencil_order=2,\n  85:                 precision=PRECISION,\n  86:                 debug={\"enable_diagnostics\": False},",
          "match": "BOUNDARY"
        }
      ],
      "line_count": 169,
      "docstring": "LFM Multi-Dimensional Regression — v1.3.7-monitor-integrated\n- Uses compensated energy_total.\n- Applies guarded energy_lock to BOTH serial and parallel paths BEFORE drift logging.\n- Writes per-step parity CSV with serial vs parallel drift.\n- Integrates EnergyMonitor (serial + parallel) and NumericIntegrityMixin checks."
    },
    {
      "filepath": "tests\\test_lfm_equation_parallel_all.py",
      "category": "CORE_ALGORITHM",
      "priority": 10,
      "file_hash": "00299ee544af04cc",
      "file_size": 5321,
      "modified": "2025-11-02T20:02:11.103002",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:     # ---------------------------------------------------------------------\n  37:     # Simple inline logger\n  38:     # ---------------------------------------------------------------------\n  39: >>> class SimpleLogger:\n  40:         def __init__(self):\n  41:             self.logs = []\n  42:         def log(self, msg): print(msg)",
          "match": "class SimpleLogger:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 40,
          "context": "  37:     # Simple inline logger\n  38:     # ---------------------------------------------------------------------\n  39:     class SimpleLogger:\n  40: >>>     def __init__(self):\n  41:             self.logs = []\n  42:         def log(self, msg): print(msg)\n  43:         def log_json(self, obj): print(json.dumps(obj))",
          "match": "def __init__(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 42,
          "context": "  39:     class SimpleLogger:\n  40:         def __init__(self):\n  41:             self.logs = []\n  42: >>>     def log(self, msg): print(msg)\n  43:         def log_json(self, obj): print(json.dumps(obj))\n  44:     \n  45:     ",
          "match": "def log(self, msg):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:         def __init__(self):\n  41:             self.logs = []\n  42:         def log(self, msg): print(msg)\n  43: >>>     def log_json(self, obj): print(json.dumps(obj))\n  44:     \n  45:     \n  46:     # ---------------------------------------------------------------------",
          "match": "def log_json(self, obj):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 49,
          "context": "  46:     # ---------------------------------------------------------------------\n  47:     # Utility: initialize Gaussian field\n  48:     # ---------------------------------------------------------------------\n  49: >>> def make_field(shape, sigma=0.5):\n  50:         ndim = len(shape)\n  51:         grids = np.meshgrid(*[np.linspace(-1, 1, n, endpoint=False) for n in shape], indexing=\"ij\")\n  52:         r2 = sum(g**2 for g in grids)",
          "match": "def make_field(shape, sigma=0.5):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:     # ---------------------------------------------------------------------\n  57:     # Run helper\n  58:     # ---------------------------------------------------------------------\n  59: >>> def run_case(name, E0, params, parallel=False, tiles=(1, 1, 1)):\n  60:         logger = SimpleLogger()\n  61:         t0 = time.time()\n  62:         if parallel:",
          "match": "def run_case(name, E0, params, parallel=False, tiles=(1, 1, 1)):"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> Unified Validation Harness for LFM Core (v1.4) + Parallel (v1.3.1)\n  10:     \n  11:     Runs:\n  12:       1️⃣  2-D Serial (no parallel)",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 12,
          "context": "   9:     Unified Validation Harness for LFM Core (v1.4) + Parallel (v1.3.1)\n  10:     \n  11:     Runs:\n  12: >>>   1️⃣  2-D Serial (no parallel)\n  13:       2️⃣  2-D Threaded (parallel)\n  14:       3️⃣  3-D Serial\n  15:       4️⃣  3-D Threaded",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 13,
          "context": "  10:     \n  11:     Runs:\n  12:       1️⃣  2-D Serial (no parallel)\n  13: >>>   2️⃣  2-D Threaded (parallel)\n  14:       3️⃣  3-D Serial\n  15:       4️⃣  3-D Threaded\n  16:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 19,
          "context": "  16:     \n  17:     Outputs:\n  18:       • results/Tests/diagnostics/diagnostics_2d_serial.csv\n  19: >>>   • results/Tests/diagnostics/diagnostics_2d_parallel.csv\n  20:       • results/Tests/diagnostics/diagnostics_3d_serial.csv\n  21:       • results/Tests/diagnostics/diagnostics_3d_parallel.csv\n  22:     \"\"\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 21,
          "context": "  18:       • results/Tests/diagnostics/diagnostics_2d_serial.csv\n  19:       • results/Tests/diagnostics/diagnostics_2d_parallel.csv\n  20:       • results/Tests/diagnostics/diagnostics_3d_serial.csv\n  21: >>>   • results/Tests/diagnostics/diagnostics_3d_parallel.csv\n  22:     \"\"\"\n  23:     \n  24:     import numpy as np",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 29,
          "context": "  26:     import time, json, os\n  27:     from pathlib import Path\n  28:     from lfm_equation import advance\n  29: >>> from lfm_parallel import run_lattice\n  30:     \n  31:     # Ensure diagnostics directory exists\n  32:     DIAG_DIR = Path(__file__).parent.parent / \"results\" / \"Tests\" / \"diagnostics\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 59,
          "context": "  56:     # ---------------------------------------------------------------------\n  57:     # Run helper\n  58:     # ---------------------------------------------------------------------\n  59: >>> def run_case(name, E0, params, parallel=False, tiles=(1, 1, 1)):\n  60:         logger = SimpleLogger()\n  61:         t0 = time.time()\n  62:         if parallel:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 62,
          "context": "  59:     def run_case(name, E0, params, parallel=False, tiles=(1, 1, 1)):\n  60:         logger = SimpleLogger()\n  61:         t0 = time.time()\n  62: >>>     if parallel:\n  63:             result = run_lattice(E0, params, steps=params[\"steps\"],\n  64:                                  tiles=tiles)\n  65:         else:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 101,
          "context": "  98:     E0_2d = make_field((64, 64))\n  99:     params_2d_serial = dict(base_params)\n 100:     params_2d_serial[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_2d_serial.csv\")\n 101: >>> E_final_2d_serial = run_case(\"2-D SERIAL\", E0_2d, params_2d_serial, parallel=False)\n 102:     \n 103:     \n 104:     # ---------------------------------------------------------------------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 105,
          "context": " 102:     \n 103:     \n 104:     # ---------------------------------------------------------------------\n 105: >>> # 2️⃣  2-D Parallel\n 106:     # ---------------------------------------------------------------------\n 107:     E0_2d = make_field((64, 64))\n 108:     params_2d_par = dict(base_params)",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 109,
          "context": " 106:     # ---------------------------------------------------------------------\n 107:     E0_2d = make_field((64, 64))\n 108:     params_2d_par = dict(base_params)\n 109: >>> params_2d_par[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_2d_parallel.csv\")\n 110:     params_2d_par[\"threads\"] = 4\n 111:     params_2d_par[\"debug\"][\"enable_halo_diag\"] = True\n 112:     E_final_2d_par = run_case(\"2-D PARALLEL\", E0_2d, params_2d_par, parallel=True, tiles=(2, 2, 1))",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 112,
          "context": " 109:     params_2d_par[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_2d_parallel.csv\")\n 110:     params_2d_par[\"threads\"] = 4\n 111:     params_2d_par[\"debug\"][\"enable_halo_diag\"] = True\n 112: >>> E_final_2d_par = run_case(\"2-D PARALLEL\", E0_2d, params_2d_par, parallel=True, tiles=(2, 2, 1))\n 113:     \n 114:     \n 115:     # ---------------------------------------------------------------------",
          "match": "PARALLEL"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 112,
          "context": " 109:     params_2d_par[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_2d_parallel.csv\")\n 110:     params_2d_par[\"threads\"] = 4\n 111:     params_2d_par[\"debug\"][\"enable_halo_diag\"] = True\n 112: >>> E_final_2d_par = run_case(\"2-D PARALLEL\", E0_2d, params_2d_par, parallel=True, tiles=(2, 2, 1))\n 113:     \n 114:     \n 115:     # ---------------------------------------------------------------------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 121,
          "context": " 118:     E0_3d = make_field((32, 32, 32))\n 119:     params_3d_serial = dict(base_params)\n 120:     params_3d_serial[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_3d_serial.csv\")\n 121: >>> E_final_3d_serial = run_case(\"3-D SERIAL\", E0_3d, params_3d_serial, parallel=False)\n 122:     \n 123:     \n 124:     # ---------------------------------------------------------------------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 125,
          "context": " 122:     \n 123:     \n 124:     # ---------------------------------------------------------------------\n 125: >>> # 4️⃣  3-D Parallel\n 126:     # ---------------------------------------------------------------------\n 127:     E0_3d = make_field((32, 32, 32))\n 128:     params_3d_par = dict(base_params)",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 129,
          "context": " 126:     # ---------------------------------------------------------------------\n 127:     E0_3d = make_field((32, 32, 32))\n 128:     params_3d_par = dict(base_params)\n 129: >>> params_3d_par[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_3d_parallel.csv\")\n 130:     params_3d_par[\"threads\"] = 4\n 131:     params_3d_par[\"debug\"][\"enable_halo_diag\"] = True\n 132:     E_final_3d_par = run_case(\"3-D PARALLEL\", E0_3d, params_3d_par, parallel=True, tiles=(2, 2, 2))",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 132,
          "context": " 129:     params_3d_par[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_3d_parallel.csv\")\n 130:     params_3d_par[\"threads\"] = 4\n 131:     params_3d_par[\"debug\"][\"enable_halo_diag\"] = True\n 132: >>> E_final_3d_par = run_case(\"3-D PARALLEL\", E0_3d, params_3d_par, parallel=True, tiles=(2, 2, 2))\n 133:     \n 134:     \n 135:     # ---------------------------------------------------------------------",
          "match": "PARALLEL"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 132,
          "context": " 129:     params_3d_par[\"diagnostics_path\"] = str(DIAG_DIR / \"diagnostics_3d_parallel.csv\")\n 130:     params_3d_par[\"threads\"] = 4\n 131:     params_3d_par[\"debug\"][\"enable_halo_diag\"] = True\n 132: >>> E_final_3d_par = run_case(\"3-D PARALLEL\", E0_3d, params_3d_par, parallel=True, tiles=(2, 2, 2))\n 133:     \n 134:     \n 135:     # ---------------------------------------------------------------------",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 146,
          "context": " 143:     plt.tight_layout()\n 144:     plt.show()\n 145:     \n 146: >>> print(f\"\\nAll four test cases executed. Check {DIAG_DIR / 'diagnostics_*.csv'} for drift/CFL logs.\\n\")\n 147:     ",
          "match": "CFL"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 82,
          "context": "  79:         \"dt\": 0.002,\n  80:         \"gamma_damp\": 0.0,\n  81:         \"stencil_order\": 2,\n  82: >>>     \"boundary\": \"periodic\",\n  83:         \"chi\": 0.0,\n  84:         \"steps\": 100,\n  85:         \"energy_monitor_every\": 10,",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 82,
          "context": "  79:         \"dt\": 0.002,\n  80:         \"gamma_damp\": 0.0,\n  81:         \"stencil_order\": 2,\n  82: >>>     \"boundary\": \"periodic\",\n  83:         \"chi\": 0.0,\n  84:         \"steps\": 100,\n  85:         \"energy_monitor_every\": 10,",
          "match": "periodic"
        }
      ],
      "line_count": 146,
      "docstring": "Unified Validation Harness for LFM Core (v1.4) + Parallel (v1.3.1)\n\nRuns:\n  1️⃣  2-D Serial (no parallel)\n  2️⃣  2-D Threaded (parallel)\n  3️⃣  3-D Serial\n  4️⃣  3-D Threaded\n\nOutputs:\n  • results/Tests/diagnostics/diagnostics_2d_serial.csv\n  • results/Tests/diagnostics/diagnostics_2d_parallel.csv\n  • results/Tests/diagnostics/diagnostics_3d_serial.csv\n  • results/Tests/diagnostics/diagnostics_3d_parallel.csv"
    },
    {
      "filepath": "lfm_parallel.py",
      "category": "PERFORMANCE",
      "priority": 9,
      "file_hash": "73eb5c409d4cdb2a",
      "file_size": 9887,
      "modified": "2025-11-02T20:02:10.870199",
      "git_info": {
        "first_commit": {
          "hash": "01880e47",
          "date": "2025-10-27 11:51:07 -0700",
          "message": "Continue expanding tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 40,
          "context": "  37:         _HAS_CUPY = False\n  38:     \n  39:     # ------------------------ Utility functions ------------------------\n  40: >>> def _is_cupy_array(x) -> bool:\n  41:         return _HAS_CUPY and hasattr(x, \"__cuda_array_interface__\")\n  42:     \n  43:     def _as_numpy(x):",
          "match": "def _is_cupy_array(x) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:     def _is_cupy_array(x) -> bool:\n  41:         return _HAS_CUPY and hasattr(x, \"__cuda_array_interface__\")\n  42:     \n  43: >>> def _as_numpy(x):\n  44:         return np.asarray(x.get() if _is_cupy_array(x) else x)\n  45:     \n  46:     def _tiles_1d(n: int, parts: int) -> List[slice]:",
          "match": "def _as_numpy(x):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 46,
          "context": "  43:     def _as_numpy(x):\n  44:         return np.asarray(x.get() if _is_cupy_array(x) else x)\n  45:     \n  46: >>> def _tiles_1d(n: int, parts: int) -> List[slice]:\n  47:         parts = max(1, int(parts))\n  48:         base = n // parts; r = n % parts\n  49:         s, out = 0, []",
          "match": "def _tiles_1d(n:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 55,
          "context": "  52:             out.append(slice(s, e)); s = e\n  53:         return out\n  54:     \n  55: >>> def _tiles_2d(shape: Tuple[int,int], tiles: Tuple[int,int]):\n  56:         ys = _tiles_1d(shape[0], tiles[0]); xs = _tiles_1d(shape[1], tiles[1])\n  57:         return [(y, x) for y in ys for x in xs]\n  58:     ",
          "match": "def _tiles_2d(shape:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:         ys = _tiles_1d(shape[0], tiles[0]); xs = _tiles_1d(shape[1], tiles[1])\n  57:         return [(y, x) for y in ys for x in xs]\n  58:     \n  59: >>> def _tiles_3d(shape: Tuple[int,int,int], tiles: Tuple[int,int,int]):\n  60:         zs = _tiles_1d(shape[0], tiles[0])\n  61:         ys = _tiles_1d(shape[1], tiles[1])\n  62:         xs = _tiles_1d(shape[2], tiles[2])",
          "match": "def _tiles_3d(shape:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:         return [(z, y, x) for z in zs for y in ys for x in xs]\n  64:     \n  65:     # ------------------------ Threaded kernel ------------------------\n  66: >>> def _normalize_tile_args(t):\n  67:         \"\"\"Return tuple of slices regardless of dimension (1D safe).\"\"\"\n  68:         return (t,) if isinstance(t, slice) else t\n  69:     ",
          "match": "def _normalize_tile_args(t):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 70,
          "context": "  67:         \"\"\"Return tuple of slices regardless of dimension (1D safe).\"\"\"\n  68:         return (t,) if isinstance(t, slice) else t\n  69:     \n  70: >>> def _step_threaded(E, E_prev, params, tiles, deterministic=False):\n  71:         dt, dx = float(params[\"dt\"]), float(params[\"dx\"])\n  72:         alpha, beta = float(params[\"alpha\"]), float(params[\"beta\"])\n  73:         gamma = float(params.get(\"gamma_damp\", 0.0))",
          "match": "def _step_threaded(E, E_prev, params, tiles, deterministic=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 82,
          "context": "  79:         E_next = xp.empty_like(E)\n  80:     \n  81:         if xp.isscalar(chi):\n  82: >>>         def chi_view(*_): return chi\n  83:         else:\n  84:             def chi_view(*s): return chi[s]\n  85:     ",
          "match": "def chi_view(*_):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 84,
          "context": "  81:         if xp.isscalar(chi):\n  82:             def chi_view(*_): return chi\n  83:         else:\n  84: >>>         def chi_view(*s): return chi[s]\n  85:     \n  86:         def update_tile(*slices):\n  87:             if E.ndim == 1:",
          "match": "def chi_view(*s):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 86,
          "context": "  83:         else:\n  84:             def chi_view(*s): return chi[s]\n  85:     \n  86: >>>     def update_tile(*slices):\n  87:             if E.ndim == 1:\n  88:                 (sy,) = slices\n  89:                 term_wave = (c*c)*L[sy]; term_mass = -(chi_view(sy)**2)*E[sy]",
          "match": "def update_tile(*slices):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 119,
          "context": " 116:         return E_next\n 117:     \n 118:     # ------------------------ Main runner ------------------------\n 119: >>> def run_lattice(E0, params:dict, steps:int,\n 120:                     tiles:Union[Tuple[int,int],Tuple[int,int,int]]=(1,1),\n 121:                     E_prev:Optional[np.ndarray]=None):\n 122:         xp = _xp_for(E0); E = xp.array(E0, copy=True)",
          "match": "def run_lattice(E0, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 179,
          "context": " 176:             monitor_stride = int(params.get(\"energy_monitor_every\", 0))\n 177:     \n 178:         # Helper: determine conservative scenario for projection\n 179: >>>     def _is_conservative():\n 180:             return (\n 181:                 params.get(\"gamma_damp\",0.0)==0.0 and\n 182:                 params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and",
          "match": "def _is_conservative():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 33,
          "context": "  30:     from numeric_integrity import NumericIntegrityMixin\n  31:     \n  32:     try:\n  33: >>>     import cupy as cp  # type: ignore\n  34:         _HAS_CUPY = True\n  35:     except Exception:\n  36:         cp = None",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 34,
          "context": "  31:     \n  32:     try:\n  33:         import cupy as cp  # type: ignore\n  34: >>>     _HAS_CUPY = True\n  35:     except Exception:\n  36:         cp = None\n  37:         _HAS_CUPY = False",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 37,
          "context": "  34:         _HAS_CUPY = True\n  35:     except Exception:\n  36:         cp = None\n  37: >>>     _HAS_CUPY = False\n  38:     \n  39:     # ------------------------ Utility functions ------------------------\n  40:     def _is_cupy_array(x) -> bool:",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 40,
          "context": "  37:         _HAS_CUPY = False\n  38:     \n  39:     # ------------------------ Utility functions ------------------------\n  40: >>> def _is_cupy_array(x) -> bool:\n  41:         return _HAS_CUPY and hasattr(x, \"__cuda_array_interface__\")\n  42:     \n  43:     def _as_numpy(x):",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 41,
          "context": "  38:     \n  39:     # ------------------------ Utility functions ------------------------\n  40:     def _is_cupy_array(x) -> bool:\n  41: >>>     return _HAS_CUPY and hasattr(x, \"__cuda_array_interface__\")\n  42:     \n  43:     def _as_numpy(x):\n  44:         return np.asarray(x.get() if _is_cupy_array(x) else x)",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 41,
          "context": "  38:     \n  39:     # ------------------------ Utility functions ------------------------\n  40:     def _is_cupy_array(x) -> bool:\n  41: >>>     return _HAS_CUPY and hasattr(x, \"__cuda_array_interface__\")\n  42:     \n  43:     def _as_numpy(x):\n  44:         return np.asarray(x.get() if _is_cupy_array(x) else x)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 44,
          "context": "  41:         return _HAS_CUPY and hasattr(x, \"__cuda_array_interface__\")\n  42:     \n  43:     def _as_numpy(x):\n  44: >>>     return np.asarray(x.get() if _is_cupy_array(x) else x)\n  45:     \n  46:     def _tiles_1d(n: int, parts: int) -> List[slice]:\n  47:         parts = max(1, int(parts))",
          "match": "cupy"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> lfm_parallel.py — Canonical LFM parallel/time-evolution runner\n  10:     v1.9.6-monitor-integrity-lockfix\n  11:     \n  12:     Adds (diagnostics only; NO physics change):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> lfm_parallel.py — Canonical LFM parallel/time-evolution runner\n  10:     v1.9.6-monitor-integrity-lockfix\n  11:     \n  12:     Adds (diagnostics only; NO physics change):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 171,
          "context": " 168:         if params.get(\"enable_monitor\", False):\n 169:             mon = EnergyMonitor(dt, dx, c, chi,\n 170:                                 outdir=params.get(\"monitor_outdir\", \"diagnostics\"),\n 171: >>>                             label=params.get(\"monitor_label\", \"lfm_parallel\"))\n 172:             # Default to every 10 steps if monitor enabled, or use explicit stride\n 173:             monitor_stride = int(params.get(\"energy_monitor_every\", 10))\n 174:         else:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 228,
          "context": " 225:                     mon.record(E, E_prev, n)\n 226:     \n 227:             # Probe prints are gated via params.debug.print_probe_steps to avoid\n 228: >>>         # unconditional console spam from the parallel runner.\n 229:             dbg = params.get(\"debug\", {}) if isinstance(params, dict) else {}\n 230:             if bool(dbg.get(\"print_probe_steps\", False)) and not bool(dbg.get(\"quiet_run\", True)):\n 231:                 if n < 3:",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 14,
          "context": "  11:     \n  12:     Adds (diagnostics only; NO physics change):\n  13:       • Integrated EnergyMonitor (optional per run)\n  14: >>>   • NumericIntegrityMixin for CFL/NaN validation\n  15:       • Guarded optional energy_lock projection (constant-energy manifold)\n  16:       • Order fix: apply energy_lock BEFORE drift logging and scale (E, E_prev)\n  17:       • 1D tile unpack fix via _normalize_tile_args()",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 141,
          "context": " 138:         integrity.quiet_warnings = bool(ni_cfg.get(\"quiet_warnings\", False))\n 139:         integrity.suppress_monitoring = bool(ni_cfg.get(\"suppress_monitoring\", False))\n 140:     \n 141: >>>     integrity.check_cfl(c, dt, dx, dim)\n 142:         integrity.validate_field(E, \"E0\")\n 143:     \n 144:         tile_list = (_tiles_1d(E.shape[0],tiles[0]) if dim==1 else",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 27,
          "context": "  24:     import numpy as np\n  25:     from pathlib import Path\n  26:     \n  27: >>> from lfm_equation import laplacian, _xp_for, apply_boundary\n  28:     from lfm_diagnostics import energy_total  # compensated measurement\n  29:     from energy_monitor import EnergyMonitor\n  30:     from numeric_integrity import NumericIntegrityMixin",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 115,
          "context": " 112:                         pass\n 113:     \n 114:         if E.ndim <= 2:\n 115: >>>         apply_boundary(E_next, mode=params.get(\"boundary\",\"periodic\"))\n 116:         return E_next\n 117:     \n 118:     # ------------------------ Main runner ------------------------",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 115,
          "context": " 112:                         pass\n 113:     \n 114:         if E.ndim <= 2:\n 115: >>>         apply_boundary(E_next, mode=params.get(\"boundary\",\"periodic\"))\n 116:         return E_next\n 117:     \n 118:     # ------------------------ Main runner ------------------------",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 115,
          "context": " 112:                         pass\n 113:     \n 114:         if E.ndim <= 2:\n 115: >>>         apply_boundary(E_next, mode=params.get(\"boundary\",\"periodic\"))\n 116:         return E_next\n 117:     \n 118:     # ------------------------ Main runner ------------------------",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 182,
          "context": " 179:         def _is_conservative():\n 180:             return (\n 181:                 params.get(\"gamma_damp\",0.0)==0.0 and\n 182: >>>             params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n 183:                 (not hasattr(params.get(\"chi\",0.0), \"shape\")) and\n 184:                 float(params.get(\"absorb_width\",0))==0.0 and\n 185:                 float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 182,
          "context": " 179:         def _is_conservative():\n 180:             return (\n 181:                 params.get(\"gamma_damp\",0.0)==0.0 and\n 182: >>>             params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n 183:                 (not hasattr(params.get(\"chi\",0.0), \"shape\")) and\n 184:                 float(params.get(\"absorb_width\",0))==0.0 and\n 185:                 float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 182,
          "context": " 179:         def _is_conservative():\n 180:             return (\n 181:                 params.get(\"gamma_damp\",0.0)==0.0 and\n 182: >>>             params.get(\"boundary\",\"periodic\") in (\"periodic\",\"reflective\") and\n 183:                 (not hasattr(params.get(\"chi\",0.0), \"shape\")) and\n 184:                 float(params.get(\"absorb_width\",0))==0.0 and\n 185:                 float(params.get(\"absorb_factor\",1.0))==1.0",
          "match": "periodic"
        }
      ],
      "line_count": 237,
      "docstring": "lfm_parallel.py — Canonical LFM parallel/time-evolution runner\nv1.9.6-monitor-integrity-lockfix\n\nAdds (diagnostics only; NO physics change):\n  • Integrated EnergyMonitor (optional per run)\n  • NumericIntegrityMixin for CFL/NaN validation\n  • Guarded optional energy_lock projection (constant-energy manifold)\n  • Order fix: apply energy_lock BEFORE drift logging and scale (E, E_prev)\n  • 1D tile unpack fix via _normalize_tile_args()"
    },
    {
      "filepath": "run_parallel_suite.py",
      "category": "PERFORMANCE",
      "priority": 9,
      "file_hash": "e7b2b27f71e36b9e",
      "file_size": 6727,
      "modified": "2025-11-02T20:02:10.889018",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 30,
          "context": "  27:     from adaptive_scheduler import AdaptiveScheduler\n  28:     \n  29:     \n  30: >>> def parse_args():\n  31:         \"\"\"Parse command line arguments.\"\"\"\n  32:         parser = argparse.ArgumentParser(\n  33:             description=\"Adaptive parallel test suite runner for LFM\",",
          "match": "def parse_args():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:         return parser.parse_args()\n  78:     \n  79:     \n  80: >>> def build_test_list_from_tiers(tiers: List[int]) -> List[Tuple[str, int, Dict]]:\n  81:         \"\"\"\n  82:         Build test list from tier numbers.\n  83:         ",
          "match": "def build_test_list_from_tiers(tiers:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 100,
          "context": "  97:         return test_list\n  98:     \n  99:     \n 100: >>> def build_test_list_from_ids(test_ids: List[str]) -> List[Tuple[str, int, Dict]]:\n 101:         \"\"\"\n 102:         Build test list from specific test IDs.\n 103:         ",
          "match": "def build_test_list_from_ids(test_ids:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 149,
          "context": " 146:         return test_list\n 147:     \n 148:     \n 149: >>> def get_fast_test_list() -> List[Tuple[str, int, Dict]]:\n 150:         \"\"\"Get fast test subset for quick validation.\"\"\"\n 151:         # These tests are known to be fast (2-5 seconds each)\n 152:         fast_tests = [",
          "match": "def get_fast_test_list() -> List[Tuple[str, int, Dict]]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 161,
          "context": " 158:         return fast_tests\n 159:     \n 160:     \n 161: >>> def main():\n 162:         \"\"\"Main entry point.\"\"\"\n 163:         args = parse_args()\n 164:         ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 143,
          "context": " 140:                     \"grid_points\": 512,\n 141:                     \"steps\": 6000,\n 142:                     \"dimensions\": 1,\n 143: >>>                 \"use_gpu\": True\n 144:                 }))\n 145:         \n 146:         return test_list",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 153,
          "context": " 150:         \"\"\"Get fast test subset for quick validation.\"\"\"\n 151:         # These tests are known to be fast (2-5 seconds each)\n 152:         fast_tests = [\n 153: >>>         (\"REL-01\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 154:             (\"REL-02\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 155:             (\"GRAV-12\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 4800, \"use_gpu\": True}),\n 156:             (\"GRAV-23\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 600, \"use_gpu\": True}),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 154,
          "context": " 151:         # These tests are known to be fast (2-5 seconds each)\n 152:         fast_tests = [\n 153:             (\"REL-01\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 154: >>>         (\"REL-02\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 155:             (\"GRAV-12\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 4800, \"use_gpu\": True}),\n 156:             (\"GRAV-23\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 600, \"use_gpu\": True}),\n 157:         ]",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 155,
          "context": " 152:         fast_tests = [\n 153:             (\"REL-01\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 154:             (\"REL-02\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 155: >>>         (\"GRAV-12\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 4800, \"use_gpu\": True}),\n 156:             (\"GRAV-23\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 600, \"use_gpu\": True}),\n 157:         ]\n 158:         return fast_tests",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 156,
          "context": " 153:             (\"REL-01\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 154:             (\"REL-02\", 1, {\"dimensions\": 1, \"grid_points\": 512, \"steps\": 6000, \"use_gpu\": True}),\n 155:             (\"GRAV-12\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 4800, \"use_gpu\": True}),\n 156: >>>         (\"GRAV-23\", 2, {\"dimensions\": 1, \"grid_points\": 64, \"steps\": 600, \"use_gpu\": True}),\n 157:         ]\n 158:         return fast_tests\n 159:     ",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> Run Parallel Test Suite - Main CLI for adaptive parallel test execution\n  10:     ======================================================================\n  11:     Intelligently schedules and runs LFM test suites in parallel based on\n  12:     resource availability and historical metrics.",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> Run Parallel Test Suite - Main CLI for adaptive parallel test execution\n  10:     ======================================================================\n  11:     Intelligently schedules and runs LFM test suites in parallel based on\n  12:     resource availability and historical metrics.",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     Run Parallel Test Suite - Main CLI for adaptive parallel test execution\n  10:     ======================================================================\n  11: >>> Intelligently schedules and runs LFM test suites in parallel based on\n  12:     resource availability and historical metrics.\n  13:     \n  14:     Usage:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 15,
          "context": "  12:     resource availability and historical metrics.\n  13:     \n  14:     Usage:\n  15: >>>     python run_parallel_suite.py --tiers 1,2         # Run Tier 1 and 2\n  16:         python run_parallel_suite.py --fast              # Run fast test subset\n  17:         python run_parallel_suite.py --tests REL-01,REL-02,GRAV-01  # Specific tests\n  18:         python run_parallel_suite.py --max-concurrent 4  # Control parallelism",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 16,
          "context": "  13:     \n  14:     Usage:\n  15:         python run_parallel_suite.py --tiers 1,2         # Run Tier 1 and 2\n  16: >>>     python run_parallel_suite.py --fast              # Run fast test subset\n  17:         python run_parallel_suite.py --tests REL-01,REL-02,GRAV-01  # Specific tests\n  18:         python run_parallel_suite.py --max-concurrent 4  # Control parallelism\n  19:     \"\"\"",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 17,
          "context": "  14:     Usage:\n  15:         python run_parallel_suite.py --tiers 1,2         # Run Tier 1 and 2\n  16:         python run_parallel_suite.py --fast              # Run fast test subset\n  17: >>>     python run_parallel_suite.py --tests REL-01,REL-02,GRAV-01  # Specific tests\n  18:         python run_parallel_suite.py --max-concurrent 4  # Control parallelism\n  19:     \"\"\"\n  20:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 18,
          "context": "  15:         python run_parallel_suite.py --tiers 1,2         # Run Tier 1 and 2\n  16:         python run_parallel_suite.py --fast              # Run fast test subset\n  17:         python run_parallel_suite.py --tests REL-01,REL-02,GRAV-01  # Specific tests\n  18: >>>     python run_parallel_suite.py --max-concurrent 4  # Control parallelism\n  19:     \"\"\"\n  20:     \n  21:     import argparse",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 18,
          "context": "  15:         python run_parallel_suite.py --tiers 1,2         # Run Tier 1 and 2\n  16:         python run_parallel_suite.py --fast              # Run fast test subset\n  17:         python run_parallel_suite.py --tests REL-01,REL-02,GRAV-01  # Specific tests\n  18: >>>     python run_parallel_suite.py --max-concurrent 4  # Control parallelism\n  19:     \"\"\"\n  20:     \n  21:     import argparse",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 33,
          "context": "  30:     def parse_args():\n  31:         \"\"\"Parse command line arguments.\"\"\"\n  32:         parser = argparse.ArgumentParser(\n  33: >>>         description=\"Adaptive parallel test suite runner for LFM\",\n  34:             formatter_class=argparse.RawDescriptionHelpFormatter\n  35:         )\n  36:         ",
          "match": "parallel"
        }
      ],
      "line_count": 223,
      "docstring": "Run Parallel Test Suite - Main CLI for adaptive parallel test execution\n======================================================================\nIntelligently schedules and runs LFM test suites in parallel based on\nresource availability and historical metrics.\n\nUsage:\n    python run_parallel_suite.py --tiers 1,2         # Run Tier 1 and 2\n    python run_parallel_suite.py --fast              # Run fast test subset\n    python run_parallel_suite.py --tests REL-01,REL-02,GRAV-01  # Specific tests\n    python run_parallel_suite.py --max-concurrent 4  # Control parallelism"
    },
    {
      "filepath": "run_parallel_tests.py",
      "category": "PERFORMANCE",
      "priority": 9,
      "file_hash": "13f640f62d7d2eca",
      "file_size": 36294,
      "modified": "2025-11-02T20:02:10.892064",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:     from lfm_results import update_master_test_status\n  35:     \n  36:     \n  37: >>> def run_single_test(test_id: str, tier: int, timeout_sec: int) -> Tuple[str, int, Dict]:\n  38:         \"\"\"\n  39:         Run a single test in a subprocess with real-time resource monitoring.\n  40:         Returns (test_id, tier, result_dict).",
          "match": "def run_single_test(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:         start_time = time.time()\n  56:         \n  57:         # Helper: query total GPU memory used (system-wide)\n  58: >>>     def _query_gpu_total_mb() -> float:\n  59:             try:\n  60:                 gpu_query = subprocess.run(\n  61:                     [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],",
          "match": "def _query_gpu_total_mb() -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 71,
          "context": "  68:             return 0.0\n  69:     \n  70:         # Helper: query per-PID GPU memory used; returns None if unsupported/unavailable\n  71: >>>     def _query_pid_gpu_mb(pid: int) -> Optional[float]:\n  72:             try:\n  73:                 proc = subprocess.run(\n  74:                     [",
          "match": "def _query_pid_gpu_mb(pid:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 211,
          "context": " 208:             })\n 209:     \n 210:     \n 211: >>> def progress_callback(result: Tuple[str, int, Dict]):\n 212:         \"\"\"Called when a test completes - print progress immediately.\"\"\"\n 213:         test_id, tier, metrics = result\n 214:         status = \"✓ PASS\" if metrics[\"exit_code\"] == 0 else \"✗ FAIL\"",
          "match": "def progress_callback(result:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 219,
          "context": " 216:         print(f\"  {status} {test_id} ({runtime:.1f}s)\", flush=True)\n 217:     \n 218:     \n 219: >>> def parse_args():\n 220:         \"\"\"Parse command line arguments.\"\"\"\n 221:         parser = argparse.ArgumentParser(description=\"Run tests in parallel for maximum speed\")\n 222:         ",
          "match": "def parse_args():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 250,
          "context": " 247:         return parser.parse_args()\n 248:     \n 249:     \n 250: >>> def get_fast_tests() -> List[Tuple[str, int]]:\n 251:         \"\"\"Get fast test list.\"\"\"\n 252:         return [\n 253:             (\"REL-01\", 1),",
          "match": "def get_fast_tests() -> List[Tuple[str, int]]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 260,
          "context": " 257:         ]\n 258:     \n 259:     \n 260: >>> def get_tests_from_tiers(tiers: List[int]) -> List[Tuple[str, int]]:\n 261:         \"\"\"Load all tests from specified tiers.\"\"\"\n 262:         tests = []\n 263:         ",
          "match": "def get_tests_from_tiers(tiers:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 272,
          "context": " 269:         return tests\n 270:     \n 271:     \n 272: >>> def get_specific_tests(test_ids: List[str]) -> List[Tuple[str, int]]:\n 273:         \"\"\"Get specific tests by ID.\"\"\"\n 274:         tests = []\n 275:         for test_id in test_ids:",
          "match": "def get_specific_tests(test_ids:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 290,
          "context": " 287:     # update_master_test_status() moved to lfm_results.py for sharing across all test harnesses\n 288:     \n 289:     \n 290: >>> def main():\n 291:         \"\"\"Run tests in parallel.\"\"\"\n 292:         args = parse_args()\n 293:         ",
          "match": "def main():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 323,
          "context": " 320:                 test_configs[tid] = cfg\n 321:     \n 322:         # Helper: GPU total/free memory (MB)\n 323: >>>     def _gpu_total_free_mb() -> Tuple[int, int]:\n 324:             try:\n 325:                 out = subprocess.run([\n 326:                     \"nvidia-smi\",",
          "match": "def _gpu_total_free_mb() -> Tuple[int, int]:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 15,
          "context": "  12:     Resource estimation and scheduling:\n  13:     - Uses last successful run metrics for each test (not historical averages)\n  14:     - Hybrid scheduling: priority tiers + longest-job-first within tier\n  15: >>> - Dynamic budgets based on available CPU/RAM/GPU at start time\n  16:     - Starvation guard ensures progress even when tests exceed budgets\n  17:     - Metrics DB (test_metrics_history.json) is committed as seed data for new users\n  18:     \"\"\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 57,
          "context": "  54:         \n  55:         start_time = time.time()\n  56:         \n  57: >>>     # Helper: query total GPU memory used (system-wide)\n  58:         def _query_gpu_total_mb() -> float:\n  59:             try:\n  60:                 gpu_query = subprocess.run(",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 58,
          "context": "  55:         start_time = time.time()\n  56:         \n  57:         # Helper: query total GPU memory used (system-wide)\n  58: >>>     def _query_gpu_total_mb() -> float:\n  59:             try:\n  60:                 gpu_query = subprocess.run(\n  61:                     [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 60,
          "context": "  57:         # Helper: query total GPU memory used (system-wide)\n  58:         def _query_gpu_total_mb() -> float:\n  59:             try:\n  60: >>>             gpu_query = subprocess.run(\n  61:                     [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],\n  62:                     capture_output=True, text=True, timeout=2\n  63:                 )",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 61,
          "context": "  58:         def _query_gpu_total_mb() -> float:\n  59:             try:\n  60:                 gpu_query = subprocess.run(\n  61: >>>                 [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],\n  62:                     capture_output=True, text=True, timeout=2\n  63:                 )\n  64:                 if gpu_query.returncode == 0 and gpu_query.stdout.strip():",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 64,
          "context": "  61:                     [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],\n  62:                     capture_output=True, text=True, timeout=2\n  63:                 )\n  64: >>>             if gpu_query.returncode == 0 and gpu_query.stdout.strip():\n  65:                     return float(gpu_query.stdout.strip().split()[0])\n  66:             except Exception:\n  67:                 pass",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 64,
          "context": "  61:                     [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],\n  62:                     capture_output=True, text=True, timeout=2\n  63:                 )\n  64: >>>             if gpu_query.returncode == 0 and gpu_query.stdout.strip():\n  65:                     return float(gpu_query.stdout.strip().split()[0])\n  66:             except Exception:\n  67:                 pass",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 65,
          "context": "  62:                     capture_output=True, text=True, timeout=2\n  63:                 )\n  64:                 if gpu_query.returncode == 0 and gpu_query.stdout.strip():\n  65: >>>                 return float(gpu_query.stdout.strip().split()[0])\n  66:             except Exception:\n  67:                 pass\n  68:             return 0.0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 70,
          "context": "  67:                 pass\n  68:             return 0.0\n  69:     \n  70: >>>     # Helper: query per-PID GPU memory used; returns None if unsupported/unavailable\n  71:         def _query_pid_gpu_mb(pid: int) -> Optional[float]:\n  72:             try:\n  73:                 proc = subprocess.run(",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 71,
          "context": "  68:             return 0.0\n  69:     \n  70:         # Helper: query per-PID GPU memory used; returns None if unsupported/unavailable\n  71: >>>     def _query_pid_gpu_mb(pid: int) -> Optional[float]:\n  72:             try:\n  73:                 proc = subprocess.run(\n  74:                     [",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 103,
          "context": " 100:         \n 101:         # Run and monitor resources\n 102:         try:\n 103: >>>         # Measure GPU baseline before starting test (for delta fallback)\n 104:             gpu_baseline_mb = _query_gpu_total_mb()\n 105:             \n 106:             # Start subprocess",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 104,
          "context": " 101:         # Run and monitor resources\n 102:         try:\n 103:             # Measure GPU baseline before starting test (for delta fallback)\n 104: >>>         gpu_baseline_mb = _query_gpu_total_mb()\n 105:             \n 106:             # Start subprocess\n 107:             process = subprocess.Popen(",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 104,
          "context": " 101:         # Run and monitor resources\n 102:         try:\n 103:             # Measure GPU baseline before starting test (for delta fallback)\n 104: >>>         gpu_baseline_mb = _query_gpu_total_mb()\n 105:             \n 106:             # Start subprocess\n 107:             process = subprocess.Popen(",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 120,
          "context": " 117:             # Monitor resources while running\n 118:             peak_cpu = 0.0\n 119:             peak_memory_mb = 0.0\n 120: >>>         peak_gpu_used_mb = 0.0  # Track per-PID used if available, else total delta\n 121:             \n 122:             try:\n 123:                 ps_process = psutil.Process(process.pid)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 153,
          "context": " 150:                         \"error\": f\"Test timed out after {timeout_sec} seconds\",\n 151:                         \"peak_cpu_percent\": peak_cpu,\n 152:                         \"peak_memory_mb\": peak_memory_mb,\n 153: >>>                     \"peak_gpu_memory_mb\": peak_gpu_used_mb,\n 154:                         \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 155:                     })\n 156:                 ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 153,
          "context": " 150:                         \"error\": f\"Test timed out after {timeout_sec} seconds\",\n 151:                         \"peak_cpu_percent\": peak_cpu,\n 152:                         \"peak_memory_mb\": peak_memory_mb,\n 153: >>>                     \"peak_gpu_memory_mb\": peak_gpu_used_mb,\n 154:                         \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 155:                     })\n 156:                 ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 170,
          "context": " 167:                         except (psutil.NoSuchProcess, psutil.AccessDenied):\n 168:                             pass\n 169:                     \n 170: >>>                 # Query per-PID GPU usage if supported; fallback to system delta\n 171:                     pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173:                         gpu_current_mb = _query_gpu_total_mb()",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 171,
          "context": " 168:                             pass\n 169:                     \n 170:                     # Query per-PID GPU usage if supported; fallback to system delta\n 171: >>>                 pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173:                         gpu_current_mb = _query_gpu_total_mb()\n 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 173,
          "context": " 170:                     # Query per-PID GPU usage if supported; fallback to system delta\n 171:                     pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173: >>>                     gpu_current_mb = _query_gpu_total_mb()\n 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 173,
          "context": " 170:                     # Query per-PID GPU usage if supported; fallback to system delta\n 171:                     pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173: >>>                     gpu_current_mb = _query_gpu_total_mb()\n 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 174,
          "context": " 171:                     pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173:                         gpu_current_mb = _query_gpu_total_mb()\n 174: >>>                     gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)\n 177:                     peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 174,
          "context": " 171:                     pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173:                         gpu_current_mb = _query_gpu_total_mb()\n 174: >>>                     gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)\n 177:                     peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 174,
          "context": " 171:                     pid_used = _query_pid_gpu_mb(process.pid)\n 172:                     if pid_used is None:\n 173:                         gpu_current_mb = _query_gpu_total_mb()\n 174: >>>                     gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)\n 177:                     peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 176,
          "context": " 173:                         gpu_current_mb = _query_gpu_total_mb()\n 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176: >>>                     gpu_used = max(0.0, pid_used)\n 177:                     peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)\n 178:                     \n 179:                     last_poll = now",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 177,
          "context": " 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)\n 177: >>>                 peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)\n 178:                     \n 179:                     last_poll = now\n 180:                 ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 177,
          "context": " 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)\n 177: >>>                 peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)\n 178:                     \n 179:                     last_poll = now\n 180:                 ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 177,
          "context": " 174:                         gpu_used = max(0.0, gpu_current_mb - gpu_baseline_mb)\n 175:                     else:\n 176:                         gpu_used = max(0.0, pid_used)\n 177: >>>                 peak_gpu_used_mb = max(peak_gpu_used_mb, gpu_used)\n 178:                     \n 179:                     last_poll = now\n 180:                 ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 194,
          "context": " 191:                 \"stderr\": \"\",\n 192:                 \"peak_cpu_percent\": peak_cpu,\n 193:                 \"peak_memory_mb\": peak_memory_mb,\n 194: >>>             \"peak_gpu_memory_mb\": peak_gpu_used_mb,\n 195:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 196:             })\n 197:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 194,
          "context": " 191:                 \"stderr\": \"\",\n 192:                 \"peak_cpu_percent\": peak_cpu,\n 193:                 \"peak_memory_mb\": peak_memory_mb,\n 194: >>>             \"peak_gpu_memory_mb\": peak_gpu_used_mb,\n 195:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 196:             })\n 197:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 206,
          "context": " 203:                 \"error\": str(e),\n 204:                 \"peak_cpu_percent\": 0.0,\n 205:                 \"peak_memory_mb\": 0.0,\n 206: >>>             \"peak_gpu_memory_mb\": 0.0,\n 207:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 208:             })\n 209:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 322,
          "context": " 319:             for tid, cfg in load_test_configs(tier):\n 320:                 test_configs[tid] = cfg\n 321:     \n 322: >>>     # Helper: GPU total/free memory (MB)\n 323:         def _gpu_total_free_mb() -> Tuple[int, int]:\n 324:             try:\n 325:                 out = subprocess.run([",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 323,
          "context": " 320:                 test_configs[tid] = cfg\n 321:     \n 322:         # Helper: GPU total/free memory (MB)\n 323: >>>     def _gpu_total_free_mb() -> Tuple[int, int]:\n 324:             try:\n 325:                 out = subprocess.run([\n 326:                     \"nvidia-smi\",",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 327,
          "context": " 324:             try:\n 325:                 out = subprocess.run([\n 326:                     \"nvidia-smi\",\n 327: >>>                 \"--query-gpu=memory.total,memory.free\",\n 328:                     \"--format=csv,noheader,nounits\"\n 329:                 ], capture_output=True, text=True, timeout=5)\n 330:                 if out.returncode == 0 and out.stdout.strip():",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 337,
          "context": " 334:                     return total, free\n 335:             except Exception:\n 336:                 pass\n 337: >>>         return 0, 0  # No GPU or not available\n 338:     \n 339:         # Budgets (CPU cores, RAM MB, GPU MB)\n 340:         cpu_cores_total = mp.cpu_count()",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 339,
          "context": " 336:                 pass\n 337:             return 0, 0  # No GPU or not available\n 338:     \n 339: >>>     # Budgets (CPU cores, RAM MB, GPU MB)\n 340:         cpu_cores_total = mp.cpu_count()\n 341:         cpu_cores_budget = max(1.0, float(cpu_cores_total - 2))  # keep 2 for OS/IDE\n 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 344,
          "context": " 341:         cpu_cores_budget = max(1.0, float(cpu_cores_total - 2))  # keep 2 for OS/IDE\n 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)\n 343:         mem_budget_mb = max(1024.0, mem_avail_mb * 0.7)  # use 70% of available\n 344: >>>     gpu_total_mb, gpu_free_mb = _gpu_total_free_mb()\n 345:         gpu_budget_mb = max(0.0, gpu_free_mb * 0.75)  # keep headroom on GPU\n 346:     \n 347:         # Worker pool size: allow many slots, scheduling will enforce budgets",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 344,
          "context": " 341:         cpu_cores_budget = max(1.0, float(cpu_cores_total - 2))  # keep 2 for OS/IDE\n 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)\n 343:         mem_budget_mb = max(1024.0, mem_avail_mb * 0.7)  # use 70% of available\n 344: >>>     gpu_total_mb, gpu_free_mb = _gpu_total_free_mb()\n 345:         gpu_budget_mb = max(0.0, gpu_free_mb * 0.75)  # keep headroom on GPU\n 346:     \n 347:         # Worker pool size: allow many slots, scheduling will enforce budgets",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 344,
          "context": " 341:         cpu_cores_budget = max(1.0, float(cpu_cores_total - 2))  # keep 2 for OS/IDE\n 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)\n 343:         mem_budget_mb = max(1024.0, mem_avail_mb * 0.7)  # use 70% of available\n 344: >>>     gpu_total_mb, gpu_free_mb = _gpu_total_free_mb()\n 345:         gpu_budget_mb = max(0.0, gpu_free_mb * 0.75)  # keep headroom on GPU\n 346:     \n 347:         # Worker pool size: allow many slots, scheduling will enforce budgets",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)\n 343:         mem_budget_mb = max(1024.0, mem_avail_mb * 0.7)  # use 70% of available\n 344:         gpu_total_mb, gpu_free_mb = _gpu_total_free_mb()\n 345: >>>     gpu_budget_mb = max(0.0, gpu_free_mb * 0.75)  # keep headroom on GPU\n 346:     \n 347:         # Worker pool size: allow many slots, scheduling will enforce budgets\n 348:         if args.workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)\n 343:         mem_budget_mb = max(1024.0, mem_avail_mb * 0.7)  # use 70% of available\n 344:         gpu_total_mb, gpu_free_mb = _gpu_total_free_mb()\n 345: >>>     gpu_budget_mb = max(0.0, gpu_free_mb * 0.75)  # keep headroom on GPU\n 346:     \n 347:         # Worker pool size: allow many slots, scheduling will enforce budgets\n 348:         if args.workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:         mem_avail_mb = psutil.virtual_memory().available / (1024**2)\n 343:         mem_budget_mb = max(1024.0, mem_avail_mb * 0.7)  # use 70% of available\n 344:         gpu_total_mb, gpu_free_mb = _gpu_total_free_mb()\n 345: >>>     gpu_budget_mb = max(0.0, gpu_free_mb * 0.75)  # keep headroom on GPU\n 346:     \n 347:         # Worker pool size: allow many slots, scheduling will enforce budgets\n 348:         if args.workers:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 357,
          "context": " 354:         print(\"PARALLEL TEST RUNNER\")\n 355:         print(\"=\"*70)\n 356:         print(f\"Running {len(tests)} tests with pool size {num_workers}\")\n 357: >>>     print(f\"Budgets -> CPU cores: {cpu_cores_budget:.1f}, RAM: {mem_budget_mb:.0f} MB, GPU: {gpu_budget_mb:.0f} MB\")\n 358:         print(f\"Output buffered per-test, progress shown on completion\\n\")\n 359:         \n 360:         # Load test metrics",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 357,
          "context": " 354:         print(\"PARALLEL TEST RUNNER\")\n 355:         print(\"=\"*70)\n 356:         print(f\"Running {len(tests)} tests with pool size {num_workers}\")\n 357: >>>     print(f\"Budgets -> CPU cores: {cpu_cores_budget:.1f}, RAM: {mem_budget_mb:.0f} MB, GPU: {gpu_budget_mb:.0f} MB\")\n 358:         print(f\"Output buffered per-test, progress shown on completion\\n\")\n 359:         \n 360:         # Load test metrics",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 382,
          "context": " 379:             est[\"enqueued_at\"] = enqueue_time\n 380:             est[\"fit_denied_cpu\"] = 0\n 381:             est[\"fit_denied_mem\"] = 0\n 382: >>>         est[\"fit_denied_gpu\"] = 0\n 383:             \n 384:             # Compute hybrid scheduling score:\n 385:             # 1) Group by priority tier (failed/never-run=0, high-prio=1, normal=2)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 400,
          "context": " 397:             # 3) Tie-breaker: resource footprint (higher resource tests first for better packing)\n 398:             cpu_need = float(est.get(\"cpu_cores_needed\", 1.0))\n 399:             mem_need = float(est.get(\"memory_mb\", 500.0))\n 400: >>>         gpu_need = float(est.get(\"gpu_memory_mb\", 0.0))\n 401:             resource_footprint = -(cpu_need + mem_need/1000.0 + gpu_need/1000.0)\n 402:             \n 403:             sort_key = (priority_tier, runtime_key, resource_footprint, test_id)  # test_id for determinism",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 400,
          "context": " 397:             # 3) Tie-breaker: resource footprint (higher resource tests first for better packing)\n 398:             cpu_need = float(est.get(\"cpu_cores_needed\", 1.0))\n 399:             mem_need = float(est.get(\"memory_mb\", 500.0))\n 400: >>>         gpu_need = float(est.get(\"gpu_memory_mb\", 0.0))\n 401:             resource_footprint = -(cpu_need + mem_need/1000.0 + gpu_need/1000.0)\n 402:             \n 403:             sort_key = (priority_tier, runtime_key, resource_footprint, test_id)  # test_id for determinism",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 401,
          "context": " 398:             cpu_need = float(est.get(\"cpu_cores_needed\", 1.0))\n 399:             mem_need = float(est.get(\"memory_mb\", 500.0))\n 400:             gpu_need = float(est.get(\"gpu_memory_mb\", 0.0))\n 401: >>>         resource_footprint = -(cpu_need + mem_need/1000.0 + gpu_need/1000.0)\n 402:             \n 403:             sort_key = (priority_tier, runtime_key, resource_footprint, test_id)  # test_id for determinism\n 404:             pending.append((sort_key, test_id, tier, est, timeout_sec))",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 411,
          "context": " 408:         # Track running usage and results\n 409:         running_cpu = 0.0\n 410:         running_mem = 0.0\n 411: >>>     running_gpu = 0.0\n 412:         running: List[Dict] = []  # dict with keys: id,tier,est,async\n 413:         all_results: List[Tuple[str, int, Dict]] = []\n 414:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 457,
          "context": " 454:                     cpu_cap = 2.0\n 455:                     need_cpu = min(need_cpu_raw, cpu_cap)\n 456:                     need_mem = float(est.get(\"memory_mb\", 500.0))\n 457: >>>                 need_gpu = float(est.get(\"gpu_memory_mb\", 0.0))\n 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 457,
          "context": " 454:                     cpu_cap = 2.0\n 455:                     need_cpu = min(need_cpu_raw, cpu_cap)\n 456:                     need_mem = float(est.get(\"memory_mb\", 500.0))\n 457: >>>                 need_gpu = float(est.get(\"gpu_memory_mb\", 0.0))\n 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 461,
          "context": " 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb\n 461: >>>                 fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463:                     # Also ensure we don't exceed pool parallelism with too many scheduled\n 464:                     if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 461,
          "context": " 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb\n 461: >>>                 fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463:                     # Also ensure we don't exceed pool parallelism with too many scheduled\n 464:                     if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 461,
          "context": " 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb\n 461: >>>                 fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463:                     # Also ensure we don't exceed pool parallelism with too many scheduled\n 464:                     if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 461,
          "context": " 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb\n 461: >>>                 fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463:                     # Also ensure we don't exceed pool parallelism with too many scheduled\n 464:                     if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 461,
          "context": " 458:     \n 459:                     fits_cpu = (running_cpu + need_cpu) <= cpu_cores_budget\n 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb\n 461: >>>                 fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463:                     # Also ensure we don't exceed pool parallelism with too many scheduled\n 464:                     if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 464,
          "context": " 461:                     fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463:                     # Also ensure we don't exceed pool parallelism with too many scheduled\n 464: >>>                 if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:\n 465:                         ar = pool.apply_async(run_single_test, args=(tid, tier, timeout_sec))\n 466:                         running.append({\n 467:                             \"id\": tid,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 476,
          "context": " 473:                             \"need_cpu_raw\": need_cpu_raw,\n 474:                             \"cpu_cap\": cpu_cap,\n 475:                             \"need_mem\": need_mem,\n 476: >>>                         \"need_gpu\": need_gpu,\n 477:                             \"started_at\": time.time(),\n 478:                             \"enqueued_at\": est.get(\"enqueued_at\", time.time()),\n 479:                             \"concurrency_at_start\": len(running),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 476,
          "context": " 473:                             \"need_cpu_raw\": need_cpu_raw,\n 474:                             \"cpu_cap\": cpu_cap,\n 475:                             \"need_mem\": need_mem,\n 476: >>>                         \"need_gpu\": need_gpu,\n 477:                             \"started_at\": time.time(),\n 478:                             \"enqueued_at\": est.get(\"enqueued_at\", time.time()),\n 479:                             \"concurrency_at_start\": len(running),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 483,
          "context": " 480:                             \"was_forced\": False,\n 481:                             \"fit_denied_cpu\": est.get(\"fit_denied_cpu\", 0),\n 482:                             \"fit_denied_mem\": est.get(\"fit_denied_mem\", 0),\n 483: >>>                         \"fit_denied_gpu\": est.get(\"fit_denied_gpu\", 0)\n 484:                         })\n 485:                         running_cpu += need_cpu\n 486:                         running_mem += need_mem",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 483,
          "context": " 480:                             \"was_forced\": False,\n 481:                             \"fit_denied_cpu\": est.get(\"fit_denied_cpu\", 0),\n 482:                             \"fit_denied_mem\": est.get(\"fit_denied_mem\", 0),\n 483: >>>                         \"fit_denied_gpu\": est.get(\"fit_denied_gpu\", 0)\n 484:                         })\n 485:                         running_cpu += need_cpu\n 486:                         running_mem += need_mem",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 487,
          "context": " 484:                         })\n 485:                         running_cpu += need_cpu\n 486:                         running_mem += need_mem\n 487: >>>                     running_gpu += need_gpu\n 488:                         # Remove from pending without skipping next item (since we removed current index)\n 489:                         pending.pop(i)\n 490:                         started_any = True",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 487,
          "context": " 484:                         })\n 485:                         running_cpu += need_cpu\n 486:                         running_mem += need_mem\n 487: >>>                     running_gpu += need_gpu\n 488:                         # Remove from pending without skipping next item (since we removed current index)\n 489:                         pending.pop(i)\n 490:                         started_any = True",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 497,
          "context": " 494:                             est[\"fit_denied_cpu\"] = est.get(\"fit_denied_cpu\", 0) + 1\n 495:                         if not fits_mem:\n 496:                             est[\"fit_denied_mem\"] = est.get(\"fit_denied_mem\", 0) + 1\n 497: >>>                     if not fits_gpu:\n 498:                             est[\"fit_denied_gpu\"] = est.get(\"fit_denied_gpu\", 0) + 1\n 499:                         i += 1\n 500:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 498,
          "context": " 495:                         if not fits_mem:\n 496:                             est[\"fit_denied_mem\"] = est.get(\"fit_denied_mem\", 0) + 1\n 497:                         if not fits_gpu:\n 498: >>>                         est[\"fit_denied_gpu\"] = est.get(\"fit_denied_gpu\", 0) + 1\n 499:                         i += 1\n 500:     \n 501:                 # If nothing could be started, wait for any completion or force-start if stalled",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 498,
          "context": " 495:                         if not fits_mem:\n 496:                             est[\"fit_denied_mem\"] = est.get(\"fit_denied_mem\", 0) + 1\n 497:                         if not fits_gpu:\n 498: >>>                         est[\"fit_denied_gpu\"] = est.get(\"fit_denied_gpu\", 0) + 1\n 499:                         i += 1\n 500:     \n 501:                 # If nothing could be started, wait for any completion or force-start if stalled",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 511,
          "context": " 508:                             sort_key, tid, tier, est, timeout_sec = pending[0]\n 509:                             need_cpu_check = min(float(est.get(\"cpu_cores_needed\", 1.0)), 2.0)\n 510:                             need_mem_check = float(est.get(\"memory_mb\", 500.0))\n 511: >>>                         need_gpu_check = float(est.get(\"gpu_memory_mb\", 0.0))\n 512:                             fits_cpu_check = need_cpu_check <= cpu_cores_budget\n 513:                             fits_mem_check = need_mem_check <= mem_budget_mb\n 514:                             fits_gpu_check = True if gpu_budget_mb <= 0.0 else need_gpu_check <= gpu_budget_mb",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 511,
          "context": " 508:                             sort_key, tid, tier, est, timeout_sec = pending[0]\n 509:                             need_cpu_check = min(float(est.get(\"cpu_cores_needed\", 1.0)), 2.0)\n 510:                             need_mem_check = float(est.get(\"memory_mb\", 500.0))\n 511: >>>                         need_gpu_check = float(est.get(\"gpu_memory_mb\", 0.0))\n 512:                             fits_cpu_check = need_cpu_check <= cpu_cores_budget\n 513:                             fits_mem_check = need_mem_check <= mem_budget_mb\n 514:                             fits_gpu_check = True if gpu_budget_mb <= 0.0 else need_gpu_check <= gpu_budget_mb",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 514,
          "context": " 511:                             need_gpu_check = float(est.get(\"gpu_memory_mb\", 0.0))\n 512:                             fits_cpu_check = need_cpu_check <= cpu_cores_budget\n 513:                             fits_mem_check = need_mem_check <= mem_budget_mb\n 514: >>>                         fits_gpu_check = True if gpu_budget_mb <= 0.0 else need_gpu_check <= gpu_budget_mb\n 515:                             reasons = []\n 516:                             if not fits_cpu_check:\n 517:                                 reasons.append(f\"CPU:{need_cpu_check:.1f}>{cpu_cores_budget:.1f}\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 514,
          "context": " 511:                             need_gpu_check = float(est.get(\"gpu_memory_mb\", 0.0))\n 512:                             fits_cpu_check = need_cpu_check <= cpu_cores_budget\n 513:                             fits_mem_check = need_mem_check <= mem_budget_mb\n 514: >>>                         fits_gpu_check = True if gpu_budget_mb <= 0.0 else need_gpu_check <= gpu_budget_mb\n 515:                             reasons = []\n 516:                             if not fits_cpu_check:\n 517:                                 reasons.append(f\"CPU:{need_cpu_check:.1f}>{cpu_cores_budget:.1f}\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 514,
          "context": " 511:                             need_gpu_check = float(est.get(\"gpu_memory_mb\", 0.0))\n 512:                             fits_cpu_check = need_cpu_check <= cpu_cores_budget\n 513:                             fits_mem_check = need_mem_check <= mem_budget_mb\n 514: >>>                         fits_gpu_check = True if gpu_budget_mb <= 0.0 else need_gpu_check <= gpu_budget_mb\n 515:                             reasons = []\n 516:                             if not fits_cpu_check:\n 517:                                 reasons.append(f\"CPU:{need_cpu_check:.1f}>{cpu_cores_budget:.1f}\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 514,
          "context": " 511:                             need_gpu_check = float(est.get(\"gpu_memory_mb\", 0.0))\n 512:                             fits_cpu_check = need_cpu_check <= cpu_cores_budget\n 513:                             fits_mem_check = need_mem_check <= mem_budget_mb\n 514: >>>                         fits_gpu_check = True if gpu_budget_mb <= 0.0 else need_gpu_check <= gpu_budget_mb\n 515:                             reasons = []\n 516:                             if not fits_cpu_check:\n 517:                                 reasons.append(f\"CPU:{need_cpu_check:.1f}>{cpu_cores_budget:.1f}\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 520,
          "context": " 517:                                 reasons.append(f\"CPU:{need_cpu_check:.1f}>{cpu_cores_budget:.1f}\")\n 518:                             if not fits_mem_check:\n 519:                                 reasons.append(f\"RAM:{need_mem_check:.0f}MB>{mem_budget_mb:.0f}MB\")\n 520: >>>                         if not fits_gpu_check:\n 521:                                 reasons.append(f\"GPU:{need_gpu_check:.0f}MB>{gpu_budget_mb:.0f}MB\")\n 522:                             if reasons:\n 523:                                 print(f\"[Scheduler] {tid} waiting (exceeds budget: {', '.join(reasons)})\", flush=True)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 521,
          "context": " 518:                             if not fits_mem_check:\n 519:                                 reasons.append(f\"RAM:{need_mem_check:.0f}MB>{mem_budget_mb:.0f}MB\")\n 520:                             if not fits_gpu_check:\n 521: >>>                             reasons.append(f\"GPU:{need_gpu_check:.0f}MB>{gpu_budget_mb:.0f}MB\")\n 522:                             if reasons:\n 523:                                 print(f\"[Scheduler] {tid} waiting (exceeds budget: {', '.join(reasons)})\", flush=True)\n 524:                         # If stalled for > 10 seconds, force start the next pending test ignoring budget constraints",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 521,
          "context": " 518:                             if not fits_mem_check:\n 519:                                 reasons.append(f\"RAM:{need_mem_check:.0f}MB>{mem_budget_mb:.0f}MB\")\n 520:                             if not fits_gpu_check:\n 521: >>>                             reasons.append(f\"GPU:{need_gpu_check:.0f}MB>{gpu_budget_mb:.0f}MB\")\n 522:                             if reasons:\n 523:                                 print(f\"[Scheduler] {tid} waiting (exceeds budget: {', '.join(reasons)})\", flush=True)\n 524:                         # If stalled for > 10 seconds, force start the next pending test ignoring budget constraints",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 521,
          "context": " 518:                             if not fits_mem_check:\n 519:                                 reasons.append(f\"RAM:{need_mem_check:.0f}MB>{mem_budget_mb:.0f}MB\")\n 520:                             if not fits_gpu_check:\n 521: >>>                             reasons.append(f\"GPU:{need_gpu_check:.0f}MB>{gpu_budget_mb:.0f}MB\")\n 522:                             if reasons:\n 523:                                 print(f\"[Scheduler] {tid} waiting (exceeds budget: {', '.join(reasons)})\", flush=True)\n 524:                         # If stalled for > 10 seconds, force start the next pending test ignoring budget constraints",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 532,
          "context": " 529:                             cpu_cap = 2.0\n 530:                             need_cpu = min(need_cpu_raw, cpu_cap)\n 531:                             need_mem = float(est.get(\"memory_mb\", 500.0))\n 532: >>>                         need_gpu = float(est.get(\"gpu_memory_mb\", 0.0))\n 533:                             print(\n 534:                                 f\"[Scheduler] Starvation guard: no tasks running for >10s. Forcing start of {tid} \"\n 535:                                 f\"(cpu={need_cpu:.1f}, mem={need_mem:.0f}MB, gpu={need_gpu:.0f}MB)\",",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 532,
          "context": " 529:                             cpu_cap = 2.0\n 530:                             need_cpu = min(need_cpu_raw, cpu_cap)\n 531:                             need_mem = float(est.get(\"memory_mb\", 500.0))\n 532: >>>                         need_gpu = float(est.get(\"gpu_memory_mb\", 0.0))\n 533:                             print(\n 534:                                 f\"[Scheduler] Starvation guard: no tasks running for >10s. Forcing start of {tid} \"\n 535:                                 f\"(cpu={need_cpu:.1f}, mem={need_mem:.0f}MB, gpu={need_gpu:.0f}MB)\",",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 535,
          "context": " 532:                             need_gpu = float(est.get(\"gpu_memory_mb\", 0.0))\n 533:                             print(\n 534:                                 f\"[Scheduler] Starvation guard: no tasks running for >10s. Forcing start of {tid} \"\n 535: >>>                             f\"(cpu={need_cpu:.1f}, mem={need_mem:.0f}MB, gpu={need_gpu:.0f}MB)\",\n 536:                                 flush=True\n 537:                             )\n 538:                             ar = pool.apply_async(run_single_test, args=(tid, tier, timeout_sec))",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 535,
          "context": " 532:                             need_gpu = float(est.get(\"gpu_memory_mb\", 0.0))\n 533:                             print(\n 534:                                 f\"[Scheduler] Starvation guard: no tasks running for >10s. Forcing start of {tid} \"\n 535: >>>                             f\"(cpu={need_cpu:.1f}, mem={need_mem:.0f}MB, gpu={need_gpu:.0f}MB)\",\n 536:                                 flush=True\n 537:                             )\n 538:                             ar = pool.apply_async(run_single_test, args=(tid, tier, timeout_sec))",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 549,
          "context": " 546:                                 \"need_cpu_raw\": need_cpu_raw,\n 547:                                 \"cpu_cap\": cpu_cap,\n 548:                                 \"need_mem\": need_mem,\n 549: >>>                             \"need_gpu\": need_gpu,\n 550:                                 \"started_at\": time.time(),\n 551:                                 \"enqueued_at\": est.get(\"enqueued_at\", time.time()),\n 552:                                 \"concurrency_at_start\": 0,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 549,
          "context": " 546:                                 \"need_cpu_raw\": need_cpu_raw,\n 547:                                 \"cpu_cap\": cpu_cap,\n 548:                                 \"need_mem\": need_mem,\n 549: >>>                             \"need_gpu\": need_gpu,\n 550:                                 \"started_at\": time.time(),\n 551:                                 \"enqueued_at\": est.get(\"enqueued_at\", time.time()),\n 552:                                 \"concurrency_at_start\": 0,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 556,
          "context": " 553:                                 \"was_forced\": True,\n 554:                                 \"fit_denied_cpu\": est.get(\"fit_denied_cpu\", 0),\n 555:                                 \"fit_denied_mem\": est.get(\"fit_denied_mem\", 0),\n 556: >>>                             \"fit_denied_gpu\": est.get(\"fit_denied_gpu\", 0)\n 557:                             })\n 558:                             running_cpu += need_cpu\n 559:                             running_mem += need_mem",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 556,
          "context": " 553:                                 \"was_forced\": True,\n 554:                                 \"fit_denied_cpu\": est.get(\"fit_denied_cpu\", 0),\n 555:                                 \"fit_denied_mem\": est.get(\"fit_denied_mem\", 0),\n 556: >>>                             \"fit_denied_gpu\": est.get(\"fit_denied_gpu\", 0)\n 557:                             })\n 558:                             running_cpu += need_cpu\n 559:                             running_mem += need_mem",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 560,
          "context": " 557:                             })\n 558:                             running_cpu += need_cpu\n 559:                             running_mem += need_mem\n 560: >>>                         running_gpu += need_gpu\n 561:                             stall_since = None\n 562:                             continue\n 563:                     else:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 560,
          "context": " 557:                             })\n 558:                             running_cpu += need_cpu\n 559:                             running_mem += need_mem\n 560: >>>                         running_gpu += need_gpu\n 561:                             stall_since = None\n 562:                             continue\n 563:                     else:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 582,
          "context": " 579:                     test_id_done, tier_done, metrics = res\n 580:                     running_cpu -= item[\"need_cpu\"]\n 581:                     running_mem -= item[\"need_mem\"]\n 582: >>>                 running_gpu -= item[\"need_gpu\"]\n 583:                     \n 584:                     # Retry logic for timeouts and exceptions\n 585:                     exit_code = metrics.get(\"exit_code\", 1)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 582,
          "context": " 579:                     test_id_done, tier_done, metrics = res\n 580:                     running_cpu -= item[\"need_cpu\"]\n 581:                     running_mem -= item[\"need_mem\"]\n 582: >>>                 running_gpu -= item[\"need_gpu\"]\n 583:                     \n 584:                     # Retry logic for timeouts and exceptions\n 585:                     exit_code = metrics.get(\"exit_code\", 1)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 620,
          "context": " 617:                         metrics[\"was_forced_by_starvation\"] = item[\"was_forced\"]\n 618:                         metrics[\"fit_denied_cpu\"] = item[\"fit_denied_cpu\"]\n 619:                         metrics[\"fit_denied_mem\"] = item[\"fit_denied_mem\"]\n 620: >>>                     metrics[\"fit_denied_gpu\"] = item[\"fit_denied_gpu\"]\n 621:                         metrics[\"cpu_cores_needed_raw\"] = item.get(\"need_cpu_raw\", metrics.get(\"cpu_cores_needed_raw\"))\n 622:                         metrics[\"cpu_cores_used_for_budget\"] = item.get(\"need_cpu\", metrics.get(\"cpu_cores_used_for_budget\"))\n 623:                         metrics[\"cpu_cap_applied\"] = (item.get(\"need_cpu_raw\") or 0) > (item.get(\"need_cpu\") or 0)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 620,
          "context": " 617:                         metrics[\"was_forced_by_starvation\"] = item[\"was_forced\"]\n 618:                         metrics[\"fit_denied_cpu\"] = item[\"fit_denied_cpu\"]\n 619:                         metrics[\"fit_denied_mem\"] = item[\"fit_denied_mem\"]\n 620: >>>                     metrics[\"fit_denied_gpu\"] = item[\"fit_denied_gpu\"]\n 621:                         metrics[\"cpu_cores_needed_raw\"] = item.get(\"need_cpu_raw\", metrics.get(\"cpu_cores_needed_raw\"))\n 622:                         metrics[\"cpu_cores_used_for_budget\"] = item.get(\"need_cpu\", metrics.get(\"cpu_cores_used_for_budget\"))\n 623:                         metrics[\"cpu_cap_applied\"] = (item.get(\"need_cpu_raw\") or 0) > (item.get(\"need_cpu\") or 0)",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> Parallel test runner using multiprocessing for maximum speed.\n  10:     Output is buffered per-test but progress is reported when each test completes.\n  11:     \n  12:     Resource estimation and scheduling:",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> Parallel test runner using multiprocessing for maximum speed.\n  10:     Output is buffered per-test but progress is reported when each test completes.\n  11:     \n  12:     Resource estimation and scheduling:",
          "match": "multiprocess"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 24,
          "context": "  21:     import sys\n  22:     import time\n  23:     import argparse\n  24: >>> import multiprocessing as mp\n  25:     from pathlib import Path\n  26:     from typing import Tuple, Dict, List, Optional\n  27:     import json",
          "match": "multiprocess"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 221,
          "context": " 218:     \n 219:     def parse_args():\n 220:         \"\"\"Parse command line arguments.\"\"\"\n 221: >>>     parser = argparse.ArgumentParser(description=\"Run tests in parallel for maximum speed\")\n 222:         \n 223:         group = parser.add_mutually_exclusive_group(required=True)\n 224:         group.add_argument(\"--fast\", action=\"store_true\",",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 232,
          "context": " 229:                           help=\"Run specific tests (comma-separated, e.g. 'REL-01,GRAV-12')\")\n 230:         \n 231:         parser.add_argument(\"--workers\", type=int, default=None,\n 232: >>>                        help=\"Number of parallel workers (default: CPU count - 2)\")\n 233:         parser.add_argument(\"--timeout\", type=int, default=7200,\n 234:                            help=\"Minimum per-test timeout in seconds (default: 7200 = 120 min). Adaptive estimates may increase this for long tests.\")\n 235:         # Optional post-run hooks",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 291,
          "context": " 288:     \n 289:     \n 290:     def main():\n 291: >>>     \"\"\"Run tests in parallel.\"\"\"\n 292:         args = parse_args()\n 293:         \n 294:         # Determine test list",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 354,
          "context": " 351:             num_workers = min(cpu_cores_total, len(tests))\n 352:     \n 353:         print(\"=\"*70)\n 354: >>>     print(\"PARALLEL TEST RUNNER\")\n 355:         print(\"=\"*70)\n 356:         print(f\"Running {len(tests)} tests with pool size {num_workers}\")\n 357:         print(f\"Budgets -> CPU cores: {cpu_cores_budget:.1f}, RAM: {mem_budget_mb:.0f} MB, GPU: {gpu_budget_mb:.0f} MB\")",
          "match": "PARALLEL"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 463,
          "context": " 460:                     fits_mem = (running_mem + need_mem) <= mem_budget_mb\n 461:                     fits_gpu = True if gpu_budget_mb <= 0.0 else (running_gpu + need_gpu) <= gpu_budget_mb\n 462:     \n 463: >>>                 # Also ensure we don't exceed pool parallelism with too many scheduled\n 464:                     if fits_cpu and fits_mem and fits_gpu and len(running) < num_workers:\n 465:                         ar = pool.apply_async(run_single_test, args=(tid, tier, timeout_sec))\n 466:                         running.append({",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 803,
          "context": " 800:     \n 801:     \n 802:     if __name__ == \"__main__\":\n 803: >>>     # Required for Windows multiprocessing\n 804:         mp.freeze_support()\n 805:         main()\n 806:     ",
          "match": "multiprocess"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 157,
          "context": " 154:                         \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 155:                     })\n 156:                 \n 157: >>>             # Poll resources periodically\n 158:                 now = time.time()\n 159:                 if now - last_poll >= poll_interval:\n 160:                     if ps_process:",
          "match": "periodic"
        }
      ],
      "line_count": 805,
      "docstring": "Parallel test runner using multiprocessing for maximum speed.\nOutput is buffered per-test but progress is reported when each test completes.\n\nResource estimation and scheduling:\n- Uses last successful run metrics for each test (not historical averages)\n- Hybrid scheduling: priority tiers + longest-job-first within tier\n- Dynamic budgets based on available CPU/RAM/GPU at start time\n- Starvation guard ensures progress even when tests exceed budgets\n- Metrics DB (test_metrics_history.json) is committed as seed data for new users"
    },
    {
      "filepath": "devtests\\test_double_slit_nogui.py",
      "category": "USER_INTERFACE",
      "priority": 8,
      "file_hash": "d21abbafb969f6c2",
      "file_size": 7222,
      "modified": "2025-11-02T21:26:22.509960",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 19,
          "context": "  16:     sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n  17:     from lfm_equation import lattice_step\n  18:     \n  19: >>> def test_double_slit():\n  20:         \"\"\"Test double slit wave propagation without GUI\"\"\"\n  21:         \n  22:         # Grid setup",
          "match": "def test_double_slit():"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 125,
          "context": " 122:                 print(f\"  Step {i:4d}: max={max_field:.3f}, barrier={field_at_barrier:.3f}, \"\n 123:                       f\"behind={field_behind_barrier:.3f}, screen={field_at_screen:.3f}, E={energy:.2f}\")\n 124:                 \n 125: >>>             # Check for numerical instability\n 126:                 if max_field > 100 or np.isnan(max_field):\n 127:                     print(f\"\\n❌ NUMERICAL INSTABILITY at step {i}\")\n 128:                     print(f\"   max_field = {max_field}\")",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 127,
          "context": " 124:                 \n 125:                 # Check for numerical instability\n 126:                 if max_field > 100 or np.isnan(max_field):\n 127: >>>                 print(f\"\\n❌ NUMERICAL INSTABILITY at step {i}\")\n 128:                     print(f\"   max_field = {max_field}\")\n 129:                     return False\n 130:                 ",
          "match": "STABILITY"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 173,
          "context": " 170:         passed = True\n 171:         issues = []\n 172:         \n 173: >>>     # 1. Numerical stability\n 174:         final_max = np.max(np.abs(E))\n 175:         if final_max > 100 or np.isnan(final_max):\n 176:             passed = False",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 177,
          "context": " 174:         final_max = np.max(np.abs(E))\n 175:         if final_max > 100 or np.isnan(final_max):\n 176:             passed = False\n 177: >>>         issues.append(\"Numerical instability\")\n 178:         else:\n 179:             print(\"✓ Numerically stable\")\n 180:         ",
          "match": "stability"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 68,
          "context": "  65:             'alpha': 1.0,\n  66:             'beta': 1.0,  # Must be > 0 for wave equation\n  67:             'gamma_damp': gamma_damp,\n  68: >>>         'boundary': 'periodic',\n  69:             'stencil_order': 2,\n  70:             'precision': 'float64'\n  71:         }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 68,
          "context": "  65:             'alpha': 1.0,\n  66:             'beta': 1.0,  # Must be > 0 for wave equation\n  67:             'gamma_damp': gamma_damp,\n  68: >>>         'boundary': 'periodic',\n  69:             'stencil_order': 2,\n  70:             'precision': 'float64'\n  71:         }",
          "match": "periodic"
        }
      ],
      "line_count": 211,
      "docstring": "Headless test of double slit scenario physics\nNo pygame, no matplotlib GUI - just numerical validation"
    },
    {
      "filepath": "lfm_control_center.py",
      "category": "USER_INTERFACE",
      "priority": 8,
      "file_hash": "732bc02bf855e5aa",
      "file_size": 11874,
      "modified": "2025-11-03T13:19:47.498239",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 24,
          "context": "  21:     import json\n  22:     \n  23:     # ANSI colors for better console output\n  24: >>> class Colors:\n  25:         GREEN = '\\033[92m'\n  26:         YELLOW = '\\033[93m' \n  27:         RED = '\\033[91m'",
          "match": "class Colors:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 34,
          "context": "  31:         BOLD = '\\033[1m'\n  32:         END = '\\033[0m'\n  33:     \n  34: >>> def clear_screen():\n  35:         \"\"\"Clear the console screen\"\"\"\n  36:         os.system('cls' if os.name == 'nt' else 'clear')\n  37:     ",
          "match": "def clear_screen():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 38,
          "context": "  35:         \"\"\"Clear the console screen\"\"\"\n  36:         os.system('cls' if os.name == 'nt' else 'clear')\n  37:     \n  38: >>> def print_header():\n  39:         \"\"\"Print the LFM banner\"\"\"\n  40:         print(f\"{Colors.CYAN}{Colors.BOLD}\")\n  41:         print(\"=\" * 60)",
          "match": "def print_header():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:         print(\"=\" * 60)\n  45:         print(f\"{Colors.END}\")\n  46:     \n  47: >>> def print_menu():\n  48:         \"\"\"Print the main menu options\"\"\"\n  49:         print(f\"\\n{Colors.WHITE}{Colors.BOLD}MAIN MENU:{Colors.END}\")\n  50:         print(f\"{Colors.GREEN}1.{Colors.END} Run Fast Tests (4 tests, ~2 minutes)\")",
          "match": "def print_menu():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:         print(f\"{Colors.RED}9.{Colors.END} Exit\")\n  59:         print()\n  60:     \n  61: >>> def get_test_status():\n  62:         \"\"\"Get summary of recent test results\"\"\"\n  63:         try:\n  64:             master_status = Path(\"results/MASTER_TEST_STATUS.csv\")",
          "match": "def get_test_status():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 76,
          "context": "  73:             pass\n  74:         return \"No test results found\"\n  75:     \n  76: >>> def run_command_with_progress(cmd: List[str], description: str):\n  77:         \"\"\"Run a command and show progress\"\"\"\n  78:         print(f\"\\n{Colors.BLUE}Starting: {description}{Colors.END}\")\n  79:         print(f\"Command: {' '.join(cmd)}\")",
          "match": "def run_command_with_progress(cmd:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 106,
          "context": " 103:         input(f\"\\n{Colors.YELLOW}Press Enter to continue...{Colors.END}\")\n 104:         return process.returncode == 0\n 105:     \n 106: >>> def select_tier():\n 107:         \"\"\"Let user select which tier to run\"\"\"\n 108:         print(f\"\\n{Colors.WHITE}Select Tier:{Colors.END}\")\n 109:         print(f\"{Colors.GREEN}1.{Colors.END} Tier 1 - Relativistic (15 tests)\")",
          "match": "def select_tier():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 120,
          "context": " 117:                 return int(choice)\n 118:             print(f\"{Colors.RED}Invalid choice. Please enter 1, 2, 3, or 4.{Colors.END}\")\n 119:     \n 120: >>> def select_specific_test():\n 121:         \"\"\"Let user select a specific test to run\"\"\"\n 122:         print(f\"\\n{Colors.WHITE}Enter test ID (e.g., REL-01, GRAV-12, ENER-03, QUAN-05):{Colors.END}\")\n 123:         test_id = input(f\"{Colors.CYAN}Test ID: {Colors.END}\").strip().upper()",
          "match": "def select_specific_test():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 133,
          "context": " 130:             print(f\"{Colors.RED}Invalid test ID format. Use REL-xx, GRAV-xx, ENER-xx, or QUAN-xx{Colors.END}\")\n 131:             return None\n 132:     \n 133: >>> def view_results_menu():\n 134:         \"\"\"Show results viewing options\"\"\"\n 135:         clear_screen()\n 136:         print_header()",
          "match": "def view_results_menu():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 175,
          "context": " 172:                 else:\n 173:                     subprocess.run(['xdg-open', str(cat_dir)])\n 174:     \n 175: >>> def run_emergence_test():\n 176:         \"\"\"Run the emergence validation test\"\"\"\n 177:         clear_screen()\n 178:         print_header()",
          "match": "def run_emergence_test():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 189,
          "context": " 186:             cmd = [\"python\", \"docs/evidence/emergence_validation/test_emergence_proof.py\"]\n 187:             return run_command_with_progress(cmd, \"Emergence Validation Test\")\n 188:     \n 189: >>> def generate_reports():\n 190:         \"\"\"Generate various reports\"\"\"\n 191:         clear_screen()\n 192:         print_header()",
          "match": "def generate_reports():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 211,
          "context": " 208:             cmd = [\"python\", \"tools/build_upload_package.py\"]\n 209:             return run_command_with_progress(cmd, \"Building Upload Package\")\n 210:     \n 211: >>> def show_system_status():\n 212:         \"\"\"Show system information and status\"\"\"\n 213:         clear_screen()\n 214:         print_header()",
          "match": "def show_system_status():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 240,
          "context": " 237:         \n 238:         input(f\"\\n{Colors.YELLOW}Press Enter to continue...{Colors.END}\")\n 239:     \n 240: >>> def main():\n 241:         \"\"\"Main control loop\"\"\"\n 242:         while True:\n 243:             clear_screen()",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 220,
          "context": " 217:         # Python version\n 218:         print(f\"Python Version: {sys.version}\")\n 219:         \n 220: >>>     # GPU status\n 221:         try:\n 222:             import cupy\n 223:             print(f\"{Colors.GREEN}✓ GPU (CuPy) Available{Colors.END}\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 222,
          "context": " 219:         \n 220:         # GPU status\n 221:         try:\n 222: >>>         import cupy\n 223:             print(f\"{Colors.GREEN}✓ GPU (CuPy) Available{Colors.END}\")\n 224:         except ImportError:\n 225:             print(f\"{Colors.YELLOW}⚠ GPU (CuPy) Not Available - CPU Only{Colors.END}\")",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 223,
          "context": " 220:         # GPU status\n 221:         try:\n 222:             import cupy\n 223: >>>         print(f\"{Colors.GREEN}✓ GPU (CuPy) Available{Colors.END}\")\n 224:         except ImportError:\n 225:             print(f\"{Colors.YELLOW}⚠ GPU (CuPy) Not Available - CPU Only{Colors.END}\")\n 226:         ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 223,
          "context": " 220:         # GPU status\n 221:         try:\n 222:             import cupy\n 223: >>>         print(f\"{Colors.GREEN}✓ GPU (CuPy) Available{Colors.END}\")\n 224:         except ImportError:\n 225:             print(f\"{Colors.YELLOW}⚠ GPU (CuPy) Not Available - CPU Only{Colors.END}\")\n 226:         ",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 225,
          "context": " 222:             import cupy\n 223:             print(f\"{Colors.GREEN}✓ GPU (CuPy) Available{Colors.END}\")\n 224:         except ImportError:\n 225: >>>         print(f\"{Colors.YELLOW}⚠ GPU (CuPy) Not Available - CPU Only{Colors.END}\")\n 226:         \n 227:         # Test status\n 228:         status = get_test_status()",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 225,
          "context": " 222:             import cupy\n 223:             print(f\"{Colors.GREEN}✓ GPU (CuPy) Available{Colors.END}\")\n 224:         except ImportError:\n 225: >>>         print(f\"{Colors.YELLOW}⚠ GPU (CuPy) Not Available - CPU Only{Colors.END}\")\n 226:         \n 227:         # Test status\n 228:         status = get_test_status()",
          "match": "CuPy"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 256,
          "context": " 253:             \n 254:             if choice == '1':\n 255:                 # Fast tests\n 256: >>>             cmd = [\"python\", \"run_parallel_tests.py\", \"--fast\"]\n 257:                 run_command_with_progress(cmd, \"Fast Test Suite (4 tests)\")\n 258:                 \n 259:             elif choice == '2':",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 263,
          "context": " 260:                 # Single tier\n 261:                 tier = select_tier()\n 262:                 if tier:\n 263: >>>                 cmd = [\"python\", \"run_parallel_tests.py\", \"--tiers\", str(tier)]\n 264:                     run_command_with_progress(cmd, f\"Tier {tier} Test Suite\")\n 265:             \n 266:             elif choice == '3':",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 270,
          "context": " 267:                 # Specific test\n 268:                 test_id = select_specific_test()\n 269:                 if test_id:\n 270: >>>                 cmd = [\"python\", \"run_parallel_tests.py\", \"--tests\", test_id]\n 271:                     run_command_with_progress(cmd, f\"Test {test_id}\")\n 272:             \n 273:             elif choice == '4':",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 278,
          "context": " 275:                 print(f\"\\n{Colors.YELLOW}Warning: This will run all 55 tests and may take 30+ minutes.{Colors.END}\")\n 276:                 confirm = input(f\"{Colors.CYAN}Continue? (y/N): {Colors.END}\")\n 277:                 if confirm.lower() == 'y':\n 278: >>>                 cmd = [\"python\", \"run_parallel_tests.py\", \"--tiers\", \"1,2,3,4\"]\n 279:                     run_command_with_progress(cmd, \"Full Test Suite (All Tiers)\")\n 280:             \n 281:             elif choice == '5':",
          "match": "parallel"
        }
      ],
      "line_count": 313,
      "docstring": "LFM Control Center - Simple Console Interface\n==============================================\nA user-friendly menu system for running LFM tests and viewing results.\nNo web frameworks - just enhanced console interaction."
    },
    {
      "filepath": "lfm_gui.py",
      "category": "USER_INTERFACE",
      "priority": 8,
      "file_hash": "0e85e40745586bdf",
      "file_size": 18202,
      "modified": "2025-11-03T13:19:47.530943",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 24,
          "context": "  21:     from pathlib import Path\n  22:     import os\n  23:     \n  24: >>> class LFMControlCenter:\n  25:         def __init__(self, root):\n  26:             self.root = root\n  27:             self.root.title(\"LFM Control Center - Lattice Field Medium\")",
          "match": "class LFMControlCenter:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     import os\n  23:     \n  24:     class LFMControlCenter:\n  25: >>>     def __init__(self, root):\n  26:             self.root = root\n  27:             self.root.title(\"LFM Control Center - Lattice Field Medium\")\n  28:             self.root.geometry(\"800x600\")",
          "match": "def __init__(self, root):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:             self.setup_ui()\n  37:             self.check_queue()\n  38:         \n  39: >>>     def setup_ui(self):\n  40:             \"\"\"Setup the main user interface\"\"\"\n  41:             # Create notebook for tabs\n  42:             notebook = ttk.Notebook(self.root)",
          "match": "def setup_ui(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:             status_bar = ttk.Label(self.root, textvariable=self.status_var, relief=tk.SUNKEN)\n  64:             status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n  65:         \n  66: >>>     def setup_test_tab(self):\n  67:             \"\"\"Setup the test execution tab\"\"\"\n  68:             # Header\n  69:             header = ttk.Label(self.test_frame, text=\"LFM Test Suite Runner\", ",
          "match": "def setup_test_tab(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 133,
          "context": " 130:                                          command=self.stop_process, state=tk.DISABLED)\n 131:             self.stop_button.pack(side=tk.RIGHT, padx=5)\n 132:         \n 133: >>>     def setup_results_tab(self):\n 134:             \"\"\"Setup the results viewing tab\"\"\"\n 135:             ttk.Label(self.results_frame, text=\"Test Results Browser\", \n 136:                      font=(\"Arial\", 14, \"bold\")).pack(pady=10)",
          "match": "def setup_results_tab(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 167,
          "context": " 164:             # Load initial results\n 165:             self.refresh_results()\n 166:         \n 167: >>>     def setup_tools_tab(self):\n 168:             \"\"\"Setup the tools and reports tab\"\"\"\n 169:             ttk.Label(self.tools_frame, text=\"Tools & Report Generation\", \n 170:                      font=(\"Arial\", 14, \"bold\")).pack(pady=10)",
          "match": "def setup_tools_tab(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 196,
          "context": " 193:             # Load initial system info\n 194:             self.refresh_system_info()\n 195:         \n 196: >>>     def run_fast_tests(self):\n 197:             \"\"\"Run the fast test suite\"\"\"\n 198:             cmd = [\"python\", \"run_parallel_tests.py\", \"--fast\"]\n 199:             self.run_command(cmd, \"Running fast tests...\")",
          "match": "def run_fast_tests(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 201,
          "context": " 198:             cmd = [\"python\", \"run_parallel_tests.py\", \"--fast\"]\n 199:             self.run_command(cmd, \"Running fast tests...\")\n 200:         \n 201: >>>     def run_emergence_test(self):\n 202:             \"\"\"Run the emergence validation test\"\"\"\n 203:             cmd = [\"python\", \"docs/evidence/emergence_validation/test_emergence_proof.py\"]\n 204:             self.run_command(cmd, \"Running emergence validation test...\")",
          "match": "def run_emergence_test(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 206,
          "context": " 203:             cmd = [\"python\", \"docs/evidence/emergence_validation/test_emergence_proof.py\"]\n 204:             self.run_command(cmd, \"Running emergence validation test...\")\n 205:         \n 206: >>>     def run_selected_tiers(self):\n 207:             \"\"\"Run tests from selected tiers\"\"\"\n 208:             selected_tiers = [str(tier) for tier, var in self.tier_vars.items() if var.get()]\n 209:             ",
          "match": "def run_selected_tiers(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 217,
          "context": " 214:             cmd = [\"python\", \"run_parallel_tests.py\", \"--tiers\", \",\".join(selected_tiers)]\n 215:             self.run_command(cmd, f\"Running tier(s) {', '.join(selected_tiers)}...\")\n 216:         \n 217: >>>     def run_specific_test(self):\n 218:             \"\"\"Run a specific test\"\"\"\n 219:             test_id = self.test_id_var.get().strip().upper()\n 220:             if not test_id:",
          "match": "def run_specific_test(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 227,
          "context": " 224:             cmd = [\"python\", \"run_parallel_tests.py\", \"--tests\", test_id]\n 225:             self.run_command(cmd, f\"Running test {test_id}...\")\n 226:         \n 227: >>>     def run_command(self, cmd, status_msg):\n 228:             \"\"\"Run a command in a separate thread\"\"\"\n 229:             if self.current_process and self.current_process.poll() is None:\n 230:                 messagebox.showwarning(\"Process Running\", \"A test is already running. Please wait or stop it first.\")",
          "match": "def run_command(self, cmd, status_msg):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 237,
          "context": " 234:             self.stop_button.config(state=tk.NORMAL)\n 235:             self.clear_output()\n 236:             \n 237: >>>         def run_in_thread():\n 238:                 try:\n 239:                     self.current_process = subprocess.Popen(\n 240:                         cmd,",
          "match": "def run_in_thread():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 259,
          "context": " 256:             thread = threading.Thread(target=run_in_thread, daemon=True)\n 257:             thread.start()\n 258:         \n 259: >>>     def stop_process(self):\n 260:             \"\"\"Stop the current process\"\"\"\n 261:             if self.current_process and self.current_process.poll() is None:\n 262:                 self.current_process.terminate()",
          "match": "def stop_process(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 267,
          "context": " 264:                 self.stop_button.config(state=tk.DISABLED)\n 265:                 self.status_var.set(\"Process stopped\")\n 266:         \n 267: >>>     def check_queue(self):\n 268:             \"\"\"Check for messages from background threads\"\"\"\n 269:             try:\n 270:                 while True:",
          "match": "def check_queue(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 294,
          "context": " 291:             # Schedule next check\n 292:             self.root.after(100, self.check_queue)\n 293:         \n 294: >>>     def clear_output(self):\n 295:             \"\"\"Clear the output text area\"\"\"\n 296:             self.output_text.delete(1.0, tk.END)\n 297:         ",
          "match": "def clear_output(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 298,
          "context": " 295:             \"\"\"Clear the output text area\"\"\"\n 296:             self.output_text.delete(1.0, tk.END)\n 297:         \n 298: >>>     def refresh_results(self):\n 299:             \"\"\"Refresh the results tree\"\"\"\n 300:             # Clear existing items\n 301:             for item in self.results_tree.get_children():",
          "match": "def refresh_results(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 340,
          "context": " 337:             for item in self.results_tree.get_children():\n 338:                 self.results_tree.item(item, open=True)\n 339:         \n 340: >>>     def open_results_folder(self):\n 341:             \"\"\"Open the results folder in file explorer\"\"\"\n 342:             results_dir = Path(\"results\")\n 343:             if results_dir.exists():",
          "match": "def open_results_folder(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 349,
          "context": " 346:                 else:  # Linux/Mac\n 347:                     subprocess.run(['xdg-open', str(results_dir)])\n 348:         \n 349: >>>     def view_test_details(self):\n 350:             \"\"\"View details of selected test\"\"\"\n 351:             selection = self.results_tree.selection()\n 352:             if not selection:",
          "match": "def view_test_details(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 373,
          "context": " 370:                 else:\n 371:                     subprocess.run(['xdg-open', str(test_dir)])\n 372:         \n 373: >>>     def update_test_status(self):\n 374:             \"\"\"Update master test status\"\"\"\n 375:             cmd = [\"python\", \"-c\", \"from lfm_results import update_master_test_status; update_master_test_status()\"]\n 376:             self.run_command(cmd, \"Updating master test status...\")",
          "match": "def update_test_status(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 378,
          "context": " 375:             cmd = [\"python\", \"-c\", \"from lfm_results import update_master_test_status; update_master_test_status()\"]\n 376:             self.run_command(cmd, \"Updating master test status...\")\n 377:         \n 378: >>>     def generate_results_report(self):\n 379:             \"\"\"Generate results report\"\"\"\n 380:             cmd = [\"python\", \"tools/compile_results_report.py\"]\n 381:             self.run_command(cmd, \"Generating results report...\")",
          "match": "def generate_results_report(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 383,
          "context": " 380:             cmd = [\"python\", \"tools/compile_results_report.py\"]\n 381:             self.run_command(cmd, \"Generating results report...\")\n 382:         \n 383: >>>     def build_upload_package(self):\n 384:             \"\"\"Build upload package\"\"\"\n 385:             cmd = [\"python\", \"tools/build_upload_package.py\"]\n 386:             self.run_command(cmd, \"Building upload package...\")",
          "match": "def build_upload_package(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 388,
          "context": " 385:             cmd = [\"python\", \"tools/build_upload_package.py\"]\n 386:             self.run_command(cmd, \"Building upload package...\")\n 387:         \n 388: >>>     def refresh_system_info(self):\n 389:             \"\"\"Refresh system information display\"\"\"\n 390:             import sys\n 391:             import platform",
          "match": "def refresh_system_info(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 426,
          "context": " 423:             self.info_text.insert(1.0, \"\\n\".join(info))\n 424:             self.info_text.config(state=tk.DISABLED)\n 425:     \n 426: >>> def main():\n 427:         \"\"\"Main entry point\"\"\"\n 428:         root = tk.Tk()\n 429:         app = LFMControlCenter(root)",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 398,
          "context": " 395:             info.append(f\"Platform: {platform.platform()}\")\n 396:             info.append(f\"Architecture: {platform.architecture()[0]}\")\n 397:             \n 398: >>>         # Check GPU availability\n 399:             try:\n 400:                 import cupy\n 401:                 info.append(\"GPU (CuPy): Available ✓\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 400,
          "context": " 397:             \n 398:             # Check GPU availability\n 399:             try:\n 400: >>>             import cupy\n 401:                 info.append(\"GPU (CuPy): Available ✓\")\n 402:             except ImportError:\n 403:                 info.append(\"GPU (CuPy): Not Available ⚠\")",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 401,
          "context": " 398:             # Check GPU availability\n 399:             try:\n 400:                 import cupy\n 401: >>>             info.append(\"GPU (CuPy): Available ✓\")\n 402:             except ImportError:\n 403:                 info.append(\"GPU (CuPy): Not Available ⚠\")\n 404:             ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 401,
          "context": " 398:             # Check GPU availability\n 399:             try:\n 400:                 import cupy\n 401: >>>             info.append(\"GPU (CuPy): Available ✓\")\n 402:             except ImportError:\n 403:                 info.append(\"GPU (CuPy): Not Available ⚠\")\n 404:             ",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 403,
          "context": " 400:                 import cupy\n 401:                 info.append(\"GPU (CuPy): Available ✓\")\n 402:             except ImportError:\n 403: >>>             info.append(\"GPU (CuPy): Not Available ⚠\")\n 404:             \n 405:             # Check test results\n 406:             try:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 403,
          "context": " 400:                 import cupy\n 401:                 info.append(\"GPU (CuPy): Available ✓\")\n 402:             except ImportError:\n 403: >>>             info.append(\"GPU (CuPy): Not Available ⚠\")\n 404:             \n 405:             # Check test results\n 406:             try:",
          "match": "CuPy"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 18,
          "context": "  15:     import tkinter as tk\n  16:     from tkinter import ttk, scrolledtext, messagebox, filedialog\n  17:     import subprocess\n  18: >>> import threading\n  19:     import time\n  20:     import queue\n  21:     from pathlib import Path",
          "match": "threading"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 198,
          "context": " 195:         \n 196:         def run_fast_tests(self):\n 197:             \"\"\"Run the fast test suite\"\"\"\n 198: >>>         cmd = [\"python\", \"run_parallel_tests.py\", \"--fast\"]\n 199:             self.run_command(cmd, \"Running fast tests...\")\n 200:         \n 201:         def run_emergence_test(self):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 214,
          "context": " 211:                 messagebox.showwarning(\"No Selection\", \"Please select at least one tier.\")\n 212:                 return\n 213:             \n 214: >>>         cmd = [\"python\", \"run_parallel_tests.py\", \"--tiers\", \",\".join(selected_tiers)]\n 215:             self.run_command(cmd, f\"Running tier(s) {', '.join(selected_tiers)}...\")\n 216:         \n 217:         def run_specific_test(self):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 224,
          "context": " 221:                 messagebox.showwarning(\"No Test ID\", \"Please enter a test ID.\")\n 222:                 return\n 223:             \n 224: >>>         cmd = [\"python\", \"run_parallel_tests.py\", \"--tests\", test_id]\n 225:             self.run_command(cmd, f\"Running test {test_id}...\")\n 226:         \n 227:         def run_command(self, cmd, status_msg):",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 256,
          "context": " 253:                 except Exception as e:\n 254:                     self.output_queue.put((\"error\", str(e)))\n 255:             \n 256: >>>         thread = threading.Thread(target=run_in_thread, daemon=True)\n 257:             thread.start()\n 258:         \n 259:         def stop_process(self):",
          "match": "threading"
        }
      ],
      "line_count": 437,
      "docstring": "LFM Control Center - Simple Windows GUI\n========================================\nA basic Tkinter-based GUI for running LFM tests.\nNo external dependencies - uses Python's built-in GUI library."
    },
    {
      "filepath": "test_double_slit_nogui.py",
      "category": "USER_INTERFACE",
      "priority": 8,
      "file_hash": "177255d21f6c5168",
      "file_size": 571,
      "modified": "2025-11-02T20:02:10.911036",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 14,
      "docstring": "Moved: This test now lives in devtests/test_double_slit_nogui.py\n\nThis stub prevents duplicate discovery at the repo root."
    },
    {
      "filepath": "energy_monitor.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "ac361ee900f77895",
      "file_size": 4434,
      "modified": "2025-11-02T20:02:10.850929",
      "git_info": {
        "first_commit": {
          "hash": "3dcfab31",
          "date": "2025-10-27 15:37:08 -0700",
          "message": "update tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     from lfm_diagnostics import energy_total, to_numpy\n  23:     \n  24:     \n  25: >>> class EnergyMonitor:\n  26:         \"\"\"\n  27:         Deterministic energy drift tracker.\n  28:     ",
          "match": "class EnergyMonitor:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:             with open(self.csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n  65:                 csv.writer(f).writerow([\"step\", \"energy\", \"drift\", \"timestamp\"])\n  66:     \n  67: >>>     def _chi_as_numpy(self):\n  68:             \"\"\"Return chi as a NumPy scalar/array (works for floats, NumPy, or CuPy).\"\"\"\n  69:             chi_safe = self.chi\n  70:             try:",
          "match": "def _chi_as_numpy(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 79,
          "context": "  76:                 pass\n  77:             return chi_safe\n  78:     \n  79: >>>     def _flush(self) -> None:\n  80:             if not self.buffer:\n  81:                 return\n  82:             with open(self.csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:",
          "match": "def _flush(self) -> None:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 87,
          "context": "  84:                 w.writerows(self.buffer)\n  85:             self.buffer.clear()\n  86:     \n  87: >>>     def record(self, E, E_prev, step: int) -> float:\n  88:             \"\"\"Record energy and drift for this step; returns the drift value.\"\"\"\n  89:             chi_np = self._chi_as_numpy()\n  90:             e_now = energy_total(to_numpy(E), to_numpy(E_prev), self.dt, self.dx, self.c, chi_np)",
          "match": "def record(self, E, E_prev, step:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 106,
          "context": " 103:     \n 104:             return drift\n 105:     \n 106: >>>     def summary(self):\n 107:             if not self.series:\n 108:                 return {\"max_drift\": None}\n 109:             drifts = [abs(d) for (_, _, d) in self.series]",
          "match": "def summary(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 116,
          "context": " 113:                 \"steps\": len(drifts),\n 114:             }\n 115:     \n 116: >>>     def finalize(self) -> None:\n 117:             \"\"\"Flush pending rows and write summary JSON alongside CSV.\"\"\"\n 118:             # ensure all records are written\n 119:             self._flush()",
          "match": "def finalize(self) -> None:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 12,
          "context": "   9:     energy_monitor.py — deterministic energy tracking for all LFM tiers\n  10:     v1.1.0 (fast-buffered)\n  11:     - Buffered CSV writes (flush every N records, default 10)\n  12: >>> - CuPy→NumPy safe handling for chi when computing energy_total()\n  13:     - Drop-in compatible with previous EnergyMonitor API\n  14:     \"\"\"\n  15:     ",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 68,
          "context": "  65:                 csv.writer(f).writerow([\"step\", \"energy\", \"drift\", \"timestamp\"])\n  66:     \n  67:         def _chi_as_numpy(self):\n  68: >>>         \"\"\"Return chi as a NumPy scalar/array (works for floats, NumPy, or CuPy).\"\"\"\n  69:             chi_safe = self.chi\n  70:             try:\n  71:                 # lazy import so this file doesn't require CuPy when not installed",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 71,
          "context": "  68:             \"\"\"Return chi as a NumPy scalar/array (works for floats, NumPy, or CuPy).\"\"\"\n  69:             chi_safe = self.chi\n  70:             try:\n  71: >>>             # lazy import so this file doesn't require CuPy when not installed\n  72:                 import cupy as cp  # type: ignore\n  73:                 if isinstance(chi_safe, cp.ndarray):\n  74:                     chi_safe = chi_safe.get()",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 72,
          "context": "  69:             chi_safe = self.chi\n  70:             try:\n  71:                 # lazy import so this file doesn't require CuPy when not installed\n  72: >>>             import cupy as cp  # type: ignore\n  73:                 if isinstance(chi_safe, cp.ndarray):\n  74:                     chi_safe = chi_safe.get()\n  75:             except Exception:",
          "match": "cupy"
        }
      ],
      "line_count": 123,
      "docstring": "energy_monitor.py — deterministic energy tracking for all LFM tiers\nv1.1.0 (fast-buffered)\n- Buffered CSV writes (flush every N records, default 10)\n- CuPy→NumPy safe handling for chi when computing energy_total()\n- Drop-in compatible with previous EnergyMonitor API"
    },
    {
      "filepath": "lfm_plotting.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "0c685b56b25f8197",
      "file_size": 4163,
      "modified": "2025-11-02T20:02:10.871517",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 22,
          "context": "  19:     # ---------------------------------------------------------------------\n  20:     # Helpers\n  21:     # ---------------------------------------------------------------------\n  22: >>> def ensure_dirs(path):\n  23:         Path(path).mkdir(parents=True, exist_ok=True)\n  24:     \n  25:     def timestamp():",
          "match": "def ensure_dirs(path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     def ensure_dirs(path):\n  23:         Path(path).mkdir(parents=True, exist_ok=True)\n  24:     \n  25: >>> def timestamp():\n  26:         return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n  27:     \n  28:     # ---------------------------------------------------------------------",
          "match": "def timestamp():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:     # ---------------------------------------------------------------------\n  29:     # Basic plots\n  30:     # ---------------------------------------------------------------------\n  31: >>> def plot_energy(times, energy, outdir, title=None, quick=False):\n  32:         ensure_dirs(outdir)\n  33:         plt.figure(figsize=(6, 4))\n  34:         plt.plot(times, energy, lw=1.5)",
          "match": "def plot_energy(times, energy, outdir, title=None, quick=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:         plt.savefig(Path(outdir) / \"energy_vs_time.png\", dpi=100 if quick else 150)\n  41:         plt.close()\n  42:     \n  43: >>> def plot_entropy(times, entropy, outdir, title=None, quick=False):\n  44:         ensure_dirs(outdir)\n  45:         plt.figure(figsize=(6, 4))\n  46:         plt.plot(times, entropy, lw=1.5, color=\"orange\")",
          "match": "def plot_entropy(times, entropy, outdir, title=None, quick=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:     # ---------------------------------------------------------------------\n  56:     # Field snapshots\n  57:     # ---------------------------------------------------------------------\n  58: >>> def save_field_snapshot(f, outdir, label=\"field\", quick=False):\n  59:         import matplotlib.pyplot as plt\n  60:         import numpy as np\n  61:         from pathlib import Path",
          "match": "def save_field_snapshot(f, outdir, label=\"field\", quick=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 87,
          "context": "  84:     # ---------------------------------------------------------------------\n  85:     # Diagnostic overlays\n  86:     # ---------------------------------------------------------------------\n  87: >>> def overlay_spectrum(freqs, amplitudes, outdir, label=\"spectrum\", quick=False):\n  88:         \"\"\"Plot FFT magnitude spectrum.\"\"\"\n  89:         ensure_dirs(outdir)\n  90:         plt.figure(figsize=(6, 4))",
          "match": "def overlay_spectrum(freqs, amplitudes, outdir, label=\"spectrum\", quick=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 100,
          "context": "  97:         plt.savefig(Path(outdir) / f\"{label}.png\", dpi=100 if quick else 150)\n  98:         plt.close()\n  99:     \n 100: >>> def overlay_energy_flow(times, flow, outdir, label=\"energy_flow\", quick=False):\n 101:         \"\"\"Plot energy transport trace (if available).\"\"\"\n 102:         ensure_dirs(outdir)\n 103:         plt.figure(figsize=(6, 4))",
          "match": "def overlay_energy_flow(times, flow, outdir, label=\"energy_flow\", quick=False):"
        }
      ],
      "line_count": 111,
      "docstring": "lfm_plotting.py — Standard plotting utilities for all LFM tiers.\nGenerates time-series plots (energy, entropy), 2D field snapshots, and\noptional overlays for diagnostics. Compatible with quick/full modes."
    },
    {
      "filepath": "lfm_visualizer.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "62a10702b5ce3117",
      "file_size": 8801,
      "modified": "2025-11-02T20:02:10.878212",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:     # ---------------------------------------------------------------------\n  29:     # Helpers\n  30:     # ---------------------------------------------------------------------\n  31: >>> def ensure_dirs(path):\n  32:         Path(path).mkdir(parents=True, exist_ok=True)\n  33:     \n  34:     def timestamp():",
          "match": "def ensure_dirs(path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 34,
          "context": "  31:     def ensure_dirs(path):\n  32:         Path(path).mkdir(parents=True, exist_ok=True)\n  33:     \n  34: >>> def timestamp():\n  35:         return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n  36:     \n  37:     def _to_img(field, tile_y=12):",
          "match": "def timestamp():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:     def timestamp():\n  35:         return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n  36:     \n  37: >>> def _to_img(field, tile_y=12):\n  38:         \"\"\"Convert 1D arrays to pseudo-2D for visualization.\"\"\"\n  39:         f = np.array(field)\n  40:         if f.ndim == 1:",
          "match": "def _to_img(field, tile_y=12):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 44,
          "context": "  41:             return np.tile(f, (tile_y, 1))\n  42:         return f\n  43:     \n  44: >>> def _annotate(ax, text):\n  45:         \"\"\"Adds semi-transparent overlay annotation.\"\"\"\n  46:         ax.text(0.02, 0.95, text, color=\"white\", fontsize=8,\n  47:                 transform=ax.transAxes, ha=\"left\", va=\"top\",",
          "match": "def _annotate(ax, text):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 50,
          "context": "  47:                 transform=ax.transAxes, ha=\"left\", va=\"top\",\n  48:                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"black\", alpha=0.4))\n  49:     \n  50: >>> def _safe_savefig(path: Path, fig=None, dpi=150):\n  51:         \"\"\"Remove existing file before saving to ensure overwrite.\"\"\"\n  52:         try:\n  53:             os.remove(path)",
          "match": "def _safe_savefig(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 109,
          "context": " 106:     # ---------------------------------------------------------------------\n 107:     # Tier Visuals (Overwrite-Safe)\n 108:     # ---------------------------------------------------------------------\n 109: >>> def _visualize_tier1(field, chi, outdir, label, quick):\n 110:         f_img = _to_img(np.array(field))\n 111:         fig, ax = plt.subplots(figsize=(5,3))\n 112:         ax.imshow(f_img.real, cmap=\"plasma\", origin=\"lower\", aspect=\"auto\")",
          "match": "def _visualize_tier1(field, chi, outdir, label, quick):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 120,
          "context": " 117:         _safe_savefig(Path(outdir)/f\"{label}.png\", fig, dpi=(80 if quick else 150))\n 118:         plt.close(fig)\n 119:     \n 120: >>> def _visualize_tier2(field, chi, outdir, label, quick):\n 121:         f_img = _to_img(np.array(field))\n 122:         fig, ax = plt.subplots(figsize=(5,4))\n 123:         ax.imshow(f_img.real, cmap=\"inferno\", origin=\"lower\", alpha=0.9)",
          "match": "def _visualize_tier2(field, chi, outdir, label, quick):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 132,
          "context": " 129:         _safe_savefig(Path(outdir)/f\"{label}.png\", fig, dpi=(80 if quick else 150))\n 130:         plt.close(fig)\n 131:     \n 132: >>> def _visualize_tier3(field, chi, outdir, label, quick):\n 133:         f_img = _to_img(np.abs(np.array(field)))\n 134:         fig, ax = plt.subplots(figsize=(5,4))\n 135:         im = ax.imshow(f_img, cmap=\"magma\", origin=\"lower\")",
          "match": "def _visualize_tier3(field, chi, outdir, label, quick):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 143,
          "context": " 140:         _safe_savefig(Path(outdir)/f\"{label}.png\", fig, dpi=(80 if quick else 150))\n 141:         plt.close(fig)\n 142:     \n 143: >>> def _visualize_tier4(field, chi, outdir, label, quick):\n 144:         f_img = _to_img(np.array(field))\n 145:         fig, ax = plt.subplots(figsize=(5,4))\n 146:         ax.imshow(f_img.real, cmap=\"twilight_shifted\", origin=\"lower\")",
          "match": "def _visualize_tier4(field, chi, outdir, label, quick):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 155,
          "context": " 152:         _safe_savefig(Path(outdir)/f\"{label}.png\", fig, dpi=(80 if quick else 150))\n 153:         plt.close(fig)\n 154:     \n 155: >>> def _visualize_tier5(field, chi, outdir, label, quick):\n 156:         f_img = _to_img(np.angle(np.array(field)))\n 157:         fig, ax = plt.subplots(figsize=(5,4))\n 158:         im = ax.imshow(f_img, cmap=\"hsv\", origin=\"lower\")",
          "match": "def _visualize_tier5(field, chi, outdir, label, quick):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 166,
          "context": " 163:         _safe_savefig(Path(outdir)/f\"{label}.png\", fig, dpi=(80 if quick else 150))\n 164:         plt.close(fig)\n 165:     \n 166: >>> def _visualize_tier6(field, chi, outdir, label, quick):\n 167:         f_img = _to_img(np.array(field))\n 168:         fig, ax = plt.subplots(figsize=(5,4))\n 169:         ax.imshow(f_img.real, cmap=\"cividis\", origin=\"lower\", alpha=0.9)",
          "match": "def _visualize_tier6(field, chi, outdir, label, quick):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 178,
          "context": " 175:         _safe_savefig(Path(outdir)/f\"{label}.png\", fig, dpi=(80 if quick else 150))\n 176:         plt.close(fig)\n 177:     \n 178: >>> def _visualize_generic(field, chi, outdir, label, quick=False):\n 179:         f_img = _to_img(np.abs(np.array(field)))\n 180:         fig, ax = plt.subplots(figsize=(5,4))\n 181:         im = ax.imshow(f_img, cmap=\"viridis\", origin=\"lower\")",
          "match": "def _visualize_generic(field, chi, outdir, label, quick=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 192,
          "context": " 189:     # ---------------------------------------------------------------------\n 190:     # Animation Generator (Overwrite-Safe)\n 191:     # ---------------------------------------------------------------------\n 192: >>> def _make_animation(E_series, outdir, label, quick, make_animation_mp4=False):\n 193:         ensure_dirs(outdir)\n 194:         frames = [_to_img(to_numpy(E)).real for E in E_series[::max(1, len(E_series)//(20 if quick else 100))]]\n 195:         fig, ax = plt.subplots(figsize=(5,4))",
          "match": "def _make_animation(E_series, outdir, label, quick, make_animation_mp4=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 200,
          "context": " 197:         _annotate(ax, \"Lattice field evolution\")\n 198:         plt.tight_layout()\n 199:     \n 200: >>>     def update(i):\n 201:             img.set_array(frames[i])\n 202:             return [img]\n 203:     ",
          "match": "def update(i):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 64,
          "context": "  61:                           outdir=\"plots\", quick=False, animate=False, make_animation_mp4=False):\n  62:         \"\"\"\n  63:         Generate static + optional animated visualizations.\n  64: >>>     - E_series: list of field arrays (CuPy or NumPy)\n  65:         - chi_series: optional curvature field\n  66:         - tier: int 1–6\n  67:         - animate: generate GIF/MP4 if True",
          "match": "CuPy"
        }
      ],
      "line_count": 223,
      "docstring": "lfm_visualizer.py — Unified visual generator for all LFM tiers (v1.9 Overwrite-Safe)\nNow includes:\n- Guaranteed PNG output for 1D data (Tier-1 fix)\n- Overwrite-safe saving (removes old PNG/GIF/MP4 before write)\n- Restored GIF/MP4 animation generation\n- Adaptive frame sampling for quick/full modes\n- Tier-aware annotation overlays\n- Automatic fallback to static PNG if animation fails"
    },
    {
      "filepath": "resource_monitor.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "c5bf4a792cfcf5e0",
      "file_size": 8446,
      "modified": "2025-11-02T20:02:10.886024",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 19,
          "context": "  16:     from typing import Dict, List, Optional\n  17:     \n  18:     \n  19: >>> class ResourceMonitor:\n  20:         \"\"\"Monitors system resources for dynamic test scheduling.\"\"\"\n  21:         \n  22:         def __init__(self, reserve_cpu_cores: int = 2, reserve_memory_mb: int = 2048, ",
          "match": "class ResourceMonitor:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 22,
          "context": "  19:     class ResourceMonitor:\n  20:         \"\"\"Monitors system resources for dynamic test scheduling.\"\"\"\n  21:         \n  22: >>>     def __init__(self, reserve_cpu_cores: int = 2, reserve_memory_mb: int = 2048, \n  23:                      reserve_gpu_memory_mb: int = 500):\n  24:             \"\"\"\n  25:             Initialize resource monitor.",
          "match": "def __init__(self, reserve_cpu_cores:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:             # GPU availability\n  41:             self.has_gpu = self.total_gpu_memory_mb > 0\n  42:         \n  43: >>>     def _query_total_gpu_memory(self) -> float:\n  44:             \"\"\"Query total GPU memory using nvidia-smi.\"\"\"\n  45:             try:\n  46:                 result = subprocess.run(",
          "match": "def _query_total_gpu_memory(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:                 pass\n  59:             return 0.0\n  60:         \n  61: >>>     def _query_gpu_free_memory(self) -> float:\n  62:             \"\"\"Query available GPU memory using nvidia-smi.\"\"\"\n  63:             try:\n  64:                 result = subprocess.run(",
          "match": "def _query_gpu_free_memory(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 78,
          "context": "  75:                 pass\n  76:             return 0.0\n  77:         \n  78: >>>     def available_resources(self) -> Dict[str, float]:\n  79:             \"\"\"\n  80:             Get currently available resources.\n  81:             ",
          "match": "def available_resources(self) -> Dict[str, float]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 107,
          "context": " 104:                 \"gpu_memory_mb\": gpu_available\n 105:             }\n 106:         \n 107: >>>     def can_fit(self, test_estimate: Dict, running_tests: List[Dict]) -> tuple[bool, str]:\n 108:             \"\"\"\n 109:             Check if test can start given current resource usage.\n 110:             ",
          "match": "def can_fit(self, test_estimate:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 143,
          "context": " 140:             \n 141:             return True, \"OK\"\n 142:         \n 143: >>>     def get_system_info(self) -> Dict:\n 144:             \"\"\"Get system resource summary.\"\"\"\n 145:             return {\n 146:                 \"cpu_cores\": self.total_cpu_cores,",
          "match": "def get_system_info(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 157,
          "context": " 154:                 }\n 155:             }\n 156:         \n 157: >>>     def check_gpu_exclusive_mode(self, test_estimate: Dict, running_tests: List[Dict]) -> bool:\n 158:             \"\"\"\n 159:             Check if GPU should be in exclusive mode.\n 160:             Phase 1: Allow multiple lightweight GPU tests to share GPU.",
          "match": "def check_gpu_exclusive_mode(self, test_estimate:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     Resource Monitor - Real-time system resource tracking\n  10:     ====================================================\n  11: >>> Monitors available CPU cores, RAM, and GPU memory to enable safe parallel execution.\n  12:     \"\"\"\n  13:     \n  14:     import psutil",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 23,
          "context": "  20:         \"\"\"Monitors system resources for dynamic test scheduling.\"\"\"\n  21:         \n  22:         def __init__(self, reserve_cpu_cores: int = 2, reserve_memory_mb: int = 2048, \n  23: >>>                  reserve_gpu_memory_mb: int = 500):\n  24:             \"\"\"\n  25:             Initialize resource monitor.\n  26:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 30,
          "context": "  27:             Args:\n  28:                 reserve_cpu_cores: CPU cores to reserve for OS\n  29:                 reserve_memory_mb: RAM to reserve for OS (MB)\n  30: >>>             reserve_gpu_memory_mb: GPU memory to reserve for driver (MB)\n  31:             \"\"\"\n  32:             self.total_cpu_cores = psutil.cpu_count(logical=True)\n  33:             self.total_memory_mb = psutil.virtual_memory().total / (1024**2)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 30,
          "context": "  27:             Args:\n  28:                 reserve_cpu_cores: CPU cores to reserve for OS\n  29:                 reserve_memory_mb: RAM to reserve for OS (MB)\n  30: >>>             reserve_gpu_memory_mb: GPU memory to reserve for driver (MB)\n  31:             \"\"\"\n  32:             self.total_cpu_cores = psutil.cpu_count(logical=True)\n  33:             self.total_memory_mb = psutil.virtual_memory().total / (1024**2)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 34,
          "context": "  31:             \"\"\"\n  32:             self.total_cpu_cores = psutil.cpu_count(logical=True)\n  33:             self.total_memory_mb = psutil.virtual_memory().total / (1024**2)\n  34: >>>         self.total_gpu_memory_mb = self._query_total_gpu_memory()\n  35:             \n  36:             self.reserve_cpu_cores = reserve_cpu_cores\n  37:             self.reserve_memory_mb = reserve_memory_mb",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 34,
          "context": "  31:             \"\"\"\n  32:             self.total_cpu_cores = psutil.cpu_count(logical=True)\n  33:             self.total_memory_mb = psutil.virtual_memory().total / (1024**2)\n  34: >>>         self.total_gpu_memory_mb = self._query_total_gpu_memory()\n  35:             \n  36:             self.reserve_cpu_cores = reserve_cpu_cores\n  37:             self.reserve_memory_mb = reserve_memory_mb",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 38,
          "context": "  35:             \n  36:             self.reserve_cpu_cores = reserve_cpu_cores\n  37:             self.reserve_memory_mb = reserve_memory_mb\n  38: >>>         self.reserve_gpu_memory_mb = reserve_gpu_memory_mb\n  39:             \n  40:             # GPU availability\n  41:             self.has_gpu = self.total_gpu_memory_mb > 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 38,
          "context": "  35:             \n  36:             self.reserve_cpu_cores = reserve_cpu_cores\n  37:             self.reserve_memory_mb = reserve_memory_mb\n  38: >>>         self.reserve_gpu_memory_mb = reserve_gpu_memory_mb\n  39:             \n  40:             # GPU availability\n  41:             self.has_gpu = self.total_gpu_memory_mb > 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 40,
          "context": "  37:             self.reserve_memory_mb = reserve_memory_mb\n  38:             self.reserve_gpu_memory_mb = reserve_gpu_memory_mb\n  39:             \n  40: >>>         # GPU availability\n  41:             self.has_gpu = self.total_gpu_memory_mb > 0\n  42:         \n  43:         def _query_total_gpu_memory(self) -> float:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 41,
          "context": "  38:             self.reserve_gpu_memory_mb = reserve_gpu_memory_mb\n  39:             \n  40:             # GPU availability\n  41: >>>         self.has_gpu = self.total_gpu_memory_mb > 0\n  42:         \n  43:         def _query_total_gpu_memory(self) -> float:\n  44:             \"\"\"Query total GPU memory using nvidia-smi.\"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 41,
          "context": "  38:             self.reserve_gpu_memory_mb = reserve_gpu_memory_mb\n  39:             \n  40:             # GPU availability\n  41: >>>         self.has_gpu = self.total_gpu_memory_mb > 0\n  42:         \n  43:         def _query_total_gpu_memory(self) -> float:\n  44:             \"\"\"Query total GPU memory using nvidia-smi.\"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 43,
          "context": "  40:             # GPU availability\n  41:             self.has_gpu = self.total_gpu_memory_mb > 0\n  42:         \n  43: >>>     def _query_total_gpu_memory(self) -> float:\n  44:             \"\"\"Query total GPU memory using nvidia-smi.\"\"\"\n  45:             try:\n  46:                 result = subprocess.run(",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 44,
          "context": "  41:             self.has_gpu = self.total_gpu_memory_mb > 0\n  42:         \n  43:         def _query_total_gpu_memory(self) -> float:\n  44: >>>         \"\"\"Query total GPU memory using nvidia-smi.\"\"\"\n  45:             try:\n  46:                 result = subprocess.run(\n  47:                     [\"nvidia-smi\", \"--query-gpu=memory.total\", \"--format=csv,noheader,nounits\"],",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:             \"\"\"Query total GPU memory using nvidia-smi.\"\"\"\n  45:             try:\n  46:                 result = subprocess.run(\n  47: >>>                 [\"nvidia-smi\", \"--query-gpu=memory.total\", \"--format=csv,noheader,nounits\"],\n  48:                     capture_output=True,\n  49:                     text=True,\n  50:                     timeout=5",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 53,
          "context": "  50:                     timeout=5\n  51:                 )\n  52:                 if result.returncode == 0:\n  53: >>>                 # Parse output (may have multiple GPUs, use first)\n  54:                     lines = result.stdout.strip().split('\\n')\n  55:                     if lines and lines[0]:\n  56:                         return float(lines[0])",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 61,
          "context": "  58:                 pass\n  59:             return 0.0\n  60:         \n  61: >>>     def _query_gpu_free_memory(self) -> float:\n  62:             \"\"\"Query available GPU memory using nvidia-smi.\"\"\"\n  63:             try:\n  64:                 result = subprocess.run(",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:             return 0.0\n  60:         \n  61:         def _query_gpu_free_memory(self) -> float:\n  62: >>>         \"\"\"Query available GPU memory using nvidia-smi.\"\"\"\n  63:             try:\n  64:                 result = subprocess.run(\n  65:                     [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,noheader,nounits\"],",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 65,
          "context": "  62:             \"\"\"Query available GPU memory using nvidia-smi.\"\"\"\n  63:             try:\n  64:                 result = subprocess.run(\n  65: >>>                 [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,noheader,nounits\"],\n  66:                     capture_output=True,\n  67:                     text=True,\n  68:                     timeout=5",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 83,
          "context": "  80:             Get currently available resources.\n  81:             \n  82:             Returns:\n  83: >>>             Dict with keys: cpu_cores, memory_mb, gpu_memory_mb\n  84:             \"\"\"\n  85:             # CPU availability (approximate from current usage)\n  86:             cpu_percent = psutil.cpu_percent(interval=0.1)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 94,
          "context": "  91:             mem_available_mb = psutil.virtual_memory().available / (1024**2)\n  92:             mem_available = max(0, mem_available_mb - self.reserve_memory_mb)\n  93:             \n  94: >>>         # GPU availability\n  95:             if self.has_gpu:\n  96:                 gpu_free = self._query_gpu_free_memory()\n  97:                 gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 95,
          "context": "  92:             mem_available = max(0, mem_available_mb - self.reserve_memory_mb)\n  93:             \n  94:             # GPU availability\n  95: >>>         if self.has_gpu:\n  96:                 gpu_free = self._query_gpu_free_memory()\n  97:                 gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 96,
          "context": "  93:             \n  94:             # GPU availability\n  95:             if self.has_gpu:\n  96: >>>             gpu_free = self._query_gpu_free_memory()\n  97:                 gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:\n  99:                 gpu_available = 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 96,
          "context": "  93:             \n  94:             # GPU availability\n  95:             if self.has_gpu:\n  96: >>>             gpu_free = self._query_gpu_free_memory()\n  97:                 gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:\n  99:                 gpu_available = 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 97,
          "context": "  94:             # GPU availability\n  95:             if self.has_gpu:\n  96:                 gpu_free = self._query_gpu_free_memory()\n  97: >>>             gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:\n  99:                 gpu_available = 0\n 100:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 97,
          "context": "  94:             # GPU availability\n  95:             if self.has_gpu:\n  96:                 gpu_free = self._query_gpu_free_memory()\n  97: >>>             gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:\n  99:                 gpu_available = 0\n 100:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 97,
          "context": "  94:             # GPU availability\n  95:             if self.has_gpu:\n  96:                 gpu_free = self._query_gpu_free_memory()\n  97: >>>             gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:\n  99:                 gpu_available = 0\n 100:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 99,
          "context": "  96:                 gpu_free = self._query_gpu_free_memory()\n  97:                 gpu_available = max(0, gpu_free - self.reserve_gpu_memory_mb)\n  98:             else:\n  99: >>>             gpu_available = 0\n 100:             \n 101:             return {\n 102:                 \"cpu_cores\": cpu_available,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 104,
          "context": " 101:             return {\n 102:                 \"cpu_cores\": cpu_available,\n 103:                 \"memory_mb\": mem_available,\n 104: >>>             \"gpu_memory_mb\": gpu_available\n 105:             }\n 106:         \n 107:         def can_fit(self, test_estimate: Dict, running_tests: List[Dict]) -> tuple[bool, str]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 104,
          "context": " 101:             return {\n 102:                 \"cpu_cores\": cpu_available,\n 103:                 \"memory_mb\": mem_available,\n 104: >>>             \"gpu_memory_mb\": gpu_available\n 105:             }\n 106:         \n 107:         def can_fit(self, test_estimate: Dict, running_tests: List[Dict]) -> tuple[bool, str]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 123,
          "context": " 120:             # Calculate total resource needs if we add this test\n 121:             total_cpu = sum(t.get(\"cpu_cores_needed\", 2) for t in running_tests) + test_estimate.get(\"cpu_cores_needed\", 2)\n 122:             total_memory = sum(t.get(\"memory_mb\", 500) for t in running_tests) + test_estimate.get(\"memory_mb\", 500)\n 123: >>>         total_gpu = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests) + test_estimate.get(\"gpu_memory_mb\", 0)\n 124:             \n 125:             # Check each constraint\n 126:             if total_memory > available[\"memory_mb\"]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 123,
          "context": " 120:             # Calculate total resource needs if we add this test\n 121:             total_cpu = sum(t.get(\"cpu_cores_needed\", 2) for t in running_tests) + test_estimate.get(\"cpu_cores_needed\", 2)\n 122:             total_memory = sum(t.get(\"memory_mb\", 500) for t in running_tests) + test_estimate.get(\"memory_mb\", 500)\n 123: >>>         total_gpu = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests) + test_estimate.get(\"gpu_memory_mb\", 0)\n 124:             \n 125:             # Check each constraint\n 126:             if total_memory > available[\"memory_mb\"]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 123,
          "context": " 120:             # Calculate total resource needs if we add this test\n 121:             total_cpu = sum(t.get(\"cpu_cores_needed\", 2) for t in running_tests) + test_estimate.get(\"cpu_cores_needed\", 2)\n 122:             total_memory = sum(t.get(\"memory_mb\", 500) for t in running_tests) + test_estimate.get(\"memory_mb\", 500)\n 123: >>>         total_gpu = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests) + test_estimate.get(\"gpu_memory_mb\", 0)\n 124:             \n 125:             # Check each constraint\n 126:             if total_memory > available[\"memory_mb\"]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 131,
          "context": " 128:                 avail = available[\"memory_mb\"] - sum(t.get(\"memory_mb\", 500) for t in running_tests)\n 129:                 return False, f\"Insufficient RAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 130:             \n 131: >>>         if test_estimate.get(\"uses_gpu\", False) and total_gpu > available[\"gpu_memory_mb\"]:\n 132:                 needed = test_estimate.get(\"gpu_memory_mb\", 0)\n 133:                 avail = available[\"gpu_memory_mb\"] - sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests)\n 134:                 return False, f\"Insufficient VRAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 131,
          "context": " 128:                 avail = available[\"memory_mb\"] - sum(t.get(\"memory_mb\", 500) for t in running_tests)\n 129:                 return False, f\"Insufficient RAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 130:             \n 131: >>>         if test_estimate.get(\"uses_gpu\", False) and total_gpu > available[\"gpu_memory_mb\"]:\n 132:                 needed = test_estimate.get(\"gpu_memory_mb\", 0)\n 133:                 avail = available[\"gpu_memory_mb\"] - sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests)\n 134:                 return False, f\"Insufficient VRAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 131,
          "context": " 128:                 avail = available[\"memory_mb\"] - sum(t.get(\"memory_mb\", 500) for t in running_tests)\n 129:                 return False, f\"Insufficient RAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 130:             \n 131: >>>         if test_estimate.get(\"uses_gpu\", False) and total_gpu > available[\"gpu_memory_mb\"]:\n 132:                 needed = test_estimate.get(\"gpu_memory_mb\", 0)\n 133:                 avail = available[\"gpu_memory_mb\"] - sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests)\n 134:                 return False, f\"Insufficient VRAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 132,
          "context": " 129:                 return False, f\"Insufficient RAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 130:             \n 131:             if test_estimate.get(\"uses_gpu\", False) and total_gpu > available[\"gpu_memory_mb\"]:\n 132: >>>             needed = test_estimate.get(\"gpu_memory_mb\", 0)\n 133:                 avail = available[\"gpu_memory_mb\"] - sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests)\n 134:                 return False, f\"Insufficient VRAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 135:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 133,
          "context": " 130:             \n 131:             if test_estimate.get(\"uses_gpu\", False) and total_gpu > available[\"gpu_memory_mb\"]:\n 132:                 needed = test_estimate.get(\"gpu_memory_mb\", 0)\n 133: >>>             avail = available[\"gpu_memory_mb\"] - sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests)\n 134:                 return False, f\"Insufficient VRAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 135:             \n 136:             if total_cpu > available[\"cpu_cores\"]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 133,
          "context": " 130:             \n 131:             if test_estimate.get(\"uses_gpu\", False) and total_gpu > available[\"gpu_memory_mb\"]:\n 132:                 needed = test_estimate.get(\"gpu_memory_mb\", 0)\n 133: >>>             avail = available[\"gpu_memory_mb\"] - sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests)\n 134:                 return False, f\"Insufficient VRAM (need {needed:.0f}MB, have {avail:.0f}MB free)\"\n 135:             \n 136:             if total_cpu > available[\"cpu_cores\"]:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 148,
          "context": " 145:             return {\n 146:                 \"cpu_cores\": self.total_cpu_cores,\n 147:                 \"memory_gb\": self.total_memory_mb / 1024,\n 148: >>>             \"gpu_memory_gb\": self.total_gpu_memory_mb / 1024 if self.has_gpu else 0,\n 149:                 \"has_gpu\": self.has_gpu,\n 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 148,
          "context": " 145:             return {\n 146:                 \"cpu_cores\": self.total_cpu_cores,\n 147:                 \"memory_gb\": self.total_memory_mb / 1024,\n 148: >>>             \"gpu_memory_gb\": self.total_gpu_memory_mb / 1024 if self.has_gpu else 0,\n 149:                 \"has_gpu\": self.has_gpu,\n 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 148,
          "context": " 145:             return {\n 146:                 \"cpu_cores\": self.total_cpu_cores,\n 147:                 \"memory_gb\": self.total_memory_mb / 1024,\n 148: >>>             \"gpu_memory_gb\": self.total_gpu_memory_mb / 1024 if self.has_gpu else 0,\n 149:                 \"has_gpu\": self.has_gpu,\n 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 149,
          "context": " 146:                 \"cpu_cores\": self.total_cpu_cores,\n 147:                 \"memory_gb\": self.total_memory_mb / 1024,\n 148:                 \"gpu_memory_gb\": self.total_gpu_memory_mb / 1024 if self.has_gpu else 0,\n 149: >>>             \"has_gpu\": self.has_gpu,\n 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,\n 152:                     \"memory_mb\": self.reserve_memory_mb,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 149,
          "context": " 146:                 \"cpu_cores\": self.total_cpu_cores,\n 147:                 \"memory_gb\": self.total_memory_mb / 1024,\n 148:                 \"gpu_memory_gb\": self.total_gpu_memory_mb / 1024 if self.has_gpu else 0,\n 149: >>>             \"has_gpu\": self.has_gpu,\n 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,\n 152:                     \"memory_mb\": self.reserve_memory_mb,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 153,
          "context": " 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,\n 152:                     \"memory_mb\": self.reserve_memory_mb,\n 153: >>>                 \"gpu_memory_mb\": self.reserve_gpu_memory_mb\n 154:                 }\n 155:             }\n 156:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 153,
          "context": " 150:                 \"reserves\": {\n 151:                     \"cpu_cores\": self.reserve_cpu_cores,\n 152:                     \"memory_mb\": self.reserve_memory_mb,\n 153: >>>                 \"gpu_memory_mb\": self.reserve_gpu_memory_mb\n 154:                 }\n 155:             }\n 156:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 157,
          "context": " 154:                 }\n 155:             }\n 156:         \n 157: >>>     def check_gpu_exclusive_mode(self, test_estimate: Dict, running_tests: List[Dict]) -> bool:\n 158:             \"\"\"\n 159:             Check if GPU should be in exclusive mode.\n 160:             Phase 1: Allow multiple lightweight GPU tests to share GPU.",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 159,
          "context": " 156:         \n 157:         def check_gpu_exclusive_mode(self, test_estimate: Dict, running_tests: List[Dict]) -> bool:\n 158:             \"\"\"\n 159: >>>         Check if GPU should be in exclusive mode.\n 160:             Phase 1: Allow multiple lightweight GPU tests to share GPU.\n 161:             \n 162:             Args:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 160,
          "context": " 157:         def check_gpu_exclusive_mode(self, test_estimate: Dict, running_tests: List[Dict]) -> bool:\n 158:             \"\"\"\n 159:             Check if GPU should be in exclusive mode.\n 160: >>>         Phase 1: Allow multiple lightweight GPU tests to share GPU.\n 161:             \n 162:             Args:\n 163:                 test_estimate: Estimate for test we want to start",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 160,
          "context": " 157:         def check_gpu_exclusive_mode(self, test_estimate: Dict, running_tests: List[Dict]) -> bool:\n 158:             \"\"\"\n 159:             Check if GPU should be in exclusive mode.\n 160: >>>         Phase 1: Allow multiple lightweight GPU tests to share GPU.\n 161:             \n 162:             Args:\n 163:                 test_estimate: Estimate for test we want to start",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 167,
          "context": " 164:                 running_tests: Currently running test estimates\n 165:             \n 166:             Returns:\n 167: >>>             True if GPU is available for this test\n 168:             \"\"\"\n 169:             if not test_estimate.get(\"uses_gpu\", False):\n 170:                 return True  # CPU test, no GPU constraint",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 169,
          "context": " 166:             Returns:\n 167:                 True if GPU is available for this test\n 168:             \"\"\"\n 169: >>>         if not test_estimate.get(\"uses_gpu\", False):\n 170:                 return True  # CPU test, no GPU constraint\n 171:             \n 172:             # Calculate total GPU memory that would be used",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 170,
          "context": " 167:                 True if GPU is available for this test\n 168:             \"\"\"\n 169:             if not test_estimate.get(\"uses_gpu\", False):\n 170: >>>             return True  # CPU test, no GPU constraint\n 171:             \n 172:             # Calculate total GPU memory that would be used\n 173:             current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 172,
          "context": " 169:             if not test_estimate.get(\"uses_gpu\", False):\n 170:                 return True  # CPU test, no GPU constraint\n 171:             \n 172: >>>         # Calculate total GPU memory that would be used\n 173:             current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174:             new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 173,
          "context": " 170:                 return True  # CPU test, no GPU constraint\n 171:             \n 172:             # Calculate total GPU memory that would be used\n 173: >>>         current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174:             new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 173,
          "context": " 170:                 return True  # CPU test, no GPU constraint\n 171:             \n 172:             # Calculate total GPU memory that would be used\n 173: >>>         current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174:             new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 173,
          "context": " 170:                 return True  # CPU test, no GPU constraint\n 171:             \n 172:             # Calculate total GPU memory that would be used\n 173: >>>         current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174:             new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 174,
          "context": " 171:             \n 172:             # Calculate total GPU memory that would be used\n 173:             current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174: >>>         new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 174,
          "context": " 171:             \n 172:             # Calculate total GPU memory that would be used\n 173:             current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174: >>>         new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 176,
          "context": " 173:             current_gpu_usage = sum(t.get(\"gpu_memory_mb\", 0) for t in running_tests if t.get(\"uses_gpu\", False))\n 174:             new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176: >>>         # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU\n 178:             available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179:             return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 177,
          "context": " 174:             new_total = current_gpu_usage + test_estimate.get(\"gpu_memory_mb\", 0)\n 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177: >>>         # This enables multiple lightweight tests to share GPU\n 178:             available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179:             return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory\n 180:     ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 178,
          "context": " 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU\n 178: >>>         available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179:             return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory\n 180:     \n 181:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 178,
          "context": " 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU\n 178: >>>         available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179:             return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory\n 180:     \n 181:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 178,
          "context": " 175:             \n 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU\n 178: >>>         available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179:             return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory\n 180:     \n 181:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 179,
          "context": " 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU\n 178:             available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179: >>>         return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory\n 180:     \n 181:     \n 182:     if __name__ == \"__main__\":",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 179,
          "context": " 176:             # Allow if total GPU usage stays under 6GB (leaving 2GB+ headroom on 8GB card)\n 177:             # This enables multiple lightweight tests to share GPU\n 178:             available_gpu = self.total_gpu_memory_mb - self.reserve_gpu_memory_mb\n 179: >>>         return new_total <= (available_gpu * 0.75)  # Use max 75% of available GPU memory\n 180:     \n 181:     \n 182:     if __name__ == \"__main__\":",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 190,
          "context": " 187:         info = monitor.get_system_info()\n 188:         print(f\"CPU: {info['cpu_cores']} cores\")\n 189:         print(f\"RAM: {info['memory_gb']:.1f} GB\")\n 190: >>>     print(f\"GPU: {info['gpu_memory_gb']:.1f} GB\" if info['has_gpu'] else \"GPU: Not available\")\n 191:         \n 192:         print(\"\\n=== Available Now ===\")\n 193:         avail = monitor.available_resources()",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 190,
          "context": " 187:         info = monitor.get_system_info()\n 188:         print(f\"CPU: {info['cpu_cores']} cores\")\n 189:         print(f\"RAM: {info['memory_gb']:.1f} GB\")\n 190: >>>     print(f\"GPU: {info['gpu_memory_gb']:.1f} GB\" if info['has_gpu'] else \"GPU: Not available\")\n 191:         \n 192:         print(\"\\n=== Available Now ===\")\n 193:         avail = monitor.available_resources()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 190,
          "context": " 187:         info = monitor.get_system_info()\n 188:         print(f\"CPU: {info['cpu_cores']} cores\")\n 189:         print(f\"RAM: {info['memory_gb']:.1f} GB\")\n 190: >>>     print(f\"GPU: {info['gpu_memory_gb']:.1f} GB\" if info['has_gpu'] else \"GPU: Not available\")\n 191:         \n 192:         print(\"\\n=== Available Now ===\")\n 193:         avail = monitor.available_resources()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 190,
          "context": " 187:         info = monitor.get_system_info()\n 188:         print(f\"CPU: {info['cpu_cores']} cores\")\n 189:         print(f\"RAM: {info['memory_gb']:.1f} GB\")\n 190: >>>     print(f\"GPU: {info['gpu_memory_gb']:.1f} GB\" if info['has_gpu'] else \"GPU: Not available\")\n 191:         \n 192:         print(\"\\n=== Available Now ===\")\n 193:         avail = monitor.available_resources()",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 196,
          "context": " 193:         avail = monitor.available_resources()\n 194:         print(f\"CPU cores: {avail['cpu_cores']:.1f}\")\n 195:         print(f\"RAM: {avail['memory_mb']:.0f} MB\")\n 196: >>>     print(f\"VRAM: {avail['gpu_memory_mb']:.0f} MB\")\n 197:         \n 198:         print(\"\\n=== Can Fit Test? ===\")\n 199:         test_estimate = {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 202,
          "context": " 199:         test_estimate = {\n 200:             \"cpu_cores_needed\": 2.0,\n 201:             \"memory_mb\": 500,\n 202: >>>         \"gpu_memory_mb\": 1200,\n 203:             \"uses_gpu\": True\n 204:         }\n 205:         can_fit, reason = monitor.can_fit(test_estimate, [])",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 203,
          "context": " 200:             \"cpu_cores_needed\": 2.0,\n 201:             \"memory_mb\": 500,\n 202:             \"gpu_memory_mb\": 1200,\n 203: >>>         \"uses_gpu\": True\n 204:         }\n 205:         can_fit, reason = monitor.can_fit(test_estimate, [])\n 206:         print(f\"Test needs: {test_estimate}\")",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     Resource Monitor - Real-time system resource tracking\n  10:     ====================================================\n  11: >>> Monitors available CPU cores, RAM, and GPU memory to enable safe parallel execution.\n  12:     \"\"\"\n  13:     \n  14:     import psutil",
          "match": "parallel"
        }
      ],
      "line_count": 207,
      "docstring": "Resource Monitor - Real-time system resource tracking\n====================================================\nMonitors available CPU cores, RAM, and GPU memory to enable safe parallel execution."
    },
    {
      "filepath": "tools\\visualize\\visualize_grav12.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "2827e9db5a59fca2",
      "file_size": 6927,
      "modified": "2025-11-02T20:02:11.117193",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 91,
          "context": "  88:             packet_times.append(float(row['time']))\n  89:             packet_energy.append(float(row['total_energy']))\n  90:     \n  91: >>> def init():\n  92:         \"\"\"Initialize animation\"\"\"\n  93:         ax_field.clear()\n  94:         ax_chi.clear()",
          "match": "def init():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 100,
          "context": "  97:         ax_energy.clear()\n  98:         return []\n  99:     \n 100: >>> def animate(frame):\n 101:         \"\"\"Update animation frame\"\"\"\n 102:         ax_field.clear()\n 103:         ax_chi.clear()",
          "match": "def animate(frame):"
        }
      ],
      "line_count": 189,
      "docstring": "Generate animated GIF visualization of GRAV-12 wave packet propagation\nShows field evolution, envelope, chi field, and detector positions"
    },
    {
      "filepath": "tools\\visualize\\visualize_grav12_phase_group.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "dd3862cb5a5392ea",
      "file_size": 10097,
      "modified": "2025-11-02T20:02:11.118193",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     from pathlib import Path\n  23:     import json\n  24:     \n  25: >>> def load_grav12_data():\n  26:         \"\"\"Load GRAV-12 results and detector signals.\"\"\"\n  27:         base_path = Path(\"results/Gravity/GRAV-12\")\n  28:         ",
          "match": "def load_grav12_data():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 46,
          "context": "  43:         \n  44:         return summary, time, signal_before, signal_after\n  45:     \n  46: >>> def compute_phase_shift(signal1, signal2, dt):\n  47:         \"\"\"Compute phase shift between two signals via cross-correlation.\"\"\"\n  48:         from scipy.signal import correlate\n  49:         ",
          "match": "def compute_phase_shift(signal1, signal2, dt):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:         \n  59:         return phase_delay, lag_idx\n  60:     \n  61: >>> def plot_phase_group_mismatch(summary, time, signal_before, signal_after, save_path):\n  62:         \"\"\"Create comprehensive visualization of phase vs group velocity mismatch.\"\"\"\n  63:         from scipy.signal import hilbert\n  64:         ",
          "match": "def plot_phase_group_mismatch(summary, time, signal_before, signal_after, save_path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 229,
          "context": " 226:         print(f\"✅ Saved visualization to: {save_path}\")\n 227:         plt.close()\n 228:     \n 229: >>> def main():\n 230:         print(\"Loading GRAV-12 data...\")\n 231:         summary, time, signal_before, signal_after = load_grav12_data()\n 232:         ",
          "match": "def main():"
        }
      ],
      "line_count": 248,
      "docstring": "Visualize GRAV-12 Phase/Group Velocity Mismatch\n\nThis script demonstrates the Klein-Gordon \"quirk\" where phase velocity\nand group velocity behave differently in spatially varying χ fields.\n\nKEY RESULT: Energy slows down (positive group delay) while wave crests\nspeed up (negative phase delay) - a testable prediction that distinguishes\nthis model from General Relativity!"
    },
    {
      "filepath": "tools\\visualize\\visualize_grav15_3d.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "c6b9b40036de8b54",
      "file_size": 7622,
      "modified": "2025-11-02T20:02:11.119194",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 26,
          "context": "  23:     from mpl_toolkits.mplot3d import Axes3D\n  24:     from pathlib import Path\n  25:     \n  26: >>> def load_snapshots(h5_path):\n  27:         \"\"\"Load 3D field snapshots from HDF5 file.\"\"\"\n  28:         with h5py.File(h5_path, 'r') as hf:\n  29:             N = int(hf['N'][()])",
          "match": "def load_snapshots(h5_path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:         \n  41:         return N, dx, dt, steps_per_snap, snapshots\n  42:     \n  43: >>> def compute_energy_density(field):\n  44:         \"\"\"Compute energy density (field squared).\"\"\"\n  45:         return field ** 2\n  46:     ",
          "match": "def compute_energy_density(field):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:         \"\"\"Compute energy density (field squared).\"\"\"\n  45:         return field ** 2\n  46:     \n  47: >>> def create_frame(ax, field, N, dx, time, angle, vmin, vmax, adaptive_threshold=True):\n  48:         \"\"\"Create a single frame showing 3D energy isosurface.\"\"\"\n  49:         ax.clear()\n  50:         ",
          "match": "def create_frame(ax, field, N, dx, time, angle, vmin, vmax, adaptive_threshold=True):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 113,
          "context": " 110:         \n 111:         return sc\n 112:     \n 113: >>> def main():\n 114:         parser = argparse.ArgumentParser(description=\"Visualize 3D energy dispersion from GRAV-15\")\n 115:         parser.add_argument(\"--input\", type=str, default=\"results/Gravity/GRAV-15/diagnostics/field_snapshots_3d_GRAV-15.h5\",\n 116:                            help=\"Path to input HDF5 file\")",
          "match": "def main():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 168,
          "context": " 165:             return\n 166:         \n 167:         # Animation function\n 168: >>>     def animate(i):\n 169:             time, field = snapshots[i]\n 170:             angle = 30 + (i / len(snapshots)) * 360  # One full rotation\n 171:             sc = create_frame(ax, field, N, dx, time, angle, vmin, vmax, adaptive_threshold=True)",
          "match": "def animate(i):"
        }
      ],
      "line_count": 198,
      "docstring": "Generate MP4 visualization of 3D energy dispersion from GRAV-15 test.\n\nRenders volumetric field snapshots as a rotating transparent cube with\nenergy density shown as colored isosurfaces or volume rendering.\n\nUsage:\n    python visualize_grav15_3d.py [--input field_snapshots_3d_GRAV-15.h5] [--output energy_dispersion_3d.mp4]"
    },
    {
      "filepath": "tools\\visualize\\visualize_grav16_camera.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "8597a0fe65142be3",
      "file_size": 6777,
      "modified": "2025-11-02T20:02:11.121192",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:     from pathlib import Path\n  37:     \n  38:     \n  39: >>> def load_metadata(h5_path):\n  40:         with h5py.File(h5_path, 'r') as hf:\n  41:             shape = tuple(hf['shape'][()])\n  42:             dx = float(hf['dx'][()])",
          "match": "def load_metadata(h5_path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 52,
          "context": "  49:         return shape, dx, dt, steps_per_snap, barrier_z, slit_positions, keys\n  50:     \n  51:     \n  52: >>> def compute_global_scale(h5_path, keys, z_idx, mode='power', q=0.995):\n  53:         \"\"\"Compute a robust global vmax for coloring from all snapshots at z=z_idx.\n  54:         Uses a high quantile to avoid single-frame spikes.\n  55:         mode: 'abs' for |E|, 'power' for E^2",
          "match": "def compute_global_scale(h5_path, keys, z_idx, mode='power', q=0.995):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 112,
          "context": " 109:         return im\n 110:     \n 111:     \n 112: >>> def main():\n 113:         ap = argparse.ArgumentParser(description='Camera-view renderer for GRAV-16 double-slit')\n 114:         ap.add_argument('--input', type=str, default='results/Gravity/GRAV-16/diagnostics/field_snapshots_3d_GRAV-16.h5')\n 115:         ap.add_argument('--output', type=str, default='results/Gravity/GRAV-16/camera_frames')",
          "match": "def main():"
        }
      ],
      "line_count": 173,
      "docstring": "Camera-style visualization for GRAV-16 double-slit experiment.\n\nRenders a 2D imshow-style representation showing:\n- Screen plane behind barrier with intensity texture\n- Barrier and slit markers overlaid\n- Time evolution suitable for MP4 encoding\n\nUsage:\n  python visualize_grav16_camera.py \\\n    --input results/Gravity/GRAV-16/diagnostics/field_snapshots_3d_GRAV-16.h5 \\\n    --output results/Gravity/GRAV-16/camera_frames \\\n    --z_frac 0.70 \\\n    --intensity power\n\nThen create MP4 (Windows example):\n  C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe -y -framerate 30 -i results\\\\Gravity\\\\GRAV-16\\\\camera_frames\\\\cam_%04d.png \\\n    -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" -c:v libx264 -pix_fmt yuv420p -movflags +faststart \\\n    results\\\\Gravity\\\\GRAV-16\\\\doubleslit_camera.mp4"
    },
    {
      "filepath": "tools\\visualize\\visualize_grav16_doubleslit.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "5b1afa64cdf5563d",
      "file_size": 7972,
      "modified": "2025-11-02T20:02:11.122190",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 29,
          "context": "  26:     from matplotlib.animation import FuncAnimation, FFMpegWriter\n  27:     from pathlib import Path\n  28:     \n  29: >>> def load_snapshots(h5_path):\n  30:         \"\"\"Load 3D field snapshots from HDF5 file.\"\"\"\n  31:         with h5py.File(h5_path, 'r') as hf:\n  32:             shape = tuple(hf['shape'][()])",
          "match": "def load_snapshots(h5_path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 48,
          "context": "  45:         \n  46:         return shape, dx, dt, steps_per_snap, barrier_z, slit_positions, snapshots\n  47:     \n  48: >>> def create_xz_frame(ax, field, shape, dx, time, barrier_z, slit_y, vmin, vmax, adaptive=True):\n  49:         \"\"\"Create XZ slice at y=slit_y (side view through one slit).\"\"\"\n  50:         ax.clear()\n  51:         ",
          "match": "def create_xz_frame(ax, field, shape, dx, time, barrier_z, slit_y, vmin, vmax, adaptive=True):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 81,
          "context": "  78:         \n  79:         return im\n  80:     \n  81: >>> def create_yz_frame(ax, field, shape, dx, time, barrier_z, z_frac, slit_positions, vmin, vmax, adaptive=True):\n  82:         \"\"\"Create YZ slice at given z_frac (interference pattern behind barrier).\"\"\"\n  83:         ax.clear()\n  84:         ",
          "match": "def create_yz_frame(ax, field, shape, dx, time, barrier_z, z_frac, slit_positions, vmin, vmax, adaptive=True):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 115,
          "context": " 112:         \n 113:         return im\n 114:     \n 115: >>> def main():\n 116:         parser = argparse.ArgumentParser(description=\"Visualize 3D double-slit experiment from GRAV-16\")\n 117:         parser.add_argument(\"--input\", type=str, \n 118:                            default=\"results/Gravity/GRAV-16/diagnostics/field_snapshots_3d_GRAV-16.h5\",",
          "match": "def main():"
        }
      ],
      "line_count": 198,
      "docstring": "Generate visualization of 3D double-slit experiment from GRAV-16 test.\n\nRenders cross-sections and/or 3D volumetric views showing interference pattern.\n\nUsage:\n    python visualize_grav16_doubleslit.py [--input FILE] [--output DIR] [--mode MODE]\n    \nModes:\n    xz_slice : XZ cross-section at y=center (side view showing both slits)\n    yz_slice : YZ cross-section behind barrier (interference pattern)\n    frames   : Individual PNG frames for all slices"
    },
    {
      "filepath": "tools\\visualize\\visualize_hamiltonian.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "b3ccf1bcaca61e47",
      "file_size": 9991,
      "modified": "2025-11-02T20:02:11.123190",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 32,
          "context": "  29:     import matplotlib.pyplot as plt\n  30:     import matplotlib.gridspec as gridspec\n  31:     \n  32: >>> def load_hamiltonian_data(test_id: str, results_dir: Path = None):\n  33:         \"\"\"Load Hamiltonian component data from test results.\"\"\"\n  34:         if results_dir is None:\n  35:             results_dir = Path(__file__).parent.parent.parent / \"results\" / \"Energy\"",
          "match": "def load_hamiltonian_data(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 50,
          "context": "  47:             'H_total': data[:, 4]\n  48:         }\n  49:     \n  50: >>> def get_test_description(test_id: str):\n  51:         \"\"\"Get human-readable description for each test.\"\"\"\n  52:         descriptions = {\n  53:             'ENER-05': 'Uniform χ=0 (massless wave)',",
          "match": "def get_test_description(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:         }\n  57:         return descriptions.get(test_id, test_id)\n  58:     \n  59: >>> def create_combined_visualization(test_ids: list, output_path: Path = None):\n  60:         \"\"\"Create multi-panel visualization showing Hamiltonian conservation.\"\"\"\n  61:         n_tests = len(test_ids)\n  62:         ",
          "match": "def create_combined_visualization(test_ids:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 165,
          "context": " 162:         \n 163:         plt.close()\n 164:     \n 165: >>> def create_single_test_detail(test_id: str, output_path: Path = None):\n 166:         \"\"\"Create detailed single-test visualization.\"\"\"\n 167:         data = load_hamiltonian_data(test_id)\n 168:         ",
          "match": "def create_single_test_detail(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 225,
          "context": " 222:         \n 223:         plt.close()\n 224:     \n 225: >>> def main():\n 226:         parser = argparse.ArgumentParser(\n 227:             description='Visualize Hamiltonian component conservation',\n 228:             formatter_class=argparse.RawDescriptionHelpFormatter,",
          "match": "def main():"
        }
      ],
      "line_count": 255,
      "docstring": "Hamiltonian Component Visualization Tool\n=========================================\n\nCreates publication-quality visualizations of energy conservation tests\nshowing how energy \"sloshes\" between kinetic, gradient, and potential\nmodes while total Hamiltonian H = KE + GE + PE remains constant.\n\nPhysics:\n- Validates Noether's theorem: time symmetry → energy conservation\n- Shows Hamiltonian partitioning: H = ½∫[(∂E/∂t)² + (∇E)² + (χE)²]dV\n- Demonstrates energy flow between modes WITHOUT external forcing\n\nUsage:\n    python visualize_hamiltonian.py --tests ENER-05 ENER-06 ENER-07\n    python visualize_hamiltonian.py --test ENER-05 --output custom.png"
    },
    {
      "filepath": "visualize_grav12.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "b60063fbd058fae9",
      "file_size": 893,
      "modified": "2025-11-02T20:02:10.925973",
      "git_info": {
        "first_commit": {
          "hash": "8351ace7",
          "date": "2025-10-30 06:49:07 -0700",
          "message": "Continue the mission"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 25,
      "docstring": "Backward-compatible shim for visualize_grav12.\n\nThis script is preserved for convenience. The implementation now lives under:\n  tools/visualize/visualize_grav12.py"
    },
    {
      "filepath": "visualize_grav12_phase_group.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "335f9d692782f15d",
      "file_size": 917,
      "modified": "2025-11-02T20:02:10.927493",
      "git_info": {
        "first_commit": {
          "hash": "8351ace7",
          "date": "2025-10-30 06:49:07 -0700",
          "message": "Continue the mission"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 25,
      "docstring": "Backward-compatible shim for visualize_grav12_phase_group.\n\nThis script is preserved for convenience. The implementation now lives under:\n  tools/visualize/visualize_grav12_phase_group.py"
    },
    {
      "filepath": "visualize_grav15_3d.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "98b684e0fbac10e6",
      "file_size": 899,
      "modified": "2025-11-02T20:02:10.927493",
      "git_info": {
        "first_commit": {
          "hash": "8351ace7",
          "date": "2025-10-30 06:49:07 -0700",
          "message": "Continue the mission"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 25,
      "docstring": "Backward-compatible shim for visualize_grav15_3d.\n\nThis script is preserved for convenience. The implementation now lives under:\n  tools/visualize/visualize_grav15_3d.py"
    },
    {
      "filepath": "visualize_grav16_camera.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "22d4328aa2bf2bde",
      "file_size": 907,
      "modified": "2025-11-02T20:02:10.927493",
      "git_info": {
        "first_commit": {
          "hash": "8351ace7",
          "date": "2025-10-30 06:49:07 -0700",
          "message": "Continue the mission"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 25,
      "docstring": "Backward-compatible shim for visualize_grav16_camera.\n\nThis script is preserved for convenience. The implementation now lives under:\n  tools/visualize/visualize_grav16_camera.py"
    },
    {
      "filepath": "visualize_grav16_doubleslit.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "eeae228a625dab99",
      "file_size": 915,
      "modified": "2025-11-02T20:02:10.930327",
      "git_info": {
        "first_commit": {
          "hash": "8351ace7",
          "date": "2025-10-30 06:49:07 -0700",
          "message": "Continue the mission"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 25,
      "docstring": "Backward-compatible shim for visualize_grav16_doubleslit.\n\nThis script is preserved for convenience. The implementation now lives under:\n  tools/visualize/visualize_grav16_doubleslit.py"
    },
    {
      "filepath": "visualize_hamiltonian.py",
      "category": "VISUALIZATION",
      "priority": 7,
      "file_hash": "1b270bf21ed70c7c",
      "file_size": 903,
      "modified": "2025-11-02T20:02:10.931585",
      "git_info": {
        "first_commit": {
          "hash": "f0885273",
          "date": "2025-10-30 17:51:45 -0700",
          "message": "Additional tests, harnesses"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 25,
      "docstring": "Backward-compatible shim for visualize_hamiltonian.\n\nThis script is preserved for convenience. The implementation now lives under:\n  tools/visualize/visualize_hamiltonian.py"
    },
    {
      "filepath": "archive\\analyze_quan_tests.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "73d5fa3371fb381e",
      "file_size": 12143,
      "modified": "2025-11-02T20:02:10.850929",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 17,
          "context": "  14:     from pathlib import Path\n  15:     from typing import Dict, Any, List, Tuple\n  16:     \n  17: >>> def load_test_summary(test_id: str) -> Dict[str, Any]:\n  18:         \"\"\"Load summary.json for a test.\"\"\"\n  19:         path = Path(f\"results/Quantization/{test_id}/summary.json\")\n  20:         if not path.exists():",
          "match": "def load_test_summary(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:         with open(path, encoding='utf-8') as f:\n  23:             return json.load(f)\n  24:     \n  25: >>> def load_config() -> Dict[str, Any]:\n  26:         \"\"\"Load test configuration.\"\"\"\n  27:         with open(\"config/config_tier4_quantization.json\", encoding='utf-8') as f:\n  28:             return json.load(f)",
          "match": "def load_config() -> Dict[str, Any]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 30,
          "context": "  27:         with open(\"config/config_tier4_quantization.json\", encoding='utf-8') as f:\n  28:             return json.load(f)\n  29:     \n  30: >>> def analyze_test(test_id: str, summary: Dict, config: Dict) -> Dict[str, Any]:\n  31:         \"\"\"Analyze a single test.\"\"\"\n  32:         # Get test config\n  33:         test_cfg = next((t for t in config[\"tests\"] if t[\"test_id\"] == test_id), {})",
          "match": "def analyze_test(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 200,
          "context": " 197:         \n 198:         return analysis\n 199:     \n 200: >>> def main():\n 201:         \"\"\"Main analysis.\"\"\"\n 202:         config = load_config()\n 203:         ",
          "match": "def main():"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 268,
          "context": " 265:         \n 266:         # Reporting bug\n 267:         print(\"=\"*80)\n 268: >>>     print(\"PARALLEL TEST RUNNER BUG IDENTIFIED\")\n 269:         print(\"=\"*80)\n 270:         print(\"The parallel test runner reports '✓ PASS' based on exit_code == 0,\")\n 271:         print(\"NOT on actual test pass/fail status in summary.json.\")",
          "match": "PARALLEL"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 270,
          "context": " 267:         print(\"=\"*80)\n 268:         print(\"PARALLEL TEST RUNNER BUG IDENTIFIED\")\n 269:         print(\"=\"*80)\n 270: >>>     print(\"The parallel test runner reports '✓ PASS' based on exit_code == 0,\")\n 271:         print(\"NOT on actual test pass/fail status in summary.json.\")\n 272:         print()\n 273:         print(\"Example:\")",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 95,
          "context": "  92:                     \"This is NOT nonlinear coupling (system IS linear). Test methodology needs refinement.\"\n  93:                 )\n  94:         \n  95: >>>     elif mode == \"wavefront_stability\":\n  96:             # Should test no nonlinear steepening\n  97:             growth = metrics.get(\"gradient_growth\", 999)\n  98:             # No explicit tolerance in config, but should be < 10x",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 105,
          "context": " 102:             analysis[\"testing_correctly\"] = growth < 10\n 103:             \n 104:             if growth >= 10:\n 105: >>>             analysis[\"issues\"].append(f\"Gradient grew {growth:.2f}x - possible instability\")\n 106:         \n 107:         elif mode == \"lattice_blowout\":\n 108:             # Should test numerical stability",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 108,
          "context": " 105:                 analysis[\"issues\"].append(f\"Gradient grew {growth:.2f}x - possible instability\")\n 106:         \n 107:         elif mode == \"lattice_blowout\":\n 108: >>>         # Should test numerical stability\n 109:             blew_up = metrics.get(\"blew_up\", True)\n 110:             max_energy = metrics.get(\"max_energy\", 999)\n 111:             tolerance = tolerances.get(\"blowout_energy_limit\", 100.0)",
          "match": "stability"
        }
      ],
      "line_count": 281,
      "docstring": "Comprehensive analysis of all 14 QUAN tests.\nValidates that each test is testing what it claims with proper thresholds."
    },
    {
      "filepath": "devtests\\test_1d_propagation.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "02dae978fea3519c",
      "file_size": 2690,
      "modified": "2025-11-02T20:02:10.954857",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 55,
          "context": "  52:     params = dict(\n  53:         dt=dt, dx=dx, alpha=alpha, beta=beta,\n  54:         chi=chi_field,  # Uniform chi field\n  55: >>>     boundary=\"periodic\"\n  56:     )\n  57:     print(f\"Chi field: shape={chi_field.shape}, range=[{chi_field.min():.6f}, {chi_field.max():.6f}]\")\n  58:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 55,
          "context": "  52:     params = dict(\n  53:         dt=dt, dx=dx, alpha=alpha, beta=beta,\n  54:         chi=chi_field,  # Uniform chi field\n  55: >>>     boundary=\"periodic\"\n  56:     )\n  57:     print(f\"Chi field: shape={chi_field.shape}, range=[{chi_field.min():.6f}, {chi_field.max():.6f}]\")\n  58:     ",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 11,
          "context": "   8:     import numpy as np\n   9:     import math\n  10:     \n  11: >>> # Import core solver\n  12:     from lfm_equation import lattice_step\n  13:     \n  14:     # Simple 1D test: traveling wave packet",
          "match": "solver"
        }
      ],
      "line_count": 81,
      "docstring": "Minimal 1D wave propagation test to debug GRAV-12 issue."
    },
    {
      "filepath": "devtests\\test_lfm_logger.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "50e0f638b5d9e9bb",
      "file_size": 2329,
      "modified": "2025-11-02T20:02:10.962139",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     from lfm_logger import LFMLogger\n  19:     \n  20:     \n  21: >>> def writer_thread(logger, idx):\n  22:         \"\"\"Simulate a test writing mixed logs concurrently.\"\"\"\n  23:         for i in range(10):\n  24:             logger.log(f\"[Thread-{idx}] text message {i}\")",
          "match": "def writer_thread(logger, idx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 29,
          "context": "  26:             time.sleep(0.001)\n  27:     \n  28:     \n  29: >>> def run_logger_test():\n  30:         tmp_dir = Path(tempfile.mkdtemp(prefix=\"lfm_logger_test_\"))\n  31:         logger = LFMLogger(tmp_dir)\n  32:         logger.record_env(gpu_name=\"TestGPU\", cuda_runtime=1234)",
          "match": "def run_logger_test():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 32,
          "context": "  29:     def run_logger_test():\n  30:         tmp_dir = Path(tempfile.mkdtemp(prefix=\"lfm_logger_test_\"))\n  31:         logger = LFMLogger(tmp_dir)\n  32: >>>     logger.record_env(gpu_name=\"TestGPU\", cuda_runtime=1234)\n  33:         logger.log(\"This is a main-thread test message.\")\n  34:         logger.log_json({\"event\": \"test_event\", \"value\": 42})\n  35:         logger.error(\"Simulated error\", Exception(\"FakeError\"))",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 32,
          "context": "  29:     def run_logger_test():\n  30:         tmp_dir = Path(tempfile.mkdtemp(prefix=\"lfm_logger_test_\"))\n  31:         logger = LFMLogger(tmp_dir)\n  32: >>>     logger.record_env(gpu_name=\"TestGPU\", cuda_runtime=1234)\n  33:         logger.log(\"This is a main-thread test message.\")\n  34:         logger.log_json({\"event\": \"test_event\", \"value\": 42})\n  35:         logger.error(\"Simulated error\", Exception(\"FakeError\"))",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 32,
          "context": "  29:     def run_logger_test():\n  30:         tmp_dir = Path(tempfile.mkdtemp(prefix=\"lfm_logger_test_\"))\n  31:         logger = LFMLogger(tmp_dir)\n  32: >>>     logger.record_env(gpu_name=\"TestGPU\", cuda_runtime=1234)\n  33:         logger.log(\"This is a main-thread test message.\")\n  34:         logger.log_json({\"event\": \"test_event\", \"value\": 42})\n  35:         logger.error(\"Simulated error\", Exception(\"FakeError\"))",
          "match": "cuda"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 15,
          "context": "  12:     \n  13:     import json\n  14:     import tempfile\n  15: >>> import threading\n  16:     import time\n  17:     from pathlib import Path\n  18:     from lfm_logger import LFMLogger",
          "match": "threading"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 40,
          "context": "  37:         # --- concurrent writes test ---\n  38:         threads = []\n  39:         for t in range(4):  # 4 threads writing simultaneously\n  40: >>>         th = threading.Thread(target=writer_thread, args=(logger, t))\n  41:             threads.append(th)\n  42:             th.start()\n  43:     ",
          "match": "threading"
        }
      ],
      "line_count": 71,
      "docstring": "Extended unit test for lfm_logger.py\nCovers environment logging, JSONL structure, errors, and concurrent writes."
    },
    {
      "filepath": "docs\\evidence\\emergence_validation\\test_emergence_proof.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "950c482875104aa2",
      "file_size": 6548,
      "modified": "2025-11-03T11:24:34.005487",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 27,
          "context": "  24:     from chi_field_equation import evolve_coupled_fields, compute_chi_from_energy_poisson\n  25:     from lfm_backend import to_numpy\n  26:     \n  27: >>> def test_spontaneous_chi_generation():\n  28:         \"\"\"\n  29:         Test if χ-field structure can emerge from uniform initial conditions\n  30:         \"\"\"",
          "match": "def test_spontaneous_chi_generation():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 122,
          "context": " 119:             'steps': steps\n 120:         }\n 121:     \n 122: >>> def plot_results(x, E_init, E_final, chi_init, chi_final, history):\n 123:         \"\"\"\n 124:         Visualize the emergence test results\n 125:         \"\"\"",
          "match": "def plot_results(x, E_init, E_final, chi_init, chi_final, history):"
        }
      ],
      "line_count": 181,
      "docstring": "LFM Emergence Test - Can χ-field structure emerge spontaneously?\n\nThis test addresses the core question: Does the LFM lattice genuinely generate\ngravitational-like effects from energy dynamics, or are they pre-programmed?\n\nTest Design:\n1. Start with UNIFORM χ-field (no gravitational structure)\n2. Place localized energy packet\n3. Allow χ to evolve self-consistently with energy density\n4. Measure: Does χ-well spontaneously form around energy?\n\nIf successful, this proves genuine emergence rather than circular validation."
    },
    {
      "filepath": "lfm_test_harness.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "0a9dce543425d1f9",
      "file_size": 14002,
      "modified": "2025-11-02T20:02:10.875464",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:     from resource_tracking import create_resource_tracker\n  41:     \n  42:     \n  43: >>> class BaseTierHarness(NumericIntegrityMixin):\n  44:         \"\"\"\n  45:         Base class for all tier test harnesses.\n  46:         ",
          "match": "class BaseTierHarness(NumericIntegrityMixin):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 175,
          "context": " 172:             )\n 173:         \n 174:         @staticmethod\n 175: >>>     def resolve_outdir(output_dir_hint: str) -> Path:\n 176:             \"\"\"\n 177:             Resolve output directory relative to script location.\n 178:             ",
          "match": "def resolve_outdir(output_dir_hint:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 197,
          "context": " 194:             return outdir\n 195:         \n 196:         @staticmethod\n 197: >>>     def hann_window(length: int) -> np.ndarray:\n 198:             \"\"\"\n 199:             Create Hanning (Hann) window for FFT windowing.\n 200:             ",
          "match": "def hann_window(length:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 320,
          "context": " 317:             slope, _ = np.linalg.lstsq(Aw, yw, rcond=None)[0]\n 318:             return float(abs(slope))\n 319:         \n 320: >>>     def start_test_tracking(self, background: bool = False):\n 321:             \"\"\"\n 322:             Start resource tracking for current test.\n 323:             ",
          "match": "def start_test_tracking(self, background:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 338,
          "context": " 335:             self._current_tracker = create_resource_tracker(sample_interval=0.5)\n 336:             self._current_tracker.start(background=background)\n 337:         \n 338: >>>     def sample_test_resources(self):\n 339:             \"\"\"\n 340:             Manually sample current resource usage.\n 341:             ",
          "match": "def sample_test_resources(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 354,
          "context": " 351:             if self._current_tracker:\n 352:                 self._current_tracker.sample()\n 353:         \n 354: >>>     def stop_test_tracking(self) -> Dict:\n 355:             \"\"\"\n 356:             Stop resource tracking and return metrics.\n 357:             ",
          "match": "def stop_test_tracking(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 380,
          "context": " 377:             self._current_tracker = None\n 378:             return metrics\n 379:         \n 380: >>>     def log_test_start(self, test_id: str, description: str, steps: int):\n 381:             \"\"\"\n 382:             Log start of a test variant.\n 383:             ",
          "match": "def log_test_start(self, test_id:"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 120,
          "context": " 117:             backend_name = \"GPU (CuPy)\" if self.use_gpu else \"CPU (NumPy)\"\n 118:             log(f\"[accel] Using {backend_name} backend.\", \"INFO\")\n 119:         \n 120: >>>     @staticmethod\n 121:         def load_config(\n 122:             config_path: Optional[str] = None,\n 123:             default_config_name: str = \"config.json\"",
          "match": "@staticmethod"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 174,
          "context": " 171:                 f\"(searched in {script_dir}/config and {script_dir.parent}/config)\"\n 172:             )\n 173:         \n 174: >>>     @staticmethod\n 175:         def resolve_outdir(output_dir_hint: str) -> Path:\n 176:             \"\"\"\n 177:             Resolve output directory relative to script location.",
          "match": "@staticmethod"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 196,
          "context": " 193:             outdir.mkdir(parents=True, exist_ok=True)\n 194:             return outdir\n 195:         \n 196: >>>     @staticmethod\n 197:         def hann_window(length: int) -> np.ndarray:\n 198:             \"\"\"\n 199:             Create Hanning (Hann) window for FFT windowing.",
          "match": "@staticmethod"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 49,
          "context": "  46:         \n  47:         Provides common functionality:\n  48:         - Config loading from standard locations\n  49: >>>     - Backend (NumPy/CuPy) selection\n  50:         - Logger initialization\n  51:         - FFT-based frequency estimation\n  52:         - Output directory management",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 83,
          "context": "  80:             self.quick = bool(self.run_settings.get(\"quick_mode\", False))\n  81:             \n  82:             # Backend selection\n  83: >>>         use_gpu = bool(self.run_settings.get(\"use_gpu\", False))\n  84:             self.xp, self.use_gpu = pick_backend(use_gpu)\n  85:             \n  86:             # Output directory",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 83,
          "context": "  80:             self.quick = bool(self.run_settings.get(\"quick_mode\", False))\n  81:             \n  82:             # Backend selection\n  83: >>>         use_gpu = bool(self.run_settings.get(\"use_gpu\", False))\n  84:             self.xp, self.use_gpu = pick_backend(use_gpu)\n  85:             \n  86:             # Output directory",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 84,
          "context": "  81:             \n  82:             # Backend selection\n  83:             use_gpu = bool(self.run_settings.get(\"use_gpu\", False))\n  84: >>>         self.xp, self.use_gpu = pick_backend(use_gpu)\n  85:             \n  86:             # Output directory\n  87:             self.out_root = Path(out_root)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 84,
          "context": "  81:             \n  82:             # Backend selection\n  83:             use_gpu = bool(self.run_settings.get(\"use_gpu\", False))\n  84: >>>         self.xp, self.use_gpu = pick_backend(use_gpu)\n  85:             \n  86:             # Output directory\n  87:             self.out_root = Path(out_root)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 117,
          "context": " 114:             self._current_tracker = None  # Active tracker for current test\n 115:             \n 116:             # Log backend info\n 117: >>>         backend_name = \"GPU (CuPy)\" if self.use_gpu else \"CPU (NumPy)\"\n 118:             log(f\"[accel] Using {backend_name} backend.\", \"INFO\")\n 119:         \n 120:         @staticmethod",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 117,
          "context": " 114:             self._current_tracker = None  # Active tracker for current test\n 115:             \n 116:             # Log backend info\n 117: >>>         backend_name = \"GPU (CuPy)\" if self.use_gpu else \"CPU (NumPy)\"\n 118:             log(f\"[accel] Using {backend_name} backend.\", \"INFO\")\n 119:         \n 120:         @staticmethod",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 117,
          "context": " 114:             self._current_tracker = None  # Active tracker for current test\n 115:             \n 116:             # Log backend info\n 117: >>>         backend_name = \"GPU (CuPy)\" if self.use_gpu else \"CPU (NumPy)\"\n 118:             log(f\"[accel] Using {backend_name} backend.\", \"INFO\")\n 119:         \n 120:         @staticmethod",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 359,
          "context": " 356:             Stop resource tracking and return metrics.\n 357:             \n 358:             Returns:\n 359: >>>             Dict with resource metrics (cpu, memory, gpu, runtime)\n 360:                 Returns zeros if tracking disabled\n 361:             \n 362:             Example:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 371,
          "context": " 368:                 return {\n 369:                     \"peak_cpu_percent\": 0.0,\n 370:                     \"peak_memory_mb\": 0.0,\n 371: >>>                 \"peak_gpu_memory_mb\": 0.0,\n 372:                     \"runtime_sec\": 0.0\n 373:                 }\n 374:             ",
          "match": "gpu"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 342,
          "context": " 339:             \"\"\"\n 340:             Manually sample current resource usage.\n 341:             \n 342: >>>         Call this periodically during test execution if not using background mode.\n 343:             \n 344:             Example:\n 345:                 >>> harness.start_test_tracking(background=False)",
          "match": "periodic"
        }
      ],
      "line_count": 406,
      "docstring": "lfm_test_harness.py — Base harness class for LFM tier test runners\n-------------------------------------------------------------------\nPurpose:\n    Eliminate duplicate code across tier runners by providing shared:\n    - Config loading with standard search paths\n    - Logger/output directory setup\n    - Backend selection and initialization\n    - Common frequency measurement methods (FFT-based)\n    - Hanning window utilities\n    - Output directory resolution\n\nAll tier-specific harnesses (Tier1Harness, Tier2Harness, etc.) should\ninherit from BaseTierHarness to reduce code duplication.\n\nBenefits:\n    - Single source of truth for config loading (~50 lines per file)\n    - Consistent FFT-based frequency estimation (~30 lines per file)\n    - Standardized logger setup (~20 lines per file)\n    - Reduces copy-paste errors and improves maintainability"
    },
    {
      "filepath": "lfm_test_metrics.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "57554f5d0c9a2d2d",
      "file_size": 8171,
      "modified": "2025-11-02T20:02:10.876805",
      "git_info": {
        "first_commit": {
          "hash": "f99fcb27",
          "date": "2025-10-31 16:46:14 -0700",
          "message": "Continue code restructure"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     from datetime import datetime\n  19:     from typing import Dict, List, Optional, Tuple\n  20:     \n  21: >>> class TestMetrics:\n  22:     \t\"\"\"\n  23:     \tManages test execution metrics database for resource-aware scheduling.\n  24:     \t\"\"\"",
          "match": "class TestMetrics:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     \t\"\"\"\n  23:     \tManages test execution metrics database for resource-aware scheduling.\n  24:     \t\"\"\"\n  25: >>> \tdef __init__(self, db_path: Path = None):\n  26:     \t\tif db_path is None:\n  27:     \t\t\tdb_path = Path(__file__).parent / \"results\" / \"test_metrics_history.json\"\n  28:     \t\tself.db_path = Path(db_path)",
          "match": "def __init__(self, db_path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 35,
          "context": "  32:     \t\t\t\tself.data = json.load(f)\n  33:     \t\telse:\n  34:     \t\t\tself.data = {}\n  35: >>> \tdef save(self):\n  36:     \t\twith open(self.db_path, 'w') as f:\n  37:     \t\t\tjson.dump(self.data, f, indent=2)\n  38:     \tdef record_run(self, test_id: str, metrics: Dict):",
          "match": "def save(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 38,
          "context": "  35:     \tdef save(self):\n  36:     \t\twith open(self.db_path, 'w') as f:\n  37:     \t\t\tjson.dump(self.data, f, indent=2)\n  38: >>> \tdef record_run(self, test_id: str, metrics: Dict):\n  39:     \t\tif test_id not in self.data:\n  40:     \t\t\tself.data[test_id] = {\"runs\": [], \"estimated_resources\": None, \"priority\": 50}\n  41:     \t\tself.data[test_id][\"runs\"].append(metrics)",
          "match": "def record_run(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 49,
          "context": "  46:     \t\tif metrics.get(\"exit_code\", 0) != 0:\n  47:     \t\t\tself.data[test_id][\"priority\"] = 90\n  48:     \t\tself.save()\n  49: >>> \tdef _compute_estimate(self, test_id: str) -> Dict:\n  50:     \t\truns = self.data[test_id][\"runs\"]\n  51:     \t\tif not runs:\n  52:     \t\t\treturn None",
          "match": "def _compute_estimate(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 82,
          "context": "  79:     \t\t\t\"sample_size\": len(runs),\n  80:     \t\t\t\"timeout_multiplier\": timeout_multiplier\n  81:     \t\t}\n  82: >>> \tdef get_estimate(self, test_id: str, test_config: Dict = None) -> Dict:\n  83:     \t\tif test_id in self.data and self.data[test_id].get(\"estimated_resources\"):\n  84:     \t\t\treturn self.data[test_id][\"estimated_resources\"]\n  85:     \t\tif test_config:",
          "match": "def get_estimate(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 96,
          "context": "  93:     \t\t\t\"confidence\": \"default_conservative\",\n  94:     \t\t\t\"sample_size\": 0\n  95:     \t\t}\n  96: >>> \tdef _estimate_from_config(self, test_id: str, config: Dict) -> Dict:\n  97:     \t\tdimensions = config.get(\"dimensions\", 1)\n  98:     \t\tgrid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n  99:     \t\tsteps = config.get(\"steps\", 6000)",
          "match": "def _estimate_from_config(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 140,
          "context": " 137:     \t\t\t\"confidence\": \"estimated_from_config\",\n 138:     \t\t\t\"sample_size\": 0\n 139:     \t\t}\n 140: >>> \tdef get_priority(self, test_id: str) -> int:\n 141:     \t\tif test_id not in self.data:\n 142:     \t\t\treturn 100\n 143:     \t\tif not self.data[test_id][\"runs\"]:",
          "match": "def get_priority(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 157,
          "context": " 154:     \t\t}\n 155:     \t\tprefix = test_id.split(\"-\")[0]\n 156:     \t\treturn tier_priorities.get(prefix, 50)\n 157: >>> \tdef get_all_test_ids(self) -> List[str]:\n 158:     \t\treturn list(self.data.keys())\n 159:     \tdef get_all_runs(self, test_id: str) -> List[Dict]:\n 160:     \t\tentry = self.data.get(test_id)",
          "match": "def get_all_test_ids(self) -> List[str]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 159,
          "context": " 156:     \t\treturn tier_priorities.get(prefix, 50)\n 157:     \tdef get_all_test_ids(self) -> List[str]:\n 158:     \t\treturn list(self.data.keys())\n 159: >>> \tdef get_all_runs(self, test_id: str) -> List[Dict]:\n 160:     \t\tentry = self.data.get(test_id)\n 161:     \t\tif not entry:\n 162:     \t\t\treturn []",
          "match": "def get_all_runs(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 164,
          "context": " 161:     \t\tif not entry:\n 162:     \t\t\treturn []\n 163:     \t\treturn list(entry.get(\"runs\", []))\n 164: >>> \tdef get_summary(self) -> Dict:\n 165:     \t\ttotal_tests = len(self.data)\n 166:     \t\twith_history = sum(1 for t in self.data.values() if t[\"runs\"])\n 167:     \t\tno_history = total_tests - with_history",
          "match": "def get_summary(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 182,
          "context": " 179:     \t\t\t\"avg_runtime_sec\": avg_runtime\n 180:     \t\t}\n 181:     \n 182: >>> def load_test_configs(tier: int) -> List[Tuple[str, Dict]]:\n 183:     \t\"\"\"Load test configurations for a tier using the central registry.\n 184:     \n 185:     \tSupports schema types:",
          "match": "def load_test_configs(tier:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 12,
          "context": "   9:     LFM Test Metrics Database - Resource usage tracking and estimation\n  10:     ============================================================\n  11:     Persistent storage of test execution metrics to enable dynamic scheduling.\n  12: >>> Tracks runtime, CPU, RAM, and GPU usage for each test run.\n  13:     \"\"\"\n  14:     \n  15:     import json",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 63,
          "context": "  60:     \t\truntime = last_success.get(\"runtime_sec\", 1.0)\n  61:     \t\tcpu_percent = last_success.get(\"peak_cpu_percent\", 100.0)\n  62:     \t\tmemory_mb = last_success.get(\"peak_memory_mb\", 500.0)\n  63: >>> \t\tgpu_memory_mb = last_success.get(\"peak_gpu_memory_mb\", 0.0)\n  64:     \t\tcpu_cores_needed = max(0.75, cpu_percent / 100.0)\n  65:     \t\tuses_gpu = gpu_memory_mb > 50\n  66:     \t\truntime_buffered = runtime * 1.1",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 63,
          "context": "  60:     \t\truntime = last_success.get(\"runtime_sec\", 1.0)\n  61:     \t\tcpu_percent = last_success.get(\"peak_cpu_percent\", 100.0)\n  62:     \t\tmemory_mb = last_success.get(\"peak_memory_mb\", 500.0)\n  63: >>> \t\tgpu_memory_mb = last_success.get(\"peak_gpu_memory_mb\", 0.0)\n  64:     \t\tcpu_cores_needed = max(0.75, cpu_percent / 100.0)\n  65:     \t\tuses_gpu = gpu_memory_mb > 50\n  66:     \t\truntime_buffered = runtime * 1.1",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 65,
          "context": "  62:     \t\tmemory_mb = last_success.get(\"peak_memory_mb\", 500.0)\n  63:     \t\tgpu_memory_mb = last_success.get(\"peak_gpu_memory_mb\", 0.0)\n  64:     \t\tcpu_cores_needed = max(0.75, cpu_percent / 100.0)\n  65: >>> \t\tuses_gpu = gpu_memory_mb > 50\n  66:     \t\truntime_buffered = runtime * 1.1\n  67:     \t\tcpu_buffered = cpu_cores_needed * 1.1\n  68:     \t\tmemory_buffered = memory_mb * 1.2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 65,
          "context": "  62:     \t\tmemory_mb = last_success.get(\"peak_memory_mb\", 500.0)\n  63:     \t\tgpu_memory_mb = last_success.get(\"peak_gpu_memory_mb\", 0.0)\n  64:     \t\tcpu_cores_needed = max(0.75, cpu_percent / 100.0)\n  65: >>> \t\tuses_gpu = gpu_memory_mb > 50\n  66:     \t\truntime_buffered = runtime * 1.1\n  67:     \t\tcpu_buffered = cpu_cores_needed * 1.1\n  68:     \t\tmemory_buffered = memory_mb * 1.2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:     \t\truntime_buffered = runtime * 1.1\n  67:     \t\tcpu_buffered = cpu_cores_needed * 1.1\n  68:     \t\tmemory_buffered = memory_mb * 1.2\n  69: >>> \t\tgpu_buffered = gpu_memory_mb * 1.1 if uses_gpu else 0.0\n  70:     \t\ttimeout_count = sum(1 for r in runs[-3:] if r.get(\"exit_code\") == -2)\n  71:     \t\ttimeout_multiplier = 3.0 + (timeout_count * 0.5)\n  72:     \t\treturn {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:     \t\truntime_buffered = runtime * 1.1\n  67:     \t\tcpu_buffered = cpu_cores_needed * 1.1\n  68:     \t\tmemory_buffered = memory_mb * 1.2\n  69: >>> \t\tgpu_buffered = gpu_memory_mb * 1.1 if uses_gpu else 0.0\n  70:     \t\ttimeout_count = sum(1 for r in runs[-3:] if r.get(\"exit_code\") == -2)\n  71:     \t\ttimeout_multiplier = 3.0 + (timeout_count * 0.5)\n  72:     \t\treturn {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:     \t\truntime_buffered = runtime * 1.1\n  67:     \t\tcpu_buffered = cpu_cores_needed * 1.1\n  68:     \t\tmemory_buffered = memory_mb * 1.2\n  69: >>> \t\tgpu_buffered = gpu_memory_mb * 1.1 if uses_gpu else 0.0\n  70:     \t\ttimeout_count = sum(1 for r in runs[-3:] if r.get(\"exit_code\") == -2)\n  71:     \t\ttimeout_multiplier = 3.0 + (timeout_count * 0.5)\n  72:     \t\treturn {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 76,
          "context": "  73:     \t\t\t\"runtime_sec\": max(1.0, runtime_buffered),\n  74:     \t\t\t\"cpu_cores_needed\": max(0.75, cpu_buffered),\n  75:     \t\t\t\"memory_mb\": max(100, memory_buffered),\n  76: >>> \t\t\t\"gpu_memory_mb\": gpu_buffered,\n  77:     \t\t\t\"uses_gpu\": uses_gpu,\n  78:     \t\t\t\"confidence\": \"last_run\",\n  79:     \t\t\t\"sample_size\": len(runs),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 76,
          "context": "  73:     \t\t\t\"runtime_sec\": max(1.0, runtime_buffered),\n  74:     \t\t\t\"cpu_cores_needed\": max(0.75, cpu_buffered),\n  75:     \t\t\t\"memory_mb\": max(100, memory_buffered),\n  76: >>> \t\t\t\"gpu_memory_mb\": gpu_buffered,\n  77:     \t\t\t\"uses_gpu\": uses_gpu,\n  78:     \t\t\t\"confidence\": \"last_run\",\n  79:     \t\t\t\"sample_size\": len(runs),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 77,
          "context": "  74:     \t\t\t\"cpu_cores_needed\": max(0.75, cpu_buffered),\n  75:     \t\t\t\"memory_mb\": max(100, memory_buffered),\n  76:     \t\t\t\"gpu_memory_mb\": gpu_buffered,\n  77: >>> \t\t\t\"uses_gpu\": uses_gpu,\n  78:     \t\t\t\"confidence\": \"last_run\",\n  79:     \t\t\t\"sample_size\": len(runs),\n  80:     \t\t\t\"timeout_multiplier\": timeout_multiplier",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 77,
          "context": "  74:     \t\t\t\"cpu_cores_needed\": max(0.75, cpu_buffered),\n  75:     \t\t\t\"memory_mb\": max(100, memory_buffered),\n  76:     \t\t\t\"gpu_memory_mb\": gpu_buffered,\n  77: >>> \t\t\t\"uses_gpu\": uses_gpu,\n  78:     \t\t\t\"confidence\": \"last_run\",\n  79:     \t\t\t\"sample_size\": len(runs),\n  80:     \t\t\t\"timeout_multiplier\": timeout_multiplier",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 91,
          "context": "  88:     \t\t\t\"runtime_sec\": 300.0,\n  89:     \t\t\t\"cpu_cores_needed\": 4.0,\n  90:     \t\t\t\"memory_mb\": 2000,\n  91: >>> \t\t\t\"gpu_memory_mb\": 3000,\n  92:     \t\t\t\"uses_gpu\": True,\n  93:     \t\t\t\"confidence\": \"default_conservative\",\n  94:     \t\t\t\"sample_size\": 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 92,
          "context": "  89:     \t\t\t\"cpu_cores_needed\": 4.0,\n  90:     \t\t\t\"memory_mb\": 2000,\n  91:     \t\t\t\"gpu_memory_mb\": 3000,\n  92: >>> \t\t\t\"uses_gpu\": True,\n  93:     \t\t\t\"confidence\": \"default_conservative\",\n  94:     \t\t\t\"sample_size\": 0\n  95:     \t\t}",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 100,
          "context": "  97:     \t\tdimensions = config.get(\"dimensions\", 1)\n  98:     \t\tgrid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n  99:     \t\tsteps = config.get(\"steps\", 6000)\n 100: >>> \t\tuses_gpu = config.get(\"use_gpu\", config.get(\"gpu_enabled\", True))\n 101:     \t\tif isinstance(grid_points, (list, tuple)):\n 102:     \t\t\tgrid_size = 1\n 103:     \t\t\tfor g in grid_points:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 100,
          "context": "  97:     \t\tdimensions = config.get(\"dimensions\", 1)\n  98:     \t\tgrid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n  99:     \t\tsteps = config.get(\"steps\", 6000)\n 100: >>> \t\tuses_gpu = config.get(\"use_gpu\", config.get(\"gpu_enabled\", True))\n 101:     \t\tif isinstance(grid_points, (list, tuple)):\n 102:     \t\t\tgrid_size = 1\n 103:     \t\t\tfor g in grid_points:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 100,
          "context": "  97:     \t\tdimensions = config.get(\"dimensions\", 1)\n  98:     \t\tgrid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n  99:     \t\tsteps = config.get(\"steps\", 6000)\n 100: >>> \t\tuses_gpu = config.get(\"use_gpu\", config.get(\"gpu_enabled\", True))\n 101:     \t\tif isinstance(grid_points, (list, tuple)):\n 102:     \t\t\tgrid_size = 1\n 103:     \t\t\tfor g in grid_points:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 127,
          "context": " 124:     \t\t\t\tgrid_size = 512 ** int(dimensions)\n 125:     \t\tmemory_per_field_mb = grid_size * 8 / (1024**2)\n 126:     \t\tmemory_mb = memory_per_field_mb * 5 * 1.5\n 127: >>> \t\tgpu_memory_mb = memory_mb if uses_gpu else 0\n 128:     \t\tcomplexity_factor = (grid_size / 1e6) * (steps / 1000)\n 129:     \t\truntime_sec = complexity_factor * (10 if uses_gpu else 50)\n 130:     \t\tcpu_cores = 4 if dimensions == 3 else 2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 127,
          "context": " 124:     \t\t\t\tgrid_size = 512 ** int(dimensions)\n 125:     \t\tmemory_per_field_mb = grid_size * 8 / (1024**2)\n 126:     \t\tmemory_mb = memory_per_field_mb * 5 * 1.5\n 127: >>> \t\tgpu_memory_mb = memory_mb if uses_gpu else 0\n 128:     \t\tcomplexity_factor = (grid_size / 1e6) * (steps / 1000)\n 129:     \t\truntime_sec = complexity_factor * (10 if uses_gpu else 50)\n 130:     \t\tcpu_cores = 4 if dimensions == 3 else 2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 129,
          "context": " 126:     \t\tmemory_mb = memory_per_field_mb * 5 * 1.5\n 127:     \t\tgpu_memory_mb = memory_mb if uses_gpu else 0\n 128:     \t\tcomplexity_factor = (grid_size / 1e6) * (steps / 1000)\n 129: >>> \t\truntime_sec = complexity_factor * (10 if uses_gpu else 50)\n 130:     \t\tcpu_cores = 4 if dimensions == 3 else 2\n 131:     \t\treturn {\n 132:     \t\t\t\"runtime_sec\": max(5.0, runtime_sec),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 135,
          "context": " 132:     \t\t\t\"runtime_sec\": max(5.0, runtime_sec),\n 133:     \t\t\t\"cpu_cores_needed\": float(cpu_cores),\n 134:     \t\t\t\"memory_mb\": max(500, memory_mb),\n 135: >>> \t\t\t\"gpu_memory_mb\": gpu_memory_mb,\n 136:     \t\t\t\"uses_gpu\": uses_gpu,\n 137:     \t\t\t\"confidence\": \"estimated_from_config\",\n 138:     \t\t\t\"sample_size\": 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 135,
          "context": " 132:     \t\t\t\"runtime_sec\": max(5.0, runtime_sec),\n 133:     \t\t\t\"cpu_cores_needed\": float(cpu_cores),\n 134:     \t\t\t\"memory_mb\": max(500, memory_mb),\n 135: >>> \t\t\t\"gpu_memory_mb\": gpu_memory_mb,\n 136:     \t\t\t\"uses_gpu\": uses_gpu,\n 137:     \t\t\t\"confidence\": \"estimated_from_config\",\n 138:     \t\t\t\"sample_size\": 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 136,
          "context": " 133:     \t\t\t\"cpu_cores_needed\": float(cpu_cores),\n 134:     \t\t\t\"memory_mb\": max(500, memory_mb),\n 135:     \t\t\t\"gpu_memory_mb\": gpu_memory_mb,\n 136: >>> \t\t\t\"uses_gpu\": uses_gpu,\n 137:     \t\t\t\"confidence\": \"estimated_from_config\",\n 138:     \t\t\t\"sample_size\": 0\n 139:     \t\t}",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 136,
          "context": " 133:     \t\t\t\"cpu_cores_needed\": float(cpu_cores),\n 134:     \t\t\t\"memory_mb\": max(500, memory_mb),\n 135:     \t\t\t\"gpu_memory_mb\": gpu_memory_mb,\n 136: >>> \t\t\t\"uses_gpu\": uses_gpu,\n 137:     \t\t\t\"confidence\": \"estimated_from_config\",\n 138:     \t\t\t\"sample_size\": 0\n 139:     \t\t}",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 226,
          "context": " 223:     \t\t\tif not test_id:\n 224:     \t\t\t\tcontinue\n 225:     \t\t\ttest_cfg = {**params, **v}\n 226: >>> \t\t\t# Harmonize GPU flag\n 227:     \t\t\ttest_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", cfg.get(\"hardware\", {}).get(\"gpu_enabled\", True))\n 228:     \t\t\ttests.append((test_id, test_cfg))\n 229:     \telse:  # schema == \"tests\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 227,
          "context": " 224:     \t\t\t\tcontinue\n 225:     \t\t\ttest_cfg = {**params, **v}\n 226:     \t\t\t# Harmonize GPU flag\n 227: >>> \t\t\ttest_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", cfg.get(\"hardware\", {}).get(\"gpu_enabled\", True))\n 228:     \t\t\ttests.append((test_id, test_cfg))\n 229:     \telse:  # schema == \"tests\"\n 230:     \t\ttest_list = cfg.get(\"tests\", [])",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 227,
          "context": " 224:     \t\t\t\tcontinue\n 225:     \t\t\ttest_cfg = {**params, **v}\n 226:     \t\t\t# Harmonize GPU flag\n 227: >>> \t\t\ttest_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", cfg.get(\"hardware\", {}).get(\"gpu_enabled\", True))\n 228:     \t\t\ttests.append((test_id, test_cfg))\n 229:     \telse:  # schema == \"tests\"\n 230:     \t\ttest_list = cfg.get(\"tests\", [])",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 227,
          "context": " 224:     \t\t\t\tcontinue\n 225:     \t\t\ttest_cfg = {**params, **v}\n 226:     \t\t\t# Harmonize GPU flag\n 227: >>> \t\t\ttest_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", cfg.get(\"hardware\", {}).get(\"gpu_enabled\", True))\n 228:     \t\t\ttests.append((test_id, test_cfg))\n 229:     \telse:  # schema == \"tests\"\n 230:     \t\ttest_list = cfg.get(\"tests\", [])",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 236,
          "context": " 233:     \t\t\tif not test_id:\n 234:     \t\t\t\tcontinue\n 235:     \t\t\ttest_cfg = {**params, **t}\n 236: >>> \t\t\t# Harmonize GPU flag\n 237:     \t\t\ttest_cfg[\"gpu_enabled\"] = cfg.get(\"hardware\", {}).get(\"gpu_enabled\", cfg.get(\"run_settings\", {}).get(\"use_gpu\", True))\n 238:     \t\t\ttests.append((test_id, test_cfg))\n 239:     \treturn tests",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 237,
          "context": " 234:     \t\t\t\tcontinue\n 235:     \t\t\ttest_cfg = {**params, **t}\n 236:     \t\t\t# Harmonize GPU flag\n 237: >>> \t\t\ttest_cfg[\"gpu_enabled\"] = cfg.get(\"hardware\", {}).get(\"gpu_enabled\", cfg.get(\"run_settings\", {}).get(\"use_gpu\", True))\n 238:     \t\t\ttests.append((test_id, test_cfg))\n 239:     \treturn tests\n 240:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 237,
          "context": " 234:     \t\t\t\tcontinue\n 235:     \t\t\ttest_cfg = {**params, **t}\n 236:     \t\t\t# Harmonize GPU flag\n 237: >>> \t\t\ttest_cfg[\"gpu_enabled\"] = cfg.get(\"hardware\", {}).get(\"gpu_enabled\", cfg.get(\"run_settings\", {}).get(\"use_gpu\", True))\n 238:     \t\t\ttests.append((test_id, test_cfg))\n 239:     \treturn tests\n 240:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 237,
          "context": " 234:     \t\t\t\tcontinue\n 235:     \t\t\ttest_cfg = {**params, **t}\n 236:     \t\t\t# Harmonize GPU flag\n 237: >>> \t\t\ttest_cfg[\"gpu_enabled\"] = cfg.get(\"hardware\", {}).get(\"gpu_enabled\", cfg.get(\"run_settings\", {}).get(\"use_gpu\", True))\n 238:     \t\t\ttests.append((test_id, test_cfg))\n 239:     \treturn tests\n 240:     ",
          "match": "gpu"
        }
      ],
      "line_count": 239,
      "docstring": "LFM Test Metrics Database - Resource usage tracking and estimation\n============================================================\nPersistent storage of test execution metrics to enable dynamic scheduling.\nTracks runtime, CPU, RAM, and GPU usage for each test run."
    },
    {
      "filepath": "run_tests_simple.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "306840e6ab248e6d",
      "file_size": 3052,
      "modified": "2025-11-02T20:02:10.893065",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 19,
          "context": "  16:     from pathlib import Path\n  17:     from test_metrics import TestMetrics\n  18:     \n  19: >>> def run_test(test_id, tier, test_metrics):\n  20:         \"\"\"Run a single test with visible output and metric recording.\"\"\"\n  21:         \n  22:         # Map tier to runner script",
          "match": "def run_test(test_id, tier, test_metrics):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 72,
          "context": "  69:         return result.returncode == 0\n  70:     \n  71:     \n  72: >>> def main():\n  73:         \"\"\"Run fast tests.\"\"\"\n  74:         \n  75:         tests = [",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 60,
          "context": "  57:             \"runtime_sec\": runtime,\n  58:             \"peak_cpu_percent\": 0.0,  # Not monitoring for now\n  59:             \"peak_memory_mb\": 0.0,\n  60: >>>         \"peak_gpu_memory_mb\": 0.0,\n  61:             \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n  62:         }\n  63:         test_metrics.record_run(test_id, metrics)",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 10,
          "context": "   7:     \n   8:     \"\"\"\n   9:     Simple sequential test runner with visible output - for debugging.\n  10: >>> Works perfectly but runs sequentially. Use this until we fix parallel threading issues.\n  11:     \"\"\"\n  12:     \n  13:     import subprocess",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 10,
          "context": "   7:     \n   8:     \"\"\"\n   9:     Simple sequential test runner with visible output - for debugging.\n  10: >>> Works perfectly but runs sequentially. Use this until we fix parallel threading issues.\n  11:     \"\"\"\n  12:     \n  13:     import subprocess",
          "match": "threading"
        }
      ],
      "line_count": 117,
      "docstring": "Simple sequential test runner with visible output - for debugging.\nWorks perfectly but runs sequentially. Use this until we fix parallel threading issues."
    },
    {
      "filepath": "test_1d_propagation.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "fa26eba7234d1d21",
      "file_size": 565,
      "modified": "2025-11-02T20:02:10.909442",
      "git_info": {
        "first_commit": {
          "hash": "8351ace7",
          "date": "2025-10-30 06:49:07 -0700",
          "message": "Continue the mission"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 14,
      "docstring": "Moved: This test now lives in devtests/test_1d_propagation.py\n\nThis stub prevents duplicate discovery at the repo root."
    },
    {
      "filepath": "test_double_slit_scenario.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "283b81d877aa2e68",
      "file_size": 6853,
      "modified": "2025-11-02T20:02:10.913039",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 117,
          "context": " 114:                   f\"behind={field_behind_barrier:8.3f}, screen={field_at_screen:8.3f}, \"\n 115:                   f\"energy={energy:.3e}\")\n 116:             \n 117: >>>         # Check for instability\n 118:             if max_field > 100 or np.isnan(max_field):\n 119:                 print(\"\\n❌ FAILED: Numerical instability detected!\")\n 120:                 break",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 119,
          "context": " 116:             \n 117:             # Check for instability\n 118:             if max_field > 100 or np.isnan(max_field):\n 119: >>>             print(\"\\n❌ FAILED: Numerical instability detected!\")\n 120:                 break\n 121:                 \n 122:             # Check if wave reached screen",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 203,
          "context": " 200:         print(\"❌ DOUBLE SLIT TEST NEEDS WORK\")\n 201:         print(\"   Issues to fix:\")\n 202:         if np.max(np.abs(E)) >= 100:\n 203: >>>         print(\"   - Numerical instability\")\n 204:         if field_at_screen < 0.01:\n 205:             print(\"   - Wave not reaching screen\")\n 206:         if len(peaks) < 2:",
          "match": "stability"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 72,
          "context": "  69:         'beta': 1.0,\n  70:         'chi': 0.0,\n  71:         'gamma_damp': 0.05,  # Light damping\n  72: >>>     'boundary': 'periodic',\n  73:         'stencil_order': 2,\n  74:     }\n  75:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 72,
          "context": "  69:         'beta': 1.0,\n  70:         'chi': 0.0,\n  71:         'gamma_damp': 0.05,  # Light damping\n  72: >>>     'boundary': 'periodic',\n  73:         'stencil_order': 2,\n  74:     }\n  75:     ",
          "match": "periodic"
        }
      ],
      "line_count": 208,
      "docstring": "Test script for double slit scenario - validates before deploying to interactive app"
    },
    {
      "filepath": "test_lfm_dispersion_3d.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "fca60556ed3f7782",
      "file_size": 8685,
      "modified": "2025-11-02T20:02:10.914253",
      "git_info": {
        "first_commit": {
          "hash": "ebbe74b4",
          "date": "2025-10-27 14:59:28 -0700",
          "message": "update tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 77,
          "context": "  74:     # --------------------------------\n  75:     # ω measurement utilities\n  76:     # --------------------------------\n  77: >>> def measure_omega_targeted(series, dt, omega_hint, span=0.30, ngrid=401):\n  78:         \"\"\"\n  79:         Scan ω in [ω_hint*(1-span), ω_hint*(1+span)] and pick the maximal\n  80:         response |Σ x(t) e^{-i ω t}| after mean-removal + Hann window.",
          "match": "def measure_omega_targeted(series, dt, omega_hint, span=0.30, ngrid=401):"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 14,
          "context": "  11:     Purpose\n  12:     -------\n  13:     Validate the canonical dispersion ω^2 = c^2 k^2 + χ^2 in 3-D for\n  14: >>> both serial (core) and threaded parallel backends, with minimal\n  15:     runtime and strong diagnostics.\n  16:     \n  17:     What's new vs v1.2",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 43,
          "context": "  40:     import matplotlib.pyplot as plt\n  41:     from pathlib import Path\n  42:     from lfm_equation import advance, core_metrics, energy_total\n  43: >>> from lfm_parallel import run_lattice\n  44:     \n  45:     # ----------------------------\n  46:     # Config",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 147,
          "context": " 144:         t_serial = time.time() - t0\n 145:         w_s, f_s, pow_s, i_s = measure_omega_targeted(series_s, dt, omega_th)\n 146:     \n 147: >>>     # ---------- PARALLEL ----------\n 148:         print(\"  Running parallel (threads 2x2x2) …\")\n 149:         params_p = dict(params_base)\n 150:         E = np.copy(E0); E_prev = np.copy(Eprev0)",
          "match": "PARALLEL"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 148,
          "context": " 145:         w_s, f_s, pow_s, i_s = measure_omega_targeted(series_s, dt, omega_th)\n 146:     \n 147:         # ---------- PARALLEL ----------\n 148: >>>     print(\"  Running parallel (threads 2x2x2) …\")\n 149:         params_p = dict(params_base)\n 150:         E = np.copy(E0); E_prev = np.copy(Eprev0)\n 151:         series_p = []",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 167,
          "context": " 164:                 print(f\"    [par]   step {n+1:4d}  drift={met['drift']:+.3e}  \"\n 165:                       f\"max|E|={met['max_abs']:.3e}\")\n 166:     \n 167: >>>     t_parallel = time.time() - t0\n 168:         w_p, f_p, pow_p, i_p = measure_omega_targeted(series_p, dt, omega_th)\n 169:     \n 170:         # ---------- Compare ----------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 178,
          "context": " 175:         results.append({\n 176:             \"dir\": label,\n 177:             \"omega_meas_serial\": w_s,\n 178: >>>         \"omega_meas_parallel\": w_p,\n 179:             \"omega_theory\": omega_th,\n 180:             \"rel_err_serial\": rel_err_s,\n 181:             \"rel_err_parallel\": rel_err_p,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 181,
          "context": " 178:             \"omega_meas_parallel\": w_p,\n 179:             \"omega_theory\": omega_th,\n 180:             \"rel_err_serial\": rel_err_s,\n 181: >>>         \"rel_err_parallel\": rel_err_p,\n 182:             \"backend_gap\": backend_gap,\n 183:             \"serial_t\": t_serial,\n 184:             \"parallel_t\": t_parallel,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 184,
          "context": " 181:             \"rel_err_parallel\": rel_err_p,\n 182:             \"backend_gap\": backend_gap,\n 183:             \"serial_t\": t_serial,\n 184: >>>         \"parallel_t\": t_parallel,\n 185:         })\n 186:     \n 187:         # ---------- Visualization ----------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 184,
          "context": " 181:             \"rel_err_parallel\": rel_err_p,\n 182:             \"backend_gap\": backend_gap,\n 183:             \"serial_t\": t_serial,\n 184: >>>         \"parallel_t\": t_parallel,\n 185:         })\n 186:     \n 187:         # ---------- Visualization ----------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 203,
          "context": " 200:             plt.xlim(max(0, f_s[0]), min(f_s[-1], 5*omega_th/(2*math.pi)))\n 201:             plt.title(\"DFT scan (serial)\")\n 202:             plt.xlabel(\"Hz\")\n 203: >>>         # Zoomed spectrum (parallel)\n 204:             plt.subplot(1,3,3)\n 205:             plt.semilogy(f_p, pow_p, lw=1)\n 206:             plt.axvline(omega_th/(2*math.pi), ls=\"--\", lw=1, color=\"k\")",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 209,
          "context": " 206:             plt.axvline(omega_th/(2*math.pi), ls=\"--\", lw=1, color=\"k\")\n 207:             plt.axvline(w_p/(2*math.pi), ls=\":\", lw=1, color=\"k\")\n 208:             plt.xlim(max(0, f_p[0]), min(f_p[-1], 5*omega_th/(2*math.pi)))\n 209: >>>         plt.title(\"DFT scan (parallel)\")\n 210:             plt.xlabel(\"Hz\")\n 211:             plt.tight_layout()\n 212:             plt.show()",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 222,
          "context": " 219:         print(\n 220:             f\"{r['dir']:>3}  ω_th={r['omega_theory']:.6f}  \"\n 221:             f\"ω_s={r['omega_meas_serial']:.6f} (Δ={r['rel_err_serial']*100:.3f}%)  \"\n 222: >>>         f\"ω_p={r['omega_meas_parallel']:.6f} (Δ={r['rel_err_parallel']*100:.3f}%)  \"\n 223:             f\"gap(s|p)={r['backend_gap']*100:.3f}%  \"\n 224:             f\"t_s={r['serial_t']:.2f}s  t_p={r['parallel_t']:.2f}s\"\n 225:         )",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 222,
          "context": " 219:         print(\n 220:             f\"{r['dir']:>3}  ω_th={r['omega_theory']:.6f}  \"\n 221:             f\"ω_s={r['omega_meas_serial']:.6f} (Δ={r['rel_err_serial']*100:.3f}%)  \"\n 222: >>>         f\"ω_p={r['omega_meas_parallel']:.6f} (Δ={r['rel_err_parallel']*100:.3f}%)  \"\n 223:             f\"gap(s|p)={r['backend_gap']*100:.3f}%  \"\n 224:             f\"t_s={r['serial_t']:.2f}s  t_p={r['parallel_t']:.2f}s\"\n 225:         )",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 224,
          "context": " 221:             f\"ω_s={r['omega_meas_serial']:.6f} (Δ={r['rel_err_serial']*100:.3f}%)  \"\n 222:             f\"ω_p={r['omega_meas_parallel']:.6f} (Δ={r['rel_err_parallel']*100:.3f}%)  \"\n 223:             f\"gap(s|p)={r['backend_gap']*100:.3f}%  \"\n 224: >>>         f\"t_s={r['serial_t']:.2f}s  t_p={r['parallel_t']:.2f}s\"\n 225:         )\n 226:     \n 227:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 228,
          "context": " 225:         )\n 226:     \n 227:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])\n 228: >>> isoP = np.std([r[\"omega_meas_parallel\"] for r in results]) / np.mean([r[\"omega_meas_parallel\"] for r in results])\n 229:     print(f\"\\nIsotropy CoV  serial={iso*100:.3f}%   parallel={isoP*100:.3f}%\")\n 230:     \n 231:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 228,
          "context": " 225:         )\n 226:     \n 227:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])\n 228: >>> isoP = np.std([r[\"omega_meas_parallel\"] for r in results]) / np.mean([r[\"omega_meas_parallel\"] for r in results])\n 229:     print(f\"\\nIsotropy CoV  serial={iso*100:.3f}%   parallel={isoP*100:.3f}%\")\n 230:     \n 231:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 229,
          "context": " 226:     \n 227:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])\n 228:     isoP = np.std([r[\"omega_meas_parallel\"] for r in results]) / np.mean([r[\"omega_meas_parallel\"] for r in results])\n 229: >>> print(f\"\\nIsotropy CoV  serial={iso*100:.3f}%   parallel={isoP*100:.3f}%\")\n 230:     \n 231:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 232:         fields = [",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 233,
          "context": " 230:     \n 231:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 232:         fields = [\n 233: >>>         \"dir\",\"omega_theory\",\"omega_meas_serial\",\"omega_meas_parallel\",\n 234:             \"rel_err_serial\",\"rel_err_parallel\",\"backend_gap\",\"serial_t\",\"parallel_t\"\n 235:         ]\n 236:         w = csv.DictWriter(f, fieldnames=fields)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 234,
          "context": " 231:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 232:         fields = [\n 233:             \"dir\",\"omega_theory\",\"omega_meas_serial\",\"omega_meas_parallel\",\n 234: >>>         \"rel_err_serial\",\"rel_err_parallel\",\"backend_gap\",\"serial_t\",\"parallel_t\"\n 235:         ]\n 236:         w = csv.DictWriter(f, fieldnames=fields)\n 237:         w.writeheader(); w.writerows(results)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 234,
          "context": " 231:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 232:         fields = [\n 233:             \"dir\",\"omega_theory\",\"omega_meas_serial\",\"omega_meas_parallel\",\n 234: >>>         \"rel_err_serial\",\"rel_err_parallel\",\"backend_gap\",\"serial_t\",\"parallel_t\"\n 235:         ]\n 236:         w = csv.DictWriter(f, fieldnames=fields)\n 237:         w.writeheader(); w.writerows(results)",
          "match": "parallel"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 70,
          "context": "  67:     \n  68:     params_base = dict(\n  69:         dt=dt, dx=dx, alpha=alpha, beta=beta, chi=chi,\n  70: >>>     boundary=\"periodic\",\n  71:         debug={\"enable_diagnostics\": False},\n  72:     )\n  73:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 70,
          "context": "  67:     \n  68:     params_base = dict(\n  69:         dt=dt, dx=dx, alpha=alpha, beta=beta, chi=chi,\n  70: >>>     boundary=\"periodic\",\n  71:         debug={\"enable_diagnostics\": False},\n  72:     )\n  73:     ",
          "match": "periodic"
        }
      ],
      "line_count": 238,
      "docstring": "Tier-2 Dispersion & Isotropy Validation — LFM 3-D (v1.3)\n\nPurpose\n-------\nValidate the canonical dispersion ω^2 = c^2 k^2 + χ^2 in 3-D for\nboth serial (core) and threaded parallel backends, with minimal\nruntime and strong diagnostics.\n\nWhat's new vs v1.2\n------------------\n• Robust, theory-guided ω estimator: scans a narrow band around ω_th\n  and picks the peak response (DFT-at-selected-freqs), not a blunt FFT.\n• Zoomed diagnostic plots around the expected low frequency.\n• Same traveling-wave initialization; clearer comments.\n• Unchanged timing + lightweight drift sampling.\n\nNotes\n-----\n– Traveling wave init:\n    φ = k·x,  ω_th = sqrt(c^2|k|^2 + χ^2)\n    E(t0)      = A·sin(φ)\n    E(t0−dt)   = A·sin(φ − ω_th·dt)     # equivalent to adding correct velocity\n– With N=64 & k = (2π/N)/dx along an axis, ω_th ≈ 0.0982 rad/s (f≈0.0156 Hz),\n  i.e., the peak sits very close to DC; generic FFT plots can hide it."
    },
    {
      "filepath": "test_lfm_logger.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "d2f21cc8d82f1062",
      "file_size": 567,
      "modified": "2025-11-02T20:02:10.918839",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 14,
      "docstring": "Moved: This test now lives in devtests/test_lfm_logger.py\n\nThis stub prevents duplicate discovery by pytest at the repo root."
    },
    {
      "filepath": "test_lorentz_covariance.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "6446c7bb107a1889",
      "file_size": 632,
      "modified": "2025-11-02T20:02:10.918839",
      "git_info": {
        "first_commit": {
          "hash": "f0885273",
          "date": "2025-10-30 17:51:45 -0700",
          "message": "Additional tests, harnesses"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 14,
      "docstring": null
    },
    {
      "filepath": "test_metrics.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "f3b9899be1cb6495",
      "file_size": 610,
      "modified": "2025-11-02T20:02:10.920271",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [],
      "line_count": 14,
      "docstring": null
    },
    {
      "filepath": "test_output_requirements.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "3d90bb92ba822417",
      "file_size": 21444,
      "modified": "2025-11-02T20:02:10.921956",
      "git_info": {
        "first_commit": {
          "hash": "ef0dcb6b",
          "date": "2025-11-01 09:54:35 -0700",
          "message": "Testing framework improvements"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 298,
          "context": " 295:     # VALIDATION FUNCTIONS\n 296:     # ============================================================================\n 297:     \n 298: >>> def get_test_output_dir(test_id: str) -> Optional[Path]:\n 299:         \"\"\"Get the output directory for a test.\"\"\"\n 300:         project_root = Path(__file__).parent\n 301:         results_dir = project_root / \"results\"",
          "match": "def get_test_output_dir(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 320,
          "context": " 317:         return test_dir if test_dir.exists() else None\n 318:     \n 319:     \n 320: >>> def check_core_requirements(test_dir: Path, test_id: str) -> Tuple[List[str], List[str]]:\n 321:         \"\"\"\n 322:         Check core requirements for a test.\n 323:         ",
          "match": "def check_core_requirements(test_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 408,
          "context": " 405:         return passes, failures\n 406:     \n 407:     \n 408: >>> def check_special_requirements(test_dir: Path, test_id: str) -> Tuple[List[str], List[str]]:\n 409:         \"\"\"\n 410:         Check special per-test requirements.\n 411:         ",
          "match": "def check_special_requirements(test_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 485,
          "context": " 482:         return passes, failures\n 483:     \n 484:     \n 485: >>> def validate_test_outputs(test_id: str, verbose: bool = True) -> bool:\n 486:         \"\"\"\n 487:         Validate all requirements for a test.\n 488:         ",
          "match": "def validate_test_outputs(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 522,
          "context": " 519:     # PYTEST INTEGRATION\n 520:     # ============================================================================\n 521:     \n 522: >>> def get_all_test_ids() -> List[str]:\n 523:         \"\"\"Get all test IDs from results directory.\"\"\"\n 524:         project_root = Path(__file__).parent\n 525:         results_dir = project_root / \"results\"",
          "match": "def get_all_test_ids() -> List[str]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 538,
          "context": " 535:     \n 536:     \n 537:     @pytest.mark.parametrize(\"test_id\", get_all_test_ids())\n 538: >>> def test_output_requirements(test_id):\n 539:         \"\"\"Pytest: Validate output requirements for each test.\"\"\"\n 540:         assert validate_test_outputs(test_id, verbose=False), f\"{test_id} failed output requirements\"\n 541:     ",
          "match": "def test_output_requirements(test_id):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 543,
          "context": " 540:         assert validate_test_outputs(test_id, verbose=False), f\"{test_id} failed output requirements\"\n 541:     \n 542:     \n 543: >>> def test_tier1_outputs():\n 544:         \"\"\"Pytest: Validate all Tier 1 (Relativistic) test outputs.\"\"\"\n 545:         test_ids = [tid for tid in get_all_test_ids() if tid.startswith(\"REL-\")]\n 546:         failures = []",
          "match": "def test_tier1_outputs():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 554,
          "context": " 551:         assert not failures, f\"Tier 1 tests failed: {', '.join(failures)}\"\n 552:     \n 553:     \n 554: >>> def test_tier2_outputs():\n 555:         \"\"\"Pytest: Validate all Tier 2 (Gravity) test outputs.\"\"\"\n 556:         test_ids = [tid for tid in get_all_test_ids() if tid.startswith(\"GRAV-\")]\n 557:         failures = []",
          "match": "def test_tier2_outputs():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 565,
          "context": " 562:         assert not failures, f\"Tier 2 tests failed: {', '.join(failures)}\"\n 563:     \n 564:     \n 565: >>> def test_tier3_outputs():\n 566:         \"\"\"Pytest: Validate all Tier 3 (Energy) test outputs.\"\"\"\n 567:         test_ids = [tid for tid in get_all_test_ids() if tid.startswith(\"ENER-\")]\n 568:         failures = []",
          "match": "def test_tier3_outputs():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 576,
          "context": " 573:         assert not failures, f\"Tier 3 tests failed: {', '.join(failures)}\"\n 574:     \n 575:     \n 576: >>> def test_tier4_outputs():\n 577:         \"\"\"Pytest: Validate all Tier 4 (Quantization) test outputs.\"\"\"\n 578:         test_ids = [tid for tid in get_all_test_ids() if tid.startswith(\"QUAN-\")]\n 579:         failures = []",
          "match": "def test_tier4_outputs():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 587,
          "context": " 584:         assert not failures, f\"Tier 4 tests failed: {', '.join(failures)}\"\n 585:     \n 586:     \n 587: >>> def test_double_slit_interference_pattern():\n 588:         \"\"\"Pytest: Validate double-slit test generates interference pattern image.\"\"\"\n 589:         test_id = \"GRAV-16\"\n 590:         test_dir = get_test_output_dir(test_id)",
          "match": "def test_double_slit_interference_pattern():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 606,
          "context": " 603:     # COMMAND-LINE INTERFACE\n 604:     # ============================================================================\n 605:     \n 606: >>> def main():\n 607:         parser = argparse.ArgumentParser(\n 608:             description=\"Validate test output requirements across all tiers\"\n 609:         )",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 57,
          "context": "  54:             \"metrics_keys\": [\n  55:                 \"peak_cpu_percent\",\n  56:                 \"peak_memory_mb\",\n  57: >>>             \"peak_gpu_memory_mb\"\n  58:             ]\n  59:         },\n  60:         \"readme.txt\": {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 72,
          "context": "  69:                 \"runtime_sec\",\n  70:                 \"peak_cpu_percent\",\n  71:                 \"peak_memory_mb\",\n  72: >>>             \"peak_gpu_memory_mb\",\n  73:                 \"timestamp\"\n  74:             ]\n  75:         },",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 181,
          "context": " 178:             \"description\": \"Time dilation - deep potential\",\n 179:             \"additional_outputs\": [\n 180:                 \"probe_serial.csv\",\n 181: >>>             \"probe_parallel.csv\",\n 182:                 \"plots/time_dilation_comparison.png\"\n 183:             ],\n 184:             \"validation\": {",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 197,
          "context": " 194:             \"description\": \"Time dilation - moderate potential\",\n 195:             \"additional_outputs\": [\n 196:                 \"probe_serial.csv\",\n 197: >>>             \"probe_parallel.csv\"\n 198:             ]\n 199:         },\n 200:         ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 205,
          "context": " 202:             \"description\": \"Time dilation - weak potential\",\n 203:             \"additional_outputs\": [\n 204:                 \"probe_serial.csv\",\n 205: >>>             \"probe_parallel.csv\"\n 206:             ]\n 207:         },\n 208:         ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 213,
          "context": " 210:             \"description\": \"Time dilation - variable chi profile\",\n 211:             \"additional_outputs\": [\n 212:                 \"probe_serial.csv\",\n 213: >>>             \"probe_parallel.csv\"\n 214:             ]\n 215:         },\n 216:         ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 222,
          "context": " 219:             \"description\": \"Shapiro delay - wave packet\",\n 220:             \"additional_outputs\": [\n 221:                 \"packet_tracking_serial.csv\",\n 222: >>>             \"packet_tracking_parallel.csv\",\n 223:                 \"plots/packet_trajectory.png\"\n 224:             ],\n 225:             \"validation\": {",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 238,
          "context": " 235:             \"description\": \"Shapiro delay - group vs phase velocity\",\n 236:             \"additional_outputs\": [\n 237:                 \"packet_tracking_serial.csv\",\n 238: >>>             \"packet_tracking_parallel.csv\"\n 239:             ]\n 240:         },\n 241:         ",
          "match": "parallel"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 519,
          "context": " 516:     \n 517:     \n 518:     # ============================================================================\n 519: >>> # PYTEST INTEGRATION\n 520:     # ============================================================================\n 521:     \n 522:     def get_all_test_ids() -> List[str]:",
          "match": "INTEGRATION"
        }
      ],
      "line_count": 655,
      "docstring": "test_output_requirements.py — Tier Test Output Requirements & Validation\n------------------------------------------------------------------------\nPurpose:\n    Define and validate required outputs for ALL tier test runs.\n    Ensures uniformity across tiers and consistency for any new tests.\n\nRequirements Framework:\n    - Core requirements (ALL tests must have)\n    - Per-tier requirements (tier-specific outputs)\n    - Per-test requirements (special outputs for individual tests)\n\nUsage as pytest:\n    pytest test_output_requirements.py -v\n    pytest test_output_requirements.py::test_tier1_outputs -v\n    pytest test_output_requirements.py -k \"double_slit\" -v\n\nUsage as validation script:\n    python test_output_requirements.py --tier 1\n    python test_output_requirements.py --test GRAV-16\n    python test_output_requirements.py --check-all"
    },
    {
      "filepath": "tests\\test_double_slit_scenario.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "c78da0032a2c228f",
      "file_size": 6738,
      "modified": "2025-11-02T20:02:11.098001",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 114,
          "context": " 111:                   f\"behind={field_behind_barrier:8.3f}, screen={field_at_screen:8.3f}, \"\n 112:                   f\"energy={energy:.3e}\")\n 113:             \n 114: >>>         # Check for instability\n 115:             if max_field > 100 or np.isnan(max_field):\n 116:                 print(\"\\n❌ FAILED: Numerical instability detected!\")\n 117:                 break",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 116,
          "context": " 113:             \n 114:             # Check for instability\n 115:             if max_field > 100 or np.isnan(max_field):\n 116: >>>             print(\"\\n❌ FAILED: Numerical instability detected!\")\n 117:                 break\n 118:                 \n 119:             # Check if wave reached screen",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 200,
          "context": " 197:         print(\"❌ DOUBLE SLIT TEST NEEDS WORK\")\n 198:         print(\"   Issues to fix:\")\n 199:         if np.max(np.abs(E)) >= 100:\n 200: >>>         print(\"   - Numerical instability\")\n 201:         if field_at_screen < 0.01:\n 202:             print(\"   - Wave not reaching screen\")\n 203:         if len(peaks) < 2:",
          "match": "stability"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 69,
          "context": "  66:         'beta': 1.0,\n  67:         'chi': 0.0,\n  68:         'gamma_damp': 0.05,  # Light damping\n  69: >>>     'boundary': 'periodic',\n  70:         'stencil_order': 2,\n  71:     }\n  72:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 69,
          "context": "  66:         'beta': 1.0,\n  67:         'chi': 0.0,\n  68:         'gamma_damp': 0.05,  # Light damping\n  69: >>>     'boundary': 'periodic',\n  70:         'stencil_order': 2,\n  71:     }\n  72:     ",
          "match": "periodic"
        }
      ],
      "line_count": 205,
      "docstring": "Test script for double slit scenario - validates before deploying to interactive app"
    },
    {
      "filepath": "tests\\test_lfm_dispersion_3d.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "504476327e2894b0",
      "file_size": 8580,
      "modified": "2025-11-02T20:02:11.100000",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 74,
          "context": "  71:     # --------------------------------\n  72:     # ω measurement utilities\n  73:     # --------------------------------\n  74: >>> def measure_omega_targeted(series, dt, omega_hint, span=0.30, ngrid=401):\n  75:         \"\"\"\n  76:         Scan ω in [ω_hint*(1-span), ω_hint*(1+span)] and pick the maximal\n  77:         response |Σ x(t) e^{-i ω t}| after mean-removal + Hann window.",
          "match": "def measure_omega_targeted(series, dt, omega_hint, span=0.30, ngrid=401):"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 14,
          "context": "  11:     Purpose\n  12:     -------\n  13:     Validate the canonical dispersion ω^2 = c^2 k^2 + χ^2 in 3-D for\n  14: >>> both serial (core) and threaded parallel backends, with minimal\n  15:     runtime and strong diagnostics.\n  16:     \n  17:     What's new vs v1.2",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 40,
          "context": "  37:     import matplotlib.pyplot as plt\n  38:     from pathlib import Path\n  39:     from lfm_equation import advance, core_metrics, energy_total\n  40: >>> from lfm_parallel import run_lattice\n  41:     \n  42:     # ----------------------------\n  43:     # Config",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 144,
          "context": " 141:         t_serial = time.time() - t0\n 142:         w_s, f_s, pow_s, i_s = measure_omega_targeted(series_s, dt, omega_th)\n 143:     \n 144: >>>     # ---------- PARALLEL ----------\n 145:         print(\"  Running parallel (threads 2x2x2) …\")\n 146:         params_p = dict(params_base)\n 147:         E = np.copy(E0); E_prev = np.copy(Eprev0)",
          "match": "PARALLEL"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 145,
          "context": " 142:         w_s, f_s, pow_s, i_s = measure_omega_targeted(series_s, dt, omega_th)\n 143:     \n 144:         # ---------- PARALLEL ----------\n 145: >>>     print(\"  Running parallel (threads 2x2x2) …\")\n 146:         params_p = dict(params_base)\n 147:         E = np.copy(E0); E_prev = np.copy(Eprev0)\n 148:         series_p = []",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 164,
          "context": " 161:                 print(f\"    [par]   step {n+1:4d}  drift={met['drift']:+.3e}  \"\n 162:                       f\"max|E|={met['max_abs']:.3e}\")\n 163:     \n 164: >>>     t_parallel = time.time() - t0\n 165:         w_p, f_p, pow_p, i_p = measure_omega_targeted(series_p, dt, omega_th)\n 166:     \n 167:         # ---------- Compare ----------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 175,
          "context": " 172:         results.append({\n 173:             \"dir\": label,\n 174:             \"omega_meas_serial\": w_s,\n 175: >>>         \"omega_meas_parallel\": w_p,\n 176:             \"omega_theory\": omega_th,\n 177:             \"rel_err_serial\": rel_err_s,\n 178:             \"rel_err_parallel\": rel_err_p,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 178,
          "context": " 175:             \"omega_meas_parallel\": w_p,\n 176:             \"omega_theory\": omega_th,\n 177:             \"rel_err_serial\": rel_err_s,\n 178: >>>         \"rel_err_parallel\": rel_err_p,\n 179:             \"backend_gap\": backend_gap,\n 180:             \"serial_t\": t_serial,\n 181:             \"parallel_t\": t_parallel,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 181,
          "context": " 178:             \"rel_err_parallel\": rel_err_p,\n 179:             \"backend_gap\": backend_gap,\n 180:             \"serial_t\": t_serial,\n 181: >>>         \"parallel_t\": t_parallel,\n 182:         })\n 183:     \n 184:         # ---------- Visualization ----------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 181,
          "context": " 178:             \"rel_err_parallel\": rel_err_p,\n 179:             \"backend_gap\": backend_gap,\n 180:             \"serial_t\": t_serial,\n 181: >>>         \"parallel_t\": t_parallel,\n 182:         })\n 183:     \n 184:         # ---------- Visualization ----------",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 200,
          "context": " 197:             plt.xlim(max(0, f_s[0]), min(f_s[-1], 5*omega_th/(2*math.pi)))\n 198:             plt.title(\"DFT scan (serial)\")\n 199:             plt.xlabel(\"Hz\")\n 200: >>>         # Zoomed spectrum (parallel)\n 201:             plt.subplot(1,3,3)\n 202:             plt.semilogy(f_p, pow_p, lw=1)\n 203:             plt.axvline(omega_th/(2*math.pi), ls=\"--\", lw=1, color=\"k\")",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 206,
          "context": " 203:             plt.axvline(omega_th/(2*math.pi), ls=\"--\", lw=1, color=\"k\")\n 204:             plt.axvline(w_p/(2*math.pi), ls=\":\", lw=1, color=\"k\")\n 205:             plt.xlim(max(0, f_p[0]), min(f_p[-1], 5*omega_th/(2*math.pi)))\n 206: >>>         plt.title(\"DFT scan (parallel)\")\n 207:             plt.xlabel(\"Hz\")\n 208:             plt.tight_layout()\n 209:             plt.show()",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 219,
          "context": " 216:         print(\n 217:             f\"{r['dir']:>3}  ω_th={r['omega_theory']:.6f}  \"\n 218:             f\"ω_s={r['omega_meas_serial']:.6f} (Δ={r['rel_err_serial']*100:.3f}%)  \"\n 219: >>>         f\"ω_p={r['omega_meas_parallel']:.6f} (Δ={r['rel_err_parallel']*100:.3f}%)  \"\n 220:             f\"gap(s|p)={r['backend_gap']*100:.3f}%  \"\n 221:             f\"t_s={r['serial_t']:.2f}s  t_p={r['parallel_t']:.2f}s\"\n 222:         )",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 219,
          "context": " 216:         print(\n 217:             f\"{r['dir']:>3}  ω_th={r['omega_theory']:.6f}  \"\n 218:             f\"ω_s={r['omega_meas_serial']:.6f} (Δ={r['rel_err_serial']*100:.3f}%)  \"\n 219: >>>         f\"ω_p={r['omega_meas_parallel']:.6f} (Δ={r['rel_err_parallel']*100:.3f}%)  \"\n 220:             f\"gap(s|p)={r['backend_gap']*100:.3f}%  \"\n 221:             f\"t_s={r['serial_t']:.2f}s  t_p={r['parallel_t']:.2f}s\"\n 222:         )",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 221,
          "context": " 218:             f\"ω_s={r['omega_meas_serial']:.6f} (Δ={r['rel_err_serial']*100:.3f}%)  \"\n 219:             f\"ω_p={r['omega_meas_parallel']:.6f} (Δ={r['rel_err_parallel']*100:.3f}%)  \"\n 220:             f\"gap(s|p)={r['backend_gap']*100:.3f}%  \"\n 221: >>>         f\"t_s={r['serial_t']:.2f}s  t_p={r['parallel_t']:.2f}s\"\n 222:         )\n 223:     \n 224:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 225,
          "context": " 222:         )\n 223:     \n 224:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])\n 225: >>> isoP = np.std([r[\"omega_meas_parallel\"] for r in results]) / np.mean([r[\"omega_meas_parallel\"] for r in results])\n 226:     print(f\"\\nIsotropy CoV  serial={iso*100:.3f}%   parallel={isoP*100:.3f}%\")\n 227:     \n 228:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 225,
          "context": " 222:         )\n 223:     \n 224:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])\n 225: >>> isoP = np.std([r[\"omega_meas_parallel\"] for r in results]) / np.mean([r[\"omega_meas_parallel\"] for r in results])\n 226:     print(f\"\\nIsotropy CoV  serial={iso*100:.3f}%   parallel={isoP*100:.3f}%\")\n 227:     \n 228:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 226,
          "context": " 223:     \n 224:     iso  = np.std([r[\"omega_meas_serial\"]   for r in results]) / np.mean([r[\"omega_meas_serial\"]   for r in results])\n 225:     isoP = np.std([r[\"omega_meas_parallel\"] for r in results]) / np.mean([r[\"omega_meas_parallel\"] for r in results])\n 226: >>> print(f\"\\nIsotropy CoV  serial={iso*100:.3f}%   parallel={isoP*100:.3f}%\")\n 227:     \n 228:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 229:         fields = [",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 230,
          "context": " 227:     \n 228:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 229:         fields = [\n 230: >>>         \"dir\",\"omega_theory\",\"omega_meas_serial\",\"omega_meas_parallel\",\n 231:             \"rel_err_serial\",\"rel_err_parallel\",\"backend_gap\",\"serial_t\",\"parallel_t\"\n 232:         ]\n 233:         w = csv.DictWriter(f, fieldnames=fields)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 231,
          "context": " 228:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 229:         fields = [\n 230:             \"dir\",\"omega_theory\",\"omega_meas_serial\",\"omega_meas_parallel\",\n 231: >>>         \"rel_err_serial\",\"rel_err_parallel\",\"backend_gap\",\"serial_t\",\"parallel_t\"\n 232:         ]\n 233:         w = csv.DictWriter(f, fieldnames=fields)\n 234:         w.writeheader(); w.writerows(results)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 231,
          "context": " 228:     with open(RESULTS_DIR / \"dispersion_results_3d.csv\", \"w\", newline=\"\") as f:\n 229:         fields = [\n 230:             \"dir\",\"omega_theory\",\"omega_meas_serial\",\"omega_meas_parallel\",\n 231: >>>         \"rel_err_serial\",\"rel_err_parallel\",\"backend_gap\",\"serial_t\",\"parallel_t\"\n 232:         ]\n 233:         w = csv.DictWriter(f, fieldnames=fields)\n 234:         w.writeheader(); w.writerows(results)",
          "match": "parallel"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 67,
          "context": "  64:     \n  65:     params_base = dict(\n  66:         dt=dt, dx=dx, alpha=alpha, beta=beta, chi=chi,\n  67: >>>     boundary=\"periodic\",\n  68:         debug={\"enable_diagnostics\": False},\n  69:     )\n  70:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 67,
          "context": "  64:     \n  65:     params_base = dict(\n  66:         dt=dt, dx=dx, alpha=alpha, beta=beta, chi=chi,\n  67: >>>     boundary=\"periodic\",\n  68:         debug={\"enable_diagnostics\": False},\n  69:     )\n  70:     ",
          "match": "periodic"
        }
      ],
      "line_count": 235,
      "docstring": "Tier-2 Dispersion & Isotropy Validation — LFM 3-D (v1.3)\n\nPurpose\n-------\nValidate the canonical dispersion ω^2 = c^2 k^2 + χ^2 in 3-D for\nboth serial (core) and threaded parallel backends, with minimal\nruntime and strong diagnostics.\n\nWhat's new vs v1.2\n------------------\n• Robust, theory-guided ω estimator: scans a narrow band around ω_th\n  and picks the peak response (DFT-at-selected-freqs), not a blunt FFT.\n• Zoomed diagnostic plots around the expected low frequency.\n• Same traveling-wave initialization; clearer comments.\n• Unchanged timing + lightweight drift sampling.\n\nNotes\n-----\n– Traveling wave init:\n    φ = k·x,  ω_th = sqrt(c^2|k|^2 + χ^2)\n    E(t0)      = A·sin(φ)\n    E(t0−dt)   = A·sin(φ − ω_th·dt)     # equivalent to adding correct velocity\n– With N=64 & k = (2π/N)/dx along an axis, ω_th ≈ 0.0982 rad/s (f≈0.0156 Hz),\n  i.e., the peak sits very close to DC; generic FFT plots can hide it."
    },
    {
      "filepath": "tests\\test_lorentz_covariance.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "a42f6cc5f0e9cf8a",
      "file_size": 4047,
      "modified": "2025-11-02T20:02:11.105010",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 27,
          "context": "  24:     from lorentz_transform import verify_klein_gordon_covariance\n  25:     \n  26:     \n  27: >>> def make_traveling_packet_1d(N, dx, dt, chi, k, amp=0.02, c=1.0):\n  28:         \"\"\"Construct PDE-consistent E and E_prev for a right-going packet.\n  29:     \n  30:         E(x,0) = A cos(k x), E_t = A omega sin(k x), E_prev = E - dt E_t.",
          "match": "def make_traveling_packet_1d(N, dx, dt, chi, k, amp=0.02, c=1.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 41,
          "context": "  38:     \n  39:     \n  40:     @pytest.mark.fast\n  41: >>> def test_verify_klein_gordon_covariance_ratio_band():\n  42:         # Grid and physics\n  43:         N = 192\n  44:         dx = 0.2",
          "match": "def test_verify_klein_gordon_covariance_ratio_band():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 82,
          "context": "  79:     \n  80:     \n  81:     @pytest.mark.fast\n  82: >>> def test_covariance_robust_to_k_and_chi():\n  83:         # Two quick parameter points to guard regressions\n  84:         cases = [\n  85:             dict(chi=0.10, k=0.30),",
          "match": "def test_covariance_robust_to_k_and_chi():"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 56,
          "context": "  53:         x, E, Ep, omega = make_traveling_packet_1d(N, dx, dt, chi, k, amp=0.02, c=c)\n  54:     \n  55:         # Params for lattice_step\n  56: >>>     params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta_param, boundary=\"periodic\", chi=chi,\n  57:                       debug={\"quiet_run\": True, \"enable_diagnostics\": False})\n  58:     \n  59:         # Evolve and collect snapshots",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 56,
          "context": "  53:         x, E, Ep, omega = make_traveling_packet_1d(N, dx, dt, chi, k, amp=0.02, c=c)\n  54:     \n  55:         # Params for lattice_step\n  56: >>>     params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta_param, boundary=\"periodic\", chi=chi,\n  57:                       debug={\"quiet_run\": True, \"enable_diagnostics\": False})\n  58:     \n  59:         # Evolve and collect snapshots",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 94,
          "context": "  91:         beta_boost = 0.2\n  92:         for case in cases:\n  93:             x, E, Ep, _ = make_traveling_packet_1d(N, dx, dt, case[\"chi\"], case[\"k\"], amp=0.02, c=c)\n  94: >>>         params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta_param, boundary=\"periodic\", chi=case[\"chi\"],\n  95:                           debug={\"quiet_run\": True, \"enable_diagnostics\": False})\n  96:             series = [E.copy()]\n  97:             E_curr, E_prev = E.copy(), Ep.copy()",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 94,
          "context": "  91:         beta_boost = 0.2\n  92:         for case in cases:\n  93:             x, E, Ep, _ = make_traveling_packet_1d(N, dx, dt, case[\"chi\"], case[\"k\"], amp=0.02, c=c)\n  94: >>>         params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta_param, boundary=\"periodic\", chi=case[\"chi\"],\n  95:                           debug={\"quiet_run\": True, \"enable_diagnostics\": False})\n  96:             series = [E.copy()]\n  97:             E_curr, E_prev = E.copy(), Ep.copy()",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 15,
          "context": "  12:     between boosted and lab frames for a simple 1D Klein–Gordon evolution.\n  13:     \n  14:     We generate a narrowband traveling wave under uniform chi and evolve\n  15: >>> with the same lattice_step used in the solver, then compare residuals\n  16:     after boosting with a modest beta.\n  17:     \"\"\"\n  18:     ",
          "match": "solver"
        }
      ],
      "line_count": 105,
      "docstring": "Unit tests for Lorentz covariance utilities.\n\nFocus: verify_klein_gordon_covariance should report O(1) residual ratio\nbetween boosted and lab frames for a simple 1D Klein–Gordon evolution.\n\nWe generate a narrowband traveling wave under uniform chi and evolve\nwith the same lattice_step used in the solver, then compare residuals\nafter boosting with a modest beta."
    },
    {
      "filepath": "tests\\test_metrics.py",
      "category": "VALIDATION",
      "priority": 6,
      "file_hash": "cc9afa2c163ce798",
      "file_size": 13760,
      "modified": "2025-11-02T20:02:11.107005",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 22,
          "context": "  19:     from typing import Dict, List, Optional, Tuple\n  20:     \n  21:     \n  22: >>> class TestMetrics:\n  23:         \"\"\"\n  24:         Manages test execution metrics database for resource-aware scheduling.\n  25:         ",
          "match": "class TestMetrics:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 33,
          "context": "  30:         - Each user's system will adapt estimates to their hardware on first run\n  31:         \"\"\"\n  32:         \n  33: >>>     def __init__(self, db_path: Path = None):\n  34:             \"\"\"\n  35:             Initialize metrics database.\n  36:             ",
          "match": "def __init__(self, db_path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:             else:\n  51:                 self.data = {}\n  52:         \n  53: >>>     def save(self):\n  54:             \"\"\"Persist database to disk.\"\"\"\n  55:             with open(self.db_path, 'w') as f:\n  56:                 json.dump(self.data, f, indent=2)",
          "match": "def save(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:             with open(self.db_path, 'w') as f:\n  56:                 json.dump(self.data, f, indent=2)\n  57:         \n  58: >>>     def record_run(self, test_id: str, metrics: Dict):\n  59:             \"\"\"\n  60:             Record test execution metrics.\n  61:             ",
          "match": "def record_run(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 87,
          "context": "  84:             \n  85:             self.save()\n  86:         \n  87: >>>     def _compute_estimate(self, test_id: str) -> Dict:\n  88:             \"\"\"\n  89:             Compute resource estimate from the LAST successful run only.\n  90:             System state varies between runs, so historical averages are unreliable.",
          "match": "def _compute_estimate(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 141,
          "context": " 138:                 \"timeout_multiplier\": timeout_multiplier\n 139:             }\n 140:         \n 141: >>>     def get_estimate(self, test_id: str, test_config: Dict = None) -> Dict:\n 142:             \"\"\"\n 143:             Get resource estimate for a test.\n 144:             ",
          "match": "def get_estimate(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 171,
          "context": " 168:                 \"sample_size\": 0\n 169:             }\n 170:         \n 171: >>>     def _estimate_from_config(self, test_id: str, config: Dict) -> Dict:\n 172:             \"\"\"\n 173:             Estimate resource requirements from test configuration.\n 174:             Conservative estimates for never-run tests.",
          "match": "def _estimate_from_config(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 238,
          "context": " 235:                 \"sample_size\": 0\n 236:             }\n 237:         \n 238: >>>     def get_priority(self, test_id: str) -> int:\n 239:             \"\"\"\n 240:             Get scheduling priority for test.\n 241:             ",
          "match": "def get_priority(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 269,
          "context": " 266:             prefix = test_id.split(\"-\")[0]\n 267:             return tier_priorities.get(prefix, 50)\n 268:         \n 269: >>>     def get_all_test_ids(self) -> List[str]:\n 270:             \"\"\"Get list of all test IDs in database.\"\"\"\n 271:             return list(self.data.keys())\n 272:     ",
          "match": "def get_all_test_ids(self) -> List[str]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 273,
          "context": " 270:             \"\"\"Get list of all test IDs in database.\"\"\"\n 271:             return list(self.data.keys())\n 272:     \n 273: >>>     def get_all_runs(self, test_id: str) -> List[Dict]:\n 274:             \"\"\"Return list of historical runs for a test id (may be empty).\"\"\"\n 275:             entry = self.data.get(test_id)\n 276:             if not entry:",
          "match": "def get_all_runs(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 280,
          "context": " 277:                 return []\n 278:             return list(entry.get(\"runs\", []))\n 279:         \n 280: >>>     def get_summary(self) -> Dict:\n 281:             \"\"\"Get summary statistics of metrics database.\"\"\"\n 282:             total_tests = len(self.data)\n 283:             with_history = sum(1 for t in self.data.values() if t[\"runs\"])",
          "match": "def get_summary(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 302,
          "context": " 299:             }\n 300:     \n 301:     \n 302: >>> def load_test_configs(tier: int) -> List[Tuple[str, Dict]]:\n 303:         \"\"\"\n 304:         Load test configurations from tier config file.\n 305:         ",
          "match": "def load_test_configs(tier:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 12,
          "context": "   9:     Test Metrics Database - Resource usage tracking and estimation\n  10:     ============================================================\n  11:     Persistent storage of test execution metrics to enable dynamic scheduling.\n  12: >>> Tracks runtime, CPU, RAM, and GPU usage for each test run.\n  13:     \"\"\"\n  14:     \n  15:     import json",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 65,
          "context": "  62:             Args:\n  63:                 test_id: Test identifier (e.g., \"REL-01\")\n  64:                 metrics: Dict with keys: runtime_sec, peak_cpu_percent, peak_memory_mb,\n  65: >>>                     peak_gpu_memory_mb, exit_code, timestamp\n  66:             \"\"\"\n  67:             if test_id not in self.data:\n  68:                 self.data[test_id] = {\"runs\": [], \"estimated_resources\": None, \"priority\": 50}",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 111,
          "context": " 108:             runtime = last_success.get(\"runtime_sec\", 1.0)\n 109:             cpu_percent = last_success.get(\"peak_cpu_percent\", 100.0)\n 110:             memory_mb = last_success.get(\"peak_memory_mb\", 500.0)\n 111: >>>         gpu_memory_mb = last_success.get(\"peak_gpu_memory_mb\", 0.0)\n 112:             \n 113:             # Convert process CPU percent to core-equivalent usage\n 114:             # psutil returns percent where 100 ~= 1 full core for the process",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 111,
          "context": " 108:             runtime = last_success.get(\"runtime_sec\", 1.0)\n 109:             cpu_percent = last_success.get(\"peak_cpu_percent\", 100.0)\n 110:             memory_mb = last_success.get(\"peak_memory_mb\", 500.0)\n 111: >>>         gpu_memory_mb = last_success.get(\"peak_gpu_memory_mb\", 0.0)\n 112:             \n 113:             # Convert process CPU percent to core-equivalent usage\n 114:             # psutil returns percent where 100 ~= 1 full core for the process",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 117,
          "context": " 114:             # psutil returns percent where 100 ~= 1 full core for the process\n 115:             cpu_cores_needed = max(0.75, cpu_percent / 100.0)\n 116:             \n 117: >>>         # Determine if test uses GPU (threshold: 50MB to catch CuPy overhead)\n 118:             uses_gpu = gpu_memory_mb > 50\n 119:             \n 120:             # Apply modest safety buffers (10% for runtime/CPU, 20% for memory)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 117,
          "context": " 114:             # psutil returns percent where 100 ~= 1 full core for the process\n 115:             cpu_cores_needed = max(0.75, cpu_percent / 100.0)\n 116:             \n 117: >>>         # Determine if test uses GPU (threshold: 50MB to catch CuPy overhead)\n 118:             uses_gpu = gpu_memory_mb > 50\n 119:             \n 120:             # Apply modest safety buffers (10% for runtime/CPU, 20% for memory)",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 118,
          "context": " 115:             cpu_cores_needed = max(0.75, cpu_percent / 100.0)\n 116:             \n 117:             # Determine if test uses GPU (threshold: 50MB to catch CuPy overhead)\n 118: >>>         uses_gpu = gpu_memory_mb > 50\n 119:             \n 120:             # Apply modest safety buffers (10% for runtime/CPU, 20% for memory)\n 121:             runtime_buffered = runtime * 1.1",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 118,
          "context": " 115:             cpu_cores_needed = max(0.75, cpu_percent / 100.0)\n 116:             \n 117:             # Determine if test uses GPU (threshold: 50MB to catch CuPy overhead)\n 118: >>>         uses_gpu = gpu_memory_mb > 50\n 119:             \n 120:             # Apply modest safety buffers (10% for runtime/CPU, 20% for memory)\n 121:             runtime_buffered = runtime * 1.1",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 124,
          "context": " 121:             runtime_buffered = runtime * 1.1\n 122:             cpu_buffered = cpu_cores_needed * 1.1\n 123:             memory_buffered = memory_mb * 1.2\n 124: >>>         gpu_buffered = gpu_memory_mb * 1.1 if uses_gpu else 0.0\n 125:             \n 126:             # Adaptive timeout multiplier: check if last few runs timed out\n 127:             timeout_count = sum(1 for r in runs[-3:] if r.get(\"exit_code\") == -2)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 124,
          "context": " 121:             runtime_buffered = runtime * 1.1\n 122:             cpu_buffered = cpu_cores_needed * 1.1\n 123:             memory_buffered = memory_mb * 1.2\n 124: >>>         gpu_buffered = gpu_memory_mb * 1.1 if uses_gpu else 0.0\n 125:             \n 126:             # Adaptive timeout multiplier: check if last few runs timed out\n 127:             timeout_count = sum(1 for r in runs[-3:] if r.get(\"exit_code\") == -2)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 124,
          "context": " 121:             runtime_buffered = runtime * 1.1\n 122:             cpu_buffered = cpu_cores_needed * 1.1\n 123:             memory_buffered = memory_mb * 1.2\n 124: >>>         gpu_buffered = gpu_memory_mb * 1.1 if uses_gpu else 0.0\n 125:             \n 126:             # Adaptive timeout multiplier: check if last few runs timed out\n 127:             timeout_count = sum(1 for r in runs[-3:] if r.get(\"exit_code\") == -2)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 134,
          "context": " 131:                 \"runtime_sec\": max(1.0, runtime_buffered),\n 132:                 \"cpu_cores_needed\": max(0.75, cpu_buffered),\n 133:                 \"memory_mb\": max(100, memory_buffered),\n 134: >>>             \"gpu_memory_mb\": gpu_buffered,\n 135:                 \"uses_gpu\": uses_gpu,\n 136:                 \"confidence\": \"last_run\",\n 137:                 \"sample_size\": len(runs),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 134,
          "context": " 131:                 \"runtime_sec\": max(1.0, runtime_buffered),\n 132:                 \"cpu_cores_needed\": max(0.75, cpu_buffered),\n 133:                 \"memory_mb\": max(100, memory_buffered),\n 134: >>>             \"gpu_memory_mb\": gpu_buffered,\n 135:                 \"uses_gpu\": uses_gpu,\n 136:                 \"confidence\": \"last_run\",\n 137:                 \"sample_size\": len(runs),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 135,
          "context": " 132:                 \"cpu_cores_needed\": max(0.75, cpu_buffered),\n 133:                 \"memory_mb\": max(100, memory_buffered),\n 134:                 \"gpu_memory_mb\": gpu_buffered,\n 135: >>>             \"uses_gpu\": uses_gpu,\n 136:                 \"confidence\": \"last_run\",\n 137:                 \"sample_size\": len(runs),\n 138:                 \"timeout_multiplier\": timeout_multiplier",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 135,
          "context": " 132:                 \"cpu_cores_needed\": max(0.75, cpu_buffered),\n 133:                 \"memory_mb\": max(100, memory_buffered),\n 134:                 \"gpu_memory_mb\": gpu_buffered,\n 135: >>>             \"uses_gpu\": uses_gpu,\n 136:                 \"confidence\": \"last_run\",\n 137:                 \"sample_size\": len(runs),\n 138:                 \"timeout_multiplier\": timeout_multiplier",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 165,
          "context": " 162:                 \"runtime_sec\": 300.0,\n 163:                 \"cpu_cores_needed\": 4.0,\n 164:                 \"memory_mb\": 2000,\n 165: >>>             \"gpu_memory_mb\": 3000,\n 166:                 \"uses_gpu\": True,\n 167:                 \"confidence\": \"default_conservative\",\n 168:                 \"sample_size\": 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 166,
          "context": " 163:                 \"cpu_cores_needed\": 4.0,\n 164:                 \"memory_mb\": 2000,\n 165:                 \"gpu_memory_mb\": 3000,\n 166: >>>             \"uses_gpu\": True,\n 167:                 \"confidence\": \"default_conservative\",\n 168:                 \"sample_size\": 0\n 169:             }",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 180,
          "context": " 177:             dimensions = config.get(\"dimensions\", 1)\n 178:             grid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n 179:             steps = config.get(\"steps\", 6000)\n 180: >>>         uses_gpu = config.get(\"use_gpu\", config.get(\"gpu_enabled\", True))\n 181:             \n 182:             # Memory estimation: total grid cells × 8 bytes × 5 fields\n 183:             # grid_points may be:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 180,
          "context": " 177:             dimensions = config.get(\"dimensions\", 1)\n 178:             grid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n 179:             steps = config.get(\"steps\", 6000)\n 180: >>>         uses_gpu = config.get(\"use_gpu\", config.get(\"gpu_enabled\", True))\n 181:             \n 182:             # Memory estimation: total grid cells × 8 bytes × 5 fields\n 183:             # grid_points may be:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 180,
          "context": " 177:             dimensions = config.get(\"dimensions\", 1)\n 178:             grid_points = config.get(\"grid_points\", config.get(\"N\", 512))\n 179:             steps = config.get(\"steps\", 6000)\n 180: >>>         uses_gpu = config.get(\"use_gpu\", config.get(\"gpu_enabled\", True))\n 181:             \n 182:             # Memory estimation: total grid cells × 8 bytes × 5 fields\n 183:             # grid_points may be:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 217,
          "context": " 214:             memory_per_field_mb = grid_size * 8 / (1024**2)\n 215:             memory_mb = memory_per_field_mb * 5 * 1.5  # 5 fields + 50% overhead\n 216:             \n 217: >>>         # GPU memory same as RAM for GPU tests\n 218:             gpu_memory_mb = memory_mb if uses_gpu else 0\n 219:             \n 220:             # Runtime estimation (heuristic)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 217,
          "context": " 214:             memory_per_field_mb = grid_size * 8 / (1024**2)\n 215:             memory_mb = memory_per_field_mb * 5 * 1.5  # 5 fields + 50% overhead\n 216:             \n 217: >>>         # GPU memory same as RAM for GPU tests\n 218:             gpu_memory_mb = memory_mb if uses_gpu else 0\n 219:             \n 220:             # Runtime estimation (heuristic)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 218,
          "context": " 215:             memory_mb = memory_per_field_mb * 5 * 1.5  # 5 fields + 50% overhead\n 216:             \n 217:             # GPU memory same as RAM for GPU tests\n 218: >>>         gpu_memory_mb = memory_mb if uses_gpu else 0\n 219:             \n 220:             # Runtime estimation (heuristic)\n 221:             # Baseline: 1M grid points, 1k steps = ~10 seconds on GPU, ~50 on CPU",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 218,
          "context": " 215:             memory_mb = memory_per_field_mb * 5 * 1.5  # 5 fields + 50% overhead\n 216:             \n 217:             # GPU memory same as RAM for GPU tests\n 218: >>>         gpu_memory_mb = memory_mb if uses_gpu else 0\n 219:             \n 220:             # Runtime estimation (heuristic)\n 221:             # Baseline: 1M grid points, 1k steps = ~10 seconds on GPU, ~50 on CPU",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 221,
          "context": " 218:             gpu_memory_mb = memory_mb if uses_gpu else 0\n 219:             \n 220:             # Runtime estimation (heuristic)\n 221: >>>         # Baseline: 1M grid points, 1k steps = ~10 seconds on GPU, ~50 on CPU\n 222:             complexity_factor = (grid_size / 1e6) * (steps / 1000)\n 223:             runtime_sec = complexity_factor * (10 if uses_gpu else 50)\n 224:             ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 223,
          "context": " 220:             # Runtime estimation (heuristic)\n 221:             # Baseline: 1M grid points, 1k steps = ~10 seconds on GPU, ~50 on CPU\n 222:             complexity_factor = (grid_size / 1e6) * (steps / 1000)\n 223: >>>         runtime_sec = complexity_factor * (10 if uses_gpu else 50)\n 224:             \n 225:             # CPU cores (rough estimate)\n 226:             cpu_cores = 4 if dimensions == 3 else 2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 232,
          "context": " 229:                 \"runtime_sec\": max(5.0, runtime_sec),\n 230:                 \"cpu_cores_needed\": float(cpu_cores),\n 231:                 \"memory_mb\": max(500, memory_mb),\n 232: >>>             \"gpu_memory_mb\": gpu_memory_mb,\n 233:                 \"uses_gpu\": uses_gpu,\n 234:                 \"confidence\": \"estimated_from_config\",\n 235:                 \"sample_size\": 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 232,
          "context": " 229:                 \"runtime_sec\": max(5.0, runtime_sec),\n 230:                 \"cpu_cores_needed\": float(cpu_cores),\n 231:                 \"memory_mb\": max(500, memory_mb),\n 232: >>>             \"gpu_memory_mb\": gpu_memory_mb,\n 233:                 \"uses_gpu\": uses_gpu,\n 234:                 \"confidence\": \"estimated_from_config\",\n 235:                 \"sample_size\": 0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 233,
          "context": " 230:                 \"cpu_cores_needed\": float(cpu_cores),\n 231:                 \"memory_mb\": max(500, memory_mb),\n 232:                 \"gpu_memory_mb\": gpu_memory_mb,\n 233: >>>             \"uses_gpu\": uses_gpu,\n 234:                 \"confidence\": \"estimated_from_config\",\n 235:                 \"sample_size\": 0\n 236:             }",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 233,
          "context": " 230:                 \"cpu_cores_needed\": float(cpu_cores),\n 231:                 \"memory_mb\": max(500, memory_mb),\n 232:                 \"gpu_memory_mb\": gpu_memory_mb,\n 233: >>>             \"uses_gpu\": uses_gpu,\n 234:                 \"confidence\": \"estimated_from_config\",\n 235:                 \"sample_size\": 0\n 236:             }",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 336,
          "context": " 333:                 test_id = v[\"test_id\"]\n 334:                 # Merge params with variant-specific overrides\n 335:                 test_cfg = {**params, **v}\n 336: >>>             test_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", True)\n 337:                 tests.append((test_id, test_cfg))\n 338:         \n 339:         elif tier == 2:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 336,
          "context": " 333:                 test_id = v[\"test_id\"]\n 334:                 # Merge params with variant-specific overrides\n 335:                 test_cfg = {**params, **v}\n 336: >>>             test_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", True)\n 337:                 tests.append((test_id, test_cfg))\n 338:         \n 339:         elif tier == 2:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:             for v in variants:\n 343:                 test_id = v[\"test_id\"]\n 344:                 test_cfg = {**params, **v}\n 345: >>>             test_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", True)\n 346:                 tests.append((test_id, test_cfg))\n 347:         \n 348:         elif tier in (3, 4):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:             for v in variants:\n 343:                 test_id = v[\"test_id\"]\n 344:                 test_cfg = {**params, **v}\n 345: >>>             test_cfg[\"use_gpu\"] = cfg.get(\"run_settings\", {}).get(\"use_gpu\", True)\n 346:                 tests.append((test_id, test_cfg))\n 347:         \n 348:         elif tier in (3, 4):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 354,
          "context": " 351:             for t in test_list:\n 352:                 test_id = t[\"test_id\"]\n 353:                 test_cfg = {**params, **t}\n 354: >>>             test_cfg[\"gpu_enabled\"] = cfg.get(\"hardware\", {}).get(\"gpu_enabled\", True)\n 355:                 tests.append((test_id, test_cfg))\n 356:         \n 357:         return tests",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 354,
          "context": " 351:             for t in test_list:\n 352:                 test_id = t[\"test_id\"]\n 353:                 test_cfg = {**params, **t}\n 354: >>>             test_cfg[\"gpu_enabled\"] = cfg.get(\"hardware\", {}).get(\"gpu_enabled\", True)\n 355:                 tests.append((test_id, test_cfg))\n 356:         \n 357:         return tests",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 369,
          "context": " 366:             \"runtime_sec\": 2.1,\n 367:             \"peak_cpu_percent\": 12.5,\n 368:             \"peak_memory_mb\": 385,\n 369: >>>         \"peak_gpu_memory_mb\": 0,\n 370:             \"exit_code\": 0,\n 371:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\"\n 372:         })",
          "match": "gpu"
        }
      ],
      "line_count": 377,
      "docstring": "Test Metrics Database - Resource usage tracking and estimation\n============================================================\nPersistent storage of test execution metrics to enable dynamic scheduling.\nTracks runtime, CPU, RAM, and GPU usage for each test run."
    },
    {
      "filepath": "archive\\add_copyright_headers.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "22ace610193087a6",
      "file_size": 4823,
      "modified": "2025-11-03T13:12:11.558195",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 32,
          "context": "  29:     # Contact: latticefieldmediumresearch@gmail.com\n  30:     \"\"\"\n  31:     \n  32: >>> def has_copyright_header(content: str) -> bool:\n  33:         \"\"\"Check if file already has copyright header.\"\"\"\n  34:         return \"Copyright (c) 2025 Greg D. Partin\" in content or \\\n  35:                \"Licensed under CC BY-NC-ND 4.0\" in content",
          "match": "def has_copyright_header(content:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:         return \"Copyright (c) 2025 Greg D. Partin\" in content or \\\n  35:                \"Licensed under CC BY-NC-ND 4.0\" in content\n  36:     \n  37: >>> def add_header_to_file(filepath: Path) -> tuple[bool, str]:\n  38:         \"\"\"\n  39:         Add copyright header to a Python file.\n  40:         ",
          "match": "def add_header_to_file(filepath:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:         except Exception as e:\n  78:             return False, f\"Error writing: {e}\"\n  79:     \n  80: >>> def find_python_files(root_dir: Path) -> list[Path]:\n  81:         \"\"\"Find all Python files in directory tree.\"\"\"\n  82:         python_files = []\n  83:         ",
          "match": "def find_python_files(root_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 95,
          "context": "  92:         \n  93:         return sorted(python_files)\n  94:     \n  95: >>> def main():\n  96:         \"\"\"Main execution function.\"\"\"\n  97:         # Get project root (where this script is located)\n  98:         script_dir = Path(__file__).parent",
          "match": "def main():"
        }
      ],
      "line_count": 149,
      "docstring": "Script to add copyright and license headers to all Python files in LFM project.\n\nThis script:\n1. Finds all .py files in the project\n2. Checks if they already have copyright headers\n3. Adds standardized copyright/license headers if missing\n4. Preserves shebang lines and existing docstrings\n\nUsage: python add_copyright_headers.py"
    },
    {
      "filepath": "archive\\check_contact_email.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "4d7fe90b5907425d",
      "file_size": 2972,
      "modified": "2025-11-03T13:12:11.559244",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:     ]\n  37:     \n  38:     \n  39: >>> def is_allowed(path: Path) -> bool:\n  40:         rel = path.as_posix()\n  41:         for p in ALLOWED_PREFIXES:\n  42:             if rel.startswith(p):",
          "match": "def is_allowed(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:         return False\n  45:     \n  46:     \n  47: >>> def main() -> int:\n  48:         root = Path(__file__).resolve().parents[1]\n  49:         violations = []\n  50:         scanned = 0",
          "match": "def main() -> int:"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 29,
          "context": "  26:     \n  27:     # Allowed paths (prefix match) where old email may legitimately persist (snapshots, evidence, outputs)\n  28:     ALLOWED_PREFIXES = [\n  29: >>>     \"docs/upload/\",            # current upload staging (regenerated periodically)\n  30:         \"docs/upload_backup_\",     # immutable backups\n  31:         \"docs/upload_ref\",         # immutable references\n  32:         \"docs/evidence/\",          # extracted evidence and templates",
          "match": "periodic"
        }
      ],
      "line_count": 86,
      "docstring": "check_contact_email.py — Guardrail to prevent old contact email from reappearing in source.\n\nScans the repository for occurrences of the old contact email and fails if any are found\noutside of explicitly allowed generated/snapshot directories.\n\nExit codes:\n- 0: No violations found\n- 1: Violations detected"
    },
    {
      "filepath": "archive\\check_last_run.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "844e6c6231586505",
      "file_size": 968,
      "modified": "2025-11-02T20:02:10.850929",
      "git_info": null,
      "innovations": [
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 20,
          "context": "  17:         last_run=last[-1]\n  18:         print(f'  CPU: {last_run.get(\"peak_cpu_percent\", \"MISSING\")}%')\n  19:         print(f'  RAM: {last_run.get(\"peak_memory_mb\", \"MISSING\")} MB')\n  20: >>>     print(f'  GPU: {last_run.get(\"peak_gpu_memory_mb\", \"MISSING\")} MB')\n  21:         print(f'  Runtime: {last_run.get(\"runtime_sec\", \"MISSING\")} s')\n  22:         print(f'  Timestamp: {last_run.get(\"timestamp\", \"MISSING\")}')\n  23:     ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 20,
          "context": "  17:         last_run=last[-1]\n  18:         print(f'  CPU: {last_run.get(\"peak_cpu_percent\", \"MISSING\")}%')\n  19:         print(f'  RAM: {last_run.get(\"peak_memory_mb\", \"MISSING\")} MB')\n  20: >>>     print(f'  GPU: {last_run.get(\"peak_gpu_memory_mb\", \"MISSING\")} MB')\n  21:         print(f'  Runtime: {last_run.get(\"runtime_sec\", \"MISSING\")} s')\n  22:         print(f'  Timestamp: {last_run.get(\"timestamp\", \"MISSING\")}')\n  23:     ",
          "match": "gpu"
        }
      ],
      "line_count": 22,
      "docstring": null
    },
    {
      "filepath": "archive\\fix_license_headers.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "95052310455385a8",
      "file_size": 4669,
      "modified": "2025-11-03T13:12:11.559244",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:     TEXT_EXTENSIONS = {\".py\", \".md\", \".txt\", \".json\", \".yaml\", \".yml\", \".rst\", \".ini\"}\n  51:     \n  52:     \n  53: >>> def should_skip_dir(path: Path, root: Path) -> bool:\n  54:         rel = path.relative_to(root).as_posix()\n  55:         for d in SKIP_DIRS:\n  56:             if rel.startswith(d):",
          "match": "def should_skip_dir(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:         return False\n  59:     \n  60:     \n  61: >>> def process_file(path: Path) -> tuple[int, bool]:\n  62:         \"\"\"Process a file and return (replacements_made, modified)\"\"\"\n  63:         try:\n  64:             content = path.read_text(encoding=\"utf-8\")",
          "match": "def process_file(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 91,
          "context": "  88:         return 0, False\n  89:     \n  90:     \n  91: >>> def main() -> None:\n  92:         root = Path(__file__).resolve().parents[1]\n  93:         total_files = 0\n  94:         modified_files = 0",
          "match": "def main() -> None:"
        }
      ],
      "line_count": 127,
      "docstring": "fix_license_headers.py — Update all license references from CC BY-NC-ND 4.0 to CC BY-NC-ND 4.0\n\nThis script replaces all occurrences of the old license identifier with the correct\nnon-commercial, no-derivatives license across the repository."
    },
    {
      "filepath": "archive\\replace_contact_email.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "f439b9f35199f9f2",
      "file_size": 5721,
      "modified": "2025-11-03T13:12:11.560590",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:     }\n  64:     \n  65:     \n  66: >>> def is_text_file(path: Path) -> bool:\n  67:         if path.suffix.lower() in TEXT_EXTENSIONS:\n  68:             return True\n  69:         # Try UTF-8 sniff as a fallback (small files only to avoid large reads)",
          "match": "def is_text_file(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 81,
          "context": "  78:             return False\n  79:     \n  80:     \n  81: >>> def should_skip_dir(root: Path, dir_name: str, include_generated: bool) -> bool:\n  82:         rel = os.path.relpath((root / dir_name).as_posix(), Path.cwd().as_posix())\n  83:         # Normalize path separators for matching\n  84:         rel = rel.replace(\"\\\\\", \"/\")",
          "match": "def should_skip_dir(root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 95,
          "context": "  92:         return False\n  93:     \n  94:     \n  95: >>> def replace_in_file(path: Path, old: str, new: str, write: bool) -> int:\n  96:         try:\n  97:             text = path.read_text(encoding=\"utf-8\")\n  98:         except Exception:",
          "match": "def replace_in_file(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 107,
          "context": " 104:         return count\n 105:     \n 106:     \n 107: >>> def main() -> None:\n 108:         parser = argparse.ArgumentParser(description=\"Safely replace contact email across repository\")\n 109:         parser.add_argument(\"--old\", default=DEFAULT_OLD, help=\"Old email string to replace\")\n 110:         parser.add_argument(\"--new\", default=DEFAULT_NEW, help=\"New email string to use\")",
          "match": "def main() -> None:"
        }
      ],
      "line_count": 167,
      "docstring": "replace_contact_email.py — Safely update the repository-wide contact email.\n\nDefault behavior:\n- Replaces all occurrences of the old email with the new one across source and docs\n  while skipping generated artifacts and backups (docs/upload*, docs/evidence, results, etc.).\n- Operates in dry-run mode unless --write is provided.\n\nUsage examples:\n  python tools/replace_contact_email.py                 # dry-run, show what would change\n  python tools/replace_contact_email.py --write         # apply changes\n  python tools/replace_contact_email.py --include-generated --write  # also update generated copies\n\nNotes:\n- Only text-like files are considered by extension and by successful UTF-8 decoding.\n- Extensions scanned by default: .py, .md, .txt, .json, .csv, .yml, .yaml, .ini, .cfg, .toml, .rst, .license, .notice"
    },
    {
      "filepath": "archive\\run_all_tiers.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "466cd453c08aced0",
      "file_size": 4826,
      "modified": "2025-11-02T20:02:10.934045",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:     # ---------------------------------------------------------------------------\n  29:     # --- Helpers\n  30:     # ---------------------------------------------------------------------------\n  31: >>> def read_json(path):\n  32:         try:\n  33:             return json.loads(Path(path).read_text())\n  34:         except Exception:",
          "match": "def read_json(path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:         except Exception:\n  35:             return None\n  36:     \n  37: >>> def collect_metrics(summary_dir):\n  38:         path = Path(summary_dir)\n  39:         summaries = []\n  40:         if path.is_file() and path.name == \"summary.json\":",
          "match": "def collect_metrics(summary_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:                 summaries.append(read_json(f))\n  45:         return summaries\n  46:     \n  47: >>> def flatten_metrics(summaries):\n  48:         metrics = {}\n  49:         for s in summaries or []:\n  50:             if not s or \"metrics\" not in s:",
          "match": "def flatten_metrics(summaries):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:                     metrics.setdefault(k, []).append(v)\n  55:         return {k: sum(v) / len(v) for k, v in metrics.items() if v}\n  56:     \n  57: >>> def discover_scripts():\n  58:         \"\"\"Find all run_tier*.py scripts in code/.\"\"\"\n  59:         return sorted(CODE.glob(\"run_tier*.py\"))\n  60:     ",
          "match": "def discover_scripts():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:         \"\"\"Find all run_tier*.py scripts in code/.\"\"\"\n  59:         return sorted(CODE.glob(\"run_tier*.py\"))\n  60:     \n  61: >>> def find_config_for(script_path):\n  62:         \"\"\"Find the matching config file by replacing 'run' with 'config'.\"\"\"\n  63:         cfg_name = script_path.stem.replace(\"run\", \"config\") + \".json\"\n  64:         cfg_path = CONFIG / cfg_name",
          "match": "def find_config_for(script_path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:         cfg_path = CONFIG / cfg_name\n  65:         return cfg_path if cfg_path.exists() else None\n  66:     \n  67: >>> def run_script(script_path):\n  68:         \"\"\"Run a single script and collect metrics if possible.\"\"\"\n  69:         print(f\"\\n▶ Running {script_path.name} …\")\n  70:         start_time = datetime.utcnow()",
          "match": "def run_script(script_path):"
        }
      ],
      "line_count": 145,
      "docstring": "LFM Phase-1 Runner — v2.1 (Auto-Discovery + Single Run Mode)\nAutomatically runs all Tier scripts or one specific script.\nAssumes naming pattern:\n    code/run_tierX_name.py  ↔  config/config_tierX_name.json"
    },
    {
      "filepath": "archive\\run_tier1_dispersion_curve.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "81beffc5ee42bfc0",
      "file_size": 5126,
      "modified": "2025-11-02T20:02:10.934045",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 22,
          "context": "  19:     import matplotlib.pyplot as plt\n  20:     \n  21:     # ------------------------------- Config Loader ------------------------------\n  22: >>> def load_config():\n  23:         script = Path(__file__).stem.replace(\"run_\", \"\")\n  24:         cfg_path = Path(__file__).resolve().parent.parent / \"config\" / f\"config_{script}.json\"\n  25:         with open(cfg_path, \"r\", encoding=\"utf-8\") as f:",
          "match": "def load_config():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 29,
          "context": "  26:             return json.load(f)\n  27:     \n  28:     # --------------------------- Spatial Laplacian helper -----------------------\n  29: >>> def laplacian(E, dx, order=2):\n  30:         if order == 2:\n  31:             return (cp.roll(E, -1) - 2*E + cp.roll(E, 1)) / dx**2\n  32:         elif order == 4:",
          "match": "def laplacian(E, dx, order=2):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:             raise ValueError(\"Unsupported stencil order; use 2 or 4\")\n  37:     \n  38:     # ---------------------------- Standing-wave init ----------------------------\n  39: >>> def init_field(N, k0, dx):\n  40:         x = cp.arange(N) * dx\n  41:         return cp.cos(k0 * x)  # real standing wave so center oscillates\n  42:     ",
          "match": "def init_field(N, k0, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 44,
          "context": "  41:         return cp.cos(k0 * x)  # real standing wave so center oscillates\n  42:     \n  43:     # -------------------------- Frequency measurement --------------------------\n  44: >>> def measure_frequency(N, steps, dx, dt, alpha, beta, chi, save_every, k_frac, stencil_order):\n  45:         c = math.sqrt(alpha / beta)\n  46:         k0 = k_frac * (math.pi / dx)  # fraction of Nyquist\n  47:         omega_theory = math.sqrt((c * k0) ** 2 + chi ** 2)",
          "match": "def measure_frequency(N, steps, dx, dt, alpha, beta, chi, save_every, k_frac, stencil_order):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 73,
          "context": "  70:         return k0, omega_meas, omega_theory\n  71:     \n  72:     # ----------------------------------- Main -----------------------------------\n  73: >>> def main():\n  74:         cfg = load_config()\n  75:         p = cfg[\"parameters\"]\n  76:     ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 17,
          "context": "  14:     \n  15:     import json, math, time\n  16:     from pathlib import Path\n  17: >>> import cupy as cp\n  18:     import numpy as np\n  19:     import matplotlib.pyplot as plt\n  20:     ",
          "match": "cupy"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 89,
          "context": "  86:         stencil_order = int(p.get(\"stencil_order\", 4))  # default to 4th-order\n  87:     \n  88:         c = math.sqrt(alpha / beta)\n  89: >>>     cfl = c * dt / dx\n  90:         if cfl > 0.9:\n  91:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9). Reduce dt or increase dx.\")\n  92:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 90,
          "context": "  87:     \n  88:         c = math.sqrt(alpha / beta)\n  89:         cfl = c * dt / dx\n  90: >>>     if cfl > 0.9:\n  91:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9). Reduce dt or increase dx.\")\n  92:     \n  93:         project_root = Path(__file__).resolve().parent.parent",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 91,
          "context": "  88:         c = math.sqrt(alpha / beta)\n  89:         cfl = c * dt / dx\n  90:         if cfl > 0.9:\n  91: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9). Reduce dt or increase dx.\")\n  92:     \n  93:         project_root = Path(__file__).resolve().parent.parent\n  94:         outdir = (project_root / cfg[\"output_dir\"]).resolve()",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 91,
          "context": "  88:         c = math.sqrt(alpha / beta)\n  89:         cfl = c * dt / dx\n  90:         if cfl > 0.9:\n  91: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9). Reduce dt or increase dx.\")\n  92:     \n  93:         project_root = Path(__file__).resolve().parent.parent\n  94:         outdir = (project_root / cfg[\"output_dir\"]).resolve()",
          "match": "cfl"
        }
      ],
      "line_count": 131,
      "docstring": "LFM Tier-1 — Dispersion Curve Diagnostic (4th-Order Stencil, Continuum)\nSweeps multiple k-fractions to measure ω(k) vs theory √(c²k²+χ²).\n\nOutputs → results/Tier1/DispersionCurve_Continuum/"
    },
    {
      "filepath": "archive\\run_tier1_dispersion_curve_copilot.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "164923a5c3f6857a",
      "file_size": 12744,
      "modified": "2025-11-02T20:02:10.934045",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:         USING_CUPY = False\n  29:     \n  30:     # ------------------------------- Config Loader ------------------------------\n  31: >>> def load_config():\n  32:         script = Path(__file__).stem.replace(\"run_\", \"\")\n  33:         cfg_path = Path(__file__).resolve().parent.parent / \"config\" / f\"config_{script}.json\"\n  34:         with open(cfg_path, \"r\", encoding=\"utf-8\") as f:",
          "match": "def load_config():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 38,
          "context": "  35:             return json.load(f)\n  36:     \n  37:     # --------------------------- Spatial Laplacian helper -----------------------\n  38: >>> def laplacian(E, dx, order=2):\n  39:         if order == 2:\n  40:             return (xp.roll(E, -1) - 2*E + xp.roll(E, 1)) / dx**2\n  41:         elif order == 4:",
          "match": "def laplacian(E, dx, order=2):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:             raise ValueError(\"Unsupported stencil order; use 2 or 4\")\n  45:     \n  46:     # -------------------------- Field initialization ----------------------------\n  47: >>> def init_traveling_wave(N, k0, dx, omega, dt):\n  48:         x = xp.arange(N) * dx\n  49:         E_now = xp.cos(k0 * x)\n  50:         E_prev = xp.cos(k0 * x - omega * dt)",
          "match": "def init_traveling_wave(N, k0, dx, omega, dt):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 54,
          "context": "  51:         return E_prev, E_now\n  52:     \n  53:     # -------------------------- Discrete dispersion helper ---------------------\n  54: >>> def discrete_omega(k0, dx, dt, c, chi, stencil_order=4):\n  55:         \"\"\"\n  56:         Leapfrog-in-time + FD Laplacian dispersion:\n  57:           sin^2(ω Δt / 2) = (Δt^2 / 4) * ( - c^2 * λ_h(k) + χ^2 ), with λ_h(k) < 0",
          "match": "def discrete_omega(k0, dx, dt, c, chi, stencil_order=4):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 74,
          "context": "  71:         return omega_disc, omega_cont, kd, lam, rhs_inside, math.sqrt(rhs_inside)\n  72:     \n  73:     # -------------------------- Debug plotting helper --------------------------\n  74: >>> def _save_debug_plots(data, xf, yf, k0, outdir=Path(\".\")):\n  75:         outdir = Path(outdir)\n  76:         try:\n  77:             trace_fn = outdir / f\"trace_debug_k_{k0:.3e}.png\"",
          "match": "def _save_debug_plots(data, xf, yf, k0, outdir=Path(\".\")):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 89,
          "context": "  86:             return None, None\n  87:     \n  88:     # -------------------------- Frequency measurement --------------------------\n  89: >>> def measure_frequency(N, steps, dx, dt, alpha, beta, chi, save_every, k_frac, stencil_order, outdir, produce_debug_plots=False):\n  90:         c = math.sqrt(alpha / beta)\n  91:         k0 = k_frac * (math.pi / dx)\n  92:         omega_theory_disc, omega_theory_cont, kd, lam, rhs_inside, arg = discrete_omega(k0, dx, dt, c, chi, stencil_order)",
          "match": "def measure_frequency(N, steps, dx, dt, alpha, beta, chi, save_every, k_frac, stencil_order, outdir, produce_debug_plots=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 184,
          "context": " 181:         return diagnostics\n 182:     \n 183:     # ----------------------------------- Main -----------------------------------\n 184: >>> def main():\n 185:         cfg = load_config()\n 186:         p = cfg[\"parameters\"]\n 187:     ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 20,
          "context": "  17:     import numpy as np\n  18:     import matplotlib.pyplot as plt\n  19:     \n  20: >>> # GPU fallback\n  21:     try:\n  22:         import cupy as cp\n  23:         xp = cp",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 22,
          "context": "  19:     \n  20:     # GPU fallback\n  21:     try:\n  22: >>>     import cupy as cp\n  23:         xp = cp\n  24:         USING_CUPY = True\n  25:     except Exception:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 24,
          "context": "  21:     try:\n  22:         import cupy as cp\n  23:         xp = cp\n  24: >>>     USING_CUPY = True\n  25:     except Exception:\n  26:         cp = np\n  27:         xp = np",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 28,
          "context": "  25:     except Exception:\n  26:         cp = np\n  27:         xp = np\n  28: >>>     USING_CUPY = False\n  29:     \n  30:     # ------------------------------- Config Loader ------------------------------\n  31:     def load_config():",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 101,
          "context": "  98:     \n  99:         # --- Single-point probe to avoid spatial averaging cancellation at high k ---\n 100:         center = N // 2\n 101: >>>     if USING_CUPY:\n 102:             probe_idx = int(center)\n 103:         else:\n 104:             probe_idx = int(center)",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 114,
          "context": " 111:             lap = laplacian(E, dx, order=stencil_order)\n 112:             E_next = (2 * E - E_prev) + (dt ** 2) * ( (c ** 2) * lap - (chi ** 2) * E )\n 113:             if n % save_every == 0:\n 114: >>>             if USING_CUPY:\n 115:                     sample_val = float(cp.asnumpy(E[probe_idx]))\n 116:                 else:\n 117:                     sample_val = float(E[probe_idx])",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 213,
          "context": " 210:         parsed_config = {\n 211:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 212:             \"save_every\": save_every, \"k_list\": k_list, \"stencil_order\": stencil_order,\n 213: >>>         \"c\": c, \"cfl\": cfl, \"using_cupy\": USING_CUPY\n 214:         }\n 215:         print(\"Parsed config:\\n\", json.dumps(parsed_config, indent=2))\n 216:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 213,
          "context": " 210:         parsed_config = {\n 211:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 212:             \"save_every\": save_every, \"k_list\": k_list, \"stencil_order\": stencil_order,\n 213: >>>         \"c\": c, \"cfl\": cfl, \"using_cupy\": USING_CUPY\n 214:         }\n 215:         print(\"Parsed config:\\n\", json.dumps(parsed_config, indent=2))\n 216:     ",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 219,
          "context": " 216:     \n 217:         rows = []\n 218:         meta = {\n 219: >>>         \"using_cupy\": USING_CUPY,\n 220:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 221:             \"stencil_order\": stencil_order, \"c\": c, \"cfl\": cfl, \"cfl_max\": cfl_max,\n 222:             \"date\": time.asctime(),",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 219,
          "context": " 216:     \n 217:         rows = []\n 218:         meta = {\n 219: >>>         \"using_cupy\": USING_CUPY,\n 220:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 221:             \"stencil_order\": stencil_order, \"c\": c, \"cfl\": cfl, \"cfl_max\": cfl_max,\n 222:             \"date\": time.asctime(),",
          "match": "CUPY"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 201,
          "context": " 198:     \n 199:         d = int(p.get(\"dimension\", 1))\n 200:         c = math.sqrt(alpha / beta)\n 201: >>>     cfl = c * dt / dx\n 202:         cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203:         if cfl > cfl_max + 1e-12:\n 204:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 202,
          "context": " 199:         d = int(p.get(\"dimension\", 1))\n 200:         c = math.sqrt(alpha / beta)\n 201:         cfl = c * dt / dx\n 202: >>>     cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203:         if cfl > cfl_max + 1e-12:\n 204:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 202,
          "context": " 199:         d = int(p.get(\"dimension\", 1))\n 200:         c = math.sqrt(alpha / beta)\n 201:         cfl = c * dt / dx\n 202: >>>     cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203:         if cfl > cfl_max + 1e-12:\n 204:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 203,
          "context": " 200:         c = math.sqrt(alpha / beta)\n 201:         cfl = c * dt / dx\n 202:         cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203: >>>     if cfl > cfl_max + 1e-12:\n 204:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     \n 206:         project_root = Path(__file__).resolve().parent.parent",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 203,
          "context": " 200:         c = math.sqrt(alpha / beta)\n 201:         cfl = c * dt / dx\n 202:         cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203: >>>     if cfl > cfl_max + 1e-12:\n 204:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     \n 206:         project_root = Path(__file__).resolve().parent.parent",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 204,
          "context": " 201:         cfl = c * dt / dx\n 202:         cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203:         if cfl > cfl_max + 1e-12:\n 204: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     \n 206:         project_root = Path(__file__).resolve().parent.parent\n 207:         outdir = (project_root / cfg[\"output_dir\"]).resolve()",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 204,
          "context": " 201:         cfl = c * dt / dx\n 202:         cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203:         if cfl > cfl_max + 1e-12:\n 204: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     \n 206:         project_root = Path(__file__).resolve().parent.parent\n 207:         outdir = (project_root / cfg[\"output_dir\"]).resolve()",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 204,
          "context": " 201:         cfl = c * dt / dx\n 202:         cfl_max = float(cfg.get(\"cfl_max\", 1.0 if d == 1 else 1.0 / math.sqrt(d)))\n 203:         if cfl > cfl_max + 1e-12:\n 204: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.6f} > {cfl_max}). Reduce dt or increase dx.\")\n 205:     \n 206:         project_root = Path(__file__).resolve().parent.parent\n 207:         outdir = (project_root / cfg[\"output_dir\"]).resolve()",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 213,
          "context": " 210:         parsed_config = {\n 211:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 212:             \"save_every\": save_every, \"k_list\": k_list, \"stencil_order\": stencil_order,\n 213: >>>         \"c\": c, \"cfl\": cfl, \"using_cupy\": USING_CUPY\n 214:         }\n 215:         print(\"Parsed config:\\n\", json.dumps(parsed_config, indent=2))\n 216:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 213,
          "context": " 210:         parsed_config = {\n 211:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 212:             \"save_every\": save_every, \"k_list\": k_list, \"stencil_order\": stencil_order,\n 213: >>>         \"c\": c, \"cfl\": cfl, \"using_cupy\": USING_CUPY\n 214:         }\n 215:         print(\"Parsed config:\\n\", json.dumps(parsed_config, indent=2))\n 216:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 221,
          "context": " 218:         meta = {\n 219:             \"using_cupy\": USING_CUPY,\n 220:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 221: >>>         \"stencil_order\": stencil_order, \"c\": c, \"cfl\": cfl, \"cfl_max\": cfl_max,\n 222:             \"date\": time.asctime(),\n 223:         }\n 224:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 221,
          "context": " 218:         meta = {\n 219:             \"using_cupy\": USING_CUPY,\n 220:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 221: >>>         \"stencil_order\": stencil_order, \"c\": c, \"cfl\": cfl, \"cfl_max\": cfl_max,\n 222:             \"date\": time.asctime(),\n 223:         }\n 224:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 221,
          "context": " 218:         meta = {\n 219:             \"using_cupy\": USING_CUPY,\n 220:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 221: >>>         \"stencil_order\": stencil_order, \"c\": c, \"cfl\": cfl, \"cfl_max\": cfl_max,\n 222:             \"date\": time.asctime(),\n 223:         }\n 224:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 221,
          "context": " 218:         meta = {\n 219:             \"using_cupy\": USING_CUPY,\n 220:             \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": alpha, \"beta\": beta, \"chi\": chi,\n 221: >>>         \"stencil_order\": stencil_order, \"c\": c, \"cfl\": cfl, \"cfl_max\": cfl_max,\n 222:             \"date\": time.asctime(),\n 223:         }\n 224:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 10,
          "context": "   7:     \n   8:     \"\"\"\n   9:     LFM Tier-1 — Dispersion Curve Diagnostic (4th-Order Stencil, Discrete-Theory)\n  10: >>> - Correct leapfrog + stencil discrete dispersion\n  11:     - Unit-safe FFT with parabolic peak refinement\n  12:     - Robust debug prints and error reporting\n  13:     - Uses single-point probe to avoid high-k spatial averaging cancellation",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 56,
          "context": "  53:     # -------------------------- Discrete dispersion helper ---------------------\n  54:     def discrete_omega(k0, dx, dt, c, chi, stencil_order=4):\n  55:         \"\"\"\n  56: >>>     Leapfrog-in-time + FD Laplacian dispersion:\n  57:           sin^2(ω Δt / 2) = (Δt^2 / 4) * ( - c^2 * λ_h(k) + χ^2 ), with λ_h(k) < 0\n  58:         \"\"\"\n  59:         kd = k0 * dx",
          "match": "Leapfrog"
        }
      ],
      "line_count": 300,
      "docstring": "LFM Tier-1 — Dispersion Curve Diagnostic (4th-Order Stencil, Discrete-Theory)\n- Correct leapfrog + stencil discrete dispersion\n- Unit-safe FFT with parabolic peak refinement\n- Robust debug prints and error reporting\n- Uses single-point probe to avoid high-k spatial averaging cancellation"
    },
    {
      "filepath": "archive\\run_tier1_highvelocity.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "0041c2713210476a",
      "file_size": 4956,
      "modified": "2025-11-02T20:02:10.937316",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 26,
          "context": "  23:     # ---------------------------------------------------------------------------\n  24:     # Config Loader  (standard LFM convention)\n  25:     # ---------------------------------------------------------------------------\n  26: >>> def load_config():\n  27:         script = Path(__file__).stem.replace(\"run_\", \"\")\n  28:         cfg_path = Path(__file__).resolve().parent.parent / \"config\" / f\"config_{script}.json\"\n  29:         with open(cfg_path, \"r\", encoding=\"utf-8\") as f:",
          "match": "def load_config():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 36,
          "context": "  33:     # ---------------------------------------------------------------------------\n  34:     # Initialize Field  (traveling wave so FFT finds frequency)\n  35:     # ---------------------------------------------------------------------------\n  36: >>> def init_field(N, k0, dx):\n  37:         x = cp.arange(N) * dx\n  38:         return cp.cos(k0 * x) + 1j * cp.sin(k0 * x)   # e^{i kx}\n  39:     ",
          "match": "def init_field(N, k0, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 44,
          "context": "  41:     # ---------------------------------------------------------------------------\n  42:     # Main Simulation\n  43:     # ---------------------------------------------------------------------------\n  44: >>> def main():\n  45:         cfg = load_config()\n  46:         p = cfg[\"parameters\"]\n  47:     ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 18,
          "context": "  15:     \n  16:     import json, math, time\n  17:     from pathlib import Path\n  18: >>> import cupy as cp\n  19:     import numpy as np\n  20:     import matplotlib.pyplot as plt\n  21:     ",
          "match": "cupy"
        }
      ],
      "line_count": 144,
      "docstring": "LFM Tier-1 — Lorentz Boost (High Velocity)\nTests isotropy and dispersion linearity for v ≈ 0.9 c.\nValidates that ω² = c²k² + χ² holds under relativistic Doppler boost.\n\nOutputs → results/Tier1/HighVelocity/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier1_isotropy.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "a7bb5ad0033f5f77",
      "file_size": 7852,
      "modified": "2025-11-02T20:02:10.938805",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 22,
          "context": "  19:     # ---------------------------------------------------------------------------\n  20:     # --- Config loader: merges master + inherited configs\n  21:     # ---------------------------------------------------------------------------\n  22: >>> def load_config(cfg_name: str):\n  23:         root = Path(__file__).resolve().parents[1] / \"config\"\n  24:         cfg_path = root / cfg_name\n  25:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 179,
          "context": " 176:     }\n 177:     import numpy as np, json\n 178:     \n 179: >>> def _json_sanitize(obj):\n 180:         if isinstance(obj, np.bool_):\n 181:             return bool(obj)\n 182:         if isinstance(obj, (np.integer, np.floating)):",
          "match": "def _json_sanitize(obj):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 14,
          "context": "  11:     Generates quantitative + visual outputs for archival in /results/Tier1/\n  12:     \"\"\"\n  13:     \n  14: >>> import json, math, cupy as cp, numpy as np, matplotlib.pyplot as plt\n  15:     from pathlib import Path\n  16:     import os, csv, platform\n  17:     from datetime import datetime",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 59,
          "context": "  56:     plot_dir.mkdir(parents=True, exist_ok=True)\n  57:     \n  58:     # ---------------------------------------------------------------------------\n  59: >>> # --- GPU memory and precision setup\n  60:     # ---------------------------------------------------------------------------\n  61:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  62:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 61,
          "context": "  58:     # ---------------------------------------------------------------------------\n  59:     # --- GPU memory and precision setup\n  60:     # ---------------------------------------------------------------------------\n  61: >>> if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  62:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  63:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  64:     dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:     # --- GPU memory and precision setup\n  60:     # ---------------------------------------------------------------------------\n  61:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  62: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  63:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  64:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  65:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:     # --- GPU memory and precision setup\n  60:     # ---------------------------------------------------------------------------\n  61:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  62: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  63:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  64:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  65:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:     # --- GPU memory and precision setup\n  60:     # ---------------------------------------------------------------------------\n  61:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  62: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  63:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  64:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  65:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 160,
          "context": " 157:         \"tier\": 1,\n 158:         \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 159:         \"hardware\": {\n 160: >>>         \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 161:             \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 162:             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:             \"os\": platform.platform(),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 160,
          "context": " 157:         \"tier\": 1,\n 158:         \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 159:         \"hardware\": {\n 160: >>>         \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 161:             \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 162:             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:             \"os\": platform.platform(),",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 161,
          "context": " 158:         \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 159:         \"hardware\": {\n 160:             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 161: >>>         \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 162:             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:             \"os\": platform.platform(),\n 164:             \"python\": platform.python_version(),",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 161,
          "context": " 158:         \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 159:         \"hardware\": {\n 160:             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 161: >>>         \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 162:             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:             \"os\": platform.platform(),\n 164:             \"python\": platform.python_version(),",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 162,
          "context": " 159:         \"hardware\": {\n 160:             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 161:             \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 162: >>>         \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:             \"os\": platform.platform(),\n 164:             \"python\": platform.python_version(),\n 165:         },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 162,
          "context": " 159:         \"hardware\": {\n 160:             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 161:             \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 162: >>>         \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:             \"os\": platform.platform(),\n 164:             \"python\": platform.python_version(),\n 165:         },",
          "match": "cuda"
        }
      ],
      "line_count": 198,
      "docstring": "LFM Tier-1 Isotropy Test — Hierarchical Config Version\nPhase-1 Proof-of-Concept Validation\nReads master_config.json → tier1_isotropy.json (+ validation_thresholds.json)\nGenerates quantitative + visual outputs for archival in /results/Tier1/"
    },
    {
      "filepath": "archive\\run_tier1_lorentz_dispersion.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "058a07e7a8cb8109",
      "file_size": 11035,
      "modified": "2025-11-02T20:02:10.939971",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 26,
          "context": "  23:     # ---------------------------------------------------------------------------\n  24:     # Config loader (same pattern as Tier-4)\n  25:     # ---------------------------------------------------------------------------\n  26: >>> def load_config(cfg_name: str):\n  27:         root = Path(__file__).resolve().parents[1] / \"config\"\n  28:         cfg_path = root / cfg_name\n  29:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 65,
          "context": "  62:     # ---------------------------------------------------------------------------\n  63:     # Utilities\n  64:     # ---------------------------------------------------------------------------\n  65: >>> def ensure_dirs(p: Path):\n  66:         p.mkdir(parents=True, exist_ok=True)\n  67:     \n  68:     def centered_coords(N, dx):",
          "match": "def ensure_dirs(p:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 68,
          "context": "  65:     def ensure_dirs(p: Path):\n  66:         p.mkdir(parents=True, exist_ok=True)\n  67:     \n  68: >>> def centered_coords(N, dx):\n  69:         # Periodic grid in [-L/2, L/2], spacing dx\n  70:         L = N * dx\n  71:         arr = cp.arange(N, dtype=DTYPE) * dx",
          "match": "def centered_coords(N, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 75,
          "context": "  72:         arr = arr - (L/2)\n  73:         return arr\n  74:     \n  75: >>> def discrete_laplacian_3d(E, dx):\n  76:         return (cp.roll(E, 1, 0) + cp.roll(E, -1, 0) +\n  77:                 cp.roll(E, 1, 1) + cp.roll(E, -1, 1) +\n  78:                 cp.roll(E, 1, 2) + cp.roll(E, -1, 2) - 6*E) / (dx*dx)",
          "match": "def discrete_laplacian_3d(E, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:                 cp.roll(E, 1, 1) + cp.roll(E, -1, 1) +\n  78:                 cp.roll(E, 1, 2) + cp.roll(E, -1, 2) - 6*E) / (dx*dx)\n  79:     \n  80: >>> def grad_sq_3d(E, dx):\n  81:         # centered differences\n  82:         gx = (cp.roll(E,-1,0) - cp.roll(E,1,0)) / (2*dx)\n  83:         gy = (cp.roll(E,-1,1) - cp.roll(E,1,1)) / (2*dx)",
          "match": "def grad_sq_3d(E, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 87,
          "context": "  84:         gz = (cp.roll(E,-1,2) - cp.roll(E,1,2)) / (2*dx)\n  85:         return gx*gx + gy*gy + gz*gz\n  86:     \n  87: >>> def total_energy(En, Em, dt, c, dx):\n  88:         # Discrete energy density: ½[(Δ_t E)^2 + c^2 |∇E|^2] (χ=0)\n  89:         dEdt = (En - Em) / dt\n  90:         g2   = grad_sq_3d(En, dx)",
          "match": "def total_energy(En, Em, dt, c, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 94,
          "context": "  91:         eps  = 0.5*(dEdt*dEdt + (c*c)*g2)\n  92:         return float(cp.sum(eps))\n  93:     \n  94: >>> def make_unit(v):\n  95:         v = np.array(v, dtype=float)\n  96:         n = np.linalg.norm(v)\n  97:         return v / n",
          "match": "def make_unit(v):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 99,
          "context": "  96:         n = np.linalg.norm(v)\n  97:         return v / n\n  98:     \n  99: >>> def make_plane_wave(N, dx, direction, cycles):\n 100:         \"\"\"\n 101:         Build E(x)=sin(k·x) with a given integer number of cycles across the box.\n 102:         k = 2π * cycles / L ;  L = N*dx",
          "match": "def make_plane_wave(N, dx, direction, cycles):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 114,
          "context": " 111:         E0 = cp.sin(phase, dtype=DTYPE)\n 112:         return E0, k\n 113:     \n 114: >>> def estimate_frequency_tfft(trace, dt):\n 115:         \"\"\"\n 116:         Estimate dominant ω via temporal FFT at a probe.\n 117:         \"\"\"",
          "match": "def estimate_frequency_tfft(trace, dt):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 129,
          "context": " 126:     # ---------------------------------------------------------------------------\n 127:     # Per-variant execution\n 128:     # ---------------------------------------------------------------------------\n 129: >>> def run_variant(variant, out_dir: Path):\n 130:         ensure_dirs(out_dir)\n 131:         # Parameters (kept consistent with Tier-4 style)\n 132:         N   = int(variant.get(\"N\", PARAM.get(\"N\", 128)))",
          "match": "def run_variant(variant, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 279,
          "context": " 276:             }\n 277:         }\n 278:     \n 279: >>>     def sanitize(obj):\n 280:             import numpy as np\n 281:             if isinstance(obj, (np.bool_,)): return bool(obj)\n 282:             if isinstance(obj, (np.integer,)): return int(obj)",
          "match": "def sanitize(obj):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 293,
          "context": " 290:     # ---------------------------------------------------------------------------\n 291:     # Main\n 292:     # ---------------------------------------------------------------------------\n 293: >>> def main():\n 294:         variants = CFG[\"variants\"]\n 295:         for i, v in enumerate(variants, 1):\n 296:             out_dir = BASE_RESULTS / f\"{i:02d}_{v.get('description','variant').replace(' ','_')}\"",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 19,
          "context": "  16:     from pathlib import Path\n  17:     from datetime import datetime, timezone\n  18:     \n  19: >>> import cupy as cp\n  20:     import numpy as np\n  21:     import matplotlib.pyplot as plt\n  22:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     BASE_RESULTS.mkdir(parents=True, exist_ok=True)\n  46:     \n  47:     # Hardware setup\n  48: >>> if CFG[\"hardware\"].get(\"gpu_enabled\", True):\n  49:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  50:     \n  51:     precision = CFG[\"hardware\"].get(\"precision\", \"float64\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 49,
          "context": "  46:     \n  47:     # Hardware setup\n  48:     if CFG[\"hardware\"].get(\"gpu_enabled\", True):\n  49: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  50:     \n  51:     precision = CFG[\"hardware\"].get(\"precision\", \"float64\")\n  52:     DTYPE = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 49,
          "context": "  46:     \n  47:     # Hardware setup\n  48:     if CFG[\"hardware\"].get(\"gpu_enabled\", True):\n  49: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  50:     \n  51:     precision = CFG[\"hardware\"].get(\"precision\", \"float64\")\n  52:     DTYPE = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 49,
          "context": "  46:     \n  47:     # Hardware setup\n  48:     if CFG[\"hardware\"].get(\"gpu_enabled\", True):\n  49: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  50:     \n  51:     precision = CFG[\"hardware\"].get(\"precision\", \"float64\")\n  52:     DTYPE = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 246,
          "context": " 243:         (out_dir / \"summary_dashboard.html\").write_text(html, encoding=\"utf-8\")\n 244:     \n 245:         # JSON summary\n 246: >>>     props = cp.cuda.runtime.getDeviceProperties(0)\n 247:         hw = {\n 248:             \"gpu_name\": props[\"name\"].decode(),\n 249:             \"compute_capability\": float(f\"{props['major']}.{props['minor']}\"),",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 248,
          "context": " 245:         # JSON summary\n 246:         props = cp.cuda.runtime.getDeviceProperties(0)\n 247:         hw = {\n 248: >>>         \"gpu_name\": props[\"name\"].decode(),\n 249:             \"compute_capability\": float(f\"{props['major']}.{props['minor']}\"),\n 250:             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 251:             \"python\": platform.python_version()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 250,
          "context": " 247:         hw = {\n 248:             \"gpu_name\": props[\"name\"].decode(),\n 249:             \"compute_capability\": float(f\"{props['major']}.{props['minor']}\"),\n 250: >>>         \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 251:             \"python\": platform.python_version()\n 252:         }\n 253:         summary = {",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 250,
          "context": " 247:         hw = {\n 248:             \"gpu_name\": props[\"name\"].decode(),\n 249:             \"compute_capability\": float(f\"{props['major']}.{props['minor']}\"),\n 250: >>>         \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 251:             \"python\": platform.python_version()\n 252:         }\n 253:         summary = {",
          "match": "cuda"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 138,
          "context": " 135:         c   = float(PARAM.get(\"c\", math.sqrt(PARAM[\"alpha\"]/PARAM[\"beta\"])))\n 136:         steps = int(variant.get(\"steps\", PARAM.get(\"steps\", 2000)))\n 137:         cycles = int(variant.get(\"cycles\", PARAM.get(\"cycles\", 4)))  # cycles across domain\n 138: >>>     # Stability (CFL): c*dt/dx ≤ 1/√3\n 139:         cfl = c*dt/dx\n 140:         print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 138,
          "context": " 135:         c   = float(PARAM.get(\"c\", math.sqrt(PARAM[\"alpha\"]/PARAM[\"beta\"])))\n 136:         steps = int(variant.get(\"steps\", PARAM.get(\"steps\", 2000)))\n 137:         cycles = int(variant.get(\"cycles\", PARAM.get(\"cycles\", 4)))  # cycles across domain\n 138: >>>     # Stability (CFL): c*dt/dx ≤ 1/√3\n 139:         cfl = c*dt/dx\n 140:         print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 139,
          "context": " 136:         steps = int(variant.get(\"steps\", PARAM.get(\"steps\", 2000)))\n 137:         cycles = int(variant.get(\"cycles\", PARAM.get(\"cycles\", 4)))  # cycles across domain\n 138:         # Stability (CFL): c*dt/dx ≤ 1/√3\n 139: >>>     cfl = c*dt/dx\n 140:         print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):\n 142:             raise RuntimeError(f\"CFL violation: c*dt/dx={cfl:.3f} > 1/sqrt(3) ≈ {1/math.sqrt(3):.3f}\")",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 140,
          "context": " 137:         cycles = int(variant.get(\"cycles\", PARAM.get(\"cycles\", 4)))  # cycles across domain\n 138:         # Stability (CFL): c*dt/dx ≤ 1/√3\n 139:         cfl = c*dt/dx\n 140: >>>     print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):\n 142:             raise RuntimeError(f\"CFL violation: c*dt/dx={cfl:.3f} > 1/sqrt(3) ≈ {1/math.sqrt(3):.3f}\")\n 143:     ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 140,
          "context": " 137:         cycles = int(variant.get(\"cycles\", PARAM.get(\"cycles\", 4)))  # cycles across domain\n 138:         # Stability (CFL): c*dt/dx ≤ 1/√3\n 139:         cfl = c*dt/dx\n 140: >>>     print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):\n 142:             raise RuntimeError(f\"CFL violation: c*dt/dx={cfl:.3f} > 1/sqrt(3) ≈ {1/math.sqrt(3):.3f}\")\n 143:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 141,
          "context": " 138:         # Stability (CFL): c*dt/dx ≤ 1/√3\n 139:         cfl = c*dt/dx\n 140:         print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141: >>>     if cfl > 1/math.sqrt(3):\n 142:             raise RuntimeError(f\"CFL violation: c*dt/dx={cfl:.3f} > 1/sqrt(3) ≈ {1/math.sqrt(3):.3f}\")\n 143:     \n 144:         directions = variant.get(\"directions\", PARAM[\"directions\"])",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 142,
          "context": " 139:         cfl = c*dt/dx\n 140:         print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):\n 142: >>>         raise RuntimeError(f\"CFL violation: c*dt/dx={cfl:.3f} > 1/sqrt(3) ≈ {1/math.sqrt(3):.3f}\")\n 143:     \n 144:         directions = variant.get(\"directions\", PARAM[\"directions\"])\n 145:     ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 142,
          "context": " 139:         cfl = c*dt/dx\n 140:         print(f\"CFL ratio = {cfl:.4f} (must be <= 0.577)\")\n 141:         if cfl > 1/math.sqrt(3):\n 142: >>>         raise RuntimeError(f\"CFL violation: c*dt/dx={cfl:.3f} > 1/sqrt(3) ≈ {1/math.sqrt(3):.3f}\")\n 143:     \n 144:         directions = variant.get(\"directions\", PARAM[\"directions\"])\n 145:     ",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 69,
          "context": "  66:         p.mkdir(parents=True, exist_ok=True)\n  67:     \n  68:     def centered_coords(N, dx):\n  69: >>>     # Periodic grid in [-L/2, L/2], spacing dx\n  70:         L = N * dx\n  71:         arr = cp.arange(N, dtype=DTYPE) * dx\n  72:         arr = arr - (L/2)",
          "match": "Periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 10,
          "context": "   7:     \n   8:     \"\"\"\n   9:     LFM Tier-1 — Lorentz Isotropy & Dispersion\n  10: >>> 3-D leapfrog KG (χ=0) plane-wave runs across multiple directions.\n  11:     Measures phase velocity, anisotropy CoV, and energy-drift.\n  12:     Outputs per-variant go to: results/Tier1/Dispersion/<variant_id>/\n  13:     \"\"\"",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 173,
          "context": " 170:             E_init = total_energy(E1, E0, dt, c, dx)\n 171:             probe = []\n 172:     \n 173: >>>         # Leapfrog update (χ=0): E^{n+1} = 2E^n - E^{n-1} + dt^2 * c^2 ∇^2 E^n\n 174:             for n in range(steps):\n 175:                 lap = discrete_laplacian_3d(E1, dx)\n 176:                 Enext = 2*E1 - E0 + (dt*dt)*(c*c)*lap",
          "match": "Leapfrog"
        }
      ],
      "line_count": 300,
      "docstring": "LFM Tier-1 — Lorentz Isotropy & Dispersion\n3-D leapfrog KG (χ=0) plane-wave runs across multiple directions.\nMeasures phase velocity, anisotropy CoV, and energy-drift.\nOutputs per-variant go to: results/Tier1/Dispersion/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier23_longrun.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "71d1cd78c8dde4aa",
      "file_size": 13928,
      "modified": "2025-11-02T20:02:10.942058",
      "git_info": null,
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 51,
          "context": "  48:     import matplotlib.pyplot as plt\n  49:     \n  50:     # ------------------------------ Config & CLI ----------------------------------\n  51: >>> @dataclass\n  52:     class RunSettings:\n  53:         campaign: str = \"museum_day_2025_10_25\"\n  54:         quick: bool = False",
          "match": "class\nclass RunSettings:"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:         seed: int = 123456\n  56:         dtype: str = \"float32\"  # keep GPU memory low; use float64 if desired\n  57:     \n  58: >>> @dataclass\n  59:     class GridCfg:\n  60:         nx: int\n  61:         ny: int",
          "match": "class\nclass GridCfg:"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 69,
          "context": "  66:         sponge_cells: int\n  67:         c: float  # wave speed\n  68:     \n  69: >>> @dataclass\n  70:     class Tier2Cfg:\n  71:         k0: float  # injected plane‑wave wavenumber magnitude\n  72:         chi_lo: float",
          "match": "class\nclass Tier2Cfg:"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 76,
          "context": "  73:         chi_hi: float\n  74:         probes_z: Tuple[int, int]  # z indices for low/high regions\n  75:     \n  76: >>> @dataclass\n  77:     class Tier3Cfg:\n  78:         init_mode: str  # 'gaussian' or 'random'\n  79:         gaussian_sigma: float",
          "match": "class\nclass Tier3Cfg:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 83,
          "context": "  80:         chi_const: float\n  81:     \n  82:     \n  83: >>> def parse_args() -> RunSettings:\n  84:         quick = (\"--quick\" in sys.argv)\n  85:         return RunSettings(quick=quick)\n  86:     ",
          "match": "def parse_args() -> RunSettings:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 89,
          "context": "  86:     \n  87:     # Default configs tuned for RTX 4060 8GB\n  88:     \n  89: >>> def make_configs(rs: RunSettings) -> Tuple[GridCfg, Tier2Cfg, Tier3Cfg]:\n  90:         if rs.quick:\n  91:             # Refined quick-run: balanced resolution + smaller dt\n  92:             grid = GridCfg(nx=128, ny=128, nz=128, dx=1.0, dt=0.20, steps=400, sponge_cells=3, c=1.0)",
          "match": "def make_configs(rs:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 104,
          "context": " 101:     \n 102:     # ------------------------------ Utilities -------------------------------------\n 103:     \n 104: >>> def ensure_dirs(base: Path) -> None:\n 105:         base.mkdir(parents=True, exist_ok=True)\n 106:         (base/\"plots\").mkdir(parents=True, exist_ok=True)\n 107:     ",
          "match": "def ensure_dirs(base:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 108,
          "context": " 105:         base.mkdir(parents=True, exist_ok=True)\n 106:         (base/\"plots\").mkdir(parents=True, exist_ok=True)\n 107:     \n 108: >>> def write_json(path: Path, obj) -> None:\n 109:         with open(path, 'w') as f:\n 110:             json.dump(obj, f, indent=2)\n 111:     ",
          "match": "def write_json(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 112,
          "context": " 109:         with open(path, 'w') as f:\n 110:             json.dump(obj, f, indent=2)\n 111:     \n 112: >>> def write_txt(path: Path, text: str) -> None:\n 113:         with open(path, 'w', encoding='utf-8') as f:\n 114:             f.write(text)\n 115:     ",
          "match": "def write_txt(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 117,
          "context": " 114:             f.write(text)\n 115:     \n 116:     \n 117: >>> def cfl_ok(grid: GridCfg) -> bool:\n 118:         r = grid.c * grid.dt / grid.dx\n 119:         # 3D KG‑type leapfrog bound → c*dt/dx <= 1/sqrt(3)\n 120:         return r <= (1.0 / math.sqrt(3.0))",
          "match": "def cfl_ok(grid:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 123,
          "context": " 120:         return r <= (1.0 / math.sqrt(3.0))\n 121:     \n 122:     \n 123: >>> def make_sponge(nx, ny, nz, sponge_cells, strength=0.015, xpmod=xp):\n 124:         \"\"\"Return 3D damping mask in [0,1], where <1 near boundaries (PML‑lite).\"\"\"\n 125:         mask = xpmod.ones((nx, ny, nz), dtype=xpmod.float32)\n 126:         if sponge_cells <= 0:",
          "match": "def make_sponge(nx, ny, nz, sponge_cells, strength=0.015, xpmod=xp):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 149,
          "context": " 146:     \n 147:     # ------------------------------ Discrete Operators ----------------------------\n 148:     \n 149: >>> def laplacian_3d(u, dx, xpmod=xp):\n 150:         return (\n 151:             (xpmod.roll(u, 1, 0) + xpmod.roll(u, -1, 0) +\n 152:              xpmod.roll(u, 1, 1) + xpmod.roll(u, -1, 1) +",
          "match": "def laplacian_3d(u, dx, xpmod=xp):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 158,
          "context": " 155:     \n 156:     # Energy density for KG‑type field: 0.5[(∂t u)^2 + c^2|∇u|^2 + χ^2 u^2]\n 157:     \n 158: >>> def grad_sq(u, dx, xpmod=xp):\n 159:         dudx = (xpmod.roll(u, -1, 0) - xpmod.roll(u, 1, 0)) / (2*dx)\n 160:         dudy = (xpmod.roll(u, -1, 1) - xpmod.roll(u, 1, 1)) / (2*dx)\n 161:         dudz = (xpmod.roll(u, -1, 2) - xpmod.roll(u, 1, 2)) / (2*dx)",
          "match": "def grad_sq(u, dx, xpmod=xp):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 166,
          "context": " 163:     \n 164:     # ------------------------------ Tier‑2: Redshift -------------------------------\n 165:     \n 166: >>> def run_tier2_redshift(rs: RunSettings, grid: GridCfg, cfg: Tier2Cfg, outdir: Path):\n 167:         ensure_dirs(outdir)\n 168:         xp.random.seed(rs.seed)\n 169:     ",
          "match": "def run_tier2_redshift(rs:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 223,
          "context": " 220:         elapsed = time.time() - t0\n 221:     \n 222:         # Estimate dominant frequency at each probe via FFT peak\n 223: >>>     def peak_freq(x, dt):\n 224:             X = np.fft.rfft(x)\n 225:             freqs = np.fft.rfftfreq(len(x), d=dt)\n 226:             i = np.argmax(np.abs(X))",
          "match": "def peak_freq(x, dt):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 289,
          "context": " 286:     \n 287:     # ------------------------------ Tier‑3: Energy --------------------------------\n 288:     \n 289: >>> def run_tier3_energy(rs: RunSettings, grid: GridCfg, cfg: Tier3Cfg, outdir: Path):\n 290:         ensure_dirs(outdir)\n 291:         xp.random.seed(rs.seed)\n 292:     ",
          "match": "def run_tier3_energy(rs:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 376,
          "context": " 373:     \n 374:     # ------------------------------ Orchestration ---------------------------------\n 375:     \n 376: >>> def main():\n 377:         rs = parse_args()\n 378:     \n 379:         # Base folders per Phase‑1 structure",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> LFM Tier‑2/3 Heavy GPU Tests — Redshift & Energy Conservation (3D)\n  10:     \n  11:     Runs two long, compute‑heavy validations aligned to Phase‑1 Test Design:\n  12:       A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 15,
          "context": "  12:       A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)\n  13:       B) Tier‑3: Global energy conservation over long steps with CFL guard + sponge boundaries\n  14:     \n  15: >>> Designed for: Python 3.11.9, CuPy‑CUDA12.x (GPU). Falls back to NumPy on CPU if CuPy unavailable.\n  16:     \n  17:     Quick check: use --quick for ~10s sanity run (small grid, few steps). Default is long run.\n  18:     ",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 15,
          "context": "  12:       A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)\n  13:       B) Tier‑3: Global energy conservation over long steps with CFL guard + sponge boundaries\n  14:     \n  15: >>> Designed for: Python 3.11.9, CuPy‑CUDA12.x (GPU). Falls back to NumPy on CPU if CuPy unavailable.\n  16:     \n  17:     Quick check: use --quick for ~10s sanity run (small grid, few steps). Default is long run.\n  18:     ",
          "match": "CUDA"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 15,
          "context": "  12:       A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)\n  13:       B) Tier‑3: Global energy conservation over long steps with CFL guard + sponge boundaries\n  14:     \n  15: >>> Designed for: Python 3.11.9, CuPy‑CUDA12.x (GPU). Falls back to NumPy on CPU if CuPy unavailable.\n  16:     \n  17:     Quick check: use --quick for ~10s sanity run (small grid, few steps). Default is long run.\n  18:     ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 15,
          "context": "  12:       A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)\n  13:       B) Tier‑3: Global energy conservation over long steps with CFL guard + sponge boundaries\n  14:     \n  15: >>> Designed for: Python 3.11.9, CuPy‑CUDA12.x (GPU). Falls back to NumPy on CPU if CuPy unavailable.\n  16:     \n  17:     Quick check: use --quick for ~10s sanity run (small grid, few steps). Default is long run.\n  18:     ",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 37,
          "context": "  34:     from pathlib import Path\n  35:     from typing import Tuple\n  36:     \n  37: >>> # ------------------------------ Backend (CuPy/NumPy) --------------------------\n  38:     try:\n  39:         import cupy as cp  # GPU\n  40:         xp = cp",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 39,
          "context": "  36:     \n  37:     # ------------------------------ Backend (CuPy/NumPy) --------------------------\n  38:     try:\n  39: >>>     import cupy as cp  # GPU\n  40:         xp = cp\n  41:         GPU = True\n  42:     except Exception:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 39,
          "context": "  36:     \n  37:     # ------------------------------ Backend (CuPy/NumPy) --------------------------\n  38:     try:\n  39: >>>     import cupy as cp  # GPU\n  40:         xp = cp\n  41:         GPU = True\n  42:     except Exception:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 41,
          "context": "  38:     try:\n  39:         import cupy as cp  # GPU\n  40:         xp = cp\n  41: >>>     GPU = True\n  42:     except Exception:\n  43:         import numpy as cp  # graceful fallback to CPU using NumPy under alias cp\n  44:         xp = cp",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 45,
          "context": "  42:     except Exception:\n  43:         import numpy as cp  # graceful fallback to CPU using NumPy under alias cp\n  44:         xp = cp\n  45: >>>     GPU = False\n  46:     \n  47:     import numpy as np\n  48:     import matplotlib.pyplot as plt",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 56,
          "context": "  53:         campaign: str = \"museum_day_2025_10_25\"\n  54:         quick: bool = False\n  55:         seed: int = 123456\n  56: >>>     dtype: str = \"float32\"  # keep GPU memory low; use float64 if desired\n  57:     \n  58:     @dataclass\n  59:     class GridCfg:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 213,
          "context": " 210:             probe_lo[n] = xp.mean(u[:, :, z_lo])\n 211:             probe_hi[n] = xp.mean(u[:, :, z_hi])\n 212:     \n 213: >>>     if GPU:\n 214:             probe_lo_h = cp.asnumpy(probe_lo)\n 215:             probe_hi_h = cp.asnumpy(probe_hi)\n 216:         else:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 245,
          "context": " 242:     \n 243:         # Save metrics & plots\n 244:         metrics = {\n 245: >>>         \"backend\": \"CuPy\" if GPU else \"NumPy\",\n 246:             \"grid\": asdict(grid),\n 247:             \"tier2_cfg\": asdict(cfg),\n 248:             \"cfl_ratio\": r,",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 245,
          "context": " 242:     \n 243:         # Save metrics & plots\n 244:         metrics = {\n 245: >>>         \"backend\": \"CuPy\" if GPU else \"NumPy\",\n 246:             \"grid\": asdict(grid),\n 247:             \"tier2_cfg\": asdict(cfg),\n 248:             \"cfl_ratio\": r,",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 334,
          "context": " 331:             # Energy density\n 332:             grad2 = grad_sq(u, dx)\n 333:             edens = 0.5*(ut*ut + (c*c)*grad2 + (chi*chi)*u*u)\n 334: >>>         if GPU:\n 335:                 energy[n] = float(cp.asnumpy(xp.sum(edens))) * (dx**3)\n 336:             else:\n 337:                 energy[n] = float(xp.sum(edens)) * (dx**3)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 348,
          "context": " 345:         drift = float(abs(energy[-1] - e0) / max(abs(e0), 1e-18))\n 346:     \n 347:         metrics = {\n 348: >>>         \"backend\": \"CuPy\" if GPU else \"NumPy\",\n 349:             \"grid\": asdict(grid),\n 350:             \"tier3_cfg\": asdict(cfg),\n 351:             \"cfl_ratio\": r,",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 348,
          "context": " 345:         drift = float(abs(energy[-1] - e0) / max(abs(e0), 1e-18))\n 346:     \n 347:         metrics = {\n 348: >>>         \"backend\": \"CuPy\" if GPU else \"NumPy\",\n 349:             \"grid\": asdict(grid),\n 350:             \"tier3_cfg\": asdict(cfg),\n 351:             \"cfl_ratio\": r,",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 356,
          "context": " 353:             \"energy_start\": float(e0),\n 354:             \"energy_end\": float(energy[-1]),\n 355:             \"energy_drift_rel\": drift,\n 356: >>>         \"pass_threshold\": 1e-4,  # Phase‑1 doc allows ≤1e‑12 ideal; practical GPU single‑precision proxy\n 357:             \"pass\": bool(drift <= 1e-4),\n 358:         }\n 359:         write_json(outdir/\"metrics.json\", metrics)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 402,
          "context": " 399:         summary = {\n 400:             \"system\": platform.platform(),\n 401:             \"python\": platform.python_version(),\n 402: >>>         \"gpu_backend\": GPU,\n 403:             \"dtype\": rs.dtype,\n 404:             \"tier2\": m2,\n 405:             \"tier3\": m3,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 402,
          "context": " 399:         summary = {\n 400:             \"system\": platform.platform(),\n 401:             \"python\": platform.python_version(),\n 402: >>>         \"gpu_backend\": GPU,\n 403:             \"dtype\": rs.dtype,\n 404:             \"tier2\": m2,\n 405:             \"tier3\": m3,",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 413,
          "context": " 410:         write_json(results_base/\"summary_overall.json\", summary)\n 411:     \n 412:         print(\"=== LFM Tier‑2/3 Heavy Tests Complete ===\")\n 413: >>>     print(json.dumps({k: summary[k] for k in [\"gpu_backend\",\"overall_pass\"]}, indent=2))\n 414:         print(f\"Results → {results_base}\")\n 415:     \n 416:     if __name__ == \"__main__\":",
          "match": "gpu"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 13,
          "context": "  10:     \n  11:     Runs two long, compute‑heavy validations aligned to Phase‑1 Test Design:\n  12:       A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)\n  13: >>>   B) Tier‑3: Global energy conservation over long steps with CFL guard + sponge boundaries\n  14:     \n  15:     Designed for: Python 3.11.9, CuPy‑CUDA12.x (GPU). Falls back to NumPy on CPU if CuPy unavailable.\n  16:     ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 25,
          "context": "  22:     Each test writes: metrics.json, plots/*.png, run_log.txt\n  23:     \n  24:     Citations (LFM internal docs):\n  25: >>> - Canonical PDE & CFL: Core Equations §2, §10\n  26:     - Tier pass criteria: Phase1 Test Design §5\n  27:     \n  28:     Author: LFM Research — Greg D. Partin & assistant",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 117,
          "context": " 114:             f.write(text)\n 115:     \n 116:     \n 117: >>> def cfl_ok(grid: GridCfg) -> bool:\n 118:         r = grid.c * grid.dt / grid.dx\n 119:         # 3D KG‑type leapfrog bound → c*dt/dx <= 1/sqrt(3)\n 120:         return r <= (1.0 / math.sqrt(3.0))",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 248,
          "context": " 245:             \"backend\": \"CuPy\" if GPU else \"NumPy\",\n 246:             \"grid\": asdict(grid),\n 247:             \"tier2_cfg\": asdict(cfg),\n 248: >>>         \"cfl_ratio\": r,\n 249:             \"elapsed_sec\": elapsed,\n 250:             \"f_lo_sim\": f_lo,\n 251:             \"f_hi_sim\": f_hi,",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 284,
          "context": " 281:         plt.savefig(outdir/\"plots/freq_ratio.png\", dpi=150)\n 282:         plt.close()\n 283:     \n 284: >>>     write_txt(outdir/\"run_log.txt\", f\"elapsed_sec={elapsed:.2f}\\nCFL={r:.4f}\\nPASS={metrics['pass']}\\n\")\n 285:         return metrics\n 286:     \n 287:     # ------------------------------ Tier‑3: Energy --------------------------------",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 351,
          "context": " 348:             \"backend\": \"CuPy\" if GPU else \"NumPy\",\n 349:             \"grid\": asdict(grid),\n 350:             \"tier3_cfg\": asdict(cfg),\n 351: >>>         \"cfl_ratio\": r,\n 352:             \"elapsed_sec\": elapsed,\n 353:             \"energy_start\": float(e0),\n 354:             \"energy_end\": float(energy[-1]),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 371,
          "context": " 368:         plt.savefig(outdir/\"plots/energy_vs_time.png\", dpi=150)\n 369:         plt.close()\n 370:     \n 371: >>>     write_txt(outdir/\"run_log.txt\", f\"elapsed_sec={elapsed:.2f}\\nCFL={r:.4f}\\nPASS={metrics['pass']}\\n\")\n 372:         return metrics\n 373:     \n 374:     # ------------------------------ Orchestration ---------------------------------",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 386,
          "context": " 383:         # Configs\n 384:         grid, t2, t3 = make_configs(rs)\n 385:     \n 386: >>>     # CFL safety check\n 387:         if not cfl_ok(grid):\n 388:             raise SystemExit(f\"CFL violated: c*dt/dx = {grid.c*grid.dt/grid.dx:.4f} > 1/sqrt(3). Adjust dt or dx.\")\n 389:     ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 387,
          "context": " 384:         grid, t2, t3 = make_configs(rs)\n 385:     \n 386:         # CFL safety check\n 387: >>>     if not cfl_ok(grid):\n 388:             raise SystemExit(f\"CFL violated: c*dt/dx = {grid.c*grid.dt/grid.dx:.4f} > 1/sqrt(3). Adjust dt or dx.\")\n 389:     \n 390:         # Run Tier‑2",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 388,
          "context": " 385:     \n 386:         # CFL safety check\n 387:         if not cfl_ok(grid):\n 388: >>>         raise SystemExit(f\"CFL violated: c*dt/dx = {grid.c*grid.dt/grid.dx:.4f} > 1/sqrt(3). Adjust dt or dx.\")\n 389:     \n 390:         # Run Tier‑2\n 391:         out2 = results_base/\"tier2_redshift\"",
          "match": "CFL"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 119,
          "context": " 116:     \n 117:     def cfl_ok(grid: GridCfg) -> bool:\n 118:         r = grid.c * grid.dt / grid.dx\n 119: >>>     # 3D KG‑type leapfrog bound → c*dt/dx <= 1/sqrt(3)\n 120:         return r <= (1.0 / math.sqrt(3.0))\n 121:     \n 122:     ",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 195,
          "context": " 192:         probe_lo = xp.zeros(T, dtype=xp.float32)\n 193:         probe_hi = xp.zeros(T, dtype=xp.float32)\n 194:     \n 195: >>>     # Leapfrog update: u_{n+1} = 2u_n − u_{n−1} + (c dt)^2 ∇^2 u_n − (dt^2) χ^2 u_n, with sponge\n 196:         c2dt2 = (c*dt)*(c*dt)\n 197:         dt2 = dt*dt\n 198:     ",
          "match": "Leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 329,
          "context": " 326:             lap = laplacian_3d(u, dx)\n 327:             u_next = 2.0*u - u_prev + c2dt2*lap - (dt2)*(chi*chi)*u\n 328:             u_next *= sponge\n 329: >>>         # Estimate ∂t u using leapfrog: (u_next - u_prev)/(2 dt)\n 330:             ut = (u_next - u_prev) / (2.0*dt)\n 331:             # Energy density\n 332:             grad2 = grad_sq(u, dx)",
          "match": "leapfrog"
        }
      ],
      "line_count": 417,
      "docstring": "LFM Tier‑2/3 Heavy GPU Tests — Redshift & Energy Conservation (3D)\n\nRuns two long, compute‑heavy validations aligned to Phase‑1 Test Design:\n  A) Tier‑2: Weak‑field redshift analogue with χ(z) gradient (3D plane wave probes)\n  B) Tier‑3: Global energy conservation over long steps with CFL guard + sponge boundaries\n\nDesigned for: Python 3.11.9, CuPy‑CUDA12.x (GPU). Falls back to NumPy on CPU if CuPy unavailable.\n\nQuick check: use --quick for ~10s sanity run (small grid, few steps). Default is long run.\n\nOutput tree (auto‑created if missing):\n  C:/LFM/results/<campaign>/tier2_redshift/ ...\n  C:/LFM/results/<campaign>/tier3_energy/ ...\nEach test writes: metrics.json, plots/*.png, run_log.txt\n\nCitations (LFM internal docs):\n- Canonical PDE & CFL: Core Equations §2, §10\n- Tier pass criteria: Phase1 Test Design §5\n\nAuthor: LFM Research — Greg D. Partin & assistant\nVersion: 1.0 — 2025‑10‑25"
    },
    {
      "filepath": "archive\\run_tier2_curvature_stability.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "253fba2d2cd9d03f",
      "file_size": 7624,
      "modified": "2025-11-02T20:02:10.942613",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     # ---------------------------------------------------------------------------\n  19:     # --- Config loader: merges master + inherited configs\n  20:     # ---------------------------------------------------------------------------\n  21: >>> def load_config(cfg_name: str):\n  22:         root = Path(__file__).resolve().parents[1] / \"config\"\n  23:         cfg_path = root / cfg_name\n  24:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)\n  52:     \n  53: >>> def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  54:     \n  55:     # ---------------------------------------------------------------------------\n  56:     # --- Safe JSON sanitizer (cross-version)",
          "match": "def ensure_dirs(p):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:     # ---------------------------------------------------------------------------\n  56:     # --- Safe JSON sanitizer (cross-version)\n  57:     # ---------------------------------------------------------------------------\n  58: >>> def _json_sanitize(obj):\n  59:         if isinstance(obj, np.bool_):\n  60:             return bool(obj)\n  61:         if isinstance(obj, (np.integer, np.floating)):",
          "match": "def _json_sanitize(obj):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 69,
          "context": "  66:     # ---------------------------------------------------------------------------\n  67:     # --- χ-field generation\n  68:     # ---------------------------------------------------------------------------\n  69: >>> def make_chi(N, variant):\n  70:         x = cp.linspace(-1, 1, N, dtype=dtype)\n  71:         y = cp.linspace(-1, 1, N, dtype=dtype)\n  72:         X, Y = cp.meshgrid(x, y)",
          "match": "def make_chi(N, variant):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 93,
          "context": "  90:     # ---------------------------------------------------------------------------\n  91:     # --- Variant execution\n  92:     # ---------------------------------------------------------------------------\n  93: >>> def run_variant(params, tol, variant, out_dir):\n  94:         ensure_dirs(out_dir)\n  95:         c = float(params.get(\"c\", 1.0))\n  96:         dt = float(params[\"time_step\"])",
          "match": "def run_variant(params, tol, variant, out_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 190,
          "context": " 187:     # ---------------------------------------------------------------------------\n 188:     # --- Main\n 189:     # ---------------------------------------------------------------------------\n 190: >>> def main():\n 191:         variants = cfg[\"variants\"]\n 192:         for i, v in enumerate(variants, 1):\n 193:             out_dir = OUT_BASE / f\"{i:02d}_{v.get('description','variant').replace(' ','_')}\"",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 14,
          "context": "  11:     Outputs per-variant in results/Tier2/Curvature/<variant_id>/\n  12:     \"\"\"\n  13:     \n  14: >>> import json, math, os, csv, platform, cupy as cp, numpy as np, matplotlib.pyplot as plt\n  15:     from pathlib import Path\n  16:     from datetime import datetime\n  17:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 39,
          "context": "  36:     \n  37:     \n  38:     # ---------------------------------------------------------------------------\n  39: >>> # --- Load configuration and setup GPU\n  40:     # ---------------------------------------------------------------------------\n  41:     cfg, ROOT = load_config(\"config_tier2_curvature_stability.json\")\n  42:     params, tol = cfg[\"parameters\"], cfg[\"tolerances\"]",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:     OUT_BASE = Path(cfg[\"base_paths\"][\"results\"]) / \"Tier2\" / \"Curvature\"\n  45:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  46:     \n  47: >>> if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  46:     \n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  46:     \n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  46:     \n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 170,
          "context": " 167:             \"variant\": variant.get(\"description\", \"variant\"),\n 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 172:                 \"python\": platform.python_version(),\n 173:             },",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 170,
          "context": " 167:             \"variant\": variant.get(\"description\", \"variant\"),\n 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 172:                 \"python\": platform.python_version(),\n 173:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 171,
          "context": " 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 172:                 \"python\": platform.python_version(),\n 173:             },\n 174:             \"parameters\": {\"N\": N, \"steps\": steps, \"dt\": dt, \"dx\": dx, \"c\": c, \"r\": (c * dt / dx) ** 2},",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 171,
          "context": " 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 172:                 \"python\": platform.python_version(),\n 173:             },\n 174:             \"parameters\": {\"N\": N, \"steps\": steps, \"dt\": dt, \"dx\": dx, \"c\": c, \"r\": (c * dt / dx) ** 2},",
          "match": "cuda"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 8,
          "context": "   5:     # Contact: latticefieldmediumresearch@gmail.com\n   6:     \n   7:     \"\"\"\n   8: >>> LFM Tier-2 — Curvature & Stability (strong χ)\n   9:     Hierarchical Config Version (uses master_config + tier2_curvature.json)\n  10:     Covers GRAV-13..14 + ENER-17..18: deflection/bending + energy transport stability\n  11:     Outputs per-variant in results/Tier2/Curvature/<variant_id>/",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 10,
          "context": "   7:     \"\"\"\n   8:     LFM Tier-2 — Curvature & Stability (strong χ)\n   9:     Hierarchical Config Version (uses master_config + tier2_curvature.json)\n  10: >>> Covers GRAV-13..14 + ENER-17..18: deflection/bending + energy transport stability\n  11:     Outputs per-variant in results/Tier2/Curvature/<variant_id>/\n  12:     \"\"\"\n  13:     ",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 41,
          "context": "  38:     # ---------------------------------------------------------------------------\n  39:     # --- Load configuration and setup GPU\n  40:     # ---------------------------------------------------------------------------\n  41: >>> cfg, ROOT = load_config(\"config_tier2_curvature_stability.json\")\n  42:     params, tol = cfg[\"parameters\"], cfg[\"tolerances\"]\n  43:     \n  44:     OUT_BASE = Path(cfg[\"base_paths\"][\"results\"]) / \"Tier2\" / \"Curvature\"",
          "match": "stability"
        }
      ],
      "line_count": 198,
      "docstring": "LFM Tier-2 — Curvature & Stability (strong χ)\nHierarchical Config Version (uses master_config + tier2_curvature.json)\nCovers GRAV-13..14 + ENER-17..18: deflection/bending + energy transport stability\nOutputs per-variant in results/Tier2/Curvature/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier2_pulse_propagation.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "f383898b020351fe",
      "file_size": 7511,
      "modified": "2025-11-02T20:02:10.944119",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     # ---------------------------------------------------------------------------\n  19:     # --- Config loader (master + inherited)\n  20:     # ---------------------------------------------------------------------------\n  21: >>> def load_config(cfg_name: str):\n  22:         root = Path(__file__).resolve().parents[1] / \"config\"\n  23:         cfg_path = root / cfg_name\n  24:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)\n  52:     \n  53: >>> def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  54:     def write_csv(path, rows, header):\n  55:         with open(path, \"w\", newline=\"\") as f:\n  56:             w = csv.writer(f); w.writerow(header); w.writerows(rows)",
          "match": "def ensure_dirs(p):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 54,
          "context": "  51:     cp.set_printoptions(precision=6, suppress=True)\n  52:     \n  53:     def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  54: >>> def write_csv(path, rows, header):\n  55:         with open(path, \"w\", newline=\"\") as f:\n  56:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  57:     ",
          "match": "def write_csv(path, rows, header):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 58,
          "context": "  55:         with open(path, \"w\", newline=\"\") as f:\n  56:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  57:     \n  58: >>> def summary_json(dst, payload):\n  59:         (dst/\"summary.json\").write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n  60:     \n  61:     def build_pulse(N, sigma, center=(0.0,0.0)):",
          "match": "def summary_json(dst, payload):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:     def summary_json(dst, payload):\n  59:         (dst/\"summary.json\").write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n  60:     \n  61: >>> def build_pulse(N, sigma, center=(0.0,0.0)):\n  62:         x = cp.linspace(-1, 1, N, dtype=dtype)\n  63:         y = cp.linspace(-1, 1, N, dtype=dtype)\n  64:         X, Y = cp.meshgrid(x, y)",
          "match": "def build_pulse(N, sigma, center=(0.0,0.0)):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:         X, Y = cp.meshgrid(x, y)\n  65:         return cp.exp(-((X-center[0])**2 + (Y-center[1])**2)/(2*sigma**2))\n  66:     \n  67: >>> def step_wave(E, E_prev, r):\n  68:         lap = (cp.roll(E,1,0)+cp.roll(E,-1,0)+cp.roll(E,1,1)+cp.roll(E,-1,1)-4*E)\n  69:         return 2*E - E_prev + r*lap\n  70:     ",
          "match": "def step_wave(E, E_prev, r):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 71,
          "context": "  68:         lap = (cp.roll(E,1,0)+cp.roll(E,-1,0)+cp.roll(E,1,1)+cp.roll(E,-1,1)-4*E)\n  69:         return 2*E - E_prev + r*lap\n  70:     \n  71: >>> def centroid(field_sq):\n  72:         N = field_sq.shape[0]\n  73:         coords = cp.linspace(-1, 1, N, dtype=dtype)\n  74:         X, Y = cp.meshgrid(coords, coords)",
          "match": "def centroid(field_sq):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 82,
          "context": "  79:     # ---------------------------------------------------------------------------\n  80:     # --- Core variant runner\n  81:     # ---------------------------------------------------------------------------\n  82: >>> def run_variant(params, tol, variant, out_dir):\n  83:         ensure_dirs(out_dir)\n  84:     \n  85:         # parameters",
          "match": "def run_variant(params, tol, variant, out_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 178,
          "context": " 175:     # ---------------------------------------------------------------------------\n 176:     # --- Main\n 177:     # ---------------------------------------------------------------------------\n 178: >>> def main():\n 179:         variants = cfg[\"variants\"]\n 180:         for i, v in enumerate(variants, 1):\n 181:             out_dir = OUT_BASE / f\"{i:02d}_{v.get('description','variant').replace(' ','_')}\"",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 14,
          "context": "  11:     Outputs per-variant: CSVs, plot, HTML, JSON summary in results/Tier2/Pulse/<variant_id>/\n  12:     \"\"\"\n  13:     \n  14: >>> import json, math, os, csv, platform, cupy as cp, numpy as np, matplotlib.pyplot as plt\n  15:     from pathlib import Path\n  16:     from datetime import datetime\n  17:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 46,
          "context": "  43:     OUT_BASE = Path(cfg[\"base_paths\"][\"results\"]) / \"Tier2\" / \"Pulse\"\n  44:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  45:     \n  46: >>> # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  45:     \n  46:     # GPU setup\n  47: >>> if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     \n  46:     # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     \n  46:     # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     \n  46:     # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 161,
          "context": " 158:             \"variant\": variant.get(\"description\",\"variant\"),\n 159:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 160:             \"hardware\": {\n 161: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 162:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:                 \"python\": platform.python_version()\n 164:             },",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 161,
          "context": " 158:             \"variant\": variant.get(\"description\",\"variant\"),\n 159:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 160:             \"hardware\": {\n 161: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 162:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:                 \"python\": platform.python_version()\n 164:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 162,
          "context": " 159:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 160:             \"hardware\": {\n 161:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 162: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:                 \"python\": platform.python_version()\n 164:             },\n 165:             \"parameters\": {\"N\": N, \"steps\": steps, \"dt\": dt, \"dx\": dx, \"c\": c,",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 162,
          "context": " 159:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 160:             \"hardware\": {\n 161:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 162: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 163:                 \"python\": platform.python_version()\n 164:             },\n 165:             \"parameters\": {\"N\": N, \"steps\": steps, \"dt\": dt, \"dx\": dx, \"c\": c,",
          "match": "cuda"
        }
      ],
      "line_count": 185,
      "docstring": "LFM Tier-2 — Pulse Propagation (Flat-χ)\nHierarchical Config Version (uses master_config + tier2_flat_pulse.json)\nCovers REL-03..REL-06: group velocity ≈ c, boosted frame sanity, mode freq variants\nOutputs per-variant: CSVs, plot, HTML, JSON summary in results/Tier2/Pulse/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier2_redshift.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "9cfb8d3a41944cc2",
      "file_size": 6634,
      "modified": "2025-11-02T20:02:10.944119",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     # ---------------------------------------------------------------------------\n  19:     # --- Config loader: merges master + inherited configs\n  20:     # ---------------------------------------------------------------------------\n  21: >>> def load_config(cfg_name: str):\n  22:         root = Path(__file__).resolve().parents[1] / \"config\"\n  23:         cfg_path = root / cfg_name\n  24:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)\n  52:     \n  53: >>> def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  54:     def write_csv(path, rows, header):\n  55:         with open(path, \"w\", newline=\"\") as f:\n  56:             w = csv.writer(f); w.writerow(header); w.writerows(rows)",
          "match": "def ensure_dirs(p):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 54,
          "context": "  51:     cp.set_printoptions(precision=6, suppress=True)\n  52:     \n  53:     def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  54: >>> def write_csv(path, rows, header):\n  55:         with open(path, \"w\", newline=\"\") as f:\n  56:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  57:     ",
          "match": "def write_csv(path, rows, header):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:     # ---------------------------------------------------------------------------\n  59:     # --- χ-field builder\n  60:     # ---------------------------------------------------------------------------\n  61: >>> def chi_grid(N, variant):\n  62:         x = cp.linspace(-1,1,N, dtype=dtype)\n  63:         y = cp.linspace(-1,1,N, dtype=dtype)\n  64:         X,Y = cp.meshgrid(x,y)",
          "match": "def chi_grid(N, variant):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 77,
          "context": "  74:     # ---------------------------------------------------------------------------\n  75:     # --- Variant execution\n  76:     # ---------------------------------------------------------------------------\n  77: >>> def run_variant(params, tol, variant, out_dir):\n  78:         ensure_dirs(out_dir)\n  79:         c = float(params.get(\"c\",1.0))\n  80:         dt = float(params[\"time_step\"]); dx = float(params[\"space_step\"])",
          "match": "def run_variant(params, tol, variant, out_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 111,
          "context": " 108:                 ts_R.append(float(cp.mean(E[:, probe_R])))\n 109:     \n 110:         # frequency estimate via FFT\n 111: >>>     def peak_freq(x, dt_s):\n 112:             a = np.abs(np.fft.rfft(x - np.mean(x)))\n 113:             if len(a) < 2: return 0.0\n 114:             k = int(np.argmax(a[1:]))+1",
          "match": "def peak_freq(x, dt_s):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 164,
          "context": " 161:     # ---------------------------------------------------------------------------\n 162:     # --- Main\n 163:     # ---------------------------------------------------------------------------\n 164: >>> def main():\n 165:         variants = cfg[\"variants\"]\n 166:         for i, v in enumerate(variants, 1):\n 167:             out_dir = OUT_BASE / f\"{i:02d}_{v.get('description','variant').replace(' ','_')}\"",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 14,
          "context": "  11:     Outputs per-variant in results/Tier2/Redshift/<variant_id>/\n  12:     \"\"\"\n  13:     \n  14: >>> import json, math, os, csv, platform, cupy as cp, numpy as np, matplotlib.pyplot as plt\n  15:     from pathlib import Path\n  16:     from datetime import datetime\n  17:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 46,
          "context": "  43:     OUT_BASE = Path(cfg[\"base_paths\"][\"results\"]) / \"Tier2\" / \"Redshift\"\n  44:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  45:     \n  46: >>> # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  45:     \n  46:     # GPU setup\n  47: >>> if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     \n  46:     # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     \n  46:     # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     \n  46:     # GPU setup\n  47:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  48: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  49:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  50:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  51:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 150,
          "context": " 147:             \"variant\": variant.get(\"description\",\"variant\"),\n 148:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 149:             \"hardware\": {\n 150: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 151:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 152:                 \"python\": platform.python_version()\n 153:             },",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 150,
          "context": " 147:             \"variant\": variant.get(\"description\",\"variant\"),\n 148:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 149:             \"hardware\": {\n 150: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 151:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 152:                 \"python\": platform.python_version()\n 153:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 151,
          "context": " 148:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 149:             \"hardware\": {\n 150:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 151: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 152:                 \"python\": platform.python_version()\n 153:             },\n 154:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"r\":(c*dt/dx)**2},",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 151,
          "context": " 148:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 149:             \"hardware\": {\n 150:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 151: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 152:                 \"python\": platform.python_version()\n 153:             },\n 154:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"r\":(c*dt/dx)**2},",
          "match": "cuda"
        }
      ],
      "line_count": 171,
      "docstring": "LFM Tier-2 — Weak-Field Redshift (variable χ)\nHierarchical Config Version (uses master_config + tier2_redshift.json)\nCovers GRAV-09..GRAV-12: frequency redshift & time-delay vs χ(x)\nOutputs per-variant in results/Tier2/Redshift/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier3_energy_suite.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "74d9b79cf99bbb76",
      "file_size": 10807,
      "modified": "2025-11-02T20:02:10.944119",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:     import matplotlib.pyplot as plt\n  29:     \n  30:     # ------------------------------- Config Loader ------------------------------\n  31: >>> def load_config():\n  32:         script = Path(__file__).stem.replace(\"run_\", \"\")\n  33:         cfg_path = Path(__file__).resolve().parent.parent / \"config\" / f\"config_{script}.json\"\n  34:         with open(cfg_path, \"r\", encoding=\"utf-8\") as f:",
          "match": "def load_config():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 38,
          "context": "  35:             return json.load(f)\n  36:     \n  37:     # ------------------------------ Utilities (I/O) -----------------------------\n  38: >>> def ensure_dirs(p: Path): p.mkdir(parents=True, exist_ok=True)\n  39:     def write_csv(path: Path, rows, header):\n  40:         with open(path, \"w\", newline=\"\") as f:\n  41:             w = csv.writer(f); w.writerow(header); w.writerows(rows)",
          "match": "def ensure_dirs(p:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:     \n  37:     # ------------------------------ Utilities (I/O) -----------------------------\n  38:     def ensure_dirs(p: Path): p.mkdir(parents=True, exist_ok=True)\n  39: >>> def write_csv(path: Path, rows, header):\n  40:         with open(path, \"w\", newline=\"\") as f:\n  41:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  42:     def write_summary_json(path: Path, obj: dict):",
          "match": "def write_csv(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 42,
          "context": "  39:     def write_csv(path: Path, rows, header):\n  40:         with open(path, \"w\", newline=\"\") as f:\n  41:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  42: >>> def write_summary_json(path: Path, obj: dict):\n  43:         path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n  44:     \n  45:     # -------------------------- Numerical helpers (2-D) -------------------------",
          "match": "def write_summary_json(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 46,
          "context": "  43:         path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n  44:     \n  45:     # -------------------------- Numerical helpers (2-D) -------------------------\n  46: >>> def laplacian(E, dx, order=4):\n  47:         if order == 2:\n  48:             return (\n  49:                 cp.roll(E,  1, 0) + cp.roll(E, -1, 0) +",
          "match": "def laplacian(E, dx, order=4):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 60,
          "context": "  57:         else:\n  58:             raise ValueError(\"Unsupported stencil order; use 2 or 4\")\n  59:     \n  60: >>> def grad_sq(E, dx):\n  61:         Ex = (cp.roll(E, -1, 1) - cp.roll(E, 1, 1)) / (2*dx)\n  62:         Ey = (cp.roll(E, -1, 0) - cp.roll(E, 1, 0)) / (2*dx)\n  63:         return Ex*Ex + Ey*Ey",
          "match": "def grad_sq(E, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 65,
          "context": "  62:         Ey = (cp.roll(E, -1, 0) - cp.roll(E, 1, 0)) / (2*dx)\n  63:         return Ex*Ex + Ey*Ey\n  64:     \n  65: >>> def energy_total(E, E_prev, dt, dx, c, chi):\n  66:         Et = (E - E_prev) / dt\n  67:         dens = 0.5*(Et*Et + (c*c)*grad_sq(E, dx) + (chi*chi)*(E*E))\n  68:         return float(cp.sum(dens) * dx*dx)",
          "match": "def energy_total(E, E_prev, dt, dx, c, chi):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 70,
          "context": "  67:         dens = 0.5*(Et*Et + (c*c)*grad_sq(E, dx) + (chi*chi)*(E*E))\n  68:         return float(cp.sum(dens) * dx*dx)\n  69:     \n  70: >>> def entropy_shannon(E):\n  71:         p = cp.abs(E)**2\n  72:         s = cp.sum(p)\n  73:         if float(s) == 0.0: return 0.0",
          "match": "def entropy_shannon(E):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 79,
          "context": "  76:         return float(-cp.sum(p * cp.log(p + eps)))\n  77:     \n  78:     # -------------------------- χ-field constructors ----------------------------\n  79: >>> def chi_field(N, pattern: dict, dtype):\n  80:         x = cp.linspace(-1, 1, N, dtype=dtype)\n  81:         y = cp.linspace(-1, 1, N, dtype=dtype)\n  82:         X, Y = cp.meshgrid(x, y)",
          "match": "def chi_field(N, pattern:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 95,
          "context": "  92:         return chi\n  93:     \n  94:     # --------------------------- Initial condition builders ---------------------\n  95: >>> def init_pulse(N, dtype, kind=\"gaussian\", kx=8.0, width=20.0):\n  96:         x = cp.linspace(-1, 1, N, dtype=dtype)\n  97:         y = cp.linspace(-1, 1, N, dtype=dtype)\n  98:         X, Y = cp.meshgrid(x, y)",
          "match": "def init_pulse(N, dtype, kind=\"gaussian\", kx=8.0, width=20.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 107,
          "context": " 104:         return cp.zeros((N, N), dtype=dtype)\n 105:     \n 106:     # ------------------------------ Variant runner ------------------------------\n 107: >>> def run_variant(params, tol, variant, out_dir: Path, dtype):\n 108:         ensure_dirs(out_dir)\n 109:     \n 110:         c  = float(params.get(\"c\", 1.0))",
          "match": "def run_variant(params, tol, variant, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 228,
          "context": " 225:         return passed, rel_drift, monotone_entropy, max_drop, runtime\n 226:     \n 227:     # ----------------------------------- Main -----------------------------------\n 228: >>> def main():\n 229:         cfg = load_config()\n 230:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 231:     ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 26,
          "context": "  23:     from pathlib import Path\n  24:     from datetime import datetime\n  25:     \n  26: >>> import cupy as cp\n  27:     import numpy as np\n  28:     import matplotlib.pyplot as plt\n  29:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 212,
          "context": " 209:             \"description\": variant.get(\"description\",\"\"),\n 210:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 211:             \"hardware\": {\n 212: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode() if cp.cuda.runtime.getDeviceCount() > 0 else \"CPU\",\n 213:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 212,
          "context": " 209:             \"description\": variant.get(\"description\",\"\"),\n 210:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 211:             \"hardware\": {\n 212: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode() if cp.cuda.runtime.getDeviceCount() > 0 else \"CPU\",\n 213:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 212,
          "context": " 209:             \"description\": variant.get(\"description\",\"\"),\n 210:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 211:             \"hardware\": {\n 212: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode() if cp.cuda.runtime.getDeviceCount() > 0 else \"CPU\",\n 213:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 213,
          "context": " 210:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 211:             \"hardware\": {\n 212:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode() if cp.cuda.runtime.getDeviceCount() > 0 else \"CPU\",\n 213: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },\n 216:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":c*dt/dx,\"stencil_order\":stencil_order},",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 213,
          "context": " 210:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 211:             \"hardware\": {\n 212:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode() if cp.cuda.runtime.getDeviceCount() > 0 else \"CPU\",\n 213: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },\n 216:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":c*dt/dx,\"stencil_order\":stencil_order},",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 213,
          "context": " 210:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 211:             \"hardware\": {\n 212:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode() if cp.cuda.runtime.getDeviceCount() > 0 else \"CPU\",\n 213: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },\n 216:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":c*dt/dx,\"stencil_order\":stencil_order},",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 232,
          "context": " 229:         cfg = load_config()\n 230:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 231:     \n 232: >>>     if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 233:             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 234:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 235:         dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 232,
          "context": " 229:         cfg = load_config()\n 230:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 231:     \n 232: >>>     if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 233:             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 234:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 235:         dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 233,
          "context": " 230:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 231:     \n 232:         if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 233: >>>         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 234:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 235:         dtype = cp.float64 if precision == \"float64\" else cp.float32\n 236:     ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 233,
          "context": " 230:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 231:     \n 232:         if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 233: >>>         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 234:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 235:         dtype = cp.float64 if precision == \"float64\" else cp.float32\n 236:     ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 233,
          "context": " 230:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 231:     \n 232:         if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 233: >>>         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 234:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 235:         dtype = cp.float64 if precision == \"float64\" else cp.float32\n 236:     ",
          "match": "cuda"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 118,
          "context": " 115:         save_every = int(params.get(\"save_every\", 10))\n 116:         stencil_order = int(params.get(\"stencil_order\", 4))\n 117:     \n 118: >>>     cfl = c*dt/dx\n 119:         if cfl > 0.9:\n 120:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 121:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 119,
          "context": " 116:         stencil_order = int(params.get(\"stencil_order\", 4))\n 117:     \n 118:         cfl = c*dt/dx\n 119: >>>     if cfl > 0.9:\n 120:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 121:     \n 122:         chi = chi_field(N, variant, dtype)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 120,
          "context": " 117:     \n 118:         cfl = c*dt/dx\n 119:         if cfl > 0.9:\n 120: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 121:     \n 122:         chi = chi_field(N, variant, dtype)\n 123:         E = init_pulse(N, dtype, kind=variant.get(\"ic\",\"gaussian\"),",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 120,
          "context": " 117:     \n 118:         cfl = c*dt/dx\n 119:         if cfl > 0.9:\n 120: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 121:     \n 122:         chi = chi_field(N, variant, dtype)\n 123:         E = init_pulse(N, dtype, kind=variant.get(\"ic\",\"gaussian\"),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 216,
          "context": " 213:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()) if cp.cuda.runtime.getDeviceCount() > 0 else 0,\n 214:                 \"python\": platform.python_version()\n 215:             },\n 216: >>>         \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":c*dt/dx,\"stencil_order\":stencil_order},\n 217:             \"metrics\": {\"energy_rel_drift\": rel_drift, \"entropy_monotonic\": bool(monotone_entropy), \"wave_max_drop\": max_drop},\n 218:             \"status\": \"Passed\" if passed else \"Failed\"\n 219:         }",
          "match": "cfl"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 155,
          "context": " 152:                 entropy_trace.append(H)\n 153:                 times.append(t*dt)\n 154:     \n 155: >>>         # Advance one leapfrog step\n 156:             lap = laplacian(E, dx, order=stencil_order)\n 157:             E_next = 2*E - E_prev + (dt*dt)*((c*c)*lap - (chi*chi)*E)\n 158:     ",
          "match": "leapfrog"
        }
      ],
      "line_count": 261,
      "docstring": "LFM Tier-3 — Energy & Transport Suite (2-D, Unified)\nCovers ENER-15..ENER-21:\n- ENER-15 Global Conservation (short)\n- ENER-16 Global Conservation (long)\n- ENER-17 Wave Integrity (mild curvature)\n- ENER-18 Wave Integrity (steep curvature)\n- ENER-19 Noise-Driven Equilibrium\n- ENER-20 Thermal/Diffusive Damping\n- ENER-21 Entropy Growth Check (long)\n\nOutputs → results/Tier3/EnergySuite/<variant_dir>/"
    },
    {
      "filepath": "archive\\run_tier3_entropy_growth.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "cb033fd3158f6fab",
      "file_size": 6740,
      "modified": "2025-11-02T20:02:10.944119",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     # ---------------------------------------------------------------------------\n  19:     # --- Config loader: merges master + inherited configs\n  20:     # ---------------------------------------------------------------------------\n  21: >>> def load_config(cfg_name: str):\n  22:         root = Path(__file__).resolve().parents[1] / \"config\"\n  23:         cfg_path = root / cfg_name\n  24:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:     # ---------------------------------------------------------------------------\n  57:     # --- Utilities\n  58:     # ---------------------------------------------------------------------------\n  59: >>> def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  60:     def write_csv(path, rows, header):\n  61:         with open(path, \"w\", newline=\"\") as f:\n  62:             w = csv.writer(f); w.writerow(header); w.writerows(rows)",
          "match": "def ensure_dirs(p):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 60,
          "context": "  57:     # --- Utilities\n  58:     # ---------------------------------------------------------------------------\n  59:     def ensure_dirs(p): p.mkdir(parents=True, exist_ok=True)\n  60: >>> def write_csv(path, rows, header):\n  61:         with open(path, \"w\", newline=\"\") as f:\n  62:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  63:     ",
          "match": "def write_csv(path, rows, header):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 64,
          "context": "  61:         with open(path, \"w\", newline=\"\") as f:\n  62:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  63:     \n  64: >>> def entropy_shannon(arr, bins=128):\n  65:         a = np.asarray(arr).ravel()\n  66:         hist, edges = np.histogram(a, bins=bins, density=True)\n  67:         p = hist / (np.sum(hist)+1e-30)",
          "match": "def entropy_shannon(arr, bins=128):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 74,
          "context": "  71:     # ---------------------------------------------------------------------------\n  72:     # --- Variant executor\n  73:     # ---------------------------------------------------------------------------\n  74: >>> def run_variant(params, variant, out_dir):\n  75:         ensure_dirs(out_dir)\n  76:         c = float(params.get(\"c\",1.0))\n  77:         dt = float(params[\"time_step\"]); dx = float(params[\"space_step\"])",
          "match": "def run_variant(params, variant, out_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 158,
          "context": " 155:     # ---------------------------------------------------------------------------\n 156:     # --- Main\n 157:     # ---------------------------------------------------------------------------\n 158: >>> def main():\n 159:         variants = cfg[\"variants\"]\n 160:         for i, v in enumerate(variants, 1):\n 161:             out_dir = OUT_BASE / f\"{i:02d}_{v.get('description','variant').replace(' ','_')}\"",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 14,
          "context": "  11:     Outputs per-variant in results/Tier3/Entropy/<variant_id>/\n  12:     \"\"\"\n  13:     \n  14: >>> import json, os, csv, platform, cupy as cp, numpy as np, matplotlib.pyplot as plt\n  15:     from pathlib import Path\n  16:     from datetime import datetime\n  17:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 48,
          "context": "  45:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  46:     \n  47:     # ---------------------------------------------------------------------------\n  48: >>> # --- GPU and precision setup\n  49:     # ---------------------------------------------------------------------------\n  50:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  51:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 50,
          "context": "  47:     # ---------------------------------------------------------------------------\n  48:     # --- GPU and precision setup\n  49:     # ---------------------------------------------------------------------------\n  50: >>> if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  51:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  52:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  53:     dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 51,
          "context": "  48:     # --- GPU and precision setup\n  49:     # ---------------------------------------------------------------------------\n  50:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  51: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  52:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  53:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  54:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 51,
          "context": "  48:     # --- GPU and precision setup\n  49:     # ---------------------------------------------------------------------------\n  50:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  51: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  52:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  53:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  54:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 51,
          "context": "  48:     # --- GPU and precision setup\n  49:     # ---------------------------------------------------------------------------\n  50:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  51: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  52:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  53:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  54:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 139,
          "context": " 136:             \"variant\": variant.get(\"description\",\"variant\"),\n 137:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 138:             \"hardware\": {\n 139: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 140:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 141:                 \"python\": platform.python_version()\n 142:             },",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 139,
          "context": " 136:             \"variant\": variant.get(\"description\",\"variant\"),\n 137:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 138:             \"hardware\": {\n 139: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 140:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 141:                 \"python\": platform.python_version()\n 142:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 140,
          "context": " 137:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 138:             \"hardware\": {\n 139:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 140: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 141:                 \"python\": platform.python_version()\n 142:             },\n 143:             \"parameters\": {",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 140,
          "context": " 137:             \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n 138:             \"hardware\": {\n 139:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 140: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 141:                 \"python\": platform.python_version()\n 142:             },\n 143:             \"parameters\": {",
          "match": "cuda"
        }
      ],
      "line_count": 165,
      "docstring": "LFM Tier-3 — Energy/Entropy Diagnostics\nHierarchical Config Version (uses master_config + tier3_entropy.json)\nCovers ENER-19..21: long-run equilibrium, diffusion, entropy trends\nOutputs per-variant in results/Tier3/Entropy/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier4_quantization_suite.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "4de28518bfeeb801",
      "file_size": 9208,
      "modified": "2025-11-02T20:02:10.949517",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 30,
          "context": "  27:     # ---------------------------------------------------------------------\n  28:     # Config loader (LFM standard)\n  29:     # ---------------------------------------------------------------------\n  30: >>> def load_config():\n  31:         script = Path(__file__).stem.replace(\"run_\", \"\")\n  32:         cfg_path = Path(__file__).resolve().parent.parent / \"config\" / f\"config_{script}.json\"\n  33:         with open(cfg_path, \"r\", encoding=\"utf-8\") as f:",
          "match": "def load_config():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:     # ---------------------------------------------------------------------\n  37:     # Utility I/O helpers\n  38:     # ---------------------------------------------------------------------\n  39: >>> def ensure_dirs(p: Path): p.mkdir(parents=True, exist_ok=True)\n  40:     \n  41:     def write_csv(path: Path, rows, header):\n  42:         with open(path, \"w\", newline=\"\") as f:",
          "match": "def ensure_dirs(p:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 41,
          "context": "  38:     # ---------------------------------------------------------------------\n  39:     def ensure_dirs(p: Path): p.mkdir(parents=True, exist_ok=True)\n  40:     \n  41: >>> def write_csv(path: Path, rows, header):\n  42:         with open(path, \"w\", newline=\"\") as f:\n  43:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  44:     ",
          "match": "def write_csv(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 45,
          "context": "  42:         with open(path, \"w\", newline=\"\") as f:\n  43:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  44:     \n  45: >>> def write_json(path: Path, obj):\n  46:         def convert(o):\n  47:             import numpy as np, cupy as cp\n  48:             if isinstance(o, (np.generic,)): return o.item()",
          "match": "def write_json(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 46,
          "context": "  43:             w = csv.writer(f); w.writerow(header); w.writerows(rows)\n  44:     \n  45:     def write_json(path: Path, obj):\n  46: >>>     def convert(o):\n  47:             import numpy as np, cupy as cp\n  48:             if isinstance(o, (np.generic,)): return o.item()\n  49:             if isinstance(o, (cp.generic,)): return float(o.get())",
          "match": "def convert(o):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:     # ---------------------------------------------------------------------\n  55:     # Numerical helpers\n  56:     # ---------------------------------------------------------------------\n  57: >>> def laplacian(E, dx):\n  58:         return (cp.roll(E, 1, 0) + cp.roll(E, -1, 0) +\n  59:                 cp.roll(E, 1, 1) + cp.roll(E, -1, 1) - 4 * E) / (dx * dx)\n  60:     ",
          "match": "def laplacian(E, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 61,
          "context": "  58:         return (cp.roll(E, 1, 0) + cp.roll(E, -1, 0) +\n  59:                 cp.roll(E, 1, 1) + cp.roll(E, -1, 1) - 4 * E) / (dx * dx)\n  60:     \n  61: >>> def grad_sq(E, dx):\n  62:         Ex = (cp.roll(E, -1, 1) - cp.roll(E, 1, 1)) / (2 * dx)\n  63:         Ey = (cp.roll(E, -1, 0) - cp.roll(E, 1, 0)) / (2 * dx)\n  64:         return Ex * Ex + Ey * Ey",
          "match": "def grad_sq(E, dx):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:         Ey = (cp.roll(E, -1, 0) - cp.roll(E, 1, 0)) / (2 * dx)\n  64:         return Ex * Ex + Ey * Ey\n  65:     \n  66: >>> def energy_total(E, E_prev, dt, dx, c, chi):\n  67:         Et = (E - E_prev) / dt\n  68:         dens = 0.5 * (Et * Et + (c ** 2) * grad_sq(E, dx) + (chi ** 2) * (E * E))\n  69:         return float(cp.sum(dens) * dx * dx)",
          "match": "def energy_total(E, E_prev, dt, dx, c, chi):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 71,
          "context": "  68:         dens = 0.5 * (Et * Et + (c ** 2) * grad_sq(E, dx) + (chi ** 2) * (E * E))\n  69:         return float(cp.sum(dens) * dx * dx)\n  70:     \n  71: >>> def entropy_shannon(E):\n  72:         p = cp.abs(E) ** 2\n  73:         s = cp.sum(p)\n  74:         if float(s) == 0.0:  # robust zero check",
          "match": "def entropy_shannon(E):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 83,
          "context": "  80:     # ---------------------------------------------------------------------\n  81:     # χ-field & initial conditions\n  82:     # ---------------------------------------------------------------------\n  83: >>> def chi_field(N, variant, dtype):\n  84:         x = cp.linspace(-1, 1, N, dtype=dtype)\n  85:         y = cp.linspace(-1, 1, N, dtype=dtype)\n  86:         X, Y = cp.meshgrid(x, y)",
          "match": "def chi_field(N, variant, dtype):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 97,
          "context": "  94:             chi = cp.full_like(X, float(variant[\"chi_const\"]))\n  95:         return chi\n  96:     \n  97: >>> def init_field(N, dtype, energy_scale=1.0, noise_amp=0.0):\n  98:         rng = cp.random.default_rng(1234)\n  99:         X = cp.linspace(-1, 1, N, dtype=dtype)\n 100:         Y = cp.linspace(-1, 1, N, dtype=dtype)",
          "match": "def init_field(N, dtype, energy_scale=1.0, noise_amp=0.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 110,
          "context": " 107:     # ---------------------------------------------------------------------\n 108:     # Variant runner\n 109:     # ---------------------------------------------------------------------\n 110: >>> def run_variant(p, tol, v, out_dir, dtype):\n 111:         ensure_dirs(out_dir)\n 112:         c = float(p.get(\"c\", 1.0))\n 113:         dt = float(p[\"time_step\"])",
          "match": "def run_variant(p, tol, v, out_dir, dtype):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 220,
          "context": " 217:     # ---------------------------------------------------------------------\n 218:     # Main\n 219:     # ---------------------------------------------------------------------\n 220: >>> def main():\n 221:         cfg = load_config()\n 222:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 223:     ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 23,
          "context": "  20:     import json, math, time, platform, csv\n  21:     from pathlib import Path\n  22:     from datetime import datetime\n  23: >>> import cupy as cp\n  24:     import numpy as np\n  25:     import matplotlib.pyplot as plt\n  26:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:     \n  45:     def write_json(path: Path, obj):\n  46:         def convert(o):\n  47: >>>         import numpy as np, cupy as cp\n  48:             if isinstance(o, (np.generic,)): return o.item()\n  49:             if isinstance(o, (cp.generic,)): return float(o.get())\n  50:             if isinstance(o, set): return list(o)",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 224,
          "context": " 221:         cfg = load_config()\n 222:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 223:     \n 224: >>>     if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 225:             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 226:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 227:         dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 224,
          "context": " 221:         cfg = load_config()\n 222:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 223:     \n 224: >>>     if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 225:             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 226:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 227:         dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 225,
          "context": " 222:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 223:     \n 224:         if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 225: >>>         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 226:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 227:         dtype = cp.float64 if precision == \"float64\" else cp.float32\n 228:     ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 225,
          "context": " 222:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 223:     \n 224:         if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 225: >>>         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 226:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 227:         dtype = cp.float64 if precision == \"float64\" else cp.float32\n 228:     ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 225,
          "context": " 222:         p, tol, variants = cfg[\"parameters\"], cfg[\"tolerances\"], cfg[\"variants\"]\n 223:     \n 224:         if cfg[\"hardware\"].get(\"gpu_enabled\", True) and cp.cuda.runtime.getDeviceCount() > 0:\n 225: >>>         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 226:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 227:         dtype = cp.float64 if precision == \"float64\" else cp.float32\n 228:     ",
          "match": "cuda"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> LFM Tier-4 — Quantization & Nonlinear Stability Suite\n  10:     Covers QUAN-22 … QUAN-29:\n  11:     - ΔE Transfer (Low / High Energy)\n  12:     - Spectral Linearity (Coarse / Fine Steps)",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 14,
          "context": "  11:     - ΔE Transfer (Low / High Energy)\n  12:     - Spectral Linearity (Coarse / Fine Steps)\n  13:     - Phase–Amplitude Coupling (Low / High Noise)\n  14: >>> - Nonlinear Wavefront Stability\n  15:     - High-Energy Lattice Blowout Test\n  16:     \n  17:     Outputs → results/Tier4/QuantizationSuite/<variant_id>/",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 168,
          "context": " 165:     \n 166:         drift_ok = drift <= tol.get(\"energy_drift\", 1e-2)\n 167:         entropy_ok = entropy_slope >= -tol.get(\"entropy_tolerance\", 0.01)\n 168: >>>     stability_ok = field_max < tol.get(\"nonlinear_stability\", 3.0)\n 169:     \n 170:         passed = drift_ok and entropy_ok and stability_ok\n 171:         status = \"PASS ✅\" if passed else \"FAIL ❌\"",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 168,
          "context": " 165:     \n 166:         drift_ok = drift <= tol.get(\"energy_drift\", 1e-2)\n 167:         entropy_ok = entropy_slope >= -tol.get(\"entropy_tolerance\", 0.01)\n 168: >>>     stability_ok = field_max < tol.get(\"nonlinear_stability\", 3.0)\n 169:     \n 170:         passed = drift_ok and entropy_ok and stability_ok\n 171:         status = \"PASS ✅\" if passed else \"FAIL ❌\"",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 170,
          "context": " 167:         entropy_ok = entropy_slope >= -tol.get(\"entropy_tolerance\", 0.01)\n 168:         stability_ok = field_max < tol.get(\"nonlinear_stability\", 3.0)\n 169:     \n 170: >>>     passed = drift_ok and entropy_ok and stability_ok\n 171:         status = \"PASS ✅\" if passed else \"FAIL ❌\"\n 172:     \n 173:         # --- Output ---",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 204,
          "context": " 201:             \"passes\": {\n 202:                 \"energy_bounded\": drift_ok,\n 203:                 \"entropy_ok\": entropy_ok,\n 204: >>>             \"stability_ok\": stability_ok\n 205:             },\n 206:             \"status\": \"Passed\" if passed else \"Failed\",\n 207:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\"",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 204,
          "context": " 201:             \"passes\": {\n 202:                 \"energy_bounded\": drift_ok,\n 203:                 \"entropy_ok\": entropy_ok,\n 204: >>>             \"stability_ok\": stability_ok\n 205:             },\n 206:             \"status\": \"Passed\" if passed else \"Failed\",\n 207:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\"",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 214,
          "context": " 211:         print(f\"[{v['variant_id']}] norm-var drift={drift:.2e} \"\n 212:               f\"(ok={drift_ok}), entropy_slope={entropy_slope:.2e} \"\n 213:               f\"(ok={entropy_ok}), |E|max={field_max:.3f} \"\n 214: >>>           f\"(ok={stability_ok}) → {status}\")\n 215:         return passed, drift\n 216:     \n 217:     # ---------------------------------------------------------------------",
          "match": "stability"
        }
      ],
      "line_count": 246,
      "docstring": "LFM Tier-4 — Quantization & Nonlinear Stability Suite\nCovers QUAN-22 … QUAN-29:\n- ΔE Transfer (Low / High Energy)\n- Spectral Linearity (Coarse / Fine Steps)\n- Phase–Amplitude Coupling (Low / High Noise)\n- Nonlinear Wavefront Stability\n- High-Energy Lattice Blowout Test\n\nOutputs → results/Tier4/QuantizationSuite/<variant_id>/"
    },
    {
      "filepath": "archive\\run_tier4_resolution_scaling.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "3e1583cce8e75c1c",
      "file_size": 8544,
      "modified": "2025-11-02T20:02:10.949517",
      "git_info": null,
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 26,
          "context": "  23:     # ---------------------------------------------------------------------------\n  24:     # --- Config loader: merges master + inherited configs\n  25:     # ---------------------------------------------------------------------------\n  26: >>> def load_config(cfg_name: str):\n  27:         root = Path(__file__).resolve().parents[1] / \"config\"\n  28:         cfg_path = root / cfg_name\n  29:         if not cfg_path.exists():",
          "match": "def load_config(cfg_name:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  55:     cp.set_printoptions(precision=6, suppress=True)\n  56:     \n  57: >>> def ensure_dirs(p):\n  58:         p.mkdir(parents=True, exist_ok=True)\n  59:     \n  60:     # ---------------------------------------------------------------------------",
          "match": "def ensure_dirs(p):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 63,
          "context": "  60:     # ---------------------------------------------------------------------------\n  61:     # --- Build initial field for different test types\n  62:     # ---------------------------------------------------------------------------\n  63: >>> def initial_field(test_type, X, Y, sigma=0.05):\n  64:         if test_type == \"isotropy\":\n  65:             return cp.exp(-100.0 * (X ** 2 + Y ** 2))\n  66:         elif test_type == \"pulse\":",
          "match": "def initial_field(test_type, X, Y, sigma=0.05):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 75,
          "context": "  72:     # ---------------------------------------------------------------------------\n  73:     # --- Variant execution\n  74:     # ---------------------------------------------------------------------------\n  75: >>> def run_variant(params, tol, variant, out_dir):\n  76:         ensure_dirs(out_dir)\n  77:     \n  78:         test_type = variant.get(\"test\", \"isotropy\")",
          "match": "def run_variant(params, tol, variant, out_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 197,
          "context": " 194:             }\n 195:         }\n 196:     \n 197: >>>     def sanitize(obj):\n 198:             import numpy as np\n 199:             if isinstance(obj, (np.bool_,)):  # convert NumPy bools\n 200:                 return bool(obj)",
          "match": "def sanitize(obj):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 214,
          "context": " 211:     # ---------------------------------------------------------------------------\n 212:     # --- Main\n 213:     # ---------------------------------------------------------------------------\n 214: >>> def main():\n 215:         variants = cfg[\"variants\"]\n 216:         for i, v in enumerate(variants, 1):\n 217:             out_dir = OUT_BASE / f\"{i:02d}_{v.get('description','variant').replace(' ','_')}\"",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 19,
          "context": "  16:     from pathlib import Path\n  17:     from datetime import datetime\n  18:     \n  19: >>> import cupy as cp\n  20:     import numpy as np\n  21:     import matplotlib.pyplot as plt\n  22:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 43,
          "context": "  40:         return merged, root\n  41:     \n  42:     # ---------------------------------------------------------------------------\n  43: >>> # --- Load configuration and setup GPU\n  44:     # ---------------------------------------------------------------------------\n  45:     cfg, ROOT = load_config(\"config_tier4_resolution_scaling.json\")\n  46:     params, tol = cfg[\"parameters\"], cfg[\"tolerances\"]",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 51,
          "context": "  48:     OUT_BASE = Path(cfg[\"base_paths\"][\"results\"]) / \"Tier4\" / \"Resolution\"\n  49:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  50:     \n  51: >>> if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  52:         cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  53:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  54:     dtype = cp.float64 if precision == \"float64\" else cp.float32",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 52,
          "context": "  49:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  50:     \n  51:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  52: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  53:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  54:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  55:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 52,
          "context": "  49:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  50:     \n  51:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  52: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  53:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  54:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  55:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 52,
          "context": "  49:     OUT_BASE.mkdir(parents=True, exist_ok=True)\n  50:     \n  51:     if cfg[\"hardware\"].get(\"gpu_enabled\", True):\n  52: >>>     cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n  53:     precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n  54:     dtype = cp.float64 if precision == \"float64\" else cp.float32\n  55:     cp.set_printoptions(precision=6, suppress=True)",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 170,
          "context": " 167:             \"variant\": variant.get(\"description\", \"variant\"),\n 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171:                 \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 172:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 173:                 \"python\": platform.python_version()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 170,
          "context": " 167:             \"variant\": variant.get(\"description\", \"variant\"),\n 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170: >>>             \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171:                 \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 172:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 173:                 \"python\": platform.python_version()",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 171,
          "context": " 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171: >>>             \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 172:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 173:                 \"python\": platform.python_version()\n 174:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 171,
          "context": " 168:             \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n 169:             \"hardware\": {\n 170:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171: >>>             \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 172:                 \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 173:                 \"python\": platform.python_version()\n 174:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 172,
          "context": " 169:             \"hardware\": {\n 170:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171:                 \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 172: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 173:                 \"python\": platform.python_version()\n 174:             },\n 175:             \"parameters\": {",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 172,
          "context": " 169:             \"hardware\": {\n 170:                 \"gpu_name\": cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode(),\n 171:                 \"compute_capability\": float(f\"{cp.cuda.runtime.getDeviceProperties(0)['major']}.{cp.cuda.runtime.getDeviceProperties(0)['minor']}\"),\n 172: >>>             \"cuda_runtime\": int(cp.cuda.runtime.runtimeGetVersion()),\n 173:                 \"python\": platform.python_version()\n 174:             },\n 175:             \"parameters\": {",
          "match": "cuda"
        }
      ],
      "line_count": 221,
      "docstring": "LFM Tier‑4 — Resolution Scaling Test\nRuns the same LFM update at multiple resolutions and checks that the\nnumerical error (energy drift) decreases at the expected rate.\nOutputs per‐variant go in results/Tier4/Resolution/<variant_id>/."
    },
    {
      "filepath": "docs\\evidence\\emergence_validation\\analyze_emergence.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "f6993a62bdc93f56",
      "file_size": 1525,
      "modified": "2025-11-03T11:25:07.467087",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 8,
          "context": "   5:     import numpy as np\n   6:     import matplotlib.pyplot as plt\n   7:     \n   8: >>> def analyze_emergence():\n   9:         \"\"\"\n  10:         Let's look more carefully at what just happened\n  11:         \"\"\"",
          "match": "def analyze_emergence():"
        }
      ],
      "line_count": 46,
      "docstring": "Quick analysis of the emergence test results"
    },
    {
      "filepath": "fix_headers.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "766e0ca9f2fba627",
      "file_size": 6171,
      "modified": "2025-11-03T13:19:47.858819",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 38,
          "context": "  35:     \n  36:     '''\n  37:     \n  38: >>> def has_full_copyright_header(content):\n  39:         \"\"\"Check if content already has full copyright header\"\"\"\n  40:         required_elements = [\n  41:             \"Copyright (c) 2025 Greg D. Partin\",",
          "match": "def has_full_copyright_header(content):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 56,
          "context": "  53:                 return False\n  54:         return True\n  55:     \n  56: >>> def fix_python_file(filepath):\n  57:         \"\"\"Fix Python file header\"\"\"\n  58:         print(f\"   Fixing {filepath.name}...\")\n  59:         ",
          "match": "def fix_python_file(filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 96,
          "context": "  93:         \n  94:         return True\n  95:     \n  96: >>> def fix_markdown_file(filepath):\n  97:         \"\"\"Fix Markdown file header\"\"\"\n  98:         print(f\"   Fixing {filepath.name}...\")\n  99:         ",
          "match": "def fix_markdown_file(filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 121,
          "context": " 118:         \n 119:         return True\n 120:     \n 121: >>> def main():\n 122:         \"\"\"Main header fixing process\"\"\"\n 123:         print(\"=\" * 60)\n 124:         print(\"  LFM COPYRIGHT HEADER FIXER\")",
          "match": "def main():"
        }
      ],
      "line_count": 179,
      "docstring": "Automated Header Fixer\n======================\nAutomatically adds proper copyright headers to LFM source files.\nEnsures IP protection compliance across the entire codebase."
    },
    {
      "filepath": "generate_prior_art.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "7329891dec37d5fe",
      "file_size": 17958,
      "modified": "2025-11-03T13:24:29.580549",
      "git_info": null,
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     import hashlib\n  23:     import re\n  24:     \n  25: >>> class PriorArtDocumenter:\n  26:         def __init__(self, code_dir):\n  27:             self.code_dir = Path(code_dir)\n  28:             self.report_dir = self.code_dir / \"docs\" / \"prior_art\"",
          "match": "class PriorArtDocumenter:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 26,
          "context": "  23:     import re\n  24:     \n  25:     class PriorArtDocumenter:\n  26: >>>     def __init__(self, code_dir):\n  27:             self.code_dir = Path(code_dir)\n  28:             self.report_dir = self.code_dir / \"docs\" / \"prior_art\"\n  29:             self.report_dir.mkdir(parents=True, exist_ok=True)",
          "match": "def __init__(self, code_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:             self.report_dir = self.code_dir / \"docs\" / \"prior_art\"\n  29:             self.report_dir.mkdir(parents=True, exist_ok=True)\n  30:             \n  31: >>>     def get_git_info(self, filepath):\n  32:             \"\"\"Get git commit information for a file\"\"\"\n  33:             try:\n  34:                 # Get first commit (creation)",
          "match": "def get_git_info(self, filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 69,
          "context": "  66:             \n  67:             return None\n  68:         \n  69: >>>     def extract_technical_innovations(self, filepath):\n  70:             \"\"\"Extract technical innovations and novel methods from source code\"\"\"\n  71:             try:\n  72:                 with open(filepath, 'r', encoding='utf-8') as f:",
          "match": "def extract_technical_innovations(self, filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 109,
          "context": " 106:             \n 107:             return innovations\n 108:         \n 109: >>>     def get_line_context(self, content, line_num, context_lines=3):\n 110:             \"\"\"Get surrounding lines for context\"\"\"\n 111:             lines = content.split('\\n')\n 112:             start = max(0, line_num - context_lines - 1)",
          "match": "def get_line_context(self, content, line_num, context_lines=3):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 122,
          "context": " 119:             \n 120:             return '\\n'.join(context)\n 121:         \n 122: >>>     def analyze_file_significance(self, filepath):\n 123:             \"\"\"Determine the significance of a file for prior art\"\"\"\n 124:             filename = filepath.name.lower()\n 125:             ",
          "match": "def analyze_file_significance(self, filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 149,
          "context": " 146:             # Utility and support functions\n 147:             return 'UTILITY', 5\n 148:         \n 149: >>>     def generate_file_report(self, filepath):\n 150:             \"\"\"Generate prior art report for a single file\"\"\"\n 151:             rel_path = filepath.relative_to(self.code_dir)\n 152:             git_info = self.get_git_info(filepath)",
          "match": "def generate_file_report(self, filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 178,
          "context": " 175:                 'docstring': self.extract_docstring(filepath)\n 176:             }\n 177:         \n 178: >>>     def count_lines(self, filepath):\n 179:             \"\"\"Count lines in file\"\"\"\n 180:             try:\n 181:                 with open(filepath, 'r', encoding='utf-8') as f:",
          "match": "def count_lines(self, filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 186,
          "context": " 183:             except:\n 184:                 return 0\n 185:         \n 186: >>>     def extract_docstring(self, filepath):\n 187:             \"\"\"Extract main docstring from Python file\"\"\"\n 188:             try:\n 189:                 with open(filepath, 'r', encoding='utf-8') as f:",
          "match": "def extract_docstring(self, filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 200,
          "context": " 197:                 pass\n 198:             return None\n 199:         \n 200: >>>     def generate_comprehensive_report(self):\n 201:             \"\"\"Generate complete prior art documentation\"\"\"\n 202:             print(\"🔍 Analyzing LFM codebase for prior art documentation...\")\n 203:             ",
          "match": "def generate_comprehensive_report(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 262,
          "context": " 259:             \n 260:             return prior_art_report\n 261:         \n 262: >>>     def save_reports(self, report):\n 263:             \"\"\"Save prior art reports in multiple formats\"\"\"\n 264:             timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n 265:             ",
          "match": "def save_reports(self, report):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 288,
          "context": " 285:             \n 286:             return json_file, md_file\n 287:         \n 288: >>>     def generate_markdown_report(self, report):\n 289:             \"\"\"Generate human-readable markdown report\"\"\"\n 290:             md = f\"\"\"# LFM Prior Art Documentation Report\n 291:     ",
          "match": "def generate_markdown_report(self, report):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 392,
          "context": " 389:             \n 390:             return md\n 391:     \n 392: >>> def main():\n 393:         \"\"\"Generate comprehensive prior art documentation\"\"\"\n 394:         print(\"=\" * 70)\n 395:         print(\"  LFM PRIOR ART DOCUMENTATION GENERATOR\")",
          "match": "def main():"
        },
        {
          "type": "Explicit innovation marker",
          "pattern": "# Novel|# Innovation|# New approach",
          "line": 83,
          "context": "  80:             patterns = [\n  81:                 (r'class\\s+(\\w+).*?:', 'Novel class/algorithm'),\n  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83: >>>             (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),",
          "match": "# Novel"
        },
        {
          "type": "Explicit innovation marker",
          "pattern": "# Novel|# Innovation|# New approach",
          "line": 83,
          "context": "  80:             patterns = [\n  81:                 (r'class\\s+(\\w+).*?:', 'Novel class/algorithm'),\n  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83: >>>             (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),",
          "match": "# Innovation"
        },
        {
          "type": "Explicit innovation marker",
          "pattern": "# Novel|# Innovation|# New approach",
          "line": 83,
          "context": "  80:             patterns = [\n  81:                 (r'class\\s+(\\w+).*?:', 'Novel class/algorithm'),\n  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83: >>>             (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),",
          "match": "# New approach"
        },
        {
          "type": "Explicit innovation marker",
          "pattern": "# Novel|# Innovation|# New approach",
          "line": 130,
          "context": " 127:             if any(x in filename for x in ['equation', 'solver', 'algorithm', 'core']):\n 128:                 return 'CORE_ALGORITHM', 10\n 129:             \n 130: >>>         # Novel interface/interaction methods\n 131:             if any(x in filename for x in ['gui', 'interface', 'control']):\n 132:                 return 'USER_INTERFACE', 8\n 133:             ",
          "match": "# Novel"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 84,
          "context": "  81:                 (r'class\\s+(\\w+).*?:', 'Novel class/algorithm'),\n  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84: >>>             (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),",
          "match": "@staticmethod"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 84,
          "context": "  81:                 (r'class\\s+(\\w+).*?:', 'Novel class/algorithm'),\n  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84: >>>             (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),",
          "match": "@classmethod"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 85,
          "context": "  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85: >>>             (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 85,
          "context": "  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85: >>>             (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 85,
          "context": "  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85: >>>             (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 85,
          "context": "  82:                 (r'def\\s+(\\w+).*?:', 'Method implementation'),\n  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85: >>>             (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 135,
          "context": " 132:                 return 'USER_INTERFACE', 8\n 133:             \n 134:             # Performance/optimization innovations\n 135: >>>         if any(x in filename for x in ['parallel', 'gpu', 'optimization', 'performance']):\n 136:                 return 'PERFORMANCE', 9\n 137:             \n 138:             # Visualization and analysis tools",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 86,
          "context": "  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86: >>>             (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 86,
          "context": "  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86: >>>             (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),",
          "match": "threading"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 86,
          "context": "  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86: >>>             (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),",
          "match": "multiprocess"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 86,
          "context": "  83:                 (r'# Novel|# Innovation|# New approach', 'Explicit innovation marker'),\n  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86: >>>             (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 135,
          "context": " 132:                 return 'USER_INTERFACE', 8\n 133:             \n 134:             # Performance/optimization innovations\n 135: >>>         if any(x in filename for x in ['parallel', 'gpu', 'optimization', 'performance']):\n 136:                 return 'PERFORMANCE', 9\n 137:             \n 138:             # Visualization and analysis tools",
          "match": "parallel"
        },
        {
          "type": "Performance optimization",
          "pattern": "optimization|optimize",
          "line": 87,
          "context": "  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87: >>>             (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),",
          "match": "optimization"
        },
        {
          "type": "Performance optimization",
          "pattern": "optimization|optimize",
          "line": 87,
          "context": "  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87: >>>             (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),",
          "match": "optimize"
        },
        {
          "type": "Performance optimization",
          "pattern": "optimization|optimize",
          "line": 87,
          "context": "  84:                 (r'@staticmethod|@classmethod', 'Advanced implementation pattern'),\n  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87: >>>             (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),",
          "match": "optimization"
        },
        {
          "type": "Performance optimization",
          "pattern": "optimization|optimize",
          "line": 134,
          "context": " 131:             if any(x in filename for x in ['gui', 'interface', 'control']):\n 132:                 return 'USER_INTERFACE', 8\n 133:             \n 134: >>>         # Performance/optimization innovations\n 135:             if any(x in filename for x in ['parallel', 'gpu', 'optimization', 'performance']):\n 136:                 return 'PERFORMANCE', 9\n 137:             ",
          "match": "optimization"
        },
        {
          "type": "Performance optimization",
          "pattern": "optimization|optimize",
          "line": 135,
          "context": " 132:                 return 'USER_INTERFACE', 8\n 133:             \n 134:             # Performance/optimization innovations\n 135: >>>         if any(x in filename for x in ['parallel', 'gpu', 'optimization', 'performance']):\n 136:                 return 'PERFORMANCE', 9\n 137:             \n 138:             # Visualization and analysis tools",
          "match": "optimization"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 88,
          "context": "  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88: >>>             (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 88,
          "context": "  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88: >>>             (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 88,
          "context": "  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88: >>>             (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]",
          "match": "convergence"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 88,
          "context": "  85:                 (r'cupy|gpu|cuda', 'GPU acceleration technique'),\n  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88: >>>             (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]",
          "match": "stability"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 89,
          "context": "  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89: >>>             (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 89,
          "context": "  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89: >>>             (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 89,
          "context": "  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89: >>>             (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             ",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 89,
          "context": "  86:                 (r'parallel|threading|multiprocess', 'Parallel processing method'),\n  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89: >>>             (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90:                 (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             ",
          "match": "Boundary"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 90,
          "context": "  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90: >>>             (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             \n  93:             for pattern, description in patterns:",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 90,
          "context": "  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90: >>>             (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             \n  93:             for pattern, description in patterns:",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 90,
          "context": "  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90: >>>             (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             \n  93:             for pattern, description in patterns:",
          "match": "solver"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 90,
          "context": "  87:                 (r'optimization|optimize', 'Performance optimization'),\n  88:                 (r'stability|CFL|convergence', 'Numerical stability technique'),\n  89:                 (r'boundary|periodic|absorbing', 'Boundary condition handling'),\n  90: >>>             (r'leapfrog|integration|solver', 'Numerical integration method'),\n  91:             ]\n  92:             \n  93:             for pattern, description in patterns:",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 127,
          "context": " 124:             filename = filepath.name.lower()\n 125:             \n 126:             # Core algorithm files\n 127: >>>         if any(x in filename for x in ['equation', 'solver', 'algorithm', 'core']):\n 128:                 return 'CORE_ALGORITHM', 10\n 129:             \n 130:             # Novel interface/interaction methods",
          "match": "solver"
        }
      ],
      "line_count": 432,
      "docstring": "LFM Prior Art Documentation Generator\n====================================\nCreates comprehensive prior art documentation from the LFM codebase.\nEstablishes public timeline of innovations and technical developments.\nPrevents third-party patent claims on disclosed methods."
    },
    {
      "filepath": "lfm_backend.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "c806680b8020f8c4",
      "file_size": 3157,
      "modified": "2025-11-02T20:02:10.860343",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 30,
          "context": "  27:         HAS_CUPY = False\n  28:     \n  29:     \n  30: >>> def pick_backend(use_gpu: bool):\n  31:         \"\"\"Select NumPy or CuPy backend based on availability and request.\n  32:         \n  33:         Args:",
          "match": "def pick_backend(use_gpu:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:         return (cp if on_gpu else np), on_gpu\n  57:     \n  58:     \n  59: >>> def to_numpy(x):\n  60:         \"\"\"Convert array to NumPy, handling CuPy arrays transparently.\n  61:         \n  62:         Args:",
          "match": "def to_numpy(x):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 79,
          "context": "  76:         return np.asarray(x)\n  77:     \n  78:     \n  79: >>> def ensure_device(x, xp):\n  80:         \"\"\"Ensure array is on the correct device (CPU or GPU).\n  81:         \n  82:         Args:",
          "match": "def ensure_device(x, xp):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 100,
          "context": "  97:         return x\n  98:     \n  99:     \n 100: >>> def get_array_module(x):\n 101:         \"\"\"Get the appropriate array module (np or cp) for an array.\n 102:         \n 103:         Args:",
          "match": "def get_array_module(x):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     LFM Backend Selection and Array Conversion Utilities\n  10:     ====================================================\n  11: >>> Centralized backend management for NumPy/CuPy interoperability.\n  12:     \n  13:     Usage:\n  14:         from lfm_backend import pick_backend, to_numpy, HAS_CUPY",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 14,
          "context": "  11:     Centralized backend management for NumPy/CuPy interoperability.\n  12:     \n  13:     Usage:\n  14: >>>     from lfm_backend import pick_backend, to_numpy, HAS_CUPY\n  15:         \n  16:         xp, on_gpu = pick_backend(use_gpu=True)\n  17:         result_np = to_numpy(gpu_array)",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 16,
          "context": "  13:     Usage:\n  14:         from lfm_backend import pick_backend, to_numpy, HAS_CUPY\n  15:         \n  16: >>>     xp, on_gpu = pick_backend(use_gpu=True)\n  17:         result_np = to_numpy(gpu_array)\n  18:     \"\"\"\n  19:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 16,
          "context": "  13:     Usage:\n  14:         from lfm_backend import pick_backend, to_numpy, HAS_CUPY\n  15:         \n  16: >>>     xp, on_gpu = pick_backend(use_gpu=True)\n  17:         result_np = to_numpy(gpu_array)\n  18:     \"\"\"\n  19:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 17,
          "context": "  14:         from lfm_backend import pick_backend, to_numpy, HAS_CUPY\n  15:         \n  16:         xp, on_gpu = pick_backend(use_gpu=True)\n  17: >>>     result_np = to_numpy(gpu_array)\n  18:     \"\"\"\n  19:     \n  20:     import numpy as np",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 23,
          "context": "  20:     import numpy as np\n  21:     \n  22:     try:\n  23: >>>     import cupy as cp\n  24:         HAS_CUPY = True\n  25:     except ImportError:\n  26:         cp = None",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 24,
          "context": "  21:     \n  22:     try:\n  23:         import cupy as cp\n  24: >>>     HAS_CUPY = True\n  25:     except ImportError:\n  26:         cp = None\n  27:         HAS_CUPY = False",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 27,
          "context": "  24:         HAS_CUPY = True\n  25:     except ImportError:\n  26:         cp = None\n  27: >>>     HAS_CUPY = False\n  28:     \n  29:     \n  30:     def pick_backend(use_gpu: bool):",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 30,
          "context": "  27:         HAS_CUPY = False\n  28:     \n  29:     \n  30: >>> def pick_backend(use_gpu: bool):\n  31:         \"\"\"Select NumPy or CuPy backend based on availability and request.\n  32:         \n  33:         Args:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 31,
          "context": "  28:     \n  29:     \n  30:     def pick_backend(use_gpu: bool):\n  31: >>>     \"\"\"Select NumPy or CuPy backend based on availability and request.\n  32:         \n  33:         Args:\n  34:             use_gpu: Whether to use GPU if available",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 34,
          "context": "  31:         \"\"\"Select NumPy or CuPy backend based on availability and request.\n  32:         \n  33:         Args:\n  34: >>>         use_gpu: Whether to use GPU if available\n  35:         \n  36:         Returns:\n  37:             Tuple of (xp, on_gpu) where:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 34,
          "context": "  31:         \"\"\"Select NumPy or CuPy backend based on availability and request.\n  32:         \n  33:         Args:\n  34: >>>         use_gpu: Whether to use GPU if available\n  35:         \n  36:         Returns:\n  37:             Tuple of (xp, on_gpu) where:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 37,
          "context": "  34:             use_gpu: Whether to use GPU if available\n  35:         \n  36:         Returns:\n  37: >>>         Tuple of (xp, on_gpu) where:\n  38:             - xp: Module reference (np or cp)\n  39:             - on_gpu: Boolean indicating if GPU is actually being used\n  40:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 39,
          "context": "  36:         Returns:\n  37:             Tuple of (xp, on_gpu) where:\n  38:             - xp: Module reference (np or cp)\n  39: >>>         - on_gpu: Boolean indicating if GPU is actually being used\n  40:         \n  41:         Example:\n  42:             >>> xp, on_gpu = pick_backend(use_gpu=True)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 39,
          "context": "  36:         Returns:\n  37:             Tuple of (xp, on_gpu) where:\n  38:             - xp: Module reference (np or cp)\n  39: >>>         - on_gpu: Boolean indicating if GPU is actually being used\n  40:         \n  41:         Example:\n  42:             >>> xp, on_gpu = pick_backend(use_gpu=True)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 42,
          "context": "  39:             - on_gpu: Boolean indicating if GPU is actually being used\n  40:         \n  41:         Example:\n  42: >>>         >>> xp, on_gpu = pick_backend(use_gpu=True)\n  43:             >>> array = xp.zeros((100, 100))  # Creates on appropriate device\n  44:         \"\"\"\n  45:         on_gpu = bool(use_gpu and HAS_CUPY)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 42,
          "context": "  39:             - on_gpu: Boolean indicating if GPU is actually being used\n  40:         \n  41:         Example:\n  42: >>>         >>> xp, on_gpu = pick_backend(use_gpu=True)\n  43:             >>> array = xp.zeros((100, 100))  # Creates on appropriate device\n  44:         \"\"\"\n  45:         on_gpu = bool(use_gpu and HAS_CUPY)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 45,
          "context": "  42:             >>> xp, on_gpu = pick_backend(use_gpu=True)\n  43:             >>> array = xp.zeros((100, 100))  # Creates on appropriate device\n  44:         \"\"\"\n  45: >>>     on_gpu = bool(use_gpu and HAS_CUPY)\n  46:         \n  47:         if use_gpu and not HAS_CUPY:\n  48:             # Lazy import to avoid circular dependency",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 45,
          "context": "  42:             >>> xp, on_gpu = pick_backend(use_gpu=True)\n  43:             >>> array = xp.zeros((100, 100))  # Creates on appropriate device\n  44:         \"\"\"\n  45: >>>     on_gpu = bool(use_gpu and HAS_CUPY)\n  46:         \n  47:         if use_gpu and not HAS_CUPY:\n  48:             # Lazy import to avoid circular dependency",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 45,
          "context": "  42:             >>> xp, on_gpu = pick_backend(use_gpu=True)\n  43:             >>> array = xp.zeros((100, 100))  # Creates on appropriate device\n  44:         \"\"\"\n  45: >>>     on_gpu = bool(use_gpu and HAS_CUPY)\n  46:         \n  47:         if use_gpu and not HAS_CUPY:\n  48:             # Lazy import to avoid circular dependency",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:         \"\"\"\n  45:         on_gpu = bool(use_gpu and HAS_CUPY)\n  46:         \n  47: >>>     if use_gpu and not HAS_CUPY:\n  48:             # Lazy import to avoid circular dependency\n  49:             try:\n  50:                 from lfm_console import log",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:         \"\"\"\n  45:         on_gpu = bool(use_gpu and HAS_CUPY)\n  46:         \n  47: >>>     if use_gpu and not HAS_CUPY:\n  48:             # Lazy import to avoid circular dependency\n  49:             try:\n  50:                 from lfm_console import log",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 51,
          "context": "  48:             # Lazy import to avoid circular dependency\n  49:             try:\n  50:                 from lfm_console import log\n  51: >>>             log(\"GPU requested but CuPy not available; using NumPy\", \"WARN\")\n  52:             except ImportError:\n  53:                 import warnings\n  54:                 warnings.warn(\"GPU requested but CuPy not available; using NumPy\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 51,
          "context": "  48:             # Lazy import to avoid circular dependency\n  49:             try:\n  50:                 from lfm_console import log\n  51: >>>             log(\"GPU requested but CuPy not available; using NumPy\", \"WARN\")\n  52:             except ImportError:\n  53:                 import warnings\n  54:                 warnings.warn(\"GPU requested but CuPy not available; using NumPy\")",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 54,
          "context": "  51:                 log(\"GPU requested but CuPy not available; using NumPy\", \"WARN\")\n  52:             except ImportError:\n  53:                 import warnings\n  54: >>>             warnings.warn(\"GPU requested but CuPy not available; using NumPy\")\n  55:         \n  56:         return (cp if on_gpu else np), on_gpu\n  57:     ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 54,
          "context": "  51:                 log(\"GPU requested but CuPy not available; using NumPy\", \"WARN\")\n  52:             except ImportError:\n  53:                 import warnings\n  54: >>>             warnings.warn(\"GPU requested but CuPy not available; using NumPy\")\n  55:         \n  56:         return (cp if on_gpu else np), on_gpu\n  57:     ",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 56,
          "context": "  53:                 import warnings\n  54:                 warnings.warn(\"GPU requested but CuPy not available; using NumPy\")\n  55:         \n  56: >>>     return (cp if on_gpu else np), on_gpu\n  57:     \n  58:     \n  59:     def to_numpy(x):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 56,
          "context": "  53:                 import warnings\n  54:                 warnings.warn(\"GPU requested but CuPy not available; using NumPy\")\n  55:         \n  56: >>>     return (cp if on_gpu else np), on_gpu\n  57:     \n  58:     \n  59:     def to_numpy(x):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 60,
          "context": "  57:     \n  58:     \n  59:     def to_numpy(x):\n  60: >>>     \"\"\"Convert array to NumPy, handling CuPy arrays transparently.\n  61:         \n  62:         Args:\n  63:             x: Array (NumPy, CuPy, or array-like)",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 63,
          "context": "  60:         \"\"\"Convert array to NumPy, handling CuPy arrays transparently.\n  61:         \n  62:         Args:\n  63: >>>         x: Array (NumPy, CuPy, or array-like)\n  64:         \n  65:         Returns:\n  66:             NumPy array",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:             NumPy array\n  67:         \n  68:         Example:\n  69: >>>         >>> gpu_array = cp.array([1, 2, 3])\n  70:             >>> cpu_array = to_numpy(gpu_array)\n  71:             >>> type(cpu_array)\n  72:             <class 'numpy.ndarray'>",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 70,
          "context": "  67:         \n  68:         Example:\n  69:             >>> gpu_array = cp.array([1, 2, 3])\n  70: >>>         >>> cpu_array = to_numpy(gpu_array)\n  71:             >>> type(cpu_array)\n  72:             <class 'numpy.ndarray'>\n  73:         \"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 74,
          "context": "  71:             >>> type(cpu_array)\n  72:             <class 'numpy.ndarray'>\n  73:         \"\"\"\n  74: >>>     if HAS_CUPY and isinstance(x, cp.ndarray):\n  75:             return cp.asnumpy(x)\n  76:         return np.asarray(x)\n  77:     ",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 80,
          "context": "  77:     \n  78:     \n  79:     def ensure_device(x, xp):\n  80: >>>     \"\"\"Ensure array is on the correct device (CPU or GPU).\n  81:         \n  82:         Args:\n  83:             x: Input array",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 91,
          "context": "  88:         \n  89:         Example:\n  90:             >>> cpu_array = np.array([1, 2, 3])\n  91: >>>         >>> gpu_array = ensure_device(cpu_array, cp)\n  92:         \"\"\"\n  93:         if xp is cp and not isinstance(x, cp.ndarray):\n  94:             return cp.asarray(x)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 95,
          "context": "  92:         \"\"\"\n  93:         if xp is cp and not isinstance(x, cp.ndarray):\n  94:             return cp.asarray(x)\n  95: >>>     if xp is np and HAS_CUPY and isinstance(x, cp.ndarray):\n  96:             return cp.asnumpy(x)\n  97:         return x\n  98:     ",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 112,
          "context": " 109:         Example:\n 110:             >>> x = cp.array([1, 2, 3])\n 111:             >>> xp = get_array_module(x)\n 112: >>>         >>> xp.zeros_like(x)  # Creates CuPy array\n 113:         \"\"\"\n 114:         if HAS_CUPY:\n 115:             return cp.get_array_module(x)",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 114,
          "context": " 111:             >>> xp = get_array_module(x)\n 112:             >>> xp.zeros_like(x)  # Creates CuPy array\n 113:         \"\"\"\n 114: >>>     if HAS_CUPY:\n 115:             return cp.get_array_module(x)\n 116:         return np\n 117:     ",
          "match": "CUPY"
        }
      ],
      "line_count": 116,
      "docstring": "LFM Backend Selection and Array Conversion Utilities\n====================================================\nCentralized backend management for NumPy/CuPy interoperability.\n\nUsage:\n    from lfm_backend import pick_backend, to_numpy, HAS_CUPY\n    \n    xp, on_gpu = pick_backend(use_gpu=True)\n    result_np = to_numpy(gpu_array)"
    },
    {
      "filepath": "lfm_config.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "ba60e1f5eead3752",
      "file_size": 9811,
      "modified": "2025-11-02T20:02:10.861190",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     import json\n  19:     \n  20:     \n  21: >>> @dataclass\n  22:     class LFMConfig:\n  23:         \"\"\"\n  24:         Type-safe configuration for LFM lattice simulations.",
          "match": "class\nclass LFMConfig:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:         # Computed properties (private, cached)\n  65:         _c: float = field(init=False, repr=False, default=None)\n  66:         \n  67: >>>     def __post_init__(self):\n  68:             \"\"\"Validate configuration and compute derived quantities.\"\"\"\n  69:             # Validate beta != 0\n  70:             if self.beta == 0:",
          "match": "def __post_init__(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 89,
          "context": "  86:             self._c = (self.alpha / self.beta) ** 0.5\n  87:             \n  88:         @property\n  89: >>>     def c(self) -> float:\n  90:             \"\"\"Speed of light: c = sqrt(alpha/beta)\"\"\"\n  91:             return self._c\n  92:             ",
          "match": "def c(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 93,
          "context": "  90:             \"\"\"Speed of light: c = sqrt(alpha/beta)\"\"\"\n  91:             return self._c\n  92:             \n  93: >>>     def cfl_ratio(self, ndim: int) -> float:\n  94:             \"\"\"\n  95:             CFL ratio for given dimensionality: (c * dt) / dx\n  96:             ",
          "match": "def cfl_ratio(self, ndim:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 105,
          "context": " 102:             \"\"\"\n 103:             return self.c * self.dt / self.dx\n 104:             \n 105: >>>     def cfl_limit(self, ndim: int) -> float:\n 106:             \"\"\"\n 107:             CFL stability limit: 1 / sqrt(ndim)\n 108:             ",
          "match": "def cfl_limit(self, ndim:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 117,
          "context": " 114:             \"\"\"\n 115:             return 1.0 / (ndim ** 0.5)\n 116:             \n 117: >>>     def is_stable(self, ndim: int) -> bool:\n 118:             \"\"\"\n 119:             Check if CFL condition is satisfied for stability.\n 120:             ",
          "match": "def is_stable(self, ndim:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 129,
          "context": " 126:             \"\"\"\n 127:             return self.cfl_ratio(ndim) <= self.cfl_limit(ndim)\n 128:             \n 129: >>>     def validate_cfl(self, ndim: int, warn: bool = True) -> bool:\n 130:             \"\"\"\n 131:             Validate CFL condition and optionally issue warning.\n 132:             ",
          "match": "def validate_cfl(self, ndim:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 149,
          "context": " 146:                 return False\n 147:             return True\n 148:             \n 149: >>>     def to_dict(self) -> Dict[str, Any]:\n 150:             \"\"\"\n 151:             Convert config to dictionary (for backward compatibility).\n 152:             ",
          "match": "def to_dict(self) -> Dict[str, Any]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 164,
          "context": " 161:             return d\n 162:             \n 163:         @classmethod\n 164: >>>     def from_dict(cls, d: Dict[str, Any]) -> LFMConfig:\n 165:             \"\"\"\n 166:             Create config from dictionary (for backward compatibility).\n 167:             ",
          "match": "def from_dict(cls, d:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 184,
          "context": " 181:             return cls(**filtered)\n 182:             \n 183:         @classmethod\n 184: >>>     def from_json_file(cls, filepath: str) -> LFMConfig:\n 185:             \"\"\"\n 186:             Load configuration from JSON file.\n 187:             ",
          "match": "def from_json_file(cls, filepath:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 198,
          "context": " 195:                 data = json.load(f)\n 196:             return cls.from_dict(data)\n 197:             \n 198: >>>     def to_json_file(self, filepath: str) -> None:\n 199:             \"\"\"\n 200:             Save configuration to JSON file.\n 201:             ",
          "match": "def to_json_file(self, filepath:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 208,
          "context": " 205:             with open(filepath, 'w') as f:\n 206:                 json.dump(self.to_dict(), f, indent=2)\n 207:                 \n 208: >>>     def copy(self, **changes) -> LFMConfig:\n 209:             \"\"\"\n 210:             Create a copy of this config with specified changes.\n 211:             ",
          "match": "def copy(self, **changes) -> LFMConfig:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 225,
          "context": " 222:             d.update(changes)\n 223:             return self.from_dict(d)\n 224:             \n 225: >>>     def __repr__(self) -> str:\n 226:             \"\"\"Concise representation showing key parameters.\"\"\"\n 227:             return (\n 228:                 f\"LFMConfig(dt={self.dt}, dx={self.dx}, \"",
          "match": "def __repr__(self) -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 238,
          "context": " 235:     # Convenience constructors for common configurations\n 236:     # ---------------------------------------------------------------------\n 237:     \n 238: >>> def make_default_config(dt: float = 0.1, dx: float = 0.5, **kwargs) -> LFMConfig:\n 239:         \"\"\"\n 240:         Create a default configuration with sensible physics parameters.\n 241:         ",
          "match": "def make_default_config(dt:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 262,
          "context": " 259:         return LFMConfig(dt=dt, dx=dx, **defaults)\n 260:     \n 261:     \n 262: >>> def make_test_config(grid_size: int = 64, cfl_factor: float = 0.5, **kwargs) -> LFMConfig:\n 263:         \"\"\"\n 264:         Create a configuration for testing with automatic CFL-safe timestep.\n 265:         ",
          "match": "def make_test_config(grid_size:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 294,
          "context": " 291:     # Migration helper: convert old params dict to config\n 292:     # ---------------------------------------------------------------------\n 293:     \n 294: >>> def params_to_config(params: Dict[str, Any]) -> LFMConfig:\n 295:         \"\"\"\n 296:         Convert old-style params dict to new LFMConfig.\n 297:         ",
          "match": "def params_to_config(params:"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 163,
          "context": " 160:             d['c'] = self.c\n 161:             return d\n 162:             \n 163: >>>     @classmethod\n 164:         def from_dict(cls, d: Dict[str, Any]) -> LFMConfig:\n 165:             \"\"\"\n 166:             Create config from dictionary (for backward compatibility).",
          "match": "@classmethod"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 183,
          "context": " 180:             filtered = {k: v for k, v in d.items() if k in valid_fields}\n 181:             return cls(**filtered)\n 182:             \n 183: >>>     @classmethod\n 184:         def from_json_file(cls, filepath: str) -> LFMConfig:\n 185:             \"\"\"\n 186:             Load configuration from JSON file.",
          "match": "@classmethod"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 55,
          "context": "  52:         precision: Literal[\"float32\", \"float64\"] = \"float64\"\n  53:         \n  54:         # Runtime options\n  55: >>>     use_gpu: bool = False\n  56:         threads: int = 1\n  57:         tiles: tuple = field(default_factory=lambda: (1,))\n  58:         ",
          "match": "gpu"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 11,
          "context": "   8:     lfm_config.py — Typed configuration for LFM simulations\n   9:     \n  10:     Provides type-safe, validated configuration objects to replace sprawling params dicts.\n  11: >>> Includes computed properties for derived quantities (c, CFL ratio, etc.).\n  12:     \"\"\"\n  13:     \n  14:     from __future__ import annotations",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 27,
          "context": "  24:         Type-safe configuration for LFM lattice simulations.\n  25:         \n  26:         Validates parameters at construction and provides computed properties\n  27: >>>     for derived quantities like speed of light and CFL limits.\n  28:         \n  29:         Example:\n  30:             >>> config = LFMConfig(dt=0.1, dx=0.5, alpha=1.0, beta=1.0)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 33,
          "context": "  30:             >>> config = LFMConfig(dt=0.1, dx=0.5, alpha=1.0, beta=1.0)\n  31:             >>> print(config.c)  # Speed of light\n  32:             1.0\n  33: >>>         >>> print(config.cfl_ratio(ndim=2))  # CFL ratio for 2D\n  34:             0.2\n  35:         \"\"\"\n  36:         ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 33,
          "context": "  30:             >>> config = LFMConfig(dt=0.1, dx=0.5, alpha=1.0, beta=1.0)\n  31:             >>> print(config.c)  # Speed of light\n  32:             1.0\n  33: >>>         >>> print(config.cfl_ratio(ndim=2))  # CFL ratio for 2D\n  34:             0.2\n  35:         \"\"\"\n  36:         ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 93,
          "context": "  90:             \"\"\"Speed of light: c = sqrt(alpha/beta)\"\"\"\n  91:             return self._c\n  92:             \n  93: >>>     def cfl_ratio(self, ndim: int) -> float:\n  94:             \"\"\"\n  95:             CFL ratio for given dimensionality: (c * dt) / dx\n  96:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 95,
          "context": "  92:             \n  93:         def cfl_ratio(self, ndim: int) -> float:\n  94:             \"\"\"\n  95: >>>         CFL ratio for given dimensionality: (c * dt) / dx\n  96:             \n  97:             Args:\n  98:                 ndim: Number of spatial dimensions (1, 2, or 3)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 101,
          "context": "  98:                 ndim: Number of spatial dimensions (1, 2, or 3)\n  99:                 \n 100:             Returns:\n 101: >>>             CFL ratio (should be < cfl_limit for stability)\n 102:             \"\"\"\n 103:             return self.c * self.dt / self.dx\n 104:             ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 101,
          "context": "  98:                 ndim: Number of spatial dimensions (1, 2, or 3)\n  99:                 \n 100:             Returns:\n 101: >>>             CFL ratio (should be < cfl_limit for stability)\n 102:             \"\"\"\n 103:             return self.c * self.dt / self.dx\n 104:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 101,
          "context": "  98:                 ndim: Number of spatial dimensions (1, 2, or 3)\n  99:                 \n 100:             Returns:\n 101: >>>             CFL ratio (should be < cfl_limit for stability)\n 102:             \"\"\"\n 103:             return self.c * self.dt / self.dx\n 104:             ",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 105,
          "context": " 102:             \"\"\"\n 103:             return self.c * self.dt / self.dx\n 104:             \n 105: >>>     def cfl_limit(self, ndim: int) -> float:\n 106:             \"\"\"\n 107:             CFL stability limit: 1 / sqrt(ndim)\n 108:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 107,
          "context": " 104:             \n 105:         def cfl_limit(self, ndim: int) -> float:\n 106:             \"\"\"\n 107: >>>         CFL stability limit: 1 / sqrt(ndim)\n 108:             \n 109:             Args:\n 110:                 ndim: Number of spatial dimensions",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 107,
          "context": " 104:             \n 105:         def cfl_limit(self, ndim: int) -> float:\n 106:             \"\"\"\n 107: >>>         CFL stability limit: 1 / sqrt(ndim)\n 108:             \n 109:             Args:\n 110:                 ndim: Number of spatial dimensions",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 113,
          "context": " 110:                 ndim: Number of spatial dimensions\n 111:                 \n 112:             Returns:\n 113: >>>             Maximum stable CFL ratio\n 114:             \"\"\"\n 115:             return 1.0 / (ndim ** 0.5)\n 116:             ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 119,
          "context": " 116:             \n 117:         def is_stable(self, ndim: int) -> bool:\n 118:             \"\"\"\n 119: >>>         Check if CFL condition is satisfied for stability.\n 120:             \n 121:             Args:\n 122:                 ndim: Number of spatial dimensions",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 119,
          "context": " 116:             \n 117:         def is_stable(self, ndim: int) -> bool:\n 118:             \"\"\"\n 119: >>>         Check if CFL condition is satisfied for stability.\n 120:             \n 121:             Args:\n 122:                 ndim: Number of spatial dimensions",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 125,
          "context": " 122:                 ndim: Number of spatial dimensions\n 123:                 \n 124:             Returns:\n 125: >>>             True if configuration satisfies CFL condition\n 126:             \"\"\"\n 127:             return self.cfl_ratio(ndim) <= self.cfl_limit(ndim)\n 128:             ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 127,
          "context": " 124:             Returns:\n 125:                 True if configuration satisfies CFL condition\n 126:             \"\"\"\n 127: >>>         return self.cfl_ratio(ndim) <= self.cfl_limit(ndim)\n 128:             \n 129:         def validate_cfl(self, ndim: int, warn: bool = True) -> bool:\n 130:             \"\"\"",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 127,
          "context": " 124:             Returns:\n 125:                 True if configuration satisfies CFL condition\n 126:             \"\"\"\n 127: >>>         return self.cfl_ratio(ndim) <= self.cfl_limit(ndim)\n 128:             \n 129:         def validate_cfl(self, ndim: int, warn: bool = True) -> bool:\n 130:             \"\"\"",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 129,
          "context": " 126:             \"\"\"\n 127:             return self.cfl_ratio(ndim) <= self.cfl_limit(ndim)\n 128:             \n 129: >>>     def validate_cfl(self, ndim: int, warn: bool = True) -> bool:\n 130:             \"\"\"\n 131:             Validate CFL condition and optionally issue warning.\n 132:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 131,
          "context": " 128:             \n 129:         def validate_cfl(self, ndim: int, warn: bool = True) -> bool:\n 130:             \"\"\"\n 131: >>>         Validate CFL condition and optionally issue warning.\n 132:             \n 133:             Args:\n 134:                 ndim: Number of spatial dimensions",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 135,
          "context": " 132:             \n 133:             Args:\n 134:                 ndim: Number of spatial dimensions\n 135: >>>             warn: If True, print warning if CFL violated\n 136:                 \n 137:             Returns:\n 138:                 True if CFL satisfied, False otherwise",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 138,
          "context": " 135:                 warn: If True, print warning if CFL violated\n 136:                 \n 137:             Returns:\n 138: >>>             True if CFL satisfied, False otherwise\n 139:             \"\"\"\n 140:             ratio = self.cfl_ratio(ndim)\n 141:             limit = self.cfl_limit(ndim)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 140,
          "context": " 137:             Returns:\n 138:                 True if CFL satisfied, False otherwise\n 139:             \"\"\"\n 140: >>>         ratio = self.cfl_ratio(ndim)\n 141:             limit = self.cfl_limit(ndim)\n 142:             \n 143:             if ratio > limit:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 141,
          "context": " 138:                 True if CFL satisfied, False otherwise\n 139:             \"\"\"\n 140:             ratio = self.cfl_ratio(ndim)\n 141: >>>         limit = self.cfl_limit(ndim)\n 142:             \n 143:             if ratio > limit:\n 144:                 if warn:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 145,
          "context": " 142:             \n 143:             if ratio > limit:\n 144:                 if warn:\n 145: >>>                 print(f\"[CFL WARNING] Ratio {ratio:.3f} exceeds limit {limit:.3f} - may be unstable\")\n 146:                 return False\n 147:             return True\n 148:             ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 262,
          "context": " 259:         return LFMConfig(dt=dt, dx=dx, **defaults)\n 260:     \n 261:     \n 262: >>> def make_test_config(grid_size: int = 64, cfl_factor: float = 0.5, **kwargs) -> LFMConfig:\n 263:         \"\"\"\n 264:         Create a configuration for testing with automatic CFL-safe timestep.\n 265:         ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 264,
          "context": " 261:     \n 262:     def make_test_config(grid_size: int = 64, cfl_factor: float = 0.5, **kwargs) -> LFMConfig:\n 263:         \"\"\"\n 264: >>>     Create a configuration for testing with automatic CFL-safe timestep.\n 265:         \n 266:         Args:\n 267:             grid_size: Number of grid points per dimension",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 268,
          "context": " 265:         \n 266:         Args:\n 267:             grid_size: Number of grid points per dimension\n 268: >>>         cfl_factor: Fraction of CFL limit to use (default 0.5 = conservative)\n 269:             **kwargs: Additional parameters\n 270:             \n 271:         Returns:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 268,
          "context": " 265:         \n 266:         Args:\n 267:             grid_size: Number of grid points per dimension\n 268: >>>         cfl_factor: Fraction of CFL limit to use (default 0.5 = conservative)\n 269:             **kwargs: Additional parameters\n 270:             \n 271:         Returns:",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 272,
          "context": " 269:             **kwargs: Additional parameters\n 270:             \n 271:         Returns:\n 272: >>>         LFMConfig with CFL-safe timestep\n 273:             \n 274:         Example:\n 275:             >>> config = make_test_config(grid_size=128, cfl_factor=0.8, chi=1.0)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 275,
          "context": " 272:             LFMConfig with CFL-safe timestep\n 273:             \n 274:         Example:\n 275: >>>         >>> config = make_test_config(grid_size=128, cfl_factor=0.8, chi=1.0)\n 276:         \"\"\"\n 277:         dx = 1.0  # Normalized\n 278:         ndim = kwargs.get('ndim', 2)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 283,
          "context": " 280:         beta = kwargs.get('beta', 1.0)\n 281:         c = (alpha / beta) ** 0.5\n 282:         \n 283: >>>     # CFL-safe timestep: c * dt / dx < 1/sqrt(ndim)\n 284:         cfl_limit = 1.0 / (ndim ** 0.5)\n 285:         dt = (cfl_factor * cfl_limit * dx) / c\n 286:         ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 284,
          "context": " 281:         c = (alpha / beta) ** 0.5\n 282:         \n 283:         # CFL-safe timestep: c * dt / dx < 1/sqrt(ndim)\n 284: >>>     cfl_limit = 1.0 / (ndim ** 0.5)\n 285:         dt = (cfl_factor * cfl_limit * dx) / c\n 286:         \n 287:         return LFMConfig(dt=dt, dx=dx, **kwargs)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 285,
          "context": " 282:         \n 283:         # CFL-safe timestep: c * dt / dx < 1/sqrt(ndim)\n 284:         cfl_limit = 1.0 / (ndim ** 0.5)\n 285: >>>     dt = (cfl_factor * cfl_limit * dx) / c\n 286:         \n 287:         return LFMConfig(dt=dt, dx=dx, **kwargs)\n 288:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 285,
          "context": " 282:         \n 283:         # CFL-safe timestep: c * dt / dx < 1/sqrt(ndim)\n 284:         cfl_limit = 1.0 / (ndim ** 0.5)\n 285: >>>     dt = (cfl_factor * cfl_limit * dx) / c\n 286:         \n 287:         return LFMConfig(dt=dt, dx=dx, **kwargs)\n 288:     ",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 48,
          "context": "  45:         gamma_damp: float = 0.0     # Damping coefficient [0, 1)\n  46:         \n  47:         # Numerical methods\n  48: >>>     boundary: Literal[\"periodic\", \"absorbing\", \"dirichlet\"] = \"periodic\"\n  49:         stencil_order: Literal[2, 4] = 2\n  50:         absorb_width: int = 1       # Width of absorbing boundary layer\n  51:         absorb_factor: float = 1.0  # Strength of absorption",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 48,
          "context": "  45:         gamma_damp: float = 0.0     # Damping coefficient [0, 1)\n  46:         \n  47:         # Numerical methods\n  48: >>>     boundary: Literal[\"periodic\", \"absorbing\", \"dirichlet\"] = \"periodic\"\n  49:         stencil_order: Literal[2, 4] = 2\n  50:         absorb_width: int = 1       # Width of absorbing boundary layer\n  51:         absorb_factor: float = 1.0  # Strength of absorption",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 48,
          "context": "  45:         gamma_damp: float = 0.0     # Damping coefficient [0, 1)\n  46:         \n  47:         # Numerical methods\n  48: >>>     boundary: Literal[\"periodic\", \"absorbing\", \"dirichlet\"] = \"periodic\"\n  49:         stencil_order: Literal[2, 4] = 2\n  50:         absorb_width: int = 1       # Width of absorbing boundary layer\n  51:         absorb_factor: float = 1.0  # Strength of absorption",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 48,
          "context": "  45:         gamma_damp: float = 0.0     # Damping coefficient [0, 1)\n  46:         \n  47:         # Numerical methods\n  48: >>>     boundary: Literal[\"periodic\", \"absorbing\", \"dirichlet\"] = \"periodic\"\n  49:         stencil_order: Literal[2, 4] = 2\n  50:         absorb_width: int = 1       # Width of absorbing boundary layer\n  51:         absorb_factor: float = 1.0  # Strength of absorption",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 50,
          "context": "  47:         # Numerical methods\n  48:         boundary: Literal[\"periodic\", \"absorbing\", \"dirichlet\"] = \"periodic\"\n  49:         stencil_order: Literal[2, 4] = 2\n  50: >>>     absorb_width: int = 1       # Width of absorbing boundary layer\n  51:         absorb_factor: float = 1.0  # Strength of absorption\n  52:         precision: Literal[\"float32\", \"float64\"] = \"float64\"\n  53:         ",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 50,
          "context": "  47:         # Numerical methods\n  48:         boundary: Literal[\"periodic\", \"absorbing\", \"dirichlet\"] = \"periodic\"\n  49:         stencil_order: Literal[2, 4] = 2\n  50: >>>     absorb_width: int = 1       # Width of absorbing boundary layer\n  51:         absorb_factor: float = 1.0  # Strength of absorption\n  52:         precision: Literal[\"float32\", \"float64\"] = \"float64\"\n  53:         ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 230,
          "context": " 227:             return (\n 228:                 f\"LFMConfig(dt={self.dt}, dx={self.dx}, \"\n 229:                 f\"c={self.c:.2f}, chi={self.chi}, \"\n 230: >>>             f\"boundary={self.boundary})\"\n 231:             )\n 232:     \n 233:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 230,
          "context": " 227:             return (\n 228:                 f\"LFMConfig(dt={self.dt}, dx={self.dx}, \"\n 229:                 f\"c={self.c:.2f}, chi={self.chi}, \"\n 230: >>>             f\"boundary={self.boundary})\"\n 231:             )\n 232:     \n 233:     ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 255,
          "context": " 252:             'beta': 1.0,\n 253:             'chi': 0.0,\n 254:             'gamma_damp': 0.0,\n 255: >>>         'boundary': 'periodic',\n 256:             'stencil_order': 2,\n 257:         }\n 258:         defaults.update(kwargs)",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 255,
          "context": " 252:             'beta': 1.0,\n 253:             'chi': 0.0,\n 254:             'gamma_damp': 0.0,\n 255: >>>         'boundary': 'periodic',\n 256:             'stencil_order': 2,\n 257:         }\n 258:         defaults.update(kwargs)",
          "match": "periodic"
        }
      ],
      "line_count": 314,
      "docstring": "lfm_config.py — Typed configuration for LFM simulations\n\nProvides type-safe, validated configuration objects to replace sprawling params dicts.\nIncludes computed properties for derived quantities (c, CFL ratio, etc.)."
    },
    {
      "filepath": "lfm_console.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "e7d0c9777848521a",
      "file_size": 6059,
      "modified": "2025-11-02T20:02:10.862838",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 148,
          "context": " 145:     # ---------------------------------------------------------------------\n 146:     # Simple runtime timer\n 147:     # ---------------------------------------------------------------------\n 148: >>> class Timer:\n 149:         def __init__(self, label=\"\"):\n 150:             self.label = label\n 151:             self.start_time = None",
          "match": "class Timer:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 32,
          "context": "  29:     # write lightweight JSONL progress/events into the same results tree.\n  30:     _GLOBAL_LOGGER = None\n  31:     \n  32: >>> def log(msg, level=\"INFO\", end=\"\\n\", flush=True):\n  33:         \"\"\"Timestamped console output with color by level.\"\"\"\n  34:         timestamp = datetime.utcnow().strftime(\"%H:%M:%S\")\n  35:         color = {",
          "match": "def log(msg, level=\"INFO\", end=\"\\n\", flush=True):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 49,
          "context": "  46:             sys.stdout.flush()\n  47:     \n  48:     \n  49: >>> def set_diagnostics_enabled(enabled: bool):\n  50:         \"\"\"Toggle whether diagnostic messages (non-critical warnings) are printed.\n  51:     \n  52:         This is intended to be set once at program startup by the harness based on",
          "match": "def set_diagnostics_enabled(enabled:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:         global DIAGNOSTICS_ENABLED\n  55:         DIAGNOSTICS_ENABLED = bool(enabled)\n  56:     \n  57: >>> def set_logger(logger):\n  58:         \"\"\"Bind an `LFMLogger` instance so console helpers can emit JSON events.\n  59:     \n  60:         The harness should call this after creating its `LFMLogger` so subsequent",
          "match": "def set_logger(logger):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:         global _GLOBAL_LOGGER\n  65:         _GLOBAL_LOGGER = logger\n  66:     \n  67: >>> def log_run_config(cfg: dict, out_dir=None):\n  68:         \"\"\"Pretty-print the top-level run config to console and write a\n  69:         machine-readable copy to `out_dir/run_config.json` (if out_dir provided).\n  70:         \"\"\"",
          "match": "def log_run_config(cfg:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 88,
          "context": "  85:     # ---------------------------------------------------------------------\n  86:     # Progress / status utilities\n  87:     # ---------------------------------------------------------------------\n  88: >>> def test_start(test_id, desc, steps=None):\n  89:         log(f\"-> Starting {test_id}: {desc} ({steps or '?'} steps)\", \"INFO\")\n  90:         if _GLOBAL_LOGGER is not None:\n  91:             try:",
          "match": "def test_start(test_id, desc, steps=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 96,
          "context": "  93:             except Exception:\n  94:                 pass\n  95:     \n  96: >>> def test_pass(test_id, metric=None):\n  97:         msg = f\"{test_id} PASS [OK]\"\n  98:         if metric:\n  99:             msg += f\" ({metric})\"",
          "match": "def test_pass(test_id, metric=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 102,
          "context": "  99:             msg += f\" ({metric})\"\n 100:         log(msg, \"PASS\")\n 101:     \n 102: >>> def test_fail(test_id, reason=None):\n 103:         msg = f\"{test_id} FAIL [X]\"\n 104:         if reason:\n 105:             msg += f\" ({reason})\"",
          "match": "def test_fail(test_id, reason=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 108,
          "context": " 105:             msg += f\" ({reason})\"\n 106:         log(msg, \"FAIL\")\n 107:     \n 108: >>> def suite_summary(results):\n 109:         \"\"\"Pretty-print a formatted PASS/FAIL table and overall result.\"\"\"\n 110:         log(\"=== SUITE SUMMARY ===\", \"INFO\")\n 111:         total = len(results)",
          "match": "def suite_summary(results):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 128,
          "context": " 125:             except Exception:\n 126:                 pass\n 127:     \n 128: >>> def report_progress(test_id: str, percent: int, phase: str = None):\n 129:         \"\"\"Emit a progress update to console and to the bound JSON logger.\n 130:     \n 131:         This is intended to be called occasionally (e.g. on percent boundaries)",
          "match": "def report_progress(test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 149,
          "context": " 146:     # Simple runtime timer\n 147:     # ---------------------------------------------------------------------\n 148:     class Timer:\n 149: >>>     def __init__(self, label=\"\"):\n 150:             self.label = label\n 151:             self.start_time = None\n 152:         def __enter__(self):",
          "match": "def __init__(self, label=\"\"):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 152,
          "context": " 149:         def __init__(self, label=\"\"):\n 150:             self.label = label\n 151:             self.start_time = None\n 152: >>>     def __enter__(self):\n 153:             self.start_time = time.time()\n 154:             return self\n 155:         def __exit__(self, *exc):",
          "match": "def __enter__(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 155,
          "context": " 152:         def __enter__(self):\n 153:             self.start_time = time.time()\n 154:             return self\n 155: >>>     def __exit__(self, *exc):\n 156:             dt = time.time() - self.start_time\n 157:             log(f\"{self.label} completed in {dt:.2f}s\", \"INFO\")\n 158:     ",
          "match": "def __exit__(self, *exc):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 73,
          "context": "  70:         \"\"\"\n  71:         # Print a compact summary to console\n  72:         rs = cfg.get(\"run_settings\", {}) if isinstance(cfg, dict) else {}\n  73: >>>     msg = f\"Run settings: quick_mode={rs.get('quick_mode', False)}; use_gpu={rs.get('use_gpu', False)}; verbose={rs.get('verbose', False)}\"\n  74:         log(msg, \"INFO\")\n  75:         # Also write structured copy to the results folder if available\n  76:         if out_dir is not None:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 73,
          "context": "  70:         \"\"\"\n  71:         # Print a compact summary to console\n  72:         rs = cfg.get(\"run_settings\", {}) if isinstance(cfg, dict) else {}\n  73: >>>     msg = f\"Run settings: quick_mode={rs.get('quick_mode', False)}; use_gpu={rs.get('use_gpu', False)}; verbose={rs.get('verbose', False)}\"\n  74:         log(msg, \"INFO\")\n  75:         # Also write structured copy to the results folder if available\n  76:         if out_dir is not None:",
          "match": "gpu"
        }
      ],
      "line_count": 157,
      "docstring": "lfm_console.py — Unified console output control for all tiers.\nHandles runtime verbosity, per-test status lines, and end summaries."
    },
    {
      "filepath": "lfm_diagnostics.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "53d780c52a0fa4ba",
      "file_size": 6814,
      "modified": "2025-11-02T20:02:10.864550",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     \n  23:     from lfm_backend import to_numpy\n  24:     \n  25: >>> def ensure_dirs(p): Path(p).mkdir(parents=True, exist_ok=True)\n  26:     \n  27:     # ------------------------- 1) Discrete energy -------------------------\n  28:     def energy_total(E, E_prev, dt, dx, c, chi):",
          "match": "def ensure_dirs(p):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 28,
          "context": "  25:     def ensure_dirs(p): Path(p).mkdir(parents=True, exist_ok=True)\n  26:     \n  27:     # ------------------------- 1) Discrete energy -------------------------\n  28: >>> def energy_total(E, E_prev, dt, dx, c, chi):\n  29:         \"\"\"\n  30:         ∫ ½[(E_t)^2 + c^2|∇E|^2 + χ^2E^2] dV\n  31:         Uses compensated (Neumaier) summation to suppress rounding error.",
          "match": "def energy_total(E, E_prev, dt, dx, c, chi):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:         return float(total * weight)\n  78:     \n  79:     # ------------------------- 2) Field spectrum --------------------------\n  80: >>> def field_spectrum(E, dx, outdir):\n  81:         \"\"\"1D: save (k, |F|) with mean removal + Hann. 2D: |F(kx,ky)| image.\"\"\"\n  82:         ensure_dirs(outdir)\n  83:         e = to_numpy(E)",
          "match": "def field_spectrum(E, dx, outdir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 124,
          "context": " 121:             raise ValueError(f\"Unsupported ndim={e.ndim}\")\n 122:     \n 123:     # ------------------------- 3) Energy flow -----------------------------\n 124: >>> def energy_flow(E_series, dt, dx, c, outdir):\n 125:         \"\"\"Write t, E_sum_sq, rel_drift (baseline-corrected).\"\"\"\n 126:         ensure_dirs(outdir)\n 127:         if not E_series:",
          "match": "def energy_flow(E_series, dt, dx, c, outdir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 144,
          "context": " 141:         plt.tight_layout(); plt.savefig(Path(outdir)/\"energy_flow.png\", dpi=130); plt.close()\n 142:     \n 143:     # ------------------------- 4) Phase correlation -----------------------\n 144: >>> def phase_corr(E_series, outdir):\n 145:         \"\"\"Normalized phase autocorrelation of mean field ([-1,1]).\"\"\"\n 146:         ensure_dirs(outdir)\n 147:         if not E_series:",
          "match": "def phase_corr(E_series, outdir):"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 14,
          "context": "  11:     \n  12:     Changes from v1.10.0:\n  13:       • energy_total() now supports 3D (compensated/Neumaier summation).\n  14: >>>   • No change to solver physics or interfaces.\n  15:     \"\"\"\n  16:     \n  17:     from pathlib import Path",
          "match": "solver"
        }
      ],
      "line_count": 165,
      "docstring": "lfm_diagnostics.py — unified diagnostic utilities for all LFM tiers\nv1.10.1-compensated-3d\n\nChanges from v1.10.0:\n  • energy_total() now supports 3D (compensated/Neumaier summation).\n  • No change to solver physics or interfaces."
    },
    {
      "filepath": "lfm_fields.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "911f88a080995fda",
      "file_size": 8170,
      "modified": "2025-11-02T20:02:10.867646",
      "git_info": {
        "first_commit": {
          "hash": "02dfe204",
          "date": "2025-10-31 16:27:53 -0700",
          "message": "test overhaul"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 23,
          "context": "  20:     import numpy as np\n  21:     \n  22:     \n  23: >>> def gaussian_field(shape, center=None, width=1.0, amplitude=1.0, xp=None):\n  24:         \"\"\"Create N-dimensional Gaussian field.\n  25:         \n  26:         Args:",
          "match": "def gaussian_field(shape, center=None, width=1.0, amplitude=1.0, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 74,
          "context": "  71:         return amplitude * xp.exp(-r_squared / (2.0 * width ** 2))\n  72:     \n  73:     \n  74: >>> def wave_packet(shape, kvec, center=None, width=1.0, amplitude=1.0, phase=0.0, xp=None):\n  75:         \"\"\"Create modulated Gaussian wave packet.\n  76:         \n  77:         Constructs a Gaussian envelope multiplied by a plane wave:",
          "match": "def wave_packet(shape, kvec, center=None, width=1.0, amplitude=1.0, phase=0.0, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 130,
          "context": " 127:         return envelope * xp.cos(phase_field + phase)\n 128:     \n 129:     \n 130: >>> def traveling_wave_init(E0, kvec, omega, dt, xp=None):\n 131:         \"\"\"Create E and E_prev for traveling wave with correct initial velocity.\n 132:         \n 133:         For leapfrog time integration, we need both E(t=0) and E(t=-dt).",
          "match": "def traveling_wave_init(E0, kvec, omega, dt, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 167,
          "context": " 164:         return E0, E_prev\n 165:     \n 166:     \n 167: >>> def plane_wave_1d(N, k, amplitude=1.0, phase=0.0, xp=None):\n 168:         \"\"\"Create 1D plane wave: A cos(kx + φ).\n 169:         \n 170:         Args:",
          "match": "def plane_wave_1d(N, k, amplitude=1.0, phase=0.0, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 187,
          "context": " 184:         return amplitude * xp.cos(k * x + phase)\n 185:     \n 186:     \n 187: >>> def gaussian_bump_3d(shape, center, width, amplitude=1.0, xp=None):\n 188:         \"\"\"Create 3D Gaussian bump (convenience wrapper for 3D case).\n 189:         \n 190:         Args:",
          "match": "def gaussian_bump_3d(shape, center, width, amplitude=1.0, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 205,
          "context": " 202:         return gaussian_field(shape, center, width, amplitude, xp)\n 203:     \n 204:     \n 205: >>> def zero_mean_field(field, xp=None):\n 206:         \"\"\"Remove mean from field (useful for controlling energy).\n 207:         \n 208:         Args:",
          "match": "def zero_mean_field(field, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 231,
          "context": " 228:         return field - xp.mean(field)\n 229:     \n 230:     \n 231: >>> def normalize_energy(E, E_prev, target_energy, dt, dx, c, chi, xp=None):\n 232:         \"\"\"Scale field to achieve target total energy.\n 233:         \n 234:         Args:",
          "match": "def normalize_energy(E, E_prev, target_energy, dt, dx, c, chi, xp=None):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 44,
          "context": "  41:             >>> # 2D Gaussian at custom center\n  42:             >>> field_2d = gaussian_field((64, 64), center=(32, 16), width=5.0)\n  43:             \n  44: >>>         >>> # 3D Gaussian on GPU\n  45:             >>> import cupy as cp\n  46:             >>> field_3d = gaussian_field((32, 32, 32), xp=cp)\n  47:         \"\"\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 45,
          "context": "  42:             >>> field_2d = gaussian_field((64, 64), center=(32, 16), width=5.0)\n  43:             \n  44:             >>> # 3D Gaussian on GPU\n  45: >>>         >>> import cupy as cp\n  46:             >>> field_3d = gaussian_field((32, 32, 32), xp=cp)\n  47:         \"\"\"\n  48:         if xp is None:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 220,
          "context": " 217:                 xp = np\n 218:             else:\n 219:                 try:\n 220: >>>                 import cupy as cp\n 221:                     if isinstance(field, cp.ndarray):\n 222:                         xp = cp\n 223:                     else:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 252,
          "context": " 249:                 xp = np\n 250:             else:\n 251:                 try:\n 252: >>>                 import cupy as cp\n 253:                     if isinstance(E, cp.ndarray):\n 254:                         xp = cp\n 255:                     else:",
          "match": "cupy"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 133,
          "context": " 130:     def traveling_wave_init(E0, kvec, omega, dt, xp=None):\n 131:         \"\"\"Create E and E_prev for traveling wave with correct initial velocity.\n 132:         \n 133: >>>     For leapfrog time integration, we need both E(t=0) and E(t=-dt).\n 134:         This function creates initial conditions for a wave propagating with\n 135:         dispersion ω = ω(k).\n 136:         ",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 133,
          "context": " 130:     def traveling_wave_init(E0, kvec, omega, dt, xp=None):\n 131:         \"\"\"Create E and E_prev for traveling wave with correct initial velocity.\n 132:         \n 133: >>>     For leapfrog time integration, we need both E(t=0) and E(t=-dt).\n 134:         This function creates initial conditions for a wave propagating with\n 135:         dispersion ω = ω(k).\n 136:         ",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 148,
          "context": " 145:             xp: Backend module\n 146:         \n 147:         Returns:\n 148: >>>         Tuple (E, E_prev) for use in leapfrog integration\n 149:         \n 150:         Example:\n 151:             >>> E0 = wave_packet((128,), kvec=0.5, width=20.0)",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 148,
          "context": " 145:             xp: Backend module\n 146:         \n 147:         Returns:\n 148: >>>         Tuple (E, E_prev) for use in leapfrog integration\n 149:         \n 150:         Example:\n 151:             >>> E0 = wave_packet((128,), kvec=0.5, width=20.0)",
          "match": "integration"
        }
      ],
      "line_count": 272,
      "docstring": "LFM Field Initialization Utilities\n==================================\nStandard field initialization patterns for test scenarios.\n\nProvides:\n- Gaussian fields (1D, 2D, 3D)\n- Wave packets (modulated Gaussians)\n- Traveling wave initialization"
    },
    {
      "filepath": "lfm_logger.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "c05df86e39e56c3e",
      "file_size": 3136,
      "modified": "2025-11-02T20:02:10.869167",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 18,
          "context": "  15:     from pathlib import Path\n  16:     import platform\n  17:     \n  18: >>> class LFMLogger:\n  19:         \"\"\"Dual-format logger: human text + structured JSONL.\"\"\"\n  20:         def __init__(self, base_dir):\n  21:             self.base_dir = Path(base_dir)",
          "match": "class LFMLogger:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 20,
          "context": "  17:     \n  18:     class LFMLogger:\n  19:         \"\"\"Dual-format logger: human text + structured JSONL.\"\"\"\n  20: >>>     def __init__(self, base_dir):\n  21:             self.base_dir = Path(base_dir)\n  22:             self.base_dir.mkdir(parents=True, exist_ok=True)\n  23:             self.text_log = self.base_dir / \"session_log.txt\"",
          "match": "def __init__(self, base_dir):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 27,
          "context": "  24:             self.json_log = self.base_dir / \"session_log.jsonl\"\n  25:             self._write_header()\n  26:     \n  27: >>>     def _write_header(self):\n  28:             header = f\"=== LFM Log — {datetime.utcnow().isoformat()}Z ===\\n\"\n  29:             if not self.text_log.exists():\n  30:                 self.text_log.write_text(header, encoding=\"utf-8\")",
          "match": "def _write_header(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 35,
          "context": "  32:                 with open(self.text_log, \"a\", encoding=\"utf-8\") as f:\n  33:                     f.write(\"\\n\" + header)\n  34:     \n  35: >>>     def log(self, msg):\n  36:             \"\"\"Append timestamped text entry.\"\"\"\n  37:             line = f\"[{datetime.utcnow().isoformat()}Z] {msg}\\n\"\n  38:             with open(self.text_log, \"a\", encoding=\"utf-8\") as f:",
          "match": "def log(self, msg):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 41,
          "context": "  38:             with open(self.text_log, \"a\", encoding=\"utf-8\") as f:\n  39:                 f.write(line)\n  40:     \n  41: >>>     def log_json(self, obj):\n  42:             \"\"\"Append structured JSONL event (auto-sanitized).\"\"\"\n  43:             def sanitize(o):\n  44:                 if isinstance(o, (bool, int, float, str)) or o is None:",
          "match": "def log_json(self, obj):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 43,
          "context": "  40:     \n  41:         def log_json(self, obj):\n  42:             \"\"\"Append structured JSONL event (auto-sanitized).\"\"\"\n  43: >>>         def sanitize(o):\n  44:                 if isinstance(o, (bool, int, float, str)) or o is None:\n  45:                     return o\n  46:                 if hasattr(o, \"item\"):  # numpy/cupy scalar",
          "match": "def sanitize(o):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 55,
          "context": "  52:             with open(self.json_log, \"a\", encoding=\"utf-8\") as f:\n  53:                 f.write(json.dumps(clean) + \"\\n\")\n  54:     \n  55: >>>     def record_env(self, gpu_name=\"Unknown\", cuda_runtime=0):\n  56:             \"\"\"Log basic environment info once per session.\"\"\"\n  57:             env = {\n  58:                 \"event\": \"environment\",",
          "match": "def record_env(self, gpu_name=\"Unknown\", cuda_runtime=0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 68,
          "context": "  65:             self.log_json(env)\n  66:             self.log(f\"Environment: {env}\")\n  67:     \n  68: >>>     def error(self, msg, err=None):\n  69:             \"\"\"Record an error with traceback text.\"\"\"\n  70:             entry = {\"event\": \"error\", \"message\": msg}\n  71:             if err:",
          "match": "def error(self, msg, err=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 76,
          "context": "  73:             self.log_json(entry)\n  74:             self.log(f\"[ERROR] {msg}\")\n  75:     \n  76: >>>     def close(self):\n  77:             \"\"\"Flush and mark log end.\"\"\"\n  78:             line = f\"--- End of Log {datetime.utcnow().isoformat()}Z ---\\n\"\n  79:             with open(self.text_log, \"a\", encoding=\"utf-8\") as f:",
          "match": "def close(self):"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 46,
          "context": "  43:             def sanitize(o):\n  44:                 if isinstance(o, (bool, int, float, str)) or o is None:\n  45:                     return o\n  46: >>>             if hasattr(o, \"item\"):  # numpy/cupy scalar\n  47:                     return o.item()\n  48:                 return str(o)\n  49:     ",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 55,
          "context": "  52:             with open(self.json_log, \"a\", encoding=\"utf-8\") as f:\n  53:                 f.write(json.dumps(clean) + \"\\n\")\n  54:     \n  55: >>>     def record_env(self, gpu_name=\"Unknown\", cuda_runtime=0):\n  56:             \"\"\"Log basic environment info once per session.\"\"\"\n  57:             env = {\n  58:                 \"event\": \"environment\",",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 55,
          "context": "  52:             with open(self.json_log, \"a\", encoding=\"utf-8\") as f:\n  53:                 f.write(json.dumps(clean) + \"\\n\")\n  54:     \n  55: >>>     def record_env(self, gpu_name=\"Unknown\", cuda_runtime=0):\n  56:             \"\"\"Log basic environment info once per session.\"\"\"\n  57:             env = {\n  58:                 \"event\": \"environment\",",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:                 \"python\": platform.python_version(),\n  60:                 \"system\": platform.system(),\n  61:                 \"release\": platform.release(),\n  62: >>>             \"gpu\": gpu_name,\n  63:                 \"cuda_runtime\": cuda_runtime\n  64:             }\n  65:             self.log_json(env)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:                 \"python\": platform.python_version(),\n  60:                 \"system\": platform.system(),\n  61:                 \"release\": platform.release(),\n  62: >>>             \"gpu\": gpu_name,\n  63:                 \"cuda_runtime\": cuda_runtime\n  64:             }\n  65:             self.log_json(env)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 63,
          "context": "  60:                 \"system\": platform.system(),\n  61:                 \"release\": platform.release(),\n  62:                 \"gpu\": gpu_name,\n  63: >>>             \"cuda_runtime\": cuda_runtime\n  64:             }\n  65:             self.log_json(env)\n  66:             self.log(f\"Environment: {env}\")",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 63,
          "context": "  60:                 \"system\": platform.system(),\n  61:                 \"release\": platform.release(),\n  62:                 \"gpu\": gpu_name,\n  63: >>>             \"cuda_runtime\": cuda_runtime\n  64:             }\n  65:             self.log_json(env)\n  66:             self.log(f\"Environment: {env}\")",
          "match": "cuda"
        }
      ],
      "line_count": 82,
      "docstring": "lfm_logger.py — Unified logging system for all LFM tiers\nOutputs both text and JSONL logs for each test or suite run."
    },
    {
      "filepath": "lfm_results.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "b0f03cc2f33f021b",
      "file_size": 20458,
      "modified": "2025-11-02T20:02:10.871955",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     # ---------------------------------------------------------------------\n  19:     # Directory helpers\n  20:     # ---------------------------------------------------------------------\n  21: >>> def ensure_dirs(path):\n  22:         \"\"\"Ensure directory exists.\"\"\"\n  23:         Path(path).mkdir(parents=True, exist_ok=True)\n  24:     ",
          "match": "def ensure_dirs(path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 28,
          "context": "  25:     # ---------------------------------------------------------------------\n  26:     # JSON helpers\n  27:     # ---------------------------------------------------------------------\n  28: >>> def write_json(path, data):\n  29:         \"\"\"Write structured JSON safely (with timestamp) using atomic replace.\"\"\"\n  30:         ensure_dirs(Path(path).parent)\n  31:         if \"timestamp\" not in data:",
          "match": "def write_json(path, data):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 34,
          "context": "  31:         if \"timestamp\" not in data:\n  32:             data[\"timestamp\"] = datetime.utcnow().isoformat() + \"Z\"\n  33:         # Convert Python and NumPy types to JSON-serializable values\n  34: >>>     def convert_types(obj):\n  35:             import numpy as np\n  36:             if isinstance(obj, np.generic):\n  37:                 try:",
          "match": "def convert_types(obj):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 68,
          "context": "  65:             except Exception:\n  66:                 pass\n  67:     \n  68: >>> def read_json(path):\n  69:         \"\"\"Read JSON file (if exists) else return None.\"\"\"\n  70:         path = Path(path)\n  71:         if not path.exists():",
          "match": "def read_json(path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 79,
          "context": "  76:     # ---------------------------------------------------------------------\n  77:     # CSV helpers\n  78:     # ---------------------------------------------------------------------\n  79: >>> def write_csv(path, rows, header=None):\n  80:         \"\"\"Write CSV with optional header using atomic replace.\"\"\"\n  81:         ensure_dirs(Path(path).parent)\n  82:         path = Path(path)",
          "match": "def write_csv(path, rows, header=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 99,
          "context": "  96:             except Exception:\n  97:                 pass\n  98:     \n  99: >>> def read_csv(path):\n 100:         \"\"\"Read CSV into list of rows.\"\"\"\n 101:         path = Path(path)\n 102:         if not path.exists():",
          "match": "def read_csv(path):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 110,
          "context": " 107:     # ---------------------------------------------------------------------\n 108:     # Result bundle helpers\n 109:     # ---------------------------------------------------------------------\n 110: >>> def save_summary(base_dir, test_id, summary_data, metrics=None):\n 111:         \"\"\"\n 112:         Save both summary.json and metrics.csv in standard LFM format.\n 113:         base_dir: root folder (e.g. results/Tier1/REL-01/)",
          "match": "def save_summary(base_dir, test_id, summary_data, metrics=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 143,
          "context": " 140:     # ---------------------------------------------------------------------\n 141:     # Per-result README generation (lightweight, no external deps)\n 142:     # ---------------------------------------------------------------------\n 143: >>> def _generate_result_readme(result_dir: Path):\n 144:         \"\"\"\n 145:         Create or overwrite result_dir/readme.txt with a short summary of contents.\n 146:         Mirrors the essentials of tools/generate_results_readmes.py for a single folder",
          "match": "def _generate_result_readme(result_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 208,
          "context": " 205:     # ---------------------------------------------------------------------\n 206:     # Proof-bundle metadata\n 207:     # ---------------------------------------------------------------------\n 208: >>> def write_metadata_bundle(base_dir, test_id, tier, category, hardware_info=None):\n 209:         \"\"\"\n 210:         Create a lightweight metadata.json for reproducibility/auditing.\n 211:         Includes date, test id, tier, category, and optional hardware info.",
          "match": "def write_metadata_bundle(base_dir, test_id, tier, category, hardware_info=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 226,
          "context": " 223:     # ---------------------------------------------------------------------\n 224:     # Master test status tracking\n 225:     # ---------------------------------------------------------------------\n 226: >>> def update_master_test_status(results_dir: Path = None):\n 227:         \"\"\"\n 228:         Scan results directory and update MASTER_TEST_STATUS.csv with current test results.\n 229:         Should be called after any test completes (individual, tier, or parallel suite).",
          "match": "def update_master_test_status(results_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 415,
          "context": " 412:         output_file = results_dir / \"MASTER_TEST_STATUS.csv\"\n 413:         lock_file = results_dir / \"MASTER_TEST_STATUS.lock\"\n 414:     \n 415: >>>     def _acquire_lock(timeout_s=3.0, interval_s=0.05):\n 416:             start = time.time()\n 417:             while True:\n 418:                 try:",
          "match": "def _acquire_lock(timeout_s=3.0, interval_s=0.05):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 427,
          "context": " 424:                         return False\n 425:                     time.sleep(interval_s)\n 426:     \n 427: >>>     def _release_lock():\n 428:             try:\n 429:                 if lock_file.exists():\n 430:                     lock_file.unlink()",
          "match": "def _release_lock():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 457,
          "context": " 454:     # ---------------------------------------------------------------------\n 455:     # Human-friendly inspection\n 456:     # ---------------------------------------------------------------------\n 457: >>> def inspect_result_dir(result_dir: Path) -> str:\n 458:         \"\"\"Return a human-readable summary for a single result directory.\"\"\"\n 459:         d = Path(result_dir)\n 460:         summary_path = d / 'summary.json'",
          "match": "def inspect_result_dir(result_dir:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 173,
          "context": " 170:                 metrics = summary.get('metrics', {})\n 171:                 for key in [\n 172:                     'runtime_sec', 'exit_code', 'peak_cpu_percent',\n 173: >>>                 'peak_memory_mb', 'peak_gpu_memory_mb'\n 174:                 ]:\n 175:                     if key in metrics and isinstance(metrics[key], (int, float, str)):\n 176:                         metric_lines.append(f\"- {key}: {metrics[key]}\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 474,
          "context": " 471:                 lines.append(f\"- tier/category: {s.get('tier')}/{s.get('category')}\")\n 472:                 lines.append(f\"- status: {s.get('status')}\")\n 473:                 metrics = s.get('metrics', {})\n 474: >>>             for k in ['runtime_sec','exit_code','peak_cpu_percent','peak_memory_mb','peak_gpu_memory_mb']:\n 475:                     if k in metrics:\n 476:                         lines.append(f\"- {k}: {metrics[k]}\")\n 477:             except Exception as e:",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 229,
          "context": " 226:     def update_master_test_status(results_dir: Path = None):\n 227:         \"\"\"\n 228:         Scan results directory and update MASTER_TEST_STATUS.csv with current test results.\n 229: >>>     Should be called after any test completes (individual, tier, or parallel suite).\n 230:         \n 231:         Args:\n 232:             results_dir: Path to results directory (default: ./results)",
          "match": "parallel"
        }
      ],
      "line_count": 501,
      "docstring": "lfm_results.py — Result handling and structured output for all LFM tiers.\nHandles safe directory creation, summary writing, CSV utilities, and\nmetadata bundling. Works with lfm_logger and lfm_plotting."
    },
    {
      "filepath": "lfm_simulator.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "ea7da8eba6f45b88",
      "file_size": 13557,
      "modified": "2025-11-02T20:02:10.874565",
      "git_info": {
        "first_commit": {
          "hash": "ac9d5137",
          "date": "2025-10-31 14:25:56 -0700",
          "message": "sanity check-in"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 23,
          "context": "  20:     from lfm_equation import lattice_step, energy_total\n  21:     \n  22:     \n  23: >>> class LFMSimulator:\n  24:         \"\"\"\n  25:         High-level lattice field simulation engine.\n  26:         ",
          "match": "class LFMSimulator:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:             >>> print(f\"Energy: {sim.energy:.3e}\")\n  37:         \"\"\"\n  38:         \n  39: >>>     def __init__(self, initial_field: np.ndarray, config: LFMConfig):\n  40:             \"\"\"\n  41:             Initialize simulator with initial field and configuration.\n  42:             ",
          "match": "def __init__(self, initial_field:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 77,
          "context": "  74:         # Time Evolution\n  75:         # ----------------------------------------------------------------\n  76:         \n  77: >>>     def step(self) -> None:\n  78:             \"\"\"\n  79:             Advance simulation by one timestep: t → t + dt.\n  80:             ",
          "match": "def step(self) -> None:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 98,
          "context": "  95:             self._last_step_time = time.perf_counter() - t0\n  96:             self._total_step_time += self._last_step_time\n  97:             \n  98: >>>     def run(self, n_steps: int, callback: Optional[Callable[[LFMSimulator], None]] = None) -> None:\n  99:             \"\"\"\n 100:             Run simulation for n timesteps with optional per-step callback.\n 101:             ",
          "match": "def run(self, n_steps:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 107,
          "context": " 104:                 callback: Optional function called after each step with simulator as argument\n 105:                 \n 106:             Example:\n 107: >>>             >>> def monitor(sim):\n 108:                 ...     if sim.step_count % 10 == 0:\n 109:                 ...         print(f\"Step {sim.step_count}, E={sim.energy:.3e}\")\n 110:                 >>> sim.run(100, callback=monitor)",
          "match": "def monitor(sim):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 117,
          "context": " 114:                 if callback is not None:\n 115:                     callback(self)\n 116:                     \n 117: >>>     def run_until(self, t_final: float, callback: Optional[Callable] = None) -> None:\n 118:             \"\"\"\n 119:             Run simulation until time t >= t_final.\n 120:             ",
          "match": "def run_until(self, t_final:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 134,
          "context": " 131:         # State Manipulation\n 132:         # ----------------------------------------------------------------\n 133:         \n 134: >>>     def reset(self, field: Optional[np.ndarray] = None) -> None:\n 135:             \"\"\"\n 136:             Reset simulation to initial state.\n 137:             ",
          "match": "def reset(self, field:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 156,
          "context": " 153:             self._time_history.clear()\n 154:             self._total_step_time = 0.0\n 155:             \n 156: >>>     def add_gaussian_pulse(self, center: Tuple[int, ...], amplitude: float = 1.0, width: float = 3.0) -> None:\n 157:             \"\"\"\n 158:             Add Gaussian pulse to current field.\n 159:             ",
          "match": "def add_gaussian_pulse(self, center:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 189,
          "context": " 186:                 r_sq = (x - cx)**2 + (y - cy)**2 + (z - cz)**2\n 187:                 self.E += amplitude * np.exp(-r_sq / (2 * width**2))\n 188:                 \n 189: >>>     def add_plane_wave(self, axis: int, position: int, amplitude: float = 1.0, width: float = 3.0) -> None:\n 190:             \"\"\"\n 191:             Add plane wave pulse perpendicular to specified axis.\n 192:             ",
          "match": "def add_plane_wave(self, axis:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 219,
          "context": " 216:         # ----------------------------------------------------------------\n 217:         \n 218:         @property\n 219: >>>     def energy(self) -> float:\n 220:             \"\"\"\n 221:             Current total energy (kinetic + potential + mass).\n 222:             ",
          "match": "def energy(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 231,
          "context": " 228:                                self.config.c, self.config.chi)\n 229:             \n 230:         @property\n 231: >>>     def cfl_ratio(self) -> float:\n 232:             \"\"\"Current CFL ratio: (c * dt) / dx\"\"\"\n 233:             return self.config.cfl_ratio(self.ndim)\n 234:             ",
          "match": "def cfl_ratio(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 236,
          "context": " 233:             return self.config.cfl_ratio(self.ndim)\n 234:             \n 235:         @property\n 236: >>>     def cfl_limit(self) -> float:\n 237:             \"\"\"CFL stability limit for current dimensionality.\"\"\"\n 238:             return self.config.cfl_limit(self.ndim)\n 239:             ",
          "match": "def cfl_limit(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 241,
          "context": " 238:             return self.config.cfl_limit(self.ndim)\n 239:             \n 240:         @property\n 241: >>>     def is_stable(self) -> bool:\n 242:             \"\"\"Check if current configuration satisfies CFL condition.\"\"\"\n 243:             return self.config.is_stable(self.ndim)\n 244:             ",
          "match": "def is_stable(self) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 245,
          "context": " 242:             \"\"\"Check if current configuration satisfies CFL condition.\"\"\"\n 243:             return self.config.is_stable(self.ndim)\n 244:             \n 245: >>>     def field_stats(self) -> Dict[str, float]:\n 246:             \"\"\"\n 247:             Get statistical summary of current field.\n 248:             ",
          "match": "def field_stats(self) -> Dict[str, float]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 260,
          "context": " 257:                 'rms': float(np.sqrt(np.mean(self.E**2))),\n 258:             }\n 259:             \n 260: >>>     def performance_stats(self) -> Dict[str, float]:\n 261:             \"\"\"\n 262:             Get performance statistics.\n 263:             ",
          "match": "def performance_stats(self) -> Dict[str, float]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 279,
          "context": " 276:         # Save/Load State\n 277:         # ----------------------------------------------------------------\n 278:         \n 279: >>>     def get_state(self) -> Dict[str, Any]:\n 280:             \"\"\"\n 281:             Get complete simulation state for saving/checkpointing.\n 282:             ",
          "match": "def get_state(self) -> Dict[str, Any]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 296,
          "context": " 293:                 'time_history': self._time_history.copy(),\n 294:             }\n 295:             \n 296: >>>     def set_state(self, state: Dict[str, Any]) -> None:\n 297:             \"\"\"\n 298:             Restore simulation from saved state.\n 299:             ",
          "match": "def set_state(self, state:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 316,
          "context": " 313:             if 'time_history' in state:\n 314:                 self._time_history = state['time_history'].copy()\n 315:                 \n 316: >>>     def save_checkpoint(self, filepath: str) -> None:\n 317:             \"\"\"\n 318:             Save simulation state to file.\n 319:             ",
          "match": "def save_checkpoint(self, filepath:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 327,
          "context": " 324:             np.savez_compressed(filepath, **state)\n 325:             \n 326:         @classmethod\n 327: >>>     def load_checkpoint(cls, filepath: str) -> LFMSimulator:\n 328:             \"\"\"\n 329:             Load simulation from checkpoint file.\n 330:             ",
          "match": "def load_checkpoint(cls, filepath:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 347,
          "context": " 344:         # String Representation\n 345:         # ----------------------------------------------------------------\n 346:         \n 347: >>>     def __repr__(self) -> str:\n 348:             \"\"\"Concise representation of simulator state.\"\"\"\n 349:             return (\n 350:                 f\"LFMSimulator(shape={self.E.shape}, t={self.t:.2f}, \"",
          "match": "def __repr__(self) -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 354,
          "context": " 351:                 f\"steps={self.step_count}, E={self.energy:.3e})\"\n 352:             )\n 353:             \n 354: >>>     def summary(self) -> str:\n 355:             \"\"\"\n 356:             Detailed summary of simulation state.\n 357:             ",
          "match": "def summary(self) -> str:"
        },
        {
          "type": "Advanced implementation pattern",
          "pattern": "@staticmethod|@classmethod",
          "line": 326,
          "context": " 323:             state = self.get_state()\n 324:             np.savez_compressed(filepath, **state)\n 325:             \n 326: >>>     @classmethod\n 327:         def load_checkpoint(cls, filepath: str) -> LFMSimulator:\n 328:             \"\"\"\n 329:             Load simulation from checkpoint file.",
          "match": "@classmethod"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 64,
          "context": "  61:             self._total_step_time = 0.0\n  62:             self._last_step_time = 0.0\n  63:             \n  64: >>>         # Validate CFL condition\n  65:             if not config.is_stable(self.ndim):\n  66:                 import warnings\n  67:                 warnings.warn(",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 68,
          "context": "  65:             if not config.is_stable(self.ndim):\n  66:                 import warnings\n  67:                 warnings.warn(\n  68: >>>                 f\"CFL ratio {config.cfl_ratio(self.ndim):.3f} exceeds \"\n  69:                     f\"stability limit {config.cfl_limit(self.ndim):.3f}\",\n  70:                     UserWarning\n  71:                 )",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 68,
          "context": "  65:             if not config.is_stable(self.ndim):\n  66:                 import warnings\n  67:                 warnings.warn(\n  68: >>>                 f\"CFL ratio {config.cfl_ratio(self.ndim):.3f} exceeds \"\n  69:                     f\"stability limit {config.cfl_limit(self.ndim):.3f}\",\n  70:                     UserWarning\n  71:                 )",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 69,
          "context": "  66:                 import warnings\n  67:                 warnings.warn(\n  68:                     f\"CFL ratio {config.cfl_ratio(self.ndim):.3f} exceeds \"\n  69: >>>                 f\"stability limit {config.cfl_limit(self.ndim):.3f}\",\n  70:                     UserWarning\n  71:                 )\n  72:         ",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 69,
          "context": "  66:                 import warnings\n  67:                 warnings.warn(\n  68:                     f\"CFL ratio {config.cfl_ratio(self.ndim):.3f} exceeds \"\n  69: >>>                 f\"stability limit {config.cfl_limit(self.ndim):.3f}\",\n  70:                     UserWarning\n  71:                 )\n  72:         ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 231,
          "context": " 228:                                self.config.c, self.config.chi)\n 229:             \n 230:         @property\n 231: >>>     def cfl_ratio(self) -> float:\n 232:             \"\"\"Current CFL ratio: (c * dt) / dx\"\"\"\n 233:             return self.config.cfl_ratio(self.ndim)\n 234:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 232,
          "context": " 229:             \n 230:         @property\n 231:         def cfl_ratio(self) -> float:\n 232: >>>         \"\"\"Current CFL ratio: (c * dt) / dx\"\"\"\n 233:             return self.config.cfl_ratio(self.ndim)\n 234:             \n 235:         @property",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 233,
          "context": " 230:         @property\n 231:         def cfl_ratio(self) -> float:\n 232:             \"\"\"Current CFL ratio: (c * dt) / dx\"\"\"\n 233: >>>         return self.config.cfl_ratio(self.ndim)\n 234:             \n 235:         @property\n 236:         def cfl_limit(self) -> float:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 236,
          "context": " 233:             return self.config.cfl_ratio(self.ndim)\n 234:             \n 235:         @property\n 236: >>>     def cfl_limit(self) -> float:\n 237:             \"\"\"CFL stability limit for current dimensionality.\"\"\"\n 238:             return self.config.cfl_limit(self.ndim)\n 239:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 237,
          "context": " 234:             \n 235:         @property\n 236:         def cfl_limit(self) -> float:\n 237: >>>         \"\"\"CFL stability limit for current dimensionality.\"\"\"\n 238:             return self.config.cfl_limit(self.ndim)\n 239:             \n 240:         @property",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 237,
          "context": " 234:             \n 235:         @property\n 236:         def cfl_limit(self) -> float:\n 237: >>>         \"\"\"CFL stability limit for current dimensionality.\"\"\"\n 238:             return self.config.cfl_limit(self.ndim)\n 239:             \n 240:         @property",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 238,
          "context": " 235:         @property\n 236:         def cfl_limit(self) -> float:\n 237:             \"\"\"CFL stability limit for current dimensionality.\"\"\"\n 238: >>>         return self.config.cfl_limit(self.ndim)\n 239:             \n 240:         @property\n 241:         def is_stable(self) -> bool:",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 242,
          "context": " 239:             \n 240:         @property\n 241:         def is_stable(self) -> bool:\n 242: >>>         \"\"\"Check if current configuration satisfies CFL condition.\"\"\"\n 243:             return self.config.is_stable(self.ndim)\n 244:             \n 245:         def field_stats(self) -> Dict[str, float]:",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 388,
          "context": " 385:                 f\"  Steps/sec: {perf['steps_per_sec']:.1f}\",\n 386:                 f\"  Avg step time: {perf['avg_step_time']*1000:.2f} ms\",\n 387:                 f\"\",\n 388: >>>             f\"Stability:\",\n 389:                 f\"  CFL ratio: {self.cfl_ratio:.3f} / {self.cfl_limit:.3f}\",\n 390:                 f\"  Stable: {'✓' if self.is_stable else '✗'}\",\n 391:             ]",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 389,
          "context": " 386:                 f\"  Avg step time: {perf['avg_step_time']*1000:.2f} ms\",\n 387:                 f\"\",\n 388:                 f\"Stability:\",\n 389: >>>             f\"  CFL ratio: {self.cfl_ratio:.3f} / {self.cfl_limit:.3f}\",\n 390:                 f\"  Stable: {'✓' if self.is_stable else '✗'}\",\n 391:             ]\n 392:             ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 389,
          "context": " 386:                 f\"  Avg step time: {perf['avg_step_time']*1000:.2f} ms\",\n 387:                 f\"\",\n 388:                 f\"Stability:\",\n 389: >>>             f\"  CFL ratio: {self.cfl_ratio:.3f} / {self.cfl_limit:.3f}\",\n 390:                 f\"  Stable: {'✓' if self.is_stable else '✗'}\",\n 391:             ]\n 392:             ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 389,
          "context": " 386:                 f\"  Avg step time: {perf['avg_step_time']*1000:.2f} ms\",\n 387:                 f\"\",\n 388:                 f\"Stability:\",\n 389: >>>             f\"  CFL ratio: {self.cfl_ratio:.3f} / {self.cfl_limit:.3f}\",\n 390:                 f\"  Stable: {'✓' if self.is_stable else '✗'}\",\n 391:             ]\n 392:             ",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 371,
          "context": " 368:                 f\"  Grid: {self.E.shape} ({self.ndim}D)\",\n 369:                 f\"  dt={self.config.dt}, dx={self.config.dx}\",\n 370:                 f\"  c={self.config.c:.3f}, chi={self.config.chi}\",\n 371: >>>             f\"  Boundary: {self.config.boundary}\",\n 372:                 f\"\",\n 373:                 f\"State:\",\n 374:                 f\"  Time: {self.t:.3f}\",",
          "match": "Boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 371,
          "context": " 368:                 f\"  Grid: {self.E.shape} ({self.ndim}D)\",\n 369:                 f\"  dt={self.config.dt}, dx={self.config.dx}\",\n 370:                 f\"  c={self.config.c:.3f}, chi={self.config.chi}\",\n 371: >>>             f\"  Boundary: {self.config.boundary}\",\n 372:                 f\"\",\n 373:                 f\"State:\",\n 374:                 f\"  Time: {self.t:.3f}\",",
          "match": "boundary"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 81,
          "context": "  78:             \"\"\"\n  79:             Advance simulation by one timestep: t → t + dt.\n  80:             \n  81: >>>         Updates E_prev and E using Verlet integration via lattice_step().\n  82:             \"\"\"\n  83:             t0 = time.perf_counter()\n  84:             ",
          "match": "integration"
        }
      ],
      "line_count": 393,
      "docstring": "lfm_simulator.py — High-level simulation engine with state management\n\nProvides LFMSimulator class that encapsulates lattice state and evolution,\noffering a clean API for interactive tools, test harnesses, and analysis."
    },
    {
      "filepath": "lfm_tiers.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "fb99306dda7d1e06",
      "file_size": 4740,
      "modified": "2025-11-03T13:19:47.829961",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 84,
          "context": "  81:     _REGISTRY_CACHE: Optional[List[Dict]] = None\n  82:     \n  83:     \n  84: >>> def get_tiers() -> List[Dict]:\n  85:         \"\"\"Return the list of tier definitions from JSON or defaults.\n  86:     \n  87:         The array is sorted by tier number.",
          "match": "def get_tiers() -> List[Dict]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 120,
          "context": " 117:         return _REGISTRY_CACHE\n 118:     \n 119:     \n 120: >>> def get_tier_by_number(tier: int) -> Optional[Dict]:\n 121:         for t in get_tiers():\n 122:             if int(t[\"tier\"]) == int(tier):\n 123:                 return t",
          "match": "def get_tier_by_number(tier:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 127,
          "context": " 124:         return None\n 125:     \n 126:     \n 127: >>> def get_by_prefix(prefix: str) -> Optional[Dict]:\n 128:         p = prefix.upper().strip()\n 129:         for t in get_tiers():\n 130:             if t[\"prefix\"].upper() == p:",
          "match": "def get_by_prefix(prefix:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 135,
          "context": " 132:         return None\n 133:     \n 134:     \n 135: >>> def canonical_id_regex_for(tier: int) -> re.Pattern:\n 136:         t = get_tier_by_number(tier)\n 137:         import re as _re\n 138:         if not t:",
          "match": "def canonical_id_regex_for(tier:"
        }
      ],
      "line_count": 140,
      "docstring": "Central Tier Registry for LFM test suites.\n\nProvides a single source of truth for:\n- Tier number\n- Display/category names\n- Results directory name\n- Test ID prefix and canonical ID pattern\n- Runner script path\n- Config file path and schema type\n- Expected test count (for reporting)\n\nReads from config/tiers_registry.json if present; otherwise falls back to the\ncurrent default tiers (1-4). This allows adding Tier 5 by editing the JSON only."
    },
    {
      "filepath": "lorentz_transform.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "f90935bbbc09674c",
      "file_size": 10040,
      "modified": "2025-11-02T20:02:10.879487",
      "git_info": {
        "first_commit": {
          "hash": "f0885273",
          "date": "2025-10-30 17:51:45 -0700",
          "message": "Additional tests, harnesses"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     from typing import Tuple, Dict, Optional\n  23:     import math\n  24:     \n  25: >>> def lorentz_factor(beta: float) -> float:\n  26:         \"\"\"Compute Lorentz gamma factor: γ = 1/√(1-β²)\"\"\"\n  27:         return 1.0 / math.sqrt(1.0 - beta**2)\n  28:     ",
          "match": "def lorentz_factor(beta:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 29,
          "context": "  26:         \"\"\"Compute Lorentz gamma factor: γ = 1/√(1-β²)\"\"\"\n  27:         return 1.0 / math.sqrt(1.0 - beta**2)\n  28:     \n  29: >>> def lorentz_boost_coordinates(x: np.ndarray, t: float, beta: float, c: float = 1.0) -> Tuple[np.ndarray, float]:\n  30:         \"\"\"\n  31:         Transform coordinates from lab frame to moving frame.\n  32:         ",
          "match": "def lorentz_boost_coordinates(x:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 52,
          "context": "  49:         t_prime = gamma * (t - beta * x / c)\n  50:         return x_prime, t_prime\n  51:     \n  52: >>> def lorentz_boost_field_1d(E_lab: np.ndarray, x_lab: np.ndarray, t_lab: float,\n  53:                                 beta: float, c: float = 1.0,\n  54:                                 kind: str = 'cubic') -> Tuple[np.ndarray, np.ndarray, float]:\n  55:         \"\"\"",
          "match": "def lorentz_boost_field_1d(E_lab:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 110,
          "context": " 107:         \n 108:         return E_prime, x_prime, t_prime\n 109:     \n 110: >>> def compute_klein_gordon_residual(E: np.ndarray, E_prev: np.ndarray, \n 111:                                        dt: float, dx: float, chi: float, \n 112:                                        c: float = 1.0, order: int = 2) -> np.ndarray:\n 113:         \"\"\"",
          "match": "def compute_klein_gordon_residual(E:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 232,
          "context": " 229:             'covariance_ratio': float(np.mean(residuals_boost) / (np.mean(residuals_lab) + 1e-30))\n 230:         }\n 231:     \n 232: >>> def test_lorentz_transform():\n 233:         \"\"\"Unit test for Lorentz transformation.\"\"\"\n 234:         print(\"Testing Lorentz transformation...\")\n 235:         ",
          "match": "def test_lorentz_transform():"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 96,
          "context": "  93:         x_needed = gamma * (x_prime + beta * c * t_prime)\n  94:         \n  95:         # Interpolate E_lab to these positions\n  96: >>>     # Handle periodic boundary conditions\n  97:         L = x_lab[-1] - x_lab[0] + (x_lab[1] - x_lab[0])  # Domain length\n  98:         x_needed_wrapped = np.mod(x_needed - x_lab[0], L) + x_lab[0]\n  99:         ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 96,
          "context": "  93:         x_needed = gamma * (x_prime + beta * c * t_prime)\n  94:         \n  95:         # Interpolate E_lab to these positions\n  96: >>>     # Handle periodic boundary conditions\n  97:         L = x_lab[-1] - x_lab[0] + (x_lab[1] - x_lab[0])  # Domain length\n  98:         x_needed_wrapped = np.mod(x_needed - x_lab[0], L) + x_lab[0]\n  99:         ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 100,
          "context": "  97:         L = x_lab[-1] - x_lab[0] + (x_lab[1] - x_lab[0])  # Domain length\n  98:         x_needed_wrapped = np.mod(x_needed - x_lab[0], L) + x_lab[0]\n  99:         \n 100: >>>     # Create interpolator (periodic)\n 101:         E_periodic = np.concatenate([E_lab, [E_lab[0]]])  # Add periodic point\n 102:         x_periodic = np.concatenate([x_lab, [x_lab[-1] + (x_lab[1] - x_lab[0])]])\n 103:         ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 101,
          "context": "  98:         x_needed_wrapped = np.mod(x_needed - x_lab[0], L) + x_lab[0]\n  99:         \n 100:         # Create interpolator (periodic)\n 101: >>>     E_periodic = np.concatenate([E_lab, [E_lab[0]]])  # Add periodic point\n 102:         x_periodic = np.concatenate([x_lab, [x_lab[-1] + (x_lab[1] - x_lab[0])]])\n 103:         \n 104:         interpolator = interp1d(x_periodic, E_periodic, kind=kind, ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 101,
          "context": "  98:         x_needed_wrapped = np.mod(x_needed - x_lab[0], L) + x_lab[0]\n  99:         \n 100:         # Create interpolator (periodic)\n 101: >>>     E_periodic = np.concatenate([E_lab, [E_lab[0]]])  # Add periodic point\n 102:         x_periodic = np.concatenate([x_lab, [x_lab[-1] + (x_lab[1] - x_lab[0])]])\n 103:         \n 104:         interpolator = interp1d(x_periodic, E_periodic, kind=kind, ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 102,
          "context": "  99:         \n 100:         # Create interpolator (periodic)\n 101:         E_periodic = np.concatenate([E_lab, [E_lab[0]]])  # Add periodic point\n 102: >>>     x_periodic = np.concatenate([x_lab, [x_lab[-1] + (x_lab[1] - x_lab[0])]])\n 103:         \n 104:         interpolator = interp1d(x_periodic, E_periodic, kind=kind, \n 105:                                bounds_error=False, fill_value='extrapolate')",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 104,
          "context": " 101:         E_periodic = np.concatenate([E_lab, [E_lab[0]]])  # Add periodic point\n 102:         x_periodic = np.concatenate([x_lab, [x_lab[-1] + (x_lab[1] - x_lab[0])]])\n 103:         \n 104: >>>     interpolator = interp1d(x_periodic, E_periodic, kind=kind, \n 105:                                bounds_error=False, fill_value='extrapolate')\n 106:         E_prime = interpolator(x_needed_wrapped)\n 107:         ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 104,
          "context": " 101:         E_periodic = np.concatenate([E_lab, [E_lab[0]]])  # Add periodic point\n 102:         x_periodic = np.concatenate([x_lab, [x_lab[-1] + (x_lab[1] - x_lab[0])]])\n 103:         \n 104: >>>     interpolator = interp1d(x_periodic, E_periodic, kind=kind, \n 105:                                bounds_error=False, fill_value='extrapolate')\n 106:         E_prime = interpolator(x_needed_wrapped)\n 107:         ",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 146,
          "context": " 143:         else:\n 144:             raise ValueError(\"order must be 2 or 4\")\n 145:         \n 146: >>>     # From leapfrog: E_next = 2E - E_prev + dt²(c²∇²E - χ²E)\n 147:         # So: (E_next - 2E + E_prev)/dt² = c²∇²E - χ²E\n 148:         # Residual = (E_next - 2E + E_prev)/dt² - c²∇²E + χ²E\n 149:         # If we're on-shell, this should be zero",
          "match": "leapfrog"
        }
      ],
      "line_count": 265,
      "docstring": "Lorentz Transformation Module for LFM\n\nImplements proper Lorentz transformations for testing actual frame covariance,\nnot just Doppler-shifted frequency comparisons.\n\nKey functions:\n- lorentz_boost_coordinates: Transform spacetime coordinates\n- lorentz_boost_field_1d: Transform scalar field E(x,t) to moving frame\n- verify_klein_gordon_boosted: Check if KG equation holds in boosted frame"
    },
    {
      "filepath": "numeric_integrity.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "25930b3a238d3a17",
      "file_size": 3435,
      "modified": "2025-11-02T20:02:10.879487",
      "git_info": {
        "first_commit": {
          "hash": "3dcfab31",
          "date": "2025-10-27 15:37:08 -0700",
          "message": "update tests"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 19,
          "context": "  16:     from lfm_console import log\n  17:     \n  18:     \n  19: >>> class NumericIntegrityMixin:\n  20:         \"\"\"Attach to any test harness or solver for auto-checks.\n  21:     \n  22:         This mixin avoids spamming the console with repeated identical",
          "match": "class NumericIntegrityMixin:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 27,
          "context": "  24:         produced a warning. When the drift falls back below the tolerance\n  25:         the cached state is cleared so future violations will be reported.\n  26:         \"\"\"\n  27: >>>     def validate_field(self, E, label=\"field\"):\n  28:             if not np.all(np.isfinite(E)):\n  29:                 raise ValueError(f\"[{label}] NaN or Inf detected.\")\n  30:             if np.max(np.abs(E)) > 1e6:",
          "match": "def validate_field(self, E, label=\"field\"):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 34,
          "context": "  31:                 raise ValueError(f\"[{label}] amplitude blow-up > 1e6.\")\n  32:             return True\n  33:     \n  34: >>>     def check_cfl(self, c, dt, dx, ndim):\n  35:             limit = 1.0 / math.sqrt(ndim)\n  36:             if c * dt / dx > limit:\n  37:                 raise ValueError(f\"CFL violation: c*dt/dx={c*dt/dx:.3f} > {limit:.3f}.\")",
          "match": "def check_cfl(self, c, dt, dx, ndim):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 40,
          "context": "  37:                 raise ValueError(f\"CFL violation: c*dt/dx={c*dt/dx:.3f} > {limit:.3f}.\")\n  38:             return True\n  39:     \n  40: >>>     def validate_energy(self, drift: float, tol: float = 1e-6, label: str = \"energy\") -> bool:\n  41:             \"\"\"Warn once per sustained violation for a given `label`.\n  42:     \n  43:             Rules:",
          "match": "def validate_energy(self, drift:"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 9,
          "context": "   6:     # Contact: latticefieldmediumresearch@gmail.com\n   7:     \n   8:     \"\"\"\n   9: >>> numeric_integrity.py — universal field and CFL validation for LFM\n  10:     v1.0.0\n  11:     \"\"\"\n  12:     ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 34,
          "context": "  31:                 raise ValueError(f\"[{label}] amplitude blow-up > 1e6.\")\n  32:             return True\n  33:     \n  34: >>>     def check_cfl(self, c, dt, dx, ndim):\n  35:             limit = 1.0 / math.sqrt(ndim)\n  36:             if c * dt / dx > limit:\n  37:                 raise ValueError(f\"CFL violation: c*dt/dx={c*dt/dx:.3f} > {limit:.3f}.\")",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 37,
          "context": "  34:         def check_cfl(self, c, dt, dx, ndim):\n  35:             limit = 1.0 / math.sqrt(ndim)\n  36:             if c * dt / dx > limit:\n  37: >>>             raise ValueError(f\"CFL violation: c*dt/dx={c*dt/dx:.3f} > {limit:.3f}.\")\n  38:             return True\n  39:     \n  40:         def validate_energy(self, drift: float, tol: float = 1e-6, label: str = \"energy\") -> bool:",
          "match": "CFL"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 20,
          "context": "  17:     \n  18:     \n  19:     class NumericIntegrityMixin:\n  20: >>>     \"\"\"Attach to any test harness or solver for auto-checks.\n  21:     \n  22:         This mixin avoids spamming the console with repeated identical\n  23:         energy warnings by caching whether a given `label` has already",
          "match": "solver"
        }
      ],
      "line_count": 87,
      "docstring": "numeric_integrity.py — universal field and CFL validation for LFM\nv1.0.0"
    },
    {
      "filepath": "pre_commit_audit.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "654e148060c592d6",
      "file_size": 6519,
      "modified": "2025-11-03T13:19:47.964527",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 20,
          "context": "  17:     from pathlib import Path\n  18:     import subprocess\n  19:     \n  20: >>> def check_git_status():\n  21:         \"\"\"Check what files are staged for commit\"\"\"\n  22:         try:\n  23:             result = subprocess.run(['git', 'status', '--porcelain'], ",
          "match": "def check_git_status():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:         except:\n  29:             return []\n  30:     \n  31: >>> def check_sensitive_content():\n  32:         \"\"\"Look for potentially sensitive information\"\"\"\n  33:         code_dir = Path(__file__).parent\n  34:         issues = []",
          "match": "def check_sensitive_content():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:         \n  57:         return issues\n  58:     \n  59: >>> def check_license_consistency():\n  60:         \"\"\"Verify license information is consistent across files\"\"\"\n  61:         issues = []\n  62:         ",
          "match": "def check_license_consistency():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 74,
          "context": "  71:         \n  72:         return issues\n  73:     \n  74: >>> def main():\n  75:         \"\"\"Main pre-commit audit\"\"\"\n  76:         print(\"=\" * 70)\n  77:         print(\"  LFM PRE-COMMIT IP AUDIT - FINAL REVIEW\")",
          "match": "def main():"
        }
      ],
      "line_count": 183,
      "docstring": "Pre-Commit IP Audit - Final Review\n==================================\nComprehensive final check for IP protection compliance before git commit.\nEnsures all files are properly protected and ready for public distribution."
    },
    {
      "filepath": "resource_tracking.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "efc4f039878f7319",
      "file_size": 9501,
      "modified": "2025-11-02T20:02:10.887873",
      "git_info": {
        "first_commit": {
          "hash": "ef0dcb6b",
          "date": "2025-11-01 09:54:35 -0700",
          "message": "Testing framework improvements"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 45,
          "context": "  42:         psutil = None\n  43:     \n  44:     \n  45: >>> class ResourceTracker:\n  46:         \"\"\"\n  47:         Track CPU, RAM, and GPU usage during test execution.\n  48:         ",
          "match": "class ResourceTracker:"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 237,
          "context": " 234:             return 0.0\n 235:     \n 236:     \n 237: >>> class DummyResourceTracker:\n 238:         \"\"\"\n 239:         Dummy tracker that returns zeros when psutil is not available.\n 240:         Allows tests to run without psutil but with degraded metrics.",
          "match": "class DummyResourceTracker:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:         Supports both manual sampling and background monitoring.\n  55:         \"\"\"\n  56:         \n  57: >>>     def __init__(self, sample_interval: float = 0.5):\n  58:             \"\"\"\n  59:             Initialize resource tracker.\n  60:             ",
          "match": "def __init__(self, sample_interval:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 83,
          "context": "  80:             self._monitor_thread = None\n  81:             self._stop_event = threading.Event()\n  82:             \n  83: >>>     def start(self, background: bool = False):\n  84:             \"\"\"\n  85:             Begin tracking resources.\n  86:             ",
          "match": "def start(self, background:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 114,
          "context": " 111:             if background:\n 112:                 self.start_background_monitoring()\n 113:         \n 114: >>>     def stop(self):\n 115:             \"\"\"Stop tracking and finalize metrics.\"\"\"\n 116:             self.stop_time = time.time()\n 117:             if self._monitoring:",
          "match": "def stop(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 120,
          "context": " 117:             if self._monitoring:\n 118:                 self.stop_background_monitoring()\n 119:         \n 120: >>>     def sample(self):\n 121:             \"\"\"\n 122:             Sample current resource usage and update peaks.\n 123:             ",
          "match": "def sample(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 149,
          "context": " 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147:                 self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149: >>>     def start_background_monitoring(self):\n 150:             \"\"\"Start background thread for continuous sampling.\"\"\"\n 151:             if self._monitoring:\n 152:                 return  # Already monitoring",
          "match": "def start_background_monitoring(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 162,
          "context": " 159:             )\n 160:             self._monitor_thread.start()\n 161:         \n 162: >>>     def stop_background_monitoring(self):\n 163:             \"\"\"Stop background monitoring thread.\"\"\"\n 164:             if not self._monitoring:\n 165:                 return",
          "match": "def stop_background_monitoring(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 172,
          "context": " 169:                 self._monitor_thread.join(timeout=2.0)\n 170:             self._monitoring = False\n 171:         \n 172: >>>     def _monitor_loop(self):\n 173:             \"\"\"Background monitoring loop.\"\"\"\n 174:             while not self._stop_event.is_set():\n 175:                 self.sample()",
          "match": "def _monitor_loop(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 178,
          "context": " 175:                 self.sample()\n 176:                 self._stop_event.wait(self.sample_interval)\n 177:         \n 178: >>>     def get_metrics(self) -> Dict:\n 179:             \"\"\"\n 180:             Return collected metrics.\n 181:             ",
          "match": "def get_metrics(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 201,
          "context": " 198:                 \"runtime_sec\": float(runtime)\n 199:             }\n 200:         \n 201: >>>     def _check_gpu_available(self) -> bool:\n 202:             \"\"\"Check if nvidia-smi is available.\"\"\"\n 203:             try:\n 204:                 result = subprocess.run(",
          "match": "def _check_gpu_available(self) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 214,
          "context": " 211:             except Exception:\n 212:                 return False\n 213:         \n 214: >>>     def _query_gpu_total_mb(self) -> float:\n 215:             \"\"\"Query total GPU memory used (system-wide) via nvidia-smi.\"\"\"\n 216:             try:\n 217:                 result = subprocess.run(",
          "match": "def _query_gpu_total_mb(self) -> float:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 243,
          "context": " 240:         Allows tests to run without psutil but with degraded metrics.\n 241:         \"\"\"\n 242:         \n 243: >>>     def __init__(self, sample_interval: float = 0.5):\n 244:             self.start_time = None\n 245:             self.stop_time = None\n 246:         ",
          "match": "def __init__(self, sample_interval:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 247,
          "context": " 244:             self.start_time = None\n 245:             self.stop_time = None\n 246:         \n 247: >>>     def start(self, background: bool = False):\n 248:             self.start_time = time.time()\n 249:         \n 250:         def stop(self):",
          "match": "def start(self, background:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 250,
          "context": " 247:         def start(self, background: bool = False):\n 248:             self.start_time = time.time()\n 249:         \n 250: >>>     def stop(self):\n 251:             self.stop_time = time.time()\n 252:         \n 253:         def sample(self):",
          "match": "def stop(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 253,
          "context": " 250:         def stop(self):\n 251:             self.stop_time = time.time()\n 252:         \n 253: >>>     def sample(self):\n 254:             pass\n 255:         \n 256:         def start_background_monitoring(self):",
          "match": "def sample(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 256,
          "context": " 253:         def sample(self):\n 254:             pass\n 255:         \n 256: >>>     def start_background_monitoring(self):\n 257:             pass\n 258:         \n 259:         def stop_background_monitoring(self):",
          "match": "def start_background_monitoring(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 259,
          "context": " 256:         def start_background_monitoring(self):\n 257:             pass\n 258:         \n 259: >>>     def stop_background_monitoring(self):\n 260:             pass\n 261:         \n 262:         def get_metrics(self) -> Dict:",
          "match": "def stop_background_monitoring(self):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 262,
          "context": " 259:         def stop_background_monitoring(self):\n 260:             pass\n 261:         \n 262: >>>     def get_metrics(self) -> Dict:\n 263:             runtime = 0.0\n 264:             if self.start_time:\n 265:                 end = self.stop_time if self.stop_time else time.time()",
          "match": "def get_metrics(self) -> Dict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 276,
          "context": " 273:             }\n 274:     \n 275:     \n 276: >>> def create_resource_tracker(sample_interval: float = 0.5) -> ResourceTracker:\n 277:         \"\"\"\n 278:         Factory function to create appropriate resource tracker.\n 279:         ",
          "match": "def create_resource_tracker(sample_interval:"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 12,
          "context": "   9:     resource_tracking.py — Resource Monitoring for LFM Test Runners\n  10:     ---------------------------------------------------------------\n  11:     Purpose:\n  12: >>>     Track CPU, RAM, and GPU usage during test execution to collect\n  13:         accurate resource metrics for performance analysis and budgeting.\n  14:     \n  15:     Features:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 17,
          "context": "  14:     \n  15:     Features:\n  16:         - Per-process CPU and memory tracking via psutil\n  17: >>>     - GPU memory tracking via nvidia-smi (if available)\n  18:         - Lightweight sampling with minimal overhead\n  19:         - Thread-safe background monitoring for long-running tests\n  20:     ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 47,
          "context": "  44:     \n  45:     class ResourceTracker:\n  46:         \"\"\"\n  47: >>>     Track CPU, RAM, and GPU usage during test execution.\n  48:         \n  49:         Monitors the current process and records peak usage for:\n  50:         - CPU percentage (multi-core aware)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 52,
          "context": "  49:         Monitors the current process and records peak usage for:\n  50:         - CPU percentage (multi-core aware)\n  51:         - Memory (RSS in MB)\n  52: >>>     - GPU memory (if nvidia-smi available)\n  53:         \n  54:         Supports both manual sampling and background monitoring.\n  55:         \"\"\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:             # Metrics\n  67:             self.peak_cpu = 0.0\n  68:             self.peak_memory_mb = 0.0\n  69: >>>         self.peak_gpu_mb = 0.0\n  70:             self.start_time = None\n  71:             self.stop_time = None\n  72:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 75,
          "context": "  72:             \n  73:             # Process handle\n  74:             self._process = None\n  75: >>>         self._gpu_available = None  # Cache GPU availability check\n  76:             self._gpu_baseline_mb = 0.0  # Baseline GPU usage before test\n  77:             \n  78:             # Background monitoring",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 75,
          "context": "  72:             \n  73:             # Process handle\n  74:             self._process = None\n  75: >>>         self._gpu_available = None  # Cache GPU availability check\n  76:             self._gpu_baseline_mb = 0.0  # Baseline GPU usage before test\n  77:             \n  78:             # Background monitoring",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 76,
          "context": "  73:             # Process handle\n  74:             self._process = None\n  75:             self._gpu_available = None  # Cache GPU availability check\n  76: >>>         self._gpu_baseline_mb = 0.0  # Baseline GPU usage before test\n  77:             \n  78:             # Background monitoring\n  79:             self._monitoring = False",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 76,
          "context": "  73:             # Process handle\n  74:             self._process = None\n  75:             self._gpu_available = None  # Cache GPU availability check\n  76: >>>         self._gpu_baseline_mb = 0.0  # Baseline GPU usage before test\n  77:             \n  78:             # Background monitoring\n  79:             self._monitoring = False",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 103,
          "context": " 100:             else:\n 101:                 self._process = None\n 102:             \n 103: >>>         # Check GPU availability and get baseline\n 104:             if self._gpu_available is None:\n 105:                 self._gpu_available = self._check_gpu_available()\n 106:             ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 104,
          "context": " 101:                 self._process = None\n 102:             \n 103:             # Check GPU availability and get baseline\n 104: >>>         if self._gpu_available is None:\n 105:                 self._gpu_available = self._check_gpu_available()\n 106:             \n 107:             if self._gpu_available:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 105,
          "context": " 102:             \n 103:             # Check GPU availability and get baseline\n 104:             if self._gpu_available is None:\n 105: >>>             self._gpu_available = self._check_gpu_available()\n 106:             \n 107:             if self._gpu_available:\n 108:                 self._gpu_baseline_mb = self._query_gpu_total_mb()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 105,
          "context": " 102:             \n 103:             # Check GPU availability and get baseline\n 104:             if self._gpu_available is None:\n 105: >>>             self._gpu_available = self._check_gpu_available()\n 106:             \n 107:             if self._gpu_available:\n 108:                 self._gpu_baseline_mb = self._query_gpu_total_mb()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 107,
          "context": " 104:             if self._gpu_available is None:\n 105:                 self._gpu_available = self._check_gpu_available()\n 106:             \n 107: >>>         if self._gpu_available:\n 108:                 self._gpu_baseline_mb = self._query_gpu_total_mb()\n 109:             \n 110:             # Start background monitoring if requested",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 108,
          "context": " 105:                 self._gpu_available = self._check_gpu_available()\n 106:             \n 107:             if self._gpu_available:\n 108: >>>             self._gpu_baseline_mb = self._query_gpu_total_mb()\n 109:             \n 110:             # Start background monitoring if requested\n 111:             if background:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 108,
          "context": " 105:                 self._gpu_available = self._check_gpu_available()\n 106:             \n 107:             if self._gpu_available:\n 108: >>>             self._gpu_baseline_mb = self._query_gpu_total_mb()\n 109:             \n 110:             # Start background monitoring if requested\n 111:             if background:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 142,
          "context": " 139:                 except (psutil.NoSuchProcess, psutil.AccessDenied):\n 140:                     pass\n 141:             \n 142: >>>         # GPU via nvidia-smi\n 143:             if self._gpu_available:\n 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 143,
          "context": " 140:                     pass\n 141:             \n 142:             # GPU via nvidia-smi\n 143: >>>         if self._gpu_available:\n 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 144,
          "context": " 141:             \n 142:             # GPU via nvidia-smi\n 143:             if self._gpu_available:\n 144: >>>             gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147:                 self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 144,
          "context": " 141:             \n 142:             # GPU via nvidia-smi\n 143:             if self._gpu_available:\n 144: >>>             gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147:                 self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 146,
          "context": " 143:             if self._gpu_available:\n 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146: >>>             gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147:                 self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149:         def start_background_monitoring(self):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 146,
          "context": " 143:             if self._gpu_available:\n 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146: >>>             gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147:                 self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149:         def start_background_monitoring(self):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 146,
          "context": " 143:             if self._gpu_available:\n 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146: >>>             gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147:                 self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149:         def start_background_monitoring(self):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 147,
          "context": " 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147: >>>             self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149:         def start_background_monitoring(self):\n 150:             \"\"\"Start background thread for continuous sampling.\"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 147,
          "context": " 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147: >>>             self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149:         def start_background_monitoring(self):\n 150:             \"\"\"Start background thread for continuous sampling.\"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 147,
          "context": " 144:                 gpu_mb = self._query_gpu_total_mb()\n 145:                 # Use delta from baseline (accounts for system overhead)\n 146:                 gpu_used = max(0.0, gpu_mb - self._gpu_baseline_mb)\n 147: >>>             self.peak_gpu_mb = max(self.peak_gpu_mb, gpu_used)\n 148:         \n 149:         def start_background_monitoring(self):\n 150:             \"\"\"Start background thread for continuous sampling.\"\"\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 186,
          "context": " 183:                 Dict with keys:\n 184:                     - peak_cpu_percent: Maximum CPU usage (%)\n 185:                     - peak_memory_mb: Maximum memory usage (MB)\n 186: >>>                 - peak_gpu_memory_mb: Maximum GPU memory usage (MB)\n 187:                     - runtime_sec: Total runtime (seconds)\n 188:             \"\"\"\n 189:             runtime = 0.0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 186,
          "context": " 183:                 Dict with keys:\n 184:                     - peak_cpu_percent: Maximum CPU usage (%)\n 185:                     - peak_memory_mb: Maximum memory usage (MB)\n 186: >>>                 - peak_gpu_memory_mb: Maximum GPU memory usage (MB)\n 187:                     - runtime_sec: Total runtime (seconds)\n 188:             \"\"\"\n 189:             runtime = 0.0",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 197,
          "context": " 194:             return {\n 195:                 \"peak_cpu_percent\": float(self.peak_cpu),\n 196:                 \"peak_memory_mb\": float(self.peak_memory_mb),\n 197: >>>             \"peak_gpu_memory_mb\": float(self.peak_gpu_mb),\n 198:                 \"runtime_sec\": float(runtime)\n 199:             }\n 200:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 197,
          "context": " 194:             return {\n 195:                 \"peak_cpu_percent\": float(self.peak_cpu),\n 196:                 \"peak_memory_mb\": float(self.peak_memory_mb),\n 197: >>>             \"peak_gpu_memory_mb\": float(self.peak_gpu_mb),\n 198:                 \"runtime_sec\": float(runtime)\n 199:             }\n 200:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 201,
          "context": " 198:                 \"runtime_sec\": float(runtime)\n 199:             }\n 200:         \n 201: >>>     def _check_gpu_available(self) -> bool:\n 202:             \"\"\"Check if nvidia-smi is available.\"\"\"\n 203:             try:\n 204:                 result = subprocess.run(",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 205,
          "context": " 202:             \"\"\"Check if nvidia-smi is available.\"\"\"\n 203:             try:\n 204:                 result = subprocess.run(\n 205: >>>                 [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],\n 206:                     capture_output=True,\n 207:                     text=True,\n 208:                     timeout=2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 214,
          "context": " 211:             except Exception:\n 212:                 return False\n 213:         \n 214: >>>     def _query_gpu_total_mb(self) -> float:\n 215:             \"\"\"Query total GPU memory used (system-wide) via nvidia-smi.\"\"\"\n 216:             try:\n 217:                 result = subprocess.run(",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 215,
          "context": " 212:                 return False\n 213:         \n 214:         def _query_gpu_total_mb(self) -> float:\n 215: >>>         \"\"\"Query total GPU memory used (system-wide) via nvidia-smi.\"\"\"\n 216:             try:\n 217:                 result = subprocess.run(\n 218:                     [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 218,
          "context": " 215:             \"\"\"Query total GPU memory used (system-wide) via nvidia-smi.\"\"\"\n 216:             try:\n 217:                 result = subprocess.run(\n 218: >>>                 [\"nvidia-smi\", \"--query-gpu=memory.used\", \"--format=csv,noheader,nounits\"],\n 219:                     capture_output=True,\n 220:                     text=True,\n 221:                     timeout=2",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 224,
          "context": " 221:                     timeout=2\n 222:                 )\n 223:                 if result.returncode == 0 and result.stdout.strip():\n 224: >>>                 # Sum all GPUs (first value from each line)\n 225:                     total = 0.0\n 226:                     for line in result.stdout.strip().split('\\n'):\n 227:                         try:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 271,
          "context": " 268:             return {\n 269:                 \"peak_cpu_percent\": 0.0,\n 270:                 \"peak_memory_mb\": 0.0,\n 271: >>>             \"peak_gpu_memory_mb\": 0.0,\n 272:                 \"runtime_sec\": float(runtime)\n 273:             }\n 274:     ",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 33,
          "context": "  30:     \n  31:     import subprocess\n  32:     import time\n  33: >>> import threading\n  34:     from typing import Dict, Optional\n  35:     from pathlib import Path\n  36:     ",
          "match": "threading"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 81,
          "context": "  78:             # Background monitoring\n  79:             self._monitoring = False\n  80:             self._monitor_thread = None\n  81: >>>         self._stop_event = threading.Event()\n  82:             \n  83:         def start(self, background: bool = False):\n  84:             \"\"\"",
          "match": "threading"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 156,
          "context": " 153:             \n 154:             self._stop_event.clear()\n 155:             self._monitoring = True\n 156: >>>         self._monitor_thread = threading.Thread(\n 157:                 target=self._monitor_loop,\n 158:                 daemon=True\n 159:             )",
          "match": "threading"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 124,
          "context": " 121:             \"\"\"\n 122:             Sample current resource usage and update peaks.\n 123:             \n 124: >>>         Call this periodically during test execution (e.g., every N steps)\n 125:             or use background monitoring for automatic sampling.\n 126:             \"\"\"\n 127:             # CPU and memory via psutil",
          "match": "periodic"
        }
      ],
      "line_count": 289,
      "docstring": "resource_tracking.py — Resource Monitoring for LFM Test Runners\n---------------------------------------------------------------\nPurpose:\n    Track CPU, RAM, and GPU usage during test execution to collect\n    accurate resource metrics for performance analysis and budgeting.\n\nFeatures:\n    - Per-process CPU and memory tracking via psutil\n    - GPU memory tracking via nvidia-smi (if available)\n    - Lightweight sampling with minimal overhead\n    - Thread-safe background monitoring for long-running tests\n\nUsage:\n    >>> tracker = ResourceTracker()\n    >>> tracker.start()\n    >>> # ... run test ...\n    >>> tracker.sample()  # or use background sampling\n    >>> metrics = tracker.get_metrics()\n    >>> print(f\"Peak CPU: {metrics['peak_cpu_percent']:.1f}%\")\n    >>> print(f\"Peak RAM: {metrics['peak_memory_mb']:.1f} MB\")"
    },
    {
      "filepath": "run_tier1_relativistic.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "0d1f8018de370397",
      "file_size": 93675,
      "modified": "2025-11-02T20:02:10.897068",
      "git_info": {
        "first_commit": {
          "hash": "1725ce9b",
          "date": "2025-10-26 17:44:34 -0700",
          "message": "Update test run logic"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 50,
          "context": "  47:         return \"config_tier1_relativistic.json\"\n  48:     \n  49:     \n  50: >>> @dataclass\n  51:     class TestSummary:\n  52:         id: str\n  53:         description: str",
          "match": "class\nclass TestSummary:"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:     \n  64:     \n  65:      \n  66: >>> class Tier1Harness(BaseTierHarness):\n  67:         def __init__(self, cfg: Dict, out_root: Path):\n  68:             super().__init__(cfg, out_root, config_name=\"config_tier1_relativistic.json\")\n  69:             self.variants = cfg[\"variants\"]",
          "match": "class Tier1Harness(BaseTierHarness):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 46,
          "context": "  43:     \n  44:     \n  45:      \n  46: >>> def _default_config_name() -> str:\n  47:         return \"config_tier1_relativistic.json\"\n  48:     \n  49:     ",
          "match": "def _default_config_name() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:     \n  65:      \n  66:     class Tier1Harness(BaseTierHarness):\n  67: >>>     def __init__(self, cfg: Dict, out_root: Path):\n  68:             super().__init__(cfg, out_root, config_name=\"config_tier1_relativistic.json\")\n  69:             self.variants = cfg[\"variants\"]\n  70:     ",
          "match": "def __init__(self, cfg:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 72,
          "context": "  69:             self.variants = cfg[\"variants\"]\n  70:     \n  71:         \n  72: >>>     def init_field_variant(self, test_id: str, params: Dict, N: int, dx: float, c: float, direction: str = \"right\"):\n  73:             \"\"\"\n  74:             Initialize field for test variant.\n  75:             ",
          "match": "def init_field_variant(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 123,
          "context": " 120:                 return xp.cos(k_ang * x, dtype=xp.float64)\n 121:     \n 122:         \n 123: >>>     def estimate_omega_proj_fft(self, series: np.ndarray, dt: float) -> float:\n 124:             \"\"\"Estimate omega from projected time series using FFT.\"\"\"\n 125:             return self.estimate_omega_fft(series, dt, method=\"parabolic\")\n 126:     ",
          "match": "def estimate_omega_proj_fft(self, series:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 127,
          "context": " 124:             \"\"\"Estimate omega from projected time series using FFT.\"\"\"\n 125:             return self.estimate_omega_fft(series, dt, method=\"parabolic\")\n 126:     \n 127: >>>     def measure_isotropy(self, E_right: List[np.ndarray], E_left: List[np.ndarray], \n 128:                             dt: float, dx: float, k_ang: float) -> Dict:\n 129:             \"\"\"\n 130:             Test isotropy by comparing dispersion for left and right propagating waves.",
          "match": "def measure_isotropy(self, E_right:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 190,
          "context": " 187:                 \"message\": f\"ω_R={omega_right:.6f}, ω_L={omega_left:.6f}, anisotropy={anisotropy*100:.3f}%\"\n 188:             }\n 189:     \n 190: >>>     def measure_boost_covariance(self, E_series: List[np.ndarray], dt: float, dx: float, \n 191:                                       c: float, chi: float, beta: float, k_ang: float) -> Dict:\n 192:             \"\"\"\n 193:             Test Lorentz boost covariance using ACTUAL coordinate transformation.",
          "match": "def measure_boost_covariance(self, E_series:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 270,
          "context": " 267:                 \"message\": f\"KG residual: lab={residual_lab_rms:.2e}, boost={residual_boost_rms:.2e}, ratio={covariance_ratio:.3f} (err={rel_err*100:.1f}%)\"\n 268:             }\n 269:     \n 270: >>>     def measure_phase_independence(self, E_cos: List[np.ndarray], E_sin: List[np.ndarray],\n 271:                                        dt: float, dx: float, k_ang: float) -> Dict:\n 272:             \"\"\"\n 273:             Test phase independence by comparing dispersion for sin(kx) and cos(kx) initial conditions.",
          "match": "def measure_phase_independence(self, E_cos:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 331,
          "context": " 328:                 \"message\": f\"ω_cos={omega_cos:.6f}, ω_sin={omega_sin:.6f}, phase_err={phase_error*100:.3f}%\"\n 329:             }\n 330:     \n 331: >>>     def measure_superposition(self, E_mode1: List[np.ndarray], E_mode2: List[np.ndarray],\n 332:                                  E_superposition: List[np.ndarray], dt: float, dx: float,\n 333:                                  k1: float, k2: float, a1: float, a2: float) -> Dict:\n 334:             \"\"\"",
          "match": "def measure_superposition(self, E_mode1:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 411,
          "context": " 408:             }\n 409:     \n 410:         \n 411: >>>     def measure_causality(self, E_series: List[np.ndarray], dx: float, dt: float, c: float, \n 412:                               test_id: str, initial_center: int) -> Dict:\n 413:             \"\"\"\n 414:             Measure propagation speed and verify causality (v ≤ c).",
          "match": "def measure_causality(self, E_series:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 519,
          "context": " 516:                 \"times\": times\n 517:             }\n 518:     \n 519: >>>     def run_variant(self, v: Dict) -> TestSummary:\n 520:             \"\"\"Run a single test variant. Dispatches to specialized methods for isotropy and boost tests.\"\"\"\n 521:             tid = v[\"test_id\"]\n 522:             ",
          "match": "def run_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 557,
          "context": " 554:             # All other tests use standard single-run logic\n 555:             return self.run_standard_variant(v)\n 556:         \n 557: >>>     def run_isotropy_variant(self, v: Dict) -> TestSummary:\n 558:             \"\"\"Run isotropy test by comparing left and right propagating waves.\"\"\"\n 559:             xp = self.xp\n 560:             tid = v[\"test_id\"]",
          "match": "def run_isotropy_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 611,
          "context": " 608:                 runtime_sec=0.0, k_fraction_lattice=float(params.get(\"_k_fraction_lattice\", 0.0))\n 609:             )\n 610:         \n 611: >>>     def run_boost_variant(self, v: Dict) -> TestSummary:\n 612:             \"\"\"Run Lorentz boost test by verifying frame-independent dispersion.\"\"\"\n 613:             xp = self.xp\n 614:             tid = v[\"test_id\"]",
          "match": "def run_boost_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 696,
          "context": " 693:                 runtime_sec=0.0, k_fraction_lattice=float(params.get(\"_k_fraction_lattice\", 0.0))\n 694:             )\n 695:         \n 696: >>>     def run_phase_independence_variant(self, v: Dict) -> TestSummary:\n 697:             \"\"\"Run phase independence test by comparing sin and cos initial conditions.\"\"\"\n 698:             xp = self.xp\n 699:             tid = v[\"test_id\"]",
          "match": "def run_phase_independence_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 750,
          "context": " 747:                 runtime_sec=0.0, k_fraction_lattice=float(params.get(\"_k_fraction_lattice\", 0.0))\n 748:             )\n 749:         \n 750: >>>     def run_superposition_variant(self, v: Dict) -> TestSummary:\n 751:             \"\"\"Run superposition test by verifying linearity with multi-mode initial condition.\"\"\"\n 752:             xp = self.xp\n 753:             tid = v[\"test_id\"]",
          "match": "def run_superposition_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 816,
          "context": " 813:                 runtime_sec=0.0, k_fraction_lattice=float(params.get(\"_k_fraction_lattice\", 0.0))\n 814:             )\n 815:         \n 816: >>>     def _run_single_mode(self, params: Dict, N: int, dx: float, dt: float, c: float, chi: float,\n 817:                             k: float, mode_type: str, amplitude: float) -> List[np.ndarray]:\n 818:             \"\"\"Helper to run simulation with a single mode.\"\"\"\n 819:             xp = self.xp",
          "match": "def _run_single_mode(self, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 845,
          "context": " 842:             \n 843:             return E_series\n 844:         \n 845: >>>     def _run_superposition_modes(self, params: Dict, N: int, dx: float, dt: float, c: float, chi: float,\n 846:                                     k1: float, k2: float, a1: float, a2: float) -> List[np.ndarray]:\n 847:             \"\"\"Helper to run simulation with superposition of modes.\"\"\"\n 848:             xp = self.xp",
          "match": "def _run_superposition_modes(self, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 871,
          "context": " 868:             \n 869:             return E_series\n 870:         \n 871: >>>     def _run_wave_evolution(self, params: Dict, N: int, dx: float, dt: float, c: float, chi: float, tid: str, phase: str) -> List[np.ndarray]:\n 872:             \"\"\"Helper to run simulation with specified phase (cos or sin).\"\"\"\n 873:             xp = self.xp\n 874:             steps = max(params.get(\"steps\", 2000), 2048 if self.quick else 4096)",
          "match": "def _run_wave_evolution(self, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 905,
          "context": " 902:             \n 903:             return E_series\n 904:         \n 905: >>>     def _run_directional_wave(self, params: Dict, N: int, dx: float, dt: float, c: float, chi: float, tid: str, direction: str) -> List[np.ndarray]:\n 906:             \"\"\"Helper to run simulation with directional initial momentum.\"\"\"\n 907:             xp = self.xp\n 908:             steps = max(params.get(\"steps\", 2000), 2048 if self.quick else 4096)",
          "match": "def _run_directional_wave(self, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 940,
          "context": " 937:             \n 938:             return E_series\n 939:         \n 940: >>>     def run_3d_directional_isotropy_variant(self, v: Dict) -> TestSummary:\n 941:             \"\"\"\n 942:             REL-09: 3D Isotropy — Directional Equivalence\n 943:             ",
          "match": "def run_3d_directional_isotropy_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1026,
          "context": "1023:                 runtime_sec=0.0, k_fraction_lattice=k_frac_lattice\n1024:             )\n1025:         \n1026: >>>     def run_3d_spherical_isotropy_variant(self, v: Dict) -> TestSummary:\n1027:             \"\"\"\n1028:             REL-10: 3D Isotropy — Spherical Symmetry\n1029:             ",
          "match": "def run_3d_spherical_isotropy_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1089,
          "context": "1086:                 runtime_sec=0.0, k_fraction_lattice=k_frac_lattice\n1087:             )\n1088:         \n1089: >>>     def _run_3d_plane_wave(self, params: Dict, N: int, dx: float, dt: float, c: float, \n1090:                                chi: float, k_ang: float, axis: str, steps: int) -> List[np.ndarray]:\n1091:             \"\"\"Run 3D simulation with plane wave along specified axis.\"\"\"\n1092:             xp = self.xp",
          "match": "def _run_3d_plane_wave(self, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1142,
          "context": "1139:             \n1140:             return E_series\n1141:         \n1142: >>>     def _run_3d_radial_wave(self, params: Dict, N: int, dx: float, dt: float, c: float,\n1143:                                 chi: float, k_ang: float, steps: int) -> List[np.ndarray]:\n1144:             \"\"\"Run 3D simulation with radially symmetric Gaussian pulse.\"\"\"\n1145:             xp = self.xp",
          "match": "def _run_3d_radial_wave(self, params:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1182,
          "context": "1179:             \n1180:             return E_series\n1181:         \n1182: >>>     def _measure_omega_3d(self, E_series: List[np.ndarray], dt: float, dx: float, \n1183:                               k_ang: float, axis: str) -> float:\n1184:             \"\"\"Measure frequency from 3D plane wave by projecting onto mode.\"\"\"\n1185:             N = E_series[0].shape[0]",
          "match": "def _measure_omega_3d(self, E_series:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1213,
          "context": "1210:             omega = self.estimate_omega_proj_fft(np.array(proj_series, dtype=np.float64), dt)\n1211:             return omega\n1212:         \n1213: >>>     def _measure_spherical_symmetry(self, E: np.ndarray, dx: float) -> float:\n1214:             \"\"\"\n1215:             Measure deviation from spherical symmetry by comparing radial profiles\n1216:             along different directions.",
          "match": "def _measure_spherical_symmetry(self, E:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1255,
          "context": "1252:             \n1253:             return float(max(dev_x, dev_y, dev_z))\n1254:         \n1255: >>>     def run_dispersion_relation_variant(self, v: Dict) -> TestSummary:\n1256:             \"\"\"\n1257:             REL-11-14: Dispersion Relation Tests\n1258:             ",
          "match": "def run_dispersion_relation_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1447,
          "context": "1444:                 runtime_sec=0.0, k_fraction_lattice=k_frac_lattice\n1445:             )\n1446:         \n1447: >>>     def run_spacelike_correlation_variant(self, v: Dict) -> TestSummary:\n1448:             \"\"\"\n1449:             Test causality by measuring space-like correlations.\n1450:             Perturb field at x=0, t=0 and measure correlation C(x,t) = <E(x,t)E(0,0)>.",
          "match": "def run_spacelike_correlation_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1620,
          "context": "1617:                 runtime_sec=0.0, k_fraction_lattice=0.0\n1618:             )\n1619:         \n1620: >>>     def run_momentum_conservation_variant(self, v: Dict) -> TestSummary:\n1621:             \"\"\"\n1622:             Test momentum conservation via two-packet collision.\n1623:             Launch two counter-propagating wave packets and measure total momentum before/after.",
          "match": "def run_momentum_conservation_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1816,
          "context": "1813:                 runtime_sec=0.0, k_fraction_lattice=0.0\n1814:             )\n1815:         \n1816: >>>     def run_standard_variant(self, v: Dict) -> TestSummary:\n1817:             \"\"\"Standard single-run test variant (non-isotropy tests).\"\"\"\n1818:             xp = self.xp\n1819:     ",
          "match": "def run_standard_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2044,
          "context": "2041:             )\n2042:     \n2043:         # ------------------------------ Run --------------------------------\n2044: >>>     def run(self) -> List[Dict]:\n2045:             results = []\n2046:             for v in self.variants:\n2047:                 # Start resource tracking for this test",
          "match": "def run(self) -> List[Dict]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2073,
          "context": "2070:     \n2071:     \n2072:     # --------------------------------- Main --------------------------------\n2073: >>> def main():\n2074:         import argparse\n2075:         parser = argparse.ArgumentParser(description=\"Tier-1 Relativistic Test Suite\")\n2076:         parser.add_argument(\"--test\", type=str, default=None, ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 12,
          "context": "   9:     LFM Tier-1 — Relativistic Propagation & Isotropy Suite\n  10:     ----------------------------------------------------\n  11:     Purpose:\n  12: >>> - Execute Tier-1 relativistic propagation and isotropy tests across CPU/GPU\n  13:         backends, collect diagnostics, and produce standardized summaries.\n  14:     \n  15:     Highlights:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 16,
          "context": "  13:         backends, collect diagnostics, and produce standardized summaries.\n  14:     \n  15:     Highlights:\n  16: >>> - Dual-backend support (NumPy/CuPy) selected by `run_settings.use_gpu` and\n  17:         availability of CuPy.\n  18:     - Keeps arrays on-device during the stepping loop where possible to minimize\n  19:         host↔device transfers and avoid mixed-type serialization bugs.",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 16,
          "context": "  13:         backends, collect diagnostics, and produce standardized summaries.\n  14:     \n  15:     Highlights:\n  16: >>> - Dual-backend support (NumPy/CuPy) selected by `run_settings.use_gpu` and\n  17:         availability of CuPy.\n  18:     - Keeps arrays on-device during the stepping loop where possible to minimize\n  19:         host↔device transfers and avoid mixed-type serialization bugs.",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 17,
          "context": "  14:     \n  15:     Highlights:\n  16:     - Dual-backend support (NumPy/CuPy) selected by `run_settings.use_gpu` and\n  17: >>>     availability of CuPy.\n  18:     - Keeps arrays on-device during the stepping loop where possible to minimize\n  19:         host↔device transfers and avoid mixed-type serialization bugs.\n  20:     - Converts to NumPy only for host-side diagnostics, plotting, and monitoring.",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 62,
          "context": "  59:         k_fraction_lattice: float\n  60:         peak_cpu_percent: float = 0.0\n  61:         peak_memory_mb: float = 0.0\n  62: >>>     peak_gpu_memory_mb: float = 0.0\n  63:     \n  64:     \n  65:      ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 596,
          "context": " 593:                 \"anisotropy\": float(anisotropy),\n 594:                 \"omega_right\": float(iso_result[\"omega_right\"]),\n 595:                 \"omega_left\": float(iso_result[\"omega_left\"]),\n 596: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 597:             }\n 598:             metrics = [\n 599:                 (\"anisotropy\", anisotropy),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 596,
          "context": " 593:                 \"anisotropy\": float(anisotropy),\n 594:                 \"omega_right\": float(iso_result[\"omega_right\"]),\n 595:                 \"omega_left\": float(iso_result[\"omega_left\"]),\n 596: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 597:             }\n 598:             metrics = [\n 599:                 (\"anisotropy\", anisotropy),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 678,
          "context": " 675:                 \"omega_lab\": float(boost_result[\"omega_lab\"]),\n 676:                 \"beta\": float(beta),\n 677:                 \"gamma\": float(boost_result[\"gamma\"]),\n 678: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 679:                 \"test_method\": \"actual_lorentz_transform\",  # Mark as non-circular\n 680:             }\n 681:             metrics = [",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 678,
          "context": " 675:                 \"omega_lab\": float(boost_result[\"omega_lab\"]),\n 676:                 \"beta\": float(beta),\n 677:                 \"gamma\": float(boost_result[\"gamma\"]),\n 678: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 679:                 \"test_method\": \"actual_lorentz_transform\",  # Mark as non-circular\n 680:             }\n 681:             metrics = [",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 735,
          "context": " 732:                 \"phase_error\": float(phase_error),\n 733:                 \"omega_cos\": float(phase_result[\"omega_cos\"]),\n 734:                 \"omega_sin\": float(phase_result[\"omega_sin\"]),\n 735: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 736:             }\n 737:             metrics = [\n 738:                 (\"phase_error\", phase_error),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 735,
          "context": " 732:                 \"phase_error\": float(phase_error),\n 733:                 \"omega_cos\": float(phase_result[\"omega_cos\"]),\n 734:                 \"omega_sin\": float(phase_result[\"omega_sin\"]),\n 735: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 736:             }\n 737:             metrics = [\n 738:                 (\"phase_error\", phase_error),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 801,
          "context": " 798:                 \"linearity_error\": float(linearity_error),\n 799:                 \"omega1\": float(super_result[\"omega1\"]),\n 800:                 \"omega2\": float(super_result[\"omega2\"]),\n 801: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 802:             }\n 803:             metrics = [\n 804:                 (\"linearity_error\", linearity_error),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 801,
          "context": " 798:                 \"linearity_error\": float(linearity_error),\n 799:                 \"omega1\": float(super_result[\"omega1\"]),\n 800:                 \"omega2\": float(super_result[\"omega2\"]),\n 801: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n 802:             }\n 803:             metrics = [\n 804:                 (\"linearity_error\", linearity_error),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1010,
          "context": "1007:                 \"omega_y\": float(omega_y),\n1008:                 \"omega_z\": float(omega_z),\n1009:                 \"omega_mean\": float(omega_mean),\n1010: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1011:             }\n1012:             metrics = [\n1013:                 (\"anisotropy\", anisotropy),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1010,
          "context": "1007:                 \"omega_y\": float(omega_y),\n1008:                 \"omega_z\": float(omega_z),\n1009:                 \"omega_mean\": float(omega_mean),\n1010: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1011:             }\n1012:             metrics = [\n1013:                 (\"anisotropy\", anisotropy),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1076,
          "context": "1073:             summary = {\n1074:                 \"id\": tid, \"description\": desc, \"passed\": passed,\n1075:                 \"spherical_error\": float(symmetry_error),\n1076: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1077:             }\n1078:             metrics = [\n1079:                 (\"spherical_error\", symmetry_error),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1076,
          "context": "1073:             summary = {\n1074:                 \"id\": tid, \"description\": desc, \"passed\": passed,\n1075:                 \"spherical_error\": float(symmetry_error),\n1076: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1077:             }\n1078:             metrics = [\n1079:                 (\"spherical_error\", symmetry_error),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1426,
          "context": "1423:                 \"chi\": float(chi),\n1424:                 \"chi_over_k\": float(chi_over_k),\n1425:                 \"runtime_sec\": 0.0,\n1426: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1427:                 \"params\": {\n1428:                     \"N\": N, \"dx\": dx, \"dt\": dt, \"steps\": steps,\n1429:                     \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"], \"chi\": chi",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1426,
          "context": "1423:                 \"chi\": float(chi),\n1424:                 \"chi_over_k\": float(chi_over_k),\n1425:                 \"runtime_sec\": 0.0,\n1426: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1427:                 \"params\": {\n1428:                     \"N\": N, \"dx\": dx, \"dt\": dt, \"steps\": steps,\n1429:                     \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"], \"chi\": chi",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1605,
          "context": "1602:                 \"threshold\": corr_threshold,\n1603:                 \"light_speed\": float(c),\n1604:                 \"runtime_sec\": 0.0,\n1605: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\"\n1606:             }\n1607:             metrics = [\n1608:                 (\"num_violations\", len(violations)),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1605,
          "context": "1602:                 \"threshold\": corr_threshold,\n1603:                 \"light_speed\": float(c),\n1604:                 \"runtime_sec\": 0.0,\n1605: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\"\n1606:             }\n1607:             metrics = [\n1608:                 (\"num_violations\", len(violations)),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1801,
          "context": "1798:                 \"relative_change\": float(rel_change),\n1799:                 \"tolerance\": momentum_tol,\n1800:                 \"runtime_sec\": 0.0,\n1801: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\"\n1802:             }\n1803:             metrics = [\n1804:                 (\"momentum_initial\", P_initial),",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1801,
          "context": "1798:                 \"relative_change\": float(rel_change),\n1799:                 \"tolerance\": momentum_tol,\n1800:                 \"runtime_sec\": 0.0,\n1801: >>>             \"backend\": \"GPU\" if self.use_gpu else \"CPU\"\n1802:             }\n1803:             metrics = [\n1804:                 (\"momentum_initial\", P_initial),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1849,
          "context": "1846:                 d.mkdir(parents=True, exist_ok=True)\n1847:     \n1848:             test_start(tid, desc, steps)\n1849: >>>         log(f\"Params: steps={steps}, quick={self.quick}, backend={'GPU' if self.use_gpu else 'CPU'}\", \"INFO\")\n1850:             log(f\"[cfg] gamma={gamma_damp} rescale={rescale_each} zero_mean={zero_mean} est={estimator}\", \"INFO\")\n1851:     \n1852:             ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1849,
          "context": "1846:                 d.mkdir(parents=True, exist_ok=True)\n1847:     \n1848:             test_start(tid, desc, steps)\n1849: >>>         log(f\"Params: steps={steps}, quick={self.quick}, backend={'GPU' if self.use_gpu else 'CPU'}\", \"INFO\")\n1850:             log(f\"[cfg] gamma={gamma_damp} rescale={rescale_each} zero_mean={zero_mean} est={estimator}\", \"INFO\")\n1851:     \n1852:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1899,
          "context": "1896:             steps_pct_check = max(1, steps // 100)\n1897:     \n1898:             for n in range(steps):\n1899: >>>             # Compute laplacian and step (keep all heavy work on xp: NumPy or CuPy)\n1900:                 Em1 = xp.roll(E, -1); Ep1 = xp.roll(E, 1)\n1901:                 lap = (Em1 - 2 * E + Ep1) / dx2\n1902:                 E_next = (2 - gamma_damp) * E - (1 - gamma_damp) * E_prev + dt2 * (c2 * lap - chi2 * E)",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1984,
          "context": "1981:                     \"max_violation\": float(causality_result[\"max_violation\"]),\n1982:                     \"runtime_sec\": float(runtime),\n1983:                     \"quick_mode\": self.quick,\n1984: >>>                 \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1985:                     \"params\": {\n1986:                         \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n1987:                         \"chi\": chi, \"gamma_damp\": gamma_damp, \"rescale_each\": rescale_each,",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1984,
          "context": "1981:                     \"max_violation\": float(causality_result[\"max_violation\"]),\n1982:                     \"runtime_sec\": float(runtime),\n1983:                     \"quick_mode\": self.quick,\n1984: >>>                 \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n1985:                     \"params\": {\n1986:                         \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n1987:                         \"chi\": chi, \"gamma_damp\": gamma_damp, \"rescale_each\": rescale_each,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2021,
          "context": "2018:                     \"omega_theory\": float(omega_theory), \"runtime_sec\": float(runtime),\n2019:                     \"k_fraction_lattice\": float(params.get(\"_k_fraction_lattice\", 0)),\n2020:                     \"quick_mode\": self.quick,\n2021: >>>                 \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n2022:                     \"params\": {\n2023:                         \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n2024:                         \"chi\": chi, \"gamma_damp\": gamma_damp, \"rescale_each\": rescale_each,",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2021,
          "context": "2018:                     \"omega_theory\": float(omega_theory), \"runtime_sec\": float(runtime),\n2019:                     \"k_fraction_lattice\": float(params.get(\"_k_fraction_lattice\", 0)),\n2020:                     \"quick_mode\": self.quick,\n2021: >>>                 \"backend\": \"GPU\" if self.use_gpu else \"CPU\",\n2022:                     \"params\": {\n2023:                         \"N\": N, \"dx\": dx, \"dt\": dt, \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n2024:                         \"chi\": chi, \"gamma_damp\": gamma_damp, \"rescale_each\": rescale_each,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2067,
          "context": "2064:                     \"k_fraction_lattice\": res.k_fraction_lattice,\n2065:                     \"peak_cpu_percent\": metrics[\"peak_cpu_percent\"],\n2066:                     \"peak_memory_mb\": metrics[\"peak_memory_mb\"],\n2067: >>>                 \"peak_gpu_memory_mb\": metrics[\"peak_gpu_memory_mb\"],\n2068:                 })\n2069:             return results\n2070:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2067,
          "context": "2064:                     \"k_fraction_lattice\": res.k_fraction_lattice,\n2065:                     \"peak_cpu_percent\": metrics[\"peak_cpu_percent\"],\n2066:                     \"peak_memory_mb\": metrics[\"peak_memory_mb\"],\n2067: >>>                 \"peak_gpu_memory_mb\": metrics[\"peak_gpu_memory_mb\"],\n2068:                 })\n2069:             return results\n2070:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2122,
          "context": "2119:                 \"runtime_sec\": r[\"runtime_sec\"],\n2120:                 \"peak_cpu_percent\": r[\"peak_cpu_percent\"],\n2121:                 \"peak_memory_mb\": r[\"peak_memory_mb\"],\n2122: >>>             \"peak_gpu_memory_mb\": r[\"peak_gpu_memory_mb\"],\n2123:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n2124:             }\n2125:             test_metrics.record_run(r[\"test_id\"], metrics_data)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2122,
          "context": "2119:                 \"runtime_sec\": r[\"runtime_sec\"],\n2120:                 \"peak_cpu_percent\": r[\"peak_cpu_percent\"],\n2121:                 \"peak_memory_mb\": r[\"peak_memory_mb\"],\n2122: >>>             \"peak_gpu_memory_mb\": r[\"peak_gpu_memory_mb\"],\n2123:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n2124:             }\n2125:             test_metrics.record_run(r[\"test_id\"], metrics_data)",
          "match": "gpu"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 1869,
          "context": "1866:             params[\"gamma_damp\"] = gamma_damp\n1867:     \n1868:             \n1869: >>>         self.check_cfl(c, dt, dx, ndim=1)\n1870:             self.validate_field(to_numpy(E), f\"{tid}-E0\")\n1871:     \n1872:             ",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1495,
          "context": "1492:                 \"dt\": dt, \"dx\": dx,\n1493:                 \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n1494:                 \"chi\": params.get(\"chi\", 0.0),\n1495: >>>             \"boundary\": \"periodic\",\n1496:                 \"precision\": \"float64\",\n1497:                 \"debug\": {\"quiet_run\": True, \"enable_diagnostics\": False}\n1498:             }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1495,
          "context": "1492:                 \"dt\": dt, \"dx\": dx,\n1493:                 \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n1494:                 \"chi\": params.get(\"chi\", 0.0),\n1495: >>>             \"boundary\": \"periodic\",\n1496:                 \"precision\": \"float64\",\n1497:                 \"debug\": {\"quiet_run\": True, \"enable_diagnostics\": False}\n1498:             }",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1695,
          "context": "1692:                 \"dt\": dt, \"dx\": dx,\n1693:                 \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n1694:                 \"chi\": chi,\n1695: >>>             \"boundary\": \"periodic\",\n1696:                 \"precision\": \"float64\",\n1697:                 \"debug\": {\"quiet_run\": True, \"enable_diagnostics\": False}\n1698:             }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1695,
          "context": "1692:                 \"dt\": dt, \"dx\": dx,\n1693:                 \"alpha\": params[\"alpha\"], \"beta\": params[\"beta\"],\n1694:                 \"chi\": chi,\n1695: >>>             \"boundary\": \"periodic\",\n1696:                 \"precision\": \"float64\",\n1697:                 \"debug\": {\"quiet_run\": True, \"enable_diagnostics\": False}\n1698:             }",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1705,
          "context": "1702:             \n1703:             momentum_history = [(0, P_initial)]\n1704:             \n1705: >>>         # Sample momentum periodically\n1706:             sample_stride = max(1, steps // 50)\n1707:             \n1708:             log(f\"Initial momentum: P = {P_initial:.6e}\", \"INFO\")",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 639,
          "context": " 636:             \n 637:             E_series = [to_numpy(E)]\n 638:             \n 639: >>>         # Time integration\n 640:             dt2 = dt ** 2; c2 = c ** 2; chi2 = chi ** 2; dx2 = dx ** 2\n 641:             \n 642:             for n in range(steps):",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 887,
          "context": " 884:             E = xp.array(E_prev, copy=True)\n 885:             E_series = [to_numpy(E)]\n 886:             \n 887: >>>         # Time integration (simplified, no monitoring for sub-runs)\n 888:             dt2 = dt ** 2; c2 = c ** 2; chi2 = chi ** 2; dx2 = dx ** 2\n 889:             \n 890:             for n in range(steps):",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 922,
          "context": " 919:             \n 920:             E_series = [to_numpy(E)]\n 921:             \n 922: >>>         # Time integration (simplified, no monitoring for sub-runs)\n 923:             dt2 = dt ** 2; c2 = c ** 2; chi2 = chi ** 2; dx2 = dx ** 2\n 924:             \n 925:             for n in range(steps):",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1122,
          "context": "1119:             E_prev = E_prev - xp.mean(E_prev)\n1120:             E = xp.array(E_prev, copy=True)\n1121:             \n1122: >>>         # Time integration (3D Klein-Gordon)\n1123:             dt2 = dt ** 2; c2 = c ** 2; chi2 = chi ** 2; dx2 = dx ** 2\n1124:             E_series = [to_numpy(E)]\n1125:             ",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1162,
          "context": "1159:             E_prev = E_prev - xp.mean(E_prev)\n1160:             E = xp.array(E_prev, copy=True)\n1161:             \n1162: >>>         # Time integration (3D Klein-Gordon)\n1163:             dt2 = dt ** 2; c2 = c ** 2; chi2 = chi ** 2; dx2 = dx ** 2\n1164:             E_series = [to_numpy(E)]\n1165:             ",
          "match": "integration"
        }
      ],
      "line_count": 2186,
      "docstring": "LFM Tier-1 — Relativistic Propagation & Isotropy Suite\n----------------------------------------------------\nPurpose:\n- Execute Tier-1 relativistic propagation and isotropy tests across CPU/GPU\n    backends, collect diagnostics, and produce standardized summaries.\n\nHighlights:\n- Dual-backend support (NumPy/CuPy) selected by `run_settings.use_gpu` and\n    availability of CuPy.\n- Keeps arrays on-device during the stepping loop where possible to minimize\n    host↔device transfers and avoid mixed-type serialization bugs.\n- Converts to NumPy only for host-side diagnostics, plotting, and monitoring.\n\nConfig & output:\n- Expects configuration at `./config/config_tier1_relativistic.json`.\n- Writes per-test results under `<output_dir>/<TEST_ID>/` with\n    `summary.json`, `metrics.csv`, `diagnostics/` and `plots/`."
    },
    {
      "filepath": "run_tier2_gravityanalogue.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "d8ef50eecf279686",
      "file_size": 174863,
      "modified": "2025-11-03T10:09:49.366659",
      "git_info": {
        "first_commit": {
          "hash": "2e782893",
          "date": "2025-10-26 21:04:18 -0700",
          "message": "work on test"
        },
        "latest_commit": {
          "hash": "8e7a1a06",
          "date": "2025-11-03 11:02:58 -0800",
          "message": "Fix GRAV-09, GRAV-11, GRAV-14 gravity analogue tests"
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 62,
          "context": "  59:         except Exception:\n  60:             return float(v)\n  61:     \n  62: >>> @dataclass\n  63:     class VariantResult:\n  64:         test_id: str\n  65:         description: str",
          "match": "class\nclass VariantResult:"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 300,
          "context": " 297:         return \"config_tier2_gravityanalogue.json\"\n 298:     \n 299:      \n 300: >>> class Tier2Harness(BaseTierHarness):\n 301:         def __init__(self, cfg: Dict, out_root: Path):\n 302:             super().__init__(cfg, out_root, config_name=\"config_tier2_gravityanalogue.json\")\n 303:             self.variants = cfg[\"variants\"]",
          "match": "class Tier2Harness(BaseTierHarness):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 56,
          "context": "  53:         compute_chi_from_energy_poisson = None\n  54:     from lfm_parallel import run_lattice\n  55:     \n  56: >>> def scalar_fast(v):\n  57:         try:\n  58:             return float(v.item())\n  59:         except Exception:",
          "match": "def scalar_fast(v):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 78,
          "context": "  75:         peak_gpu_memory_mb: float = 0.0\n  76:     \n  77:      \n  78: >>> def build_chi_field(kind: str, shape_or_N, dx: float, params: Dict, xp, ndim: int = 3):\n  79:         # Handle both legacy N (int) and new shape (tuple) arguments\n  80:         if isinstance(shape_or_N, int):\n  81:             N = shape_or_N",
          "match": "def build_chi_field(kind:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 244,
          "context": " 241:             g3 = g2[:, :, xp.newaxis] * g1[xp.newaxis, xp.newaxis, :]\n 242:             return chi0 * g3\n 243:     \n 244: >>> def gaussian_packet(N, kvec, amplitude, width, xp, center=None):\n 245:         \"\"\"\n 246:         Create a 3D Gaussian wave packet optionally centered at `center` (ix,iy,iz).\n 247:         If kvec has all zeros, this degenerates to a localized bump useful for local",
          "match": "def gaussian_packet(N, kvec, amplitude, width, xp, center=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 263,
          "context": " 260:         phase_x = xp.sin(kvec[0]*ax + 0.5)[xp.newaxis, xp.newaxis, :]\n 261:         return amplitude * env3 * phase_x\n 262:     \n 263: >>> def gaussian_bump(N, amplitude, width, xp, center):\n 264:         \"\"\"Pure 3D Gaussian bump centered at `center` (ix,iy,iz).\"\"\"\n 265:         cx, cy, cz = [float(v) for v in center]\n 266:         ax = xp.arange(N, dtype=xp.float64)",
          "match": "def gaussian_bump(N, amplitude, width, xp, center):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 272,
          "context": " 269:         gz = xp.exp(-((ax - cz)**2)/(2.0*width*width))\n 270:         return (amplitude * (gx[:, xp.newaxis]*gy[xp.newaxis,:])[:, :, xp.newaxis]*gz[xp.newaxis,xp.newaxis,:])\n 271:     \n 272: >>> def traveling_packet_x(N, amplitude, width, kx, omega, xp, center_x: float):\n 273:         \"\"\"Construct a right-going narrowband packet along +x.\n 274:     \n 275:         E(x,y,z,t) ≈ env(x)*cos(kx*(x-center_x) - omega*t)",
          "match": "def traveling_packet_x(N, amplitude, width, kx, omega, xp, center_x:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 291,
          "context": " 288:         phase0 = xp.cos(kx * (ax - cx))[xp.newaxis, xp.newaxis, :]  # (1,1,N)\n 289:         return env3 * phase0  # (N,N,N); amplitude applied by caller\n 290:     \n 291: >>> def local_omega_theory(c, k_mag, chi):\n 292:         return math.sqrt((c*c)*(k_mag*k_mag) + chi*chi)\n 293:     \n 294:     ",
          "match": "def local_omega_theory(c, k_mag, chi):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 296,
          "context": " 293:     \n 294:     \n 295:      \n 296: >>> def _default_config_name() -> str:\n 297:         return \"config_tier2_gravityanalogue.json\"\n 298:     \n 299:      ",
          "match": "def _default_config_name() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 301,
          "context": " 298:     \n 299:      \n 300:     class Tier2Harness(BaseTierHarness):\n 301: >>>     def __init__(self, cfg: Dict, out_root: Path):\n 302:             super().__init__(cfg, out_root, config_name=\"config_tier2_gravityanalogue.json\")\n 303:             self.variants = cfg[\"variants\"]\n 304:             ",
          "match": "def __init__(self, cfg:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 345,
          "context": " 342:             except Exception:\n 343:                 pass\n 344:     \n 345: >>>     def run_variant(self, v: Dict) -> VariantResult:\n 346:             xp = self.xp\n 347:             tid = v[\"test_id\"]\n 348:             desc = v.get(\"description\", tid)",
          "match": "def run_variant(self, v:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1914,
          "context": "1911:                 # Compute arrival time at detector plane for slab vs control (uniform bg)\n1912:                 # Build detector time series: average absolute field at x=x_det across y,z\n1913:                 x_det = PROBE_A if ndim == 1 else PROBE_A[0]\n1914: >>>             def plane_signal(series):\n1915:                     # series_A already holds E at PROBE_A (x_det center); improve robustness by recomputing averaging\n1916:                     # Reconstruct light-weight average using last E snapshot (approx): fallback to recorded scalar series\n1917:                     return np.asarray(series)",
          "match": "def plane_signal(series):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1976,
          "context": "1973:                 log(f\"Expected: slab_field=0.30 (chi_slab), ctrl_field=0.05 (chi_bg)\", \"INFO\")\n1974:                 \n1975:                 # Control run simulation with rebuilt initial conditions\n1976: >>>             def simulate(E0_in, Ep0_in, params_in, track_centroid=False, track_peak=False):\n1977:                     E, Eprev = E0_in.copy(), Ep0_in.copy()\n1978:                     sig = []\n1979:                     centroids = [] if track_centroid else None",
          "match": "def simulate(E0_in, Ep0_in, params_in, track_centroid=False, track_peak=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2070,
          "context": "2067:                 \n2068:                 # Arrival time: PHYSICIST'S MEASUREMENT - use PEAK position!\n2069:                 # Peak position is more robust than centroid (doesn't stall due to dispersion)\n2070: >>>             def peak_arrival_time(peak_data, x_target):\n2071:                     \"\"\"Find when peak crosses x_target position\"\"\"\n2072:                     for i in range(len(peak_data) - 1):\n2073:                         step1, x1, amp1 = peak_data[i]",
          "match": "def peak_arrival_time(peak_data, x_target):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2133,
          "context": "2130:                 \n2131:                 if use_centroid:\n2132:                     # Centroid fallback\n2133: >>>                 def centroid_arrival_time(centroid_data, x_target):\n2134:                         \"\"\"Find when centroid crosses x_target position\"\"\"\n2135:                         for i in range(len(centroid_data) - 1):\n2136:                             step1, x1 = centroid_data[i]",
          "match": "def centroid_arrival_time(centroid_data, x_target):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2171,
          "context": "2168:                 \n2169:                 # Fallback: detector peak measurement (old method)\n2170:                 if not use_centroid:\n2171: >>>                 def arrival_time(sig):\n2172:                         s = np.abs(sig)\n2173:                         idx = int(np.argmax(s))\n2174:                         return idx * dt",
          "match": "def arrival_time(sig):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2374,
          "context": "2371:                 \n2372:                 # Extract envelope arrival time using cumulative energy (50% crossing)\n2373:                 # This is more robust to dispersion than threshold-based methods\n2374: >>>             def find_envelope_arrival(signal, dt_step, threshold_frac=0.5):\n2375:                     from scipy.signal import hilbert\n2376:                     s = np.asarray(signal, float)\n2377:                     analytic_signal = hilbert(s)",
          "match": "def find_envelope_arrival(signal, dt_step, threshold_frac=0.5):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2496,
          "context": "2493:                 log(f\"Extra delay (Shapiro): measured={delay_measured:.2f}s, theory={delay_theory:.2f}s\", \"INFO\")\n2494:     \n2495:                 # DIAGNOSTIC: Compute local carrier frequency around arrival segments via FFT\n2496: >>>             def local_fft_freq(sig, t0, t1, dt_step):\n2497:                     i0 = max(0, int(t0/dt_step))\n2498:                     i1 = min(len(sig), max(i0+16, int(t1/dt_step)))\n2499:                     segment = np.asarray(sig[i0:i1], float)",
          "match": "def local_fft_freq(sig, t0, t1, dt_step):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2608,
          "context": "2605:                 from lfm_equation import laplacian as _lap\n2606:                 import csv\n2607:     \n2608: >>>             def make_ic_for(chi_field_local):\n2609:                     # PDE-consistent ICs for the given chi field (1D only)\n2610:                     # CRITICAL: Always use chi_bg for IC construction!\n2611:                     # Both packets start in background region, so k/omega determined by chi_bg",
          "match": "def make_ic_for(chi_field_local):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2633,
          "context": "2630:                     Eprev = (E - dt * E_t + 0.5 * (dt*dt) * E_tt).astype(self.dtype)\n2631:                     return E, Eprev\n2632:     \n2633: >>>             def simulate_detector(chi_field_local, steps_local, track_packet=False):\n2634:                     params_local = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n2635:                                         chi=to_numpy(chi_field_local) if xp is np else chi_field_local)\n2636:                     E_loc, Ep_loc = make_ic_for(chi_field_local)",
          "match": "def simulate_detector(chi_field_local, steps_local, track_packet=False):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2697,
          "context": "2694:                     log(f\"Wrote detector signals: {csv_slab.name}, {csv_ctrl.name}\", \"INFO\")\n2695:     \n2696:                 # Arrival estimator (reuse 50% cumulative energy)\n2697: >>>             def find_envelope_arrival(signal, dt_step, threshold_frac=0.5):\n2698:                     from scipy.signal import hilbert\n2699:                     s = np.asarray(signal, float)\n2700:                     env = np.abs(hilbert(s))",
          "match": "def find_envelope_arrival(signal, dt_step, threshold_frac=0.5):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2718,
          "context": "2715:                 x_slab_entry = x0_frac * N\n2716:                 x_slab_exit = x1_frac * N\n2717:                 \n2718: >>>             def find_crossing_time(packet_track, x_target):\n2719:                     \"\"\"Find when packet peak crosses x_target\"\"\"\n2720:                     for i, (step, x_peak, amp) in enumerate(packet_track):\n2721:                         if x_peak >= x_target:",
          "match": "def find_crossing_time(packet_track, x_target):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2763,
          "context": "2760:                 \n2761:                 # PHYSICIST APPROACH #2 (robust): 50% cumulative energy around the EXPECTED arrival\n2762:                 # Use a prediction window centered at t_pred (from vg_bg and geometry) to avoid spurious later maxima\n2763: >>>             def arrival_time_50pct_windowed(env, dt_val, t_center, search_halfwidth=None, energy_halfwidth=None, threshold=0.5):\n2764:                     \"\"\"Find the 50% cumulative energy time in a small window around the local peak near t_center.\"\"\"\n2765:                     # Use config-provided or default window sizes\n2766:                     if search_halfwidth is None:",
          "match": "def arrival_time_50pct_windowed(env, dt_val, t_center, search_halfwidth=None, energy_halfwidth=None, threshold=0.5):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 3013,
          "context": "3010:             return VariantResult(tid,desc,passed,err,ratio_s,ratio_p,ratio_th,\n3011:                                  t_serial+t_parallel,self.on_gpu)\n3012:     \n3013: >>>     def run(self)->List[Dict]:\n3014:             results = []\n3015:             for v in self.variants:\n3016:                 # Start resource tracking for this test",
          "match": "def run(self)->List[Dict]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 3035,
          "context": "3032:             return results\n3033:     \n3034:     # --------------------------- Main ---------------------------\n3035: >>> def main():\n3036:         import argparse\n3037:         parser = argparse.ArgumentParser(description=\"Tier-2 Gravity Analogue Test Suite\")\n3038:         parser.add_argument(\"--test\", type=str, default=None,",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 72,
          "context": "  69:         ratio_meas_parallel: float\n  70:         ratio_theory: float\n  71:         runtime_sec: float\n  72: >>>     on_gpu: bool\n  73:         peak_cpu_percent: float = 0.0\n  74:         peak_memory_mb: float = 0.0\n  75:         peak_gpu_memory_mb: float = 0.0",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 75,
          "context": "  72:         on_gpu: bool\n  73:         peak_cpu_percent: float = 0.0\n  74:         peak_memory_mb: float = 0.0\n  75: >>>     peak_gpu_memory_mb: float = 0.0\n  76:     \n  77:      \n  78:     def build_chi_field(kind: str, shape_or_N, dx: float, params: Dict, xp, ndim: int = 3):",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 335,
          "context": " 332:             self.verbose_stride = int(self.run_settings.get(\"verbose_stride\", 200))\n 333:             self.monitor_flush_interval = int(self.run_settings.get(\"monitor_flush_interval\", 50))\n 334:             self.dtype = self.xp.float32 if self.quick else self.xp.float64\n 335: >>>         self.on_gpu = self.use_gpu  # Alias for compatibility\n 336:             \n 337:             # Set diagnostics if available\n 338:             try:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 335,
          "context": " 332:             self.verbose_stride = int(self.run_settings.get(\"verbose_stride\", 200))\n 333:             self.monitor_flush_interval = int(self.run_settings.get(\"monitor_flush_interval\", 50))\n 334:             self.dtype = self.xp.float32 if self.quick else self.xp.float64\n 335: >>>         self.on_gpu = self.use_gpu  # Alias for compatibility\n 336:             \n 337:             # Set diagnostics if available\n 338:             try:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 590,
          "context": " 587:                     \"ratio_meas_parallel\": float('nan'),\n 588:                     \"ratio_theory\": 1.0,\n 589:                     \"runtime_sec\": 0.0,\n 590: >>>                 \"on_gpu\": self.on_gpu,\n 591:                     \"method\": \"chi_from_energy_poisson\",\n 592:                     \"profile_halfwidth_cells\": int(halfw),\n 593:                     \"profile_median_ratio\": float(median_ratio),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 590,
          "context": " 587:                     \"ratio_meas_parallel\": float('nan'),\n 588:                     \"ratio_theory\": 1.0,\n 589:                     \"runtime_sec\": 0.0,\n 590: >>>                 \"on_gpu\": self.on_gpu,\n 591:                     \"method\": \"chi_from_energy_poisson\",\n 592:                     \"profile_halfwidth_cells\": int(halfw),\n 593:                     \"profile_median_ratio\": float(median_ratio),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 645,
          "context": " 642:                 return VariantResult(\n 643:                     test_id=tid, description=desc, passed=passed,\n 644:                     rel_err_ratio=rel_err, ratio_meas_serial=ratio, ratio_meas_parallel=float('nan'),\n 645: >>>                 ratio_theory=1.0, runtime_sec=0.0, on_gpu=self.on_gpu\n 646:                 )\n 647:     \n 648:             # Dynamic χ-field evolution test: full wave equation □χ=-4πGρ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 645,
          "context": " 642:                 return VariantResult(\n 643:                     test_id=tid, description=desc, passed=passed,\n 644:                     rel_err_ratio=rel_err, ratio_meas_serial=ratio, ratio_meas_parallel=float('nan'),\n 645: >>>                 ratio_theory=1.0, runtime_sec=0.0, on_gpu=self.on_gpu\n 646:                 )\n 647:     \n 648:             # Dynamic χ-field evolution test: full wave equation □χ=-4πGρ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 734,
          "context": " 731:                     \"chi_reached_edge\": bool(chi_reached_edge),\n 732:                     \"energy_drift_frac\": float(energy_drift_frac),\n 733:                     \"runtime_sec\": float(t_elapsed),\n 734: >>>                 \"on_gpu\": self.on_gpu,\n 735:                     \"G_coupling\": float(Gc),\n 736:                     \"c_chi\": float(c_chi),\n 737:                     \"chi_update_every\": int(chi_update_every)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 734,
          "context": " 731:                     \"chi_reached_edge\": bool(chi_reached_edge),\n 732:                     \"energy_drift_frac\": float(energy_drift_frac),\n 733:                     \"runtime_sec\": float(t_elapsed),\n 734: >>>                 \"on_gpu\": self.on_gpu,\n 735:                     \"G_coupling\": float(Gc),\n 736:                     \"c_chi\": float(c_chi),\n 737:                     \"chi_update_every\": int(chi_update_every)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 810,
          "context": " 807:                 return VariantResult(\n 808:                     test_id=tid, description=desc, passed=passed,\n 809:                     rel_err_ratio=energy_drift_frac, ratio_meas_serial=chi_pert_max, ratio_meas_parallel=float('nan'),\n 810: >>>                 ratio_theory=chi_pert_threshold, runtime_sec=t_elapsed, on_gpu=self.on_gpu\n 811:                 )\n 812:     \n 813:             # Gravitational wave propagation test",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 810,
          "context": " 807:                 return VariantResult(\n 808:                     test_id=tid, description=desc, passed=passed,\n 809:                     rel_err_ratio=energy_drift_frac, ratio_meas_serial=chi_pert_max, ratio_meas_parallel=float('nan'),\n 810: >>>                 ratio_theory=chi_pert_threshold, runtime_sec=t_elapsed, on_gpu=self.on_gpu\n 811:                 )\n 812:     \n 813:             # Gravitational wave propagation test",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 913,
          "context": " 910:                     \"G_coupling\": float(Gc),\n 911:                     \"chi_bg\": float(chi_bg),\n 912:                     \"runtime_sec\": float(t_elapsed),\n 913: >>>                 \"on_gpu\": self.on_gpu\n 914:                 }\n 915:                 metrics = [\n 916:                     (\"chi_pert_max\", chi_pert_max),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 913,
          "context": " 910:                     \"G_coupling\": float(Gc),\n 911:                     \"chi_bg\": float(chi_bg),\n 912:                     \"runtime_sec\": float(t_elapsed),\n 913: >>>                 \"on_gpu\": self.on_gpu\n 914:                 }\n 915:                 metrics = [\n 916:                     (\"chi_pert_max\", chi_pert_max),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 984,
          "context": " 981:                     test_id=tid, description=desc, passed=passed,\n 982:                     rel_err_ratio=chi_pert_max / chi_bg if chi_bg > 0 else 0.0,\n 983:                     ratio_meas_serial=chi_pert_max, ratio_meas_parallel=float('nan'),\n 984: >>>                 ratio_theory=chi_bg, runtime_sec=t_elapsed, on_gpu=self.on_gpu\n 985:                 )\n 986:     \n 987:             # Light bending / gravitational lensing test",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 984,
          "context": " 981:                     test_id=tid, description=desc, passed=passed,\n 982:                     rel_err_ratio=chi_pert_max / chi_bg if chi_bg > 0 else 0.0,\n 983:                     ratio_meas_serial=chi_pert_max, ratio_meas_parallel=float('nan'),\n 984: >>>                 ratio_theory=chi_bg, runtime_sec=t_elapsed, on_gpu=self.on_gpu\n 985:                 )\n 986:     \n 987:             # Light bending / gravitational lensing test",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1086,
          "context": "1083:                     \"deflection_correct_sign\": bool(deflection_correct_sign),\n1084:                     \"time_delay\": float(expected_x - actual_x) * dx / vg_avg if vg_avg > 0 else 0.0,\n1085:                     \"runtime_sec\": float(t_elapsed),\n1086: >>>                 \"on_gpu\": self.on_gpu\n1087:                 }\n1088:                 metrics = [\n1089:                     (\"deflection_angle\", deflection_angle),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1086,
          "context": "1083:                     \"deflection_correct_sign\": bool(deflection_correct_sign),\n1084:                     \"time_delay\": float(expected_x - actual_x) * dx / vg_avg if vg_avg > 0 else 0.0,\n1085:                     \"runtime_sec\": float(t_elapsed),\n1086: >>>                 \"on_gpu\": self.on_gpu\n1087:                 }\n1088:                 metrics = [\n1089:                     (\"deflection_angle\", deflection_angle),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1143,
          "context": "1140:                 return VariantResult(\n1141:                     test_id=tid, description=desc, passed=passed,\n1142:                     rel_err_ratio=abs(deflection_angle), ratio_meas_serial=float(actual_x), ratio_meas_parallel=float('nan'),\n1143: >>>                 ratio_theory=float(expected_x), runtime_sec=t_elapsed, on_gpu=self.on_gpu\n1144:                 )\n1145:     \n1146:             # Initial conditions depend on test mode",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1143,
          "context": "1140:                 return VariantResult(\n1141:                     test_id=tid, description=desc, passed=passed,\n1142:                     rel_err_ratio=abs(deflection_angle), ratio_meas_serial=float(actual_x), ratio_meas_parallel=float('nan'),\n1143: >>>                 ratio_theory=float(expected_x), runtime_sec=t_elapsed, on_gpu=self.on_gpu\n1144:                 )\n1145:     \n1146:             # Initial conditions depend on test mode",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1411,
          "context": "1408:                     \"rel_err_G\": float(rel_err_G),\n1409:                     \"omega_A\": float(wA_s), \"omega_B\": float(wB_s),\n1410:                     \"chi_A\": float(chiA), \"chi_B\": float(chiB),\n1411: >>>                 \"runtime_sec\": 0.0, \"on_gpu\": self.on_gpu\n1412:                 }\n1413:                 metrics = [(\"delta_omega_over_omega\", delta_omega_over_omega), (\"delta_chi_over_chi\", delta_chi_over_chi),\n1414:                            (\"ratio_match_error\", ratio_match), (\"G_measured\", G_measured), (\"G_expected\", G_expected), (\"rel_err_G\", rel_err_G)]",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1411,
          "context": "1408:                     \"rel_err_G\": float(rel_err_G),\n1409:                     \"omega_A\": float(wA_s), \"omega_B\": float(wB_s),\n1410:                     \"chi_A\": float(chiA), \"chi_B\": float(chiB),\n1411: >>>                 \"runtime_sec\": 0.0, \"on_gpu\": self.on_gpu\n1412:                 }\n1413:                 metrics = [(\"delta_omega_over_omega\", delta_omega_over_omega), (\"delta_chi_over_chi\", delta_chi_over_chi),\n1414:                            (\"ratio_match_error\", ratio_match), (\"G_measured\", G_measured), (\"G_expected\", G_expected), (\"rel_err_G\", rel_err_G)]",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1420,
          "context": "1417:                 return VariantResult(\n1418:                     test_id=tid, description=desc, passed=passed,\n1419:                     rel_err_ratio=ratio_match, ratio_meas_serial=delta_omega_over_omega, ratio_meas_parallel=float('nan'),\n1420: >>>                 ratio_theory=delta_chi_over_chi, runtime_sec=0.0, on_gpu=self.on_gpu\n1421:                 )\n1422:             \n1423:             # GR calibration: Shapiro delay validation",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1420,
          "context": "1417:                 return VariantResult(\n1418:                     test_id=tid, description=desc, passed=passed,\n1419:                     rel_err_ratio=ratio_match, ratio_meas_serial=delta_omega_over_omega, ratio_meas_parallel=float('nan'),\n1420: >>>                 ratio_theory=delta_chi_over_chi, runtime_sec=0.0, on_gpu=self.on_gpu\n1421:                 )\n1422:             \n1423:             # GR calibration: Shapiro delay validation",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1485,
          "context": "1482:                     \"correspondence_ratio\": float(gr_correspondence_ratio),\n1483:                     \"chi_bg\": float(chi_bg), \"chi_slab\": float(chi_slab),\n1484:                     \"L_slab\": float(L_slab),\n1485: >>>                 \"runtime_sec\": 0.0, \"on_gpu\": self.on_gpu\n1486:                 }\n1487:                 metrics = [(\"delay_lfm\", delay_theory_lfm), (\"delay_gr\", delay_theory_gr), (\"correspondence_ratio\", gr_correspondence_ratio)]\n1488:                 save_summary(test_dir, tid, summary, metrics=metrics)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1485,
          "context": "1482:                     \"correspondence_ratio\": float(gr_correspondence_ratio),\n1483:                     \"chi_bg\": float(chi_bg), \"chi_slab\": float(chi_slab),\n1484:                     \"L_slab\": float(L_slab),\n1485: >>>                 \"runtime_sec\": 0.0, \"on_gpu\": self.on_gpu\n1486:                 }\n1487:                 metrics = [(\"delay_lfm\", delay_theory_lfm), (\"delay_gr\", delay_theory_gr), (\"correspondence_ratio\", gr_correspondence_ratio)]\n1488:                 save_summary(test_dir, tid, summary, metrics=metrics)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1493,
          "context": "1490:                 return VariantResult(\n1491:                     test_id=tid, description=desc, passed=passed,\n1492:                     rel_err_ratio=abs(gr_correspondence_ratio - 1.0), ratio_meas_serial=delay_theory_lfm, ratio_meas_parallel=float('nan'),\n1493: >>>                 ratio_theory=delay_theory_gr, runtime_sec=0.0, on_gpu=self.on_gpu\n1494:                 )\n1495:     \n1496:             # Preserve earlier probe selections; only override for generic local_frequency cases",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1493,
          "context": "1490:                 return VariantResult(\n1491:                     test_id=tid, description=desc, passed=passed,\n1492:                     rel_err_ratio=abs(gr_correspondence_ratio - 1.0), ratio_meas_serial=delay_theory_lfm, ratio_meas_parallel=float('nan'),\n1493: >>>                 ratio_theory=delay_theory_gr, runtime_sec=0.0, on_gpu=self.on_gpu\n1494:                 )\n1495:     \n1496:             # Preserve earlier probe selections; only override for generic local_frequency cases",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 3011,
          "context": "3008:             log(f\"{tid} {'PASS ✅' if passed else 'FAIL ❌'} \"\n3009:                 f\"(ratio_err={err*100:.2f}%)\",\"INFO\" if passed else \"FAIL\")\n3010:             return VariantResult(tid,desc,passed,err,ratio_s,ratio_p,ratio_th,\n3011: >>>                              t_serial+t_parallel,self.on_gpu)\n3012:     \n3013:         def run(self)->List[Dict]:\n3014:             results = []",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 3029,
          "context": "3026:                 res.runtime_sec = metrics[\"runtime_sec\"]\n3027:                 res.peak_cpu_percent = metrics[\"peak_cpu_percent\"]\n3028:                 res.peak_memory_mb = metrics[\"peak_memory_mb\"]\n3029: >>>             res.peak_gpu_memory_mb = metrics[\"peak_gpu_memory_mb\"]\n3030:                 \n3031:                 results.append(res.__dict__)\n3032:             return results",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 3029,
          "context": "3026:                 res.runtime_sec = metrics[\"runtime_sec\"]\n3027:                 res.peak_cpu_percent = metrics[\"peak_cpu_percent\"]\n3028:                 res.peak_memory_mb = metrics[\"peak_memory_mb\"]\n3029: >>>             res.peak_gpu_memory_mb = metrics[\"peak_gpu_memory_mb\"]\n3030:                 \n3031:                 results.append(res.__dict__)\n3032:             return results",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 3093,
          "context": "3090:                 \"runtime_sec\": r[\"runtime_sec\"],\n3091:                 \"peak_cpu_percent\": r[\"peak_cpu_percent\"],\n3092:                 \"peak_memory_mb\": r[\"peak_memory_mb\"],\n3093: >>>             \"peak_gpu_memory_mb\": r[\"peak_gpu_memory_mb\"],\n3094:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n3095:             }\n3096:             test_metrics.record_run(r[\"test_id\"], metrics_data)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 3093,
          "context": "3090:                 \"runtime_sec\": r[\"runtime_sec\"],\n3091:                 \"peak_cpu_percent\": r[\"peak_cpu_percent\"],\n3092:                 \"peak_memory_mb\": r[\"peak_memory_mb\"],\n3093: >>>             \"peak_gpu_memory_mb\": r[\"peak_gpu_memory_mb\"],\n3094:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n3095:             }\n3096:             test_metrics.record_run(r[\"test_id\"], metrics_data)",
          "match": "gpu"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 54,
          "context": "  51:         compute_chi_from_energy_poisson = getattr(_chi_mod, 'compute_chi_from_energy_poisson', None)\n  52:     except Exception:\n  53:         compute_chi_from_energy_poisson = None\n  54: >>> from lfm_parallel import run_lattice\n  55:     \n  56:     def scalar_fast(v):\n  57:         try:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 69,
          "context": "  66:         passed: bool\n  67:         rel_err_ratio: float\n  68:         ratio_meas_serial: float\n  69: >>>     ratio_meas_parallel: float\n  70:         ratio_theory: float\n  71:         runtime_sec: float\n  72:         on_gpu: bool",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 587,
          "context": " 584:                     \"id\": tid, \"description\": desc, \"passed\": passed,\n 585:                     \"rel_err_ratio\": float(rel_err),\n 586:                     \"ratio_meas_serial\": float(ratio),\n 587: >>>                 \"ratio_meas_parallel\": float('nan'),\n 588:                     \"ratio_theory\": 1.0,\n 589:                     \"runtime_sec\": 0.0,\n 590:                     \"on_gpu\": self.on_gpu,",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 644,
          "context": " 641:                     log(f\"Plotting skipped ({type(_e).__name__}: {_e})\", \"WARN\")\n 642:                 return VariantResult(\n 643:                     test_id=tid, description=desc, passed=passed,\n 644: >>>                 rel_err_ratio=rel_err, ratio_meas_serial=ratio, ratio_meas_parallel=float('nan'),\n 645:                     ratio_theory=1.0, runtime_sec=0.0, on_gpu=self.on_gpu\n 646:                 )\n 647:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 809,
          "context": " 806:                 \n 807:                 return VariantResult(\n 808:                     test_id=tid, description=desc, passed=passed,\n 809: >>>                 rel_err_ratio=energy_drift_frac, ratio_meas_serial=chi_pert_max, ratio_meas_parallel=float('nan'),\n 810:                     ratio_theory=chi_pert_threshold, runtime_sec=t_elapsed, on_gpu=self.on_gpu\n 811:                 )\n 812:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 983,
          "context": " 980:                 return VariantResult(\n 981:                     test_id=tid, description=desc, passed=passed,\n 982:                     rel_err_ratio=chi_pert_max / chi_bg if chi_bg > 0 else 0.0,\n 983: >>>                 ratio_meas_serial=chi_pert_max, ratio_meas_parallel=float('nan'),\n 984:                     ratio_theory=chi_bg, runtime_sec=t_elapsed, on_gpu=self.on_gpu\n 985:                 )\n 986:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1142,
          "context": "1139:                 \n1140:                 return VariantResult(\n1141:                     test_id=tid, description=desc, passed=passed,\n1142: >>>                 rel_err_ratio=abs(deflection_angle), ratio_meas_serial=float(actual_x), ratio_meas_parallel=float('nan'),\n1143:                     ratio_theory=float(expected_x), runtime_sec=t_elapsed, on_gpu=self.on_gpu\n1144:                 )\n1145:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1419,
          "context": "1416:                 \n1417:                 return VariantResult(\n1418:                     test_id=tid, description=desc, passed=passed,\n1419: >>>                 rel_err_ratio=ratio_match, ratio_meas_serial=delta_omega_over_omega, ratio_meas_parallel=float('nan'),\n1420:                     ratio_theory=delta_chi_over_chi, runtime_sec=0.0, on_gpu=self.on_gpu\n1421:                 )\n1422:             ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1492,
          "context": "1489:                 \n1490:                 return VariantResult(\n1491:                     test_id=tid, description=desc, passed=passed,\n1492: >>>                 rel_err_ratio=abs(gr_correspondence_ratio - 1.0), ratio_meas_serial=delay_theory_lfm, ratio_meas_parallel=float('nan'),\n1493:                     ratio_theory=delay_theory_gr, runtime_sec=0.0, on_gpu=self.on_gpu\n1494:                 )\n1495:     ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1508,
          "context": "1505:             \n1506:             # Phase_delay modes handle simulation differently (envelope-initialized CW packet)\n1507:             if mode in (\"phase_delay\", \"phase_delay_diff\"):\n1508: >>>             t_serial, t_parallel = 0.0, 0.0\n1509:                 series_A, series_B, series_Ap, series_Bp = [], [], [], []\n1510:             elif mode == \"energy_dispersion_3d\":\n1511:                 # 3D dispersion visualizer: save volumetric snapshots",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1512,
          "context": "1509:                 series_A, series_B, series_Ap, series_Bp = [], [], [], []\n1510:             elif mode == \"energy_dispersion_3d\":\n1511:                 # 3D dispersion visualizer: save volumetric snapshots\n1512: >>>             t_serial, t_parallel = 0.0, 0.0\n1513:                 series_A, series_B, series_Ap, series_Bp = [], [], [], []\n1514:                 snapshot_stride = int(p.get(\"snapshot_stride\", 50))\n1515:                 snapshot_count = int(p.get(\"snapshot_count\", 200))",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1518,
          "context": "1515:                 snapshot_count = int(p.get(\"snapshot_count\", 200))\n1516:                 snapshots_3d = []  # List of (step, time, field_3d_array)\n1517:                 log(f\"3D dispersion: will save {snapshot_count} snapshots every {snapshot_stride} steps\", \"INFO\")\n1518: >>>             # Run single simulation (no parallel comparison)\n1519:                 E, Ep = E0.copy(), Eprev0.copy()\n1520:                 t0 = time.time()\n1521:                 next_pct = self.progress_percent_stride if self.progress_percent_stride > 0 else 100",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1551,
          "context": "1548:                         snap_grp.create_dataset(f'step_{step:06d}', data=field, compression='gzip')\n1549:                         snap_grp[f'step_{step:06d}'].attrs['time'] = t\n1550:                 log(f\"Saved 3D snapshots to {h5_path.name} ({h5_path.stat().st_size / (1024**2):.1f} MB)\", \"INFO\")\n1551: >>>             t_parallel = 0.0\n1552:             elif mode == \"double_slit_3d\":\n1553:                 # Double-slit 3D: simulate with barrier enforcement + continuous source + snapshots\n1554:                 t_serial, t_parallel = 0.0, 0.0",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1554,
          "context": "1551:                 t_parallel = 0.0\n1552:             elif mode == \"double_slit_3d\":\n1553:                 # Double-slit 3D: simulate with barrier enforcement + continuous source + snapshots\n1554: >>>             t_serial, t_parallel = 0.0, 0.0\n1555:                 series_A, series_B, series_Ap, series_Bp = [], [], [], []\n1556:                 \n1557:                 # Barrier parameters",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1653,
          "context": "1650:                         snap_grp.create_dataset(f'step_{step:06d}', data=field, compression='gzip')\n1651:                         snap_grp[f'step_{step:06d}'].attrs['time'] = t\n1652:                 log(f\"Saved double-slit 3D snapshots to {h5_path.name} ({h5_path.stat().st_size / (1024**2):.1f} MB)\", \"INFO\")\n1653: >>>             t_parallel = 0.0\n1654:     \n1655:                 # Post-process: generate interference pattern image and 1D intensity profile CSV\n1656:                 try:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1732,
          "context": "1729:                 except Exception as e:\n1730:                     log(f\"Interference post-processing failed ({type(e).__name__}: {e})\", \"WARN\")\n1731:             else:\n1732: >>>             # For other modes: run standard serial and parallel simulations\n1733:                 series_A, series_B = [], []\n1734:                 # Packet tracking for time_delay mode (Tier 2 diagnostic)\n1735:                 track_packet = bool(diag_cfg.get(\"track_packet\", True)) and (mode == \"time_delay\")",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1825,
          "context": "1822:                         writer.writerows(centroid_tracking_serial)\n1823:                     log(f\"Wrote centroid tracking: {csv_path.name}\", \"INFO\")\n1824:     \n1825: >>>             # Parallel\n1826:                 series_Ap, series_Bp = [], []\n1827:                 packet_tracking_parallel = [] if track_packet else None\n1828:                 E, Ep = E0.copy(), Eprev0.copy()",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1827,
          "context": "1824:     \n1825:                 # Parallel\n1826:                 series_Ap, series_Bp = [], []\n1827: >>>             packet_tracking_parallel = [] if track_packet else None\n1828:                 E, Ep = E0.copy(), Eprev0.copy()\n1829:                 t0 = time.time()\n1830:                 next_pct = self.progress_percent_stride if self.progress_percent_stride > 0 else 100",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1833,
          "context": "1830:                 next_pct = self.progress_percent_stride if self.progress_percent_stride > 0 else 100\n1831:                 run_lattice_local = run_lattice\n1832:                 scalar_fast_local = scalar_fast\n1833: >>>             # reuse the same steps_pct_check for parallel progress throttling\n1834:                 for n in range(steps):\n1835:                     E_next = run_lattice_local(E, params, 1, tiles=tiles3, E_prev=Ep)\n1836:                     Ep, E = E, E_next",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1843,
          "context": "1840:                         host_E = to_numpy_local(E)\n1841:                         series_Ap.append(float(host_E[PROBE_A]))\n1842:                         series_Bp.append(float(host_E[PROBE_B]))\n1843: >>>                     # Packet tracking for parallel run\n1844:                         if packet_tracking_parallel is not None:\n1845:                             if ndim == 1:\n1846:                                 E_slice = np.abs(host_E)  # 1D: already along x-axis",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1844,
          "context": "1841:                         series_Ap.append(float(host_E[PROBE_A]))\n1842:                         series_Bp.append(float(host_E[PROBE_B]))\n1843:                         # Packet tracking for parallel run\n1844: >>>                     if packet_tracking_parallel is not None:\n1845:                             if ndim == 1:\n1846:                                 E_slice = np.abs(host_E)  # 1D: already along x-axis\n1847:                             else:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1851,
          "context": "1848:                                 E_slice = np.abs(host_E[:, N//2, N//2])  # 3D: x-slice at center y,z\n1849:                             x_peak = int(np.argmax(E_slice))\n1850:                             max_amp = float(np.max(E_slice))\n1851: >>>                         packet_tracking_parallel.append([n, x_peak, max_amp])\n1852:                             if log_packet_positions and (n % log_packet_stride) == 0 and n > 0:\n1853:                                 log(f\"[{tid}] Packet at x={x_peak} (amplitude={max_amp:.3e})\", \"INFO\")\n1854:                     else:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1863,
          "context": "1860:                     if self.show_progress and (n % steps_pct_check == 0):\n1861:                         pct = int((n + 1) * 100 / max(1, steps))\n1862:                         if pct >= next_pct:\n1863: >>>                         report_progress(tid, pct, phase=\"parallel\")\n1864:                             next_pct += self.progress_percent_stride\n1865:                 t_parallel = time.time() - t0\n1866:                 ",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1865,
          "context": "1862:                         if pct >= next_pct:\n1863:                             report_progress(tid, pct, phase=\"parallel\")\n1864:                             next_pct += self.progress_percent_stride\n1865: >>>             t_parallel = time.time() - t0\n1866:                 \n1867:                 # Write packet tracking CSV for parallel run\n1868:                 if packet_tracking_parallel:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1867,
          "context": "1864:                             next_pct += self.progress_percent_stride\n1865:                 t_parallel = time.time() - t0\n1866:                 \n1867: >>>             # Write packet tracking CSV for parallel run\n1868:                 if packet_tracking_parallel:\n1869:                     csv_path = diag_dir / f\"packet_tracking_{tid}_parallel.csv\"\n1870:                     with open(csv_path, 'w', newline='') as f:",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1868,
          "context": "1865:                 t_parallel = time.time() - t0\n1866:                 \n1867:                 # Write packet tracking CSV for parallel run\n1868: >>>             if packet_tracking_parallel:\n1869:                     csv_path = diag_dir / f\"packet_tracking_{tid}_parallel.csv\"\n1870:                     with open(csv_path, 'w', newline='') as f:\n1871:                         writer = csv.writer(f)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1869,
          "context": "1866:                 \n1867:                 # Write packet tracking CSV for parallel run\n1868:                 if packet_tracking_parallel:\n1869: >>>                 csv_path = diag_dir / f\"packet_tracking_{tid}_parallel.csv\"\n1870:                     with open(csv_path, 'w', newline='') as f:\n1871:                         writer = csv.writer(f)\n1872:                         writer.writerow(['step', 'x_peak', 'max_amplitude'])",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1873,
          "context": "1870:                     with open(csv_path, 'w', newline='') as f:\n1871:                         writer = csv.writer(f)\n1872:                         writer.writerow(['step', 'x_peak', 'max_amplitude'])\n1873: >>>                     writer.writerows(packet_tracking_parallel)\n1874:                     log(f\"Wrote packet tracking: {csv_path.name}\", \"INFO\")\n1875:     \n1876:                 # End of standard serial/parallel simulation loops",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 1876,
          "context": "1873:                         writer.writerows(packet_tracking_parallel)\n1874:                     log(f\"Wrote packet tracking: {csv_path.name}\", \"INFO\")\n1875:     \n1876: >>>             # End of standard serial/parallel simulation loops\n1877:     \n1878:             # Measurement depends on test mode\n1879:             if mode == \"time_dilation\":",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 2290,
          "context": "2287:                         field_snapshots[n + 1] = to_numpy(E).copy()\n2288:                 \n2289:                 t_serial = time_module.time() - t0\n2290: >>>             t_parallel = 0.0  # Phase delay only does one run, not parallel\n2291:                 \n2292:                 sig_before = np.array(sig_before)\n2293:                 sig_after = np.array(sig_after)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 2290,
          "context": "2287:                         field_snapshots[n + 1] = to_numpy(E).copy()\n2288:                 \n2289:                 t_serial = time_module.time() - t0\n2290: >>>             t_parallel = 0.0  # Phase delay only does one run, not parallel\n2291:                 \n2292:                 sig_before = np.array(sig_before)\n2293:                 sig_after = np.array(sig_after)",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 2915,
          "context": "2912:                 \n2913:                 wA_s = float(np.sqrt(omega2_field[PROBE_A]))\n2914:                 wB_s = float(np.sqrt(omega2_field[PROBE_B]))\n2915: >>>             wA_p, wB_p = wA_s, wB_s  # Parallel gives same local frequencies\n2916:                 \n2917:                 # Theory: for k=0, ω = χ exactly\n2918:                 k_mag_local = 0.0",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 2946,
          "context": "2943:                 \n2944:                 wA_s = float(np.sqrt(omega2_field[PROBE_A]))\n2945:                 wB_s = float(np.sqrt(omega2_field[PROBE_B]))\n2946: >>>             wA_p, wB_p = wA_s, wB_s  # Parallel gives same local frequencies\n2947:                 \n2948:                 # Theory: for k=0, ω = χ exactly\n2949:                 k_mag_local = 0.0",
          "match": "Parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 2998,
          "context": "2995:     \n2996:             save_summary(test_dir,tid,{\"id\":tid,\"description\":desc,\"passed\":passed,\n2997:                 \"rel_err_ratio\":float(err),\"ratio_serial\":float(ratio_s),\n2998: >>>             \"ratio_parallel\":float(ratio_p),\"ratio_theory\":float(ratio_th),\n2999:                 \"omegaA_serial\":float(wA_s),\"omegaB_serial\":float(wB_s),\n3000:                 \"omegaA_parallel\":float(wA_p),\"omegaB_parallel\":float(wB_p),\n3001:                 \"omegaA_theory\":float(wA_th),\"omegaB_theory\":float(wB_th),",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 3000,
          "context": "2997:                 \"rel_err_ratio\":float(err),\"ratio_serial\":float(ratio_s),\n2998:                 \"ratio_parallel\":float(ratio_p),\"ratio_theory\":float(ratio_th),\n2999:                 \"omegaA_serial\":float(wA_s),\"omegaB_serial\":float(wB_s),\n3000: >>>             \"omegaA_parallel\":float(wA_p),\"omegaB_parallel\":float(wB_p),\n3001:                 \"omegaA_theory\":float(wA_th),\"omegaB_theory\":float(wB_th),\n3002:                 \"chiA\":float(chiA),\"chiB\":float(chiB),\n3003:                 \"freq_shift_theory_pct\":float(freq_shift_theory_pct),",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 3000,
          "context": "2997:                 \"rel_err_ratio\":float(err),\"ratio_serial\":float(ratio_s),\n2998:                 \"ratio_parallel\":float(ratio_p),\"ratio_theory\":float(ratio_th),\n2999:                 \"omegaA_serial\":float(wA_s),\"omegaB_serial\":float(wB_s),\n3000: >>>             \"omegaA_parallel\":float(wA_p),\"omegaB_parallel\":float(wB_p),\n3001:                 \"omegaA_theory\":float(wA_th),\"omegaB_theory\":float(wB_th),\n3002:                 \"chiA\":float(chiA),\"chiB\":float(chiB),\n3003:                 \"freq_shift_theory_pct\":float(freq_shift_theory_pct),",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 3011,
          "context": "3008:             log(f\"{tid} {'PASS ✅' if passed else 'FAIL ❌'} \"\n3009:                 f\"(ratio_err={err*100:.2f}%)\",\"INFO\" if passed else \"FAIL\")\n3010:             return VariantResult(tid,desc,passed,err,ratio_s,ratio_p,ratio_th,\n3011: >>>                              t_serial+t_parallel,self.on_gpu)\n3012:     \n3013:         def run(self)->List[Dict]:\n3014:             results = []",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 3149,
          "context": "3146:             # Full suite: show summary and write CSV\n3147:             suite_summary(results)\n3148:             suite_rows = [[r[\"test_id\"], r[\"description\"], r[\"passed\"], r[\"rel_err_ratio\"],\n3149: >>>                        r[\"ratio_meas_serial\"], r[\"ratio_meas_parallel\"], r[\"ratio_theory\"], r[\"runtime_sec\"]] for r in results]\n3150:             write_csv(outdir/\"suite_summary.csv\", suite_rows,\n3151:                       [\"test_id\",\"description\",\"passed\",\"rel_err_ratio\",\"ratio_meas_serial\",\"ratio_meas_parallel\",\"ratio_theory\",\"runtime_sec\"])\n3152:             write_metadata_bundle(outdir, \"TIER2-GRAVITY\", tier=2, category=\"Gravity\")",
          "match": "parallel"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 3151,
          "context": "3148:             suite_rows = [[r[\"test_id\"], r[\"description\"], r[\"passed\"], r[\"rel_err_ratio\"],\n3149:                            r[\"ratio_meas_serial\"], r[\"ratio_meas_parallel\"], r[\"ratio_theory\"], r[\"runtime_sec\"]] for r in results]\n3150:             write_csv(outdir/\"suite_summary.csv\", suite_rows,\n3151: >>>                   [\"test_id\",\"description\",\"passed\",\"rel_err_ratio\",\"ratio_meas_serial\",\"ratio_meas_parallel\",\"ratio_theory\",\"runtime_sec\"])\n3152:             write_metadata_bundle(outdir, \"TIER2-GRAVITY\", tier=2, category=\"Gravity\")\n3153:             log(\"=== Tier-2 Suite Complete ===\", \"INFO\")\n3154:     ",
          "match": "parallel"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 886,
          "context": " 883:                 chi_responded = chi_pert_max > 0.01 * chi_bg\n 884:                 # 2. System is stable (no NaN/Inf)\n 885:                 system_stable = np.all(np.isfinite(chi_final)) and np.all(np.isfinite(E_final))\n 886: >>>             # 3. χ-perturbation is reasonable (not too large, indicating instability)\n 887:                 chi_reasonable = chi_pert_max < 10.0 * chi_bg\n 888:                 \n 889:                 passed = bool(chi_responded and system_stable and chi_reasonable)",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 1333,
          "context": "1330:                 Eprev0 = E0.copy()  # zero initial velocity\n1331:                 log(f\"Local frequency mode: uniform field, single-step measurement\", \"INFO\")\n1332:     \n1333: >>>         self.check_cfl(c, dt, dx, ndim=ndim)\n1334:             # Time-delay and phase_delay modes need absorbing boundaries to prevent wrapping\n1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)",
          "match": "cfl"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 519,
          "context": " 516:                 params_run = {\n 517:                     \"dt\": dt, \"dx\": dx, \"alpha\": alpha, \"beta\": beta,\n 518:                     \"chi\": chi_from_energy,  # spatially varying chi (numpy)\n 519: >>>                 \"boundary\": \"periodic\",\n 520:                     \"precision\": \"float64\",\n 521:                     \"debug\": {\"quiet_run\": True, \"enable_diagnostics\": False}\n 522:                 }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 519,
          "context": " 516:                 params_run = {\n 517:                     \"dt\": dt, \"dx\": dx, \"alpha\": alpha, \"beta\": beta,\n 518:                     \"chi\": chi_from_energy,  # spatially varying chi (numpy)\n 519: >>>                 \"boundary\": \"periodic\",\n 520:                     \"precision\": \"float64\",\n 521:                     \"debug\": {\"quiet_run\": True, \"enable_diagnostics\": False}\n 522:                 }",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1028,
          "context": "1025:                 # Run simulation to track packet trajectory\n1026:                 # (advance already imported at module level)\n1027:                 params_bend = {\n1028: >>>                 \"dt\": dt, \"dx\": dx, \"alpha\": alpha, \"beta\": beta, \"boundary\": \"absorbing\",\n1029:                     \"chi\": to_numpy(chi_field) if xp is np else chi_field,\n1030:                     \"Eprev\": to_numpy(Eprev0) if xp is np else Eprev0\n1031:                 }",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1028,
          "context": "1025:                 # Run simulation to track packet trajectory\n1026:                 # (advance already imported at module level)\n1027:                 params_bend = {\n1028: >>>                 \"dt\": dt, \"dx\": dx, \"alpha\": alpha, \"beta\": beta, \"boundary\": \"absorbing\",\n1029:                     \"chi\": to_numpy(chi_field) if xp is np else chi_field,\n1030:                     \"Eprev\": to_numpy(Eprev0) if xp is np else Eprev0\n1031:                 }",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1186,
          "context": "1183:                 kx = (k_fraction*math.pi/dx)\n1184:                 omega_bg = local_omega_theory(c, kx, chi_bg)\n1185:                 log(f\"SLAB RUN INITIAL CONDITIONS: k_fraction={k_fraction:.6f}, kx={kx:.6f}, omega_bg={omega_bg:.6f}\", \"INFO\")\n1186: >>>             # Packet centered very close to left boundary so it has to travel to detector\n1187:                 x_center = float(p.get(\"packet_center_frac\", 0.03)) * N  # ~2 cells from left edge\n1188:                 width_cells = float(p.get(\"packet_width_cells\", 3.0))  # Narrow packet\n1189:                 # Build envelope along x-axis",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1334,
          "context": "1331:                 log(f\"Local frequency mode: uniform field, single-step measurement\", \"INFO\")\n1332:     \n1333:             self.check_cfl(c, dt, dx, ndim=ndim)\n1334: >>>         # Time-delay and phase_delay modes need absorbing boundaries to prevent wrapping\n1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337:             boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1336,
          "context": "1333:             self.check_cfl(c, dt, dx, ndim=ndim)\n1334:             # Time-delay and phase_delay modes need absorbing boundaries to prevent wrapping\n1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336: >>>         # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337:             boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"\n1338:             params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1339:                           chi=to_numpy(chi_field) if xp is np else chi_field)",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1337,
          "context": "1334:             # Time-delay and phase_delay modes need absorbing boundaries to prevent wrapping\n1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337: >>>         boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"\n1338:             params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1339:                           chi=to_numpy(chi_field) if xp is np else chi_field)\n1340:             if \"debug\" in self.run_settings:",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1337,
          "context": "1334:             # Time-delay and phase_delay modes need absorbing boundaries to prevent wrapping\n1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337: >>>         boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"\n1338:             params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1339:                           chi=to_numpy(chi_field) if xp is np else chi_field)\n1340:             if \"debug\" in self.run_settings:",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1337,
          "context": "1334:             # Time-delay and phase_delay modes need absorbing boundaries to prevent wrapping\n1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337: >>>         boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"\n1338:             params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1339:                           chi=to_numpy(chi_field) if xp is np else chi_field)\n1340:             if \"debug\" in self.run_settings:",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1338,
          "context": "1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337:             boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"\n1338: >>>         params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1339:                           chi=to_numpy(chi_field) if xp is np else chi_field)\n1340:             if \"debug\" in self.run_settings:\n1341:                 params.setdefault(\"debug\", {})",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1338,
          "context": "1335:             # Include phase_delay_diff (GRAV-14) as it measures differential group delay at a single detector\n1336:             # Other modes use periodic (time_dilation tests need global coupling anyway)\n1337:             boundary_type = \"absorbing\" if mode in (\"time_delay\", \"phase_delay\", \"phase_delay_diff\") else \"periodic\"\n1338: >>>         params = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1339:                           chi=to_numpy(chi_field) if xp is np else chi_field)\n1340:             if \"debug\" in self.run_settings:\n1341:                 params.setdefault(\"debug\", {})",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1606,
          "context": "1603:                 for n in range(steps):\n1604:                     E_next = lattice_step(E, Ep, params)\n1605:                     \n1606: >>>                 # Enforce barrier: set field to zero inside barrier (absorbing obstacle)\n1607:                     E_next[barrier_mask] = 0.0\n1608:                     \n1609:                     # Continuous source: refresh source plane with oscillating wave (vectorized)",
          "match": "absorbing"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1961,
          "context": "1958:                 E_dot_ctrl = (amplitude * env * omega_ctrl * sin_spatial).astype(self.dtype)\n1959:                 Eprev0_ctrl = (E0_ctrl - dt * E_dot_ctrl).astype(self.dtype)\n1960:                 \n1961: >>>             params_ctrl = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1962:                                    chi=to_numpy(chi_ctrl) if xp is np else chi_ctrl)\n1963:                 \n1964:                 # DIAGNOSTIC: Print chi values at slab location for BOTH runs",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1961,
          "context": "1958:                 E_dot_ctrl = (amplitude * env * omega_ctrl * sin_spatial).astype(self.dtype)\n1959:                 Eprev0_ctrl = (E0_ctrl - dt * E_dot_ctrl).astype(self.dtype)\n1960:                 \n1961: >>>             params_ctrl = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n1962:                                    chi=to_numpy(chi_ctrl) if xp is np else chi_ctrl)\n1963:                 \n1964:                 # DIAGNOSTIC: Print chi values at slab location for BOTH runs",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 2220,
          "context": "2217:                 det_before = int(det_before_frac * N)\n2218:                 det_after = int(det_after_frac * N)\n2219:                 \n2220: >>>             # Run simulation with envelope as INITIAL CONDITION (not boundary injection)\n2221:                 # Initialize with rightward-propagating Gaussian wave packet\n2222:                 import time as time_module\n2223:                 ",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 2634,
          "context": "2631:                     return E, Eprev\n2632:     \n2633:                 def simulate_detector(chi_field_local, steps_local, track_packet=False):\n2634: >>>                 params_local = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n2635:                                         chi=to_numpy(chi_field_local) if xp is np else chi_field_local)\n2636:                     E_loc, Ep_loc = make_ic_for(chi_field_local)\n2637:                     sig = []",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 2634,
          "context": "2631:                     return E, Eprev\n2632:     \n2633:                 def simulate_detector(chi_field_local, steps_local, track_packet=False):\n2634: >>>                 params_local = dict(dt=dt, dx=dx, alpha=alpha, beta=beta, boundary=boundary_type,\n2635:                                         chi=to_numpy(chi_field_local) if xp is np else chi_field_local)\n2636:                     E_loc, Ep_loc = make_ic_for(chi_field_local)\n2637:                     sig = []",
          "match": "boundary"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1253,
          "context": "1250:                     E = (wave_amp * envelope * c_th).astype(self.dtype)\n1251:                     # For ψ=A(x-v_g t)·e^{i(kx-ωt)} ⇒ E=A cos(kx) at t=0 ⇒ E_t = ωA sin(kx) - v_g A' cos(kx)\n1252:                     E_t = (wave_amp * (omega * envelope * s_th - vg_bg * d_envelope_dx * c_th)).astype(self.dtype)\n1253: >>>                 # PDE-consistent second derivative using identical Laplacian as solver\n1254:                     lapE = laplacian(E, dx, order=int(p.get(\"stencil_order\", 2)))\n1255:                     chi_arr = chi_field.astype(self.dtype)\n1256:                     E_tt = ( (c*c) * lapE - (chi_arr * chi_arr) * E ).astype(self.dtype)",
          "match": "solver"
        }
      ],
      "line_count": 3156,
      "docstring": "LFM Tier-2 — Gravity Analogue Suite\n-----------------------------------\nPurpose:\n- Execute Tier-2 gravity-analogue tests to validate local dispersion relation\n  ω²(x) = c²k² + χ²(x) in spatially-varying χ-fields.\n  \nPhysics:\n- Single-step measurement: apply wave equation once to uniform E-field\n- For uniform field: ∇²E ≈ 0 → E_next = E - dt²χ²E → ω²(x) = χ²(x)\n- Measure ω at two probe locations (center vs edge) to verify χ-dependence\n- This tests gravitational frequency shift analog: deeper wells → higher frequencies\n\nPass Criteria:\n- Frequency ratio ω_A/ω_B matches χ_A/χ_B within 2% error\n- Tests both Gaussian wells (curved potentials) and linear gradients\n- Validates that local oscillation frequency tracks local coupling strength\n\nConfig & output:\n- Expects configuration at `./config/config_tier2_gravityanalogue.json`.\n- Writes per-test results under `results/Gravity/<TEST_ID>/` with\n  `summary.json`, `diagnostics/` and `plots/`."
    },
    {
      "filepath": "run_tier3_energy.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "9e83cdf346029935",
      "file_size": 23271,
      "modified": "2025-11-02T20:02:10.902263",
      "git_info": {
        "first_commit": {
          "hash": "543f9910",
          "date": "2025-10-30 15:16:45 -0700",
          "message": "Updated tests, gravity and relativity have confirmed we have a unified theory of some sort!"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:     def _default_config_name() -> str:\n  55:         return \"config_tier3_energy.json\"\n  56:     \n  57: >>> @dataclass\n  58:     class TestResult:\n  59:         test_id: str\n  60:         description: str",
          "match": "class\nclass TestResult:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 54,
          "context": "  51:     from lfm_test_harness import BaseTierHarness\n  52:     from lfm_test_metrics import TestMetrics\n  53:     \n  54: >>> def _default_config_name() -> str:\n  55:         return \"config_tier3_energy.json\"\n  56:     \n  57:     @dataclass",
          "match": "def _default_config_name() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 68,
          "context": "  65:         runtime_sec: float\n  66:     \n  67:     # -------------------------- Numerical helpers (2-D) -------------------------\n  68: >>> def laplacian(E, dx, order=4, xp=None):\n  69:         \"\"\"Compute Laplacian using specified backend (NumPy or CuPy).\"\"\"\n  70:         if xp is None:\n  71:             xp = get_array_module(E)",
          "match": "def laplacian(E, dx, order=4, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 85,
          "context": "  82:         else:\n  83:             raise ValueError(\"Unsupported stencil order; use 2 or 4\")\n  84:     \n  85: >>> def grad_sq(E, dx, xp=None):\n  86:         \"\"\"Compute gradient squared using specified backend.\"\"\"\n  87:         if xp is None:\n  88:             xp = get_array_module(E)",
          "match": "def grad_sq(E, dx, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 93,
          "context": "  90:         Ey = (xp.roll(E, -1, 0) - xp.roll(E, 1, 0)) / (2*dx)\n  91:         return Ex*Ex + Ey*Ey\n  92:     \n  93: >>> def energy_total(E, E_prev, dt, dx, c, chi, xp=None):\n  94:         \"\"\"Compute total energy using specified backend.\"\"\"\n  95:         if xp is None:\n  96:             xp = get_array_module(E)",
          "match": "def energy_total(E, E_prev, dt, dx, c, chi, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 101,
          "context": "  98:         dens = 0.5*(Et*Et + (c*c)*grad_sq(E, dx, xp) + (chi*chi)*(E*E))\n  99:         return float(xp.sum(dens) * dx*dx)\n 100:     \n 101: >>> def energy_components(E, E_prev, dt, dx, c, chi, xp=None):\n 102:         \"\"\"\n 103:         Compute Hamiltonian energy components: KE, GE, PE.\n 104:         ",
          "match": "def energy_components(E, E_prev, dt, dx, c, chi, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 122,
          "context": " 119:         \n 120:         return KE, GE, PE\n 121:     \n 122: >>> def entropy_shannon(E, xp=None):\n 123:         \"\"\"Compute Shannon entropy using specified backend.\"\"\"\n 124:         if xp is None:\n 125:             xp = cp if (_HAS_CUPY and isinstance(E, cp.ndarray)) else np",
          "match": "def entropy_shannon(E, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 134,
          "context": " 131:         return float(-xp.sum(p * xp.log(p + eps)))\n 132:     \n 133:     # -------------------------- χ-field constructors ----------------------------\n 134: >>> def chi_field(N, pattern: dict, dtype, xp):\n 135:         \"\"\"Build χ-field using specified backend.\"\"\"\n 136:         x = xp.linspace(-1, 1, N, dtype=dtype)\n 137:         y = xp.linspace(-1, 1, N, dtype=dtype)",
          "match": "def chi_field(N, pattern:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 151,
          "context": " 148:         return chi\n 149:     \n 150:     # --------------------------- Initial condition builders ---------------------\n 151: >>> def init_pulse(N, dtype, xp, kind=\"gaussian\", kx=8.0, width=20.0):\n 152:         \"\"\"Build initial condition using specified backend.\"\"\"\n 153:         x = xp.linspace(-1, 1, N, dtype=dtype)\n 154:         y = xp.linspace(-1, 1, N, dtype=dtype)",
          "match": "def init_pulse(N, dtype, xp, kind=\"gaussian\", kx=8.0, width=20.0):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 168,
          "context": " 165:         return xp.zeros((N, N), dtype=dtype)\n 166:     \n 167:     # ------------------------------ Test runner ------------------------------\n 168: >>> def run_test(params, tol, test, out_dir: Path, dtype, xp, on_gpu):\n 169:         \"\"\"Run a single energy conservation test.\"\"\"\n 170:         ensure_dirs(out_dir)\n 171:         test_id = test.get(\"test_id\", \"ENER-??\")",
          "match": "def run_test(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 384,
          "context": " 381:         return TestResult(test_id, desc, passed, float(rel_drift), bool(monotone_entropy), float(max_drop), runtime)\n 382:     \n 383:     # ----------------------------------- Main -----------------------------------\n 384: >>> def main():\n 385:         import argparse\n 386:         parser = argparse.ArgumentParser(description=\"Tier-3 Energy Conservation Test Suite\")\n 387:         parser.add_argument(\"--test\", type=str, default=None,",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 42,
          "context": "  39:     import matplotlib.pyplot as plt\n  40:     \n  41:     try:\n  42: >>>     import cupy as cp\n  43:         _HAS_CUPY = True\n  44:     except Exception:\n  45:         cp = None",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 43,
          "context": "  40:     \n  41:     try:\n  42:         import cupy as cp\n  43: >>>     _HAS_CUPY = True\n  44:     except Exception:\n  45:         cp = None\n  46:         _HAS_CUPY = False",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 46,
          "context": "  43:         _HAS_CUPY = True\n  44:     except Exception:\n  45:         cp = None\n  46: >>>     _HAS_CUPY = False\n  47:     \n  48:     from lfm_backend import to_numpy, get_array_module\n  49:     from lfm_console import log, suite_summary",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 69,
          "context": "  66:     \n  67:     # -------------------------- Numerical helpers (2-D) -------------------------\n  68:     def laplacian(E, dx, order=4, xp=None):\n  69: >>>     \"\"\"Compute Laplacian using specified backend (NumPy or CuPy).\"\"\"\n  70:         if xp is None:\n  71:             xp = get_array_module(E)\n  72:         if order == 2:",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 113,
          "context": " 110:         H_total = KE + GE + PE should be conserved.\n 111:         \"\"\"\n 112:         if xp is None:\n 113: >>>         xp = cp if (_HAS_CUPY and isinstance(E, cp.ndarray)) else np\n 114:         \n 115:         Et = (E - E_prev) / dt\n 116:         KE = float(0.5 * xp.sum(Et * Et) * dx*dx)",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 125,
          "context": " 122:     def entropy_shannon(E, xp=None):\n 123:         \"\"\"Compute Shannon entropy using specified backend.\"\"\"\n 124:         if xp is None:\n 125: >>>         xp = cp if (_HAS_CUPY and isinstance(E, cp.ndarray)) else np\n 126:         p = xp.abs(E)**2\n 127:         s = xp.sum(p)\n 128:         if float(s) == 0.0: return 0.0",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 168,
          "context": " 165:         return xp.zeros((N, N), dtype=dtype)\n 166:     \n 167:     # ------------------------------ Test runner ------------------------------\n 168: >>> def run_test(params, tol, test, out_dir: Path, dtype, xp, on_gpu):\n 169:         \"\"\"Run a single energy conservation test.\"\"\"\n 170:         ensure_dirs(out_dir)\n 171:         test_id = test.get(\"test_id\", \"ENER-??\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 343,
          "context": " 340:                      [\"time\", \"KE\", \"GE\", \"PE\", \"H_total\"])\n 341:     \n 342:         # --- Hardware info ---\n 343: >>>     if on_gpu and _HAS_CUPY:\n 344:             try:\n 345:                 gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 343,
          "context": " 340:                      [\"time\", \"KE\", \"GE\", \"PE\", \"H_total\"])\n 341:     \n 342:         # --- Hardware info ---\n 343: >>>     if on_gpu and _HAS_CUPY:\n 344:             try:\n 345:                 gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:         # --- Hardware info ---\n 343:         if on_gpu and _HAS_CUPY:\n 344:             try:\n 345: >>>             gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348:                 gpu_name = \"GPU (unknown)\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 345,
          "context": " 342:         # --- Hardware info ---\n 343:         if on_gpu and _HAS_CUPY:\n 344:             try:\n 345: >>>             gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348:                 gpu_name = \"GPU (unknown)\"",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 346,
          "context": " 343:         if on_gpu and _HAS_CUPY:\n 344:             try:\n 345:                 gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346: >>>             cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348:                 gpu_name = \"GPU (unknown)\"\n 349:                 cuda_ver = 0",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 346,
          "context": " 343:         if on_gpu and _HAS_CUPY:\n 344:             try:\n 345:                 gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346: >>>             cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348:                 gpu_name = \"GPU (unknown)\"\n 349:                 cuda_ver = 0",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 348,
          "context": " 345:                 gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348: >>>             gpu_name = \"GPU (unknown)\"\n 349:                 cuda_ver = 0\n 350:         else:\n 351:             gpu_name = \"CPU\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 348,
          "context": " 345:                 gpu_name = cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode()\n 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348: >>>             gpu_name = \"GPU (unknown)\"\n 349:                 cuda_ver = 0\n 350:         else:\n 351:             gpu_name = \"CPU\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 349,
          "context": " 346:                 cuda_ver = int(cp.cuda.runtime.runtimeGetVersion())\n 347:             except Exception:\n 348:                 gpu_name = \"GPU (unknown)\"\n 349: >>>             cuda_ver = 0\n 350:         else:\n 351:             gpu_name = \"CPU\"\n 352:             cuda_ver = 0",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 351,
          "context": " 348:                 gpu_name = \"GPU (unknown)\"\n 349:                 cuda_ver = 0\n 350:         else:\n 351: >>>         gpu_name = \"CPU\"\n 352:             cuda_ver = 0\n 353:     \n 354:         # --- Save summary ---",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 352,
          "context": " 349:                 cuda_ver = 0\n 350:         else:\n 351:             gpu_name = \"CPU\"\n 352: >>>         cuda_ver = 0\n 353:     \n 354:         # --- Save summary ---\n 355:         summary = {",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 362,
          "context": " 359:             \"description\": desc,\n 360:             \"timestamp\": datetime.now(timezone.utc).isoformat(),\n 361:             \"hardware\": {\n 362: >>>             \"gpu_name\": gpu_name,\n 363:                 \"cuda_runtime\": cuda_ver,\n 364:                 \"python\": platform.python_version(),\n 365:                 \"backend\": \"CuPy\" if on_gpu else \"NumPy\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 362,
          "context": " 359:             \"description\": desc,\n 360:             \"timestamp\": datetime.now(timezone.utc).isoformat(),\n 361:             \"hardware\": {\n 362: >>>             \"gpu_name\": gpu_name,\n 363:                 \"cuda_runtime\": cuda_ver,\n 364:                 \"python\": platform.python_version(),\n 365:                 \"backend\": \"CuPy\" if on_gpu else \"NumPy\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 363,
          "context": " 360:             \"timestamp\": datetime.now(timezone.utc).isoformat(),\n 361:             \"hardware\": {\n 362:                 \"gpu_name\": gpu_name,\n 363: >>>             \"cuda_runtime\": cuda_ver,\n 364:                 \"python\": platform.python_version(),\n 365:                 \"backend\": \"CuPy\" if on_gpu else \"NumPy\"\n 366:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 363,
          "context": " 360:             \"timestamp\": datetime.now(timezone.utc).isoformat(),\n 361:             \"hardware\": {\n 362:                 \"gpu_name\": gpu_name,\n 363: >>>             \"cuda_runtime\": cuda_ver,\n 364:                 \"python\": platform.python_version(),\n 365:                 \"backend\": \"CuPy\" if on_gpu else \"NumPy\"\n 366:             },",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 365,
          "context": " 362:                 \"gpu_name\": gpu_name,\n 363:                 \"cuda_runtime\": cuda_ver,\n 364:                 \"python\": platform.python_version(),\n 365: >>>             \"backend\": \"CuPy\" if on_gpu else \"NumPy\"\n 366:             },\n 367:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":cfl,\"stencil_order\":stencil_order},\n 368:             \"metrics\": {",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 365,
          "context": " 362:                 \"gpu_name\": gpu_name,\n 363:                 \"cuda_runtime\": cuda_ver,\n 364:                 \"python\": platform.python_version(),\n 365: >>>             \"backend\": \"CuPy\" if on_gpu else \"NumPy\"\n 366:             },\n 367:             \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":cfl,\"stencil_order\":stencil_order},\n 368:             \"metrics\": {",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 409,
          "context": " 406:         \n 407:         # Resolve backend\n 408:         from lfm_backend import pick_backend\n 409: >>>     use_gpu = cfg[\"hardware\"].get(\"gpu_enabled\", True)\n 410:         xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 409,
          "context": " 406:         \n 407:         # Resolve backend\n 408:         from lfm_backend import pick_backend\n 409: >>>     use_gpu = cfg[\"hardware\"].get(\"gpu_enabled\", True)\n 410:         xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 410,
          "context": " 407:         # Resolve backend\n 408:         from lfm_backend import pick_backend\n 409:         use_gpu = cfg[\"hardware\"].get(\"gpu_enabled\", True)\n 410: >>>     xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:\n 413:                 cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 410,
          "context": " 407:         # Resolve backend\n 408:         from lfm_backend import pick_backend\n 409:         use_gpu = cfg[\"hardware\"].get(\"gpu_enabled\", True)\n 410: >>>     xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:\n 413:                 cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 411,
          "context": " 408:         from lfm_backend import pick_backend\n 409:         use_gpu = cfg[\"hardware\"].get(\"gpu_enabled\", True)\n 410:         xp, on_gpu = pick_backend(use_gpu)\n 411: >>>     if on_gpu and _HAS_CUPY:\n 412:             try:\n 413:                 cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 414:             except Exception:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 411,
          "context": " 408:         from lfm_backend import pick_backend\n 409:         use_gpu = cfg[\"hardware\"].get(\"gpu_enabled\", True)\n 410:         xp, on_gpu = pick_backend(use_gpu)\n 411: >>>     if on_gpu and _HAS_CUPY:\n 412:             try:\n 413:                 cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 414:             except Exception:",
          "match": "CUPY"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 413,
          "context": " 410:         xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:\n 413: >>>             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 414:             except Exception:\n 415:                 log(\"GPU memory pool setup failed; continuing with default allocator\", \"WARN\")\n 416:         ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 413,
          "context": " 410:         xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:\n 413: >>>             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 414:             except Exception:\n 415:                 log(\"GPU memory pool setup failed; continuing with default allocator\", \"WARN\")\n 416:         ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 413,
          "context": " 410:         xp, on_gpu = pick_backend(use_gpu)\n 411:         if on_gpu and _HAS_CUPY:\n 412:             try:\n 413: >>>             cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 414:             except Exception:\n 415:                 log(\"GPU memory pool setup failed; continuing with default allocator\", \"WARN\")\n 416:         ",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 415,
          "context": " 412:             try:\n 413:                 cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)\n 414:             except Exception:\n 415: >>>             log(\"GPU memory pool setup failed; continuing with default allocator\", \"WARN\")\n 416:         \n 417:         precision = cfg[\"hardware\"].get(\"precision\", \"float64\")\n 418:         dtype = xp.float64 if precision == \"float64\" else xp.float32",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 440,
          "context": " 437:                 return\n 438:             log(f\"=== Running Single Test: {args.test} ===\", \"INFO\")\n 439:         else:\n 440: >>>         log(f\"=== Tier-3 Energy Conservation Suite Start (backend={'CuPy' if on_gpu else 'NumPy'}) ===\", \"INFO\")\n 441:     \n 442:         # Run tests\n 443:         results = []",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 440,
          "context": " 437:                 return\n 438:             log(f\"=== Running Single Test: {args.test} ===\", \"INFO\")\n 439:         else:\n 440: >>>         log(f\"=== Tier-3 Energy Conservation Suite Start (backend={'CuPy' if on_gpu else 'NumPy'}) ===\", \"INFO\")\n 441:     \n 442:         # Run tests\n 443:         results = []",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 461,
          "context": " 458:             tracker.start(background=True)\n 459:             \n 460:             # Run test\n 461: >>>         result = run_test(p, tol, test, out_base / test_dirname, dtype, xp, on_gpu)\n 462:             \n 463:             # Stop tracking and get metrics\n 464:             tracker.stop()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 477,
          "context": " 474:                 \"runtime_sec\": metrics[\"runtime_sec\"],\n 475:                 \"peak_cpu_percent\": metrics[\"peak_cpu_percent\"],\n 476:                 \"peak_memory_mb\": metrics[\"peak_memory_mb\"],\n 477: >>>             \"peak_gpu_memory_mb\": metrics[\"peak_gpu_memory_mb\"],\n 478:             })\n 479:     \n 480:         # Suite summary",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 477,
          "context": " 474:                 \"runtime_sec\": metrics[\"runtime_sec\"],\n 475:                 \"peak_cpu_percent\": metrics[\"peak_cpu_percent\"],\n 476:                 \"peak_memory_mb\": metrics[\"peak_memory_mb\"],\n 477: >>>             \"peak_gpu_memory_mb\": metrics[\"peak_gpu_memory_mb\"],\n 478:             })\n 479:     \n 480:         # Suite summary",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 498,
          "context": " 495:                 \"runtime_sec\": r[\"runtime_sec\"],\n 496:                 \"peak_cpu_percent\": r[\"peak_cpu_percent\"],\n 497:                 \"peak_memory_mb\": r[\"peak_memory_mb\"],\n 498: >>>             \"peak_gpu_memory_mb\": r[\"peak_gpu_memory_mb\"],\n 499:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 500:             }\n 501:             test_metrics.record_run(r[\"test_id\"], metrics_data)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 498,
          "context": " 495:                 \"runtime_sec\": r[\"runtime_sec\"],\n 496:                 \"peak_cpu_percent\": r[\"peak_cpu_percent\"],\n 497:                 \"peak_memory_mb\": r[\"peak_memory_mb\"],\n 498: >>>             \"peak_gpu_memory_mb\": r[\"peak_gpu_memory_mb\"],\n 499:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n 500:             }\n 501:             test_metrics.record_run(r[\"test_id\"], metrics_data)",
          "match": "gpu"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 182,
          "context": " 179:         save_every = int(params.get(\"save_every\", 10))\n 180:         stencil_order = int(params.get(\"stencil_order\", 4))\n 181:     \n 182: >>>     cfl = c*dt/dx\n 183:         if cfl > 0.9:\n 184:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 185:     ",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 183,
          "context": " 180:         stencil_order = int(params.get(\"stencil_order\", 4))\n 181:     \n 182:         cfl = c*dt/dx\n 183: >>>     if cfl > 0.9:\n 184:             raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 185:     \n 186:         chi = chi_field(N, test, dtype, xp)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 184,
          "context": " 181:     \n 182:         cfl = c*dt/dx\n 183:         if cfl > 0.9:\n 184: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 185:     \n 186:         chi = chi_field(N, test, dtype, xp)\n 187:         E = init_pulse(N, dtype, xp, kind=test.get(\"ic\",\"gaussian\"),",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 184,
          "context": " 181:     \n 182:         cfl = c*dt/dx\n 183:         if cfl > 0.9:\n 184: >>>         raise ValueError(f\"CFL too high (c*dt/dx={cfl:.3f} > 0.9).\")\n 185:     \n 186:         chi = chi_field(N, test, dtype, xp)\n 187:         E = init_pulse(N, dtype, xp, kind=test.get(\"ic\",\"gaussian\"),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 208,
          "context": " 205:         t0 = time.time()\n 206:     \n 207:         for t in range(steps):\n 208: >>>         # --- Optionally enforce energy (only for stability tests, NOT conservation tests) ---\n 209:             if enforce_energy:\n 210:                 Etot_cur = energy_total(E, E_prev, dt, dx, c, chi, xp)\n 211:                 scale_cur = math.sqrt(E0 / (Etot_cur + 1e-30))",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 367,
          "context": " 364:                 \"python\": platform.python_version(),\n 365:                 \"backend\": \"CuPy\" if on_gpu else \"NumPy\"\n 366:             },\n 367: >>>         \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":cfl,\"stencil_order\":stencil_order},\n 368:             \"metrics\": {\n 369:                 \"energy_rel_drift\": float(rel_drift),\n 370:                 \"entropy_monotonic\": bool(monotone_entropy),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 367,
          "context": " 364:                 \"python\": platform.python_version(),\n 365:                 \"backend\": \"CuPy\" if on_gpu else \"NumPy\"\n 366:             },\n 367: >>>         \"parameters\": {\"N\":N,\"steps\":steps,\"dt\":dt,\"dx\":dx,\"c\":c,\"cfl\":cfl,\"stencil_order\":stencil_order},\n 368:             \"metrics\": {\n 369:                 \"energy_rel_drift\": float(rel_drift),\n 370:                 \"entropy_monotonic\": bool(monotone_entropy),",
          "match": "cfl"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 229,
          "context": " 226:                     GE_trace.append(GE)\n 227:                     PE_trace.append(PE)\n 228:     \n 229: >>>         # Advance one leapfrog step\n 230:             lap = laplacian(E, dx, order=stencil_order, xp=xp)\n 231:             E_next = 2*E - E_prev + (dt*dt)*((c*c)*lap - (chi*chi)*E)\n 232:     ",
          "match": "leapfrog"
        }
      ],
      "line_count": 563,
      "docstring": "LFM Tier-3 — Energy Conservation Tests (2-D, Unified)\n---------------------------------------------------\nPurpose:\n- Execute Tier-3 energy conservation tests to validate fundamental conservation\n  laws and thermodynamic emergence in the lattice field model.\n  \nPhysics:\n- Tests energy drift in isolated systems (ENER-01, 02)\n- Tests energy conservation in curved spacetime (χ-gradients, ENER-03, 04)\n- Tests entropy growth from random initial conditions (ENER-05, 07)\n- Tests controlled energy extraction via damping (ENER-06)\n\nPass Criteria:\n- Clean wave packets: energy drift < 1% over long runs\n- Noisy initial conditions: entropy increases monotonically\n- Damping: energy decreases as expected\n\nConfig & output:\n- Expects configuration at `./config/config_tier3_energy.json`.\n- Writes per-test results under `results/Energy/<TEST_ID>/` with\n  `summary.json`, `diagnostics/` and `plots/`."
    },
    {
      "filepath": "run_tier4_quantization.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "d9036bcd4e69f1f1",
      "file_size": 102316,
      "modified": "2025-11-02T20:02:10.906706",
      "git_info": {
        "first_commit": {
          "hash": "f0885273",
          "date": "2025-10-30 17:51:45 -0700",
          "message": "Additional tests, harnesses"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 29,
          "context": "  26:     from lfm_test_harness import BaseTierHarness\n  27:     from lfm_test_metrics import TestMetrics\n  28:     \n  29: >>> @dataclass\n  30:     class TestResult:\n  31:         test_id: str\n  32:         description: str",
          "match": "class\nclass TestResult:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:         metrics: Dict\n  35:         runtime_sec: float\n  36:     \n  37: >>> def _default_config_name() -> str:\n  38:         return \"config_tier4_quantization.json\"\n  39:     \n  40:     # ------------------------------- 1D helpers --------------------------------",
          "match": "def _default_config_name() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 41,
          "context": "  38:         return \"config_tier4_quantization.json\"\n  39:     \n  40:     # ------------------------------- 1D helpers --------------------------------\n  41: >>> def laplacian_1d(E, dx, order=2, xp=None):\n  42:         \"\"\"1D Laplacian with periodic boundaries (will be overridden by apply_dirichlet if needed)\"\"\"\n  43:         if xp is None:\n  44:             xp = get_array_module(E)",
          "match": "def laplacian_1d(E, dx, order=2, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 52,
          "context": "  49:         else:\n  50:             raise ValueError('order must be 2 or 4')\n  51:     \n  52: >>> def apply_dirichlet(E):\n  53:         \"\"\"Force E=0 at boundaries for Dirichlet conditions\"\"\"\n  54:         E[0] = 0.0\n  55:         E[-1] = 0.0",
          "match": "def apply_dirichlet(E):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:         E[0] = 0.0\n  55:         E[-1] = 0.0\n  56:     \n  57: >>> def energy_total(E, E_prev, dt, dx, c, chi, xp=None):\n  58:         \"\"\"\n  59:         Compute total Klein-Gordon energy: H = ½ ∫ [(∂E/∂t)² + c²(∇E)² + χ²E²] dV\n  60:         Works with both NumPy and CuPy arrays.",
          "match": "def energy_total(E, E_prev, dt, dx, c, chi, xp=None):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 95,
          "context": "  92:         return float(xp.sum(energy_density) * dV)\n  93:     \n  94:     # ----------------------- Energy Transfer Tests (QUAN-01, 02) --------------------------\n  95: >>> def run_energy_transfer(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n  96:         \"\"\"\n  97:         Test energy conservation during mode exchange.\n  98:         Initialize two modes with different amplitudes, evolve, verify total energy constant.",
          "match": "def run_energy_transfer(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 136,
          "context": " 133:         \n 134:         c = 1.0  # Speed of light in lattice units\n 135:         \n 136: >>>     def compute_mode_energy(field, field_prev, mode_n):\n 137:             \"\"\"Project onto mode and compute its energy\"\"\"\n 138:             k_n = mode_n * np.pi / L\n 139:             mode_shape = np.sin(k_n * to_numpy(x))",
          "match": "def compute_mode_energy(field, field_prev, mode_n):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 232,
          "context": " 229:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 230:     \n 231:     # ----------------------- Spectral Linearity Tests (QUAN-03, 04) --------------------------\n 232: >>> def run_spectral_linearity(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 233:         \"\"\"\n 234:         Test that spectral response scales linearly with amplitude.\n 235:         For linear system: E(2A) should have 4x energy of E(A).",
          "match": "def run_spectral_linearity(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 342,
          "context": " 339:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 340:     \n 341:     # ----------------------- Linearity Tests (QUAN-05, 06) --------------------------\n 342: >>> def run_phase_amplitude_coupling(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 343:         \"\"\"\n 344:         Test linearity via superposition principle.\n 345:         ",
          "match": "def run_phase_amplitude_coupling(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 377,
          "context": " 374:         log(f\"[{test_id}] Linearity test via superposition: modes n={mode1},{mode2}, A={base_amplitude}\", \"INFO\")\n 375:         \n 376:         # Helper to evolve a field\n 377: >>>     def evolve_field(E_init):\n 378:             E = E_init.copy()\n 379:             k1 = mode1 * np.pi / L\n 380:             omega1 = np.sqrt(k1**2 + chi**2)",
          "match": "def evolve_field(E_init):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 498,
          "context": " 495:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 496:     \n 497:     # ----------------------- Wavefront Stability Test (QUAN-07) --------------------------\n 498: >>> def run_wavefront_stability(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 499:         \"\"\"\n 500:         Test that large-amplitude wavepackets maintain shape (no nonlinear steepening).\n 501:         For linear system, Gaussian packet should disperse but not steepen.",
          "match": "def run_wavefront_stability(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 628,
          "context": " 625:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 626:     \n 627:     # ----------------------- Lattice Blowout Test (QUAN-08) --------------------------\n 628: >>> def run_lattice_blowout(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 629:         \"\"\"\n 630:         Test numerical stability at high energy near CFL limit.\n 631:         Should not blow up (fields stay finite).",
          "match": "def run_lattice_blowout(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 750,
          "context": " 747:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 748:     \n 749:     # ----------------------- Planck distribution test --------------------------\n 750: >>> def run_planck_distribution(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 751:         \"\"\"\n 752:         QUAN-14: Non-thermalization test (conservation check)\n 753:         ",
          "match": "def run_planck_distribution(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 999,
          "context": " 996:     \n 997:     \n 998:     # ------------------------- Zero-point energy test --------------------------\n 999: >>> def run_zero_point_energy(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1000:         \"\"\"\n1001:         QUAN-11: Zero-point energy - quantum ground state E₀ = ½ℏω ≠ 0\n1002:         ",
          "match": "def run_zero_point_energy(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1224,
          "context": "1221:     \n1222:     \n1223:     # ----------------------- Wave-particle duality test ------------------------\n1224: >>> def run_wave_particle_duality(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1225:         \"\"\"\n1226:         QUAN-13: Wave-particle duality - which-way information destroys interference\n1227:         ",
          "match": "def run_wave_particle_duality(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1361,
          "context": "1358:         log(f\"[{test_id}] Analysis region: {len(I_no_det_screen)} points from x=[{x_screen.min():.1f}, {x_screen.max():.1f}], excluding slits at x={slit1_center:.1f}, {slit2_center:.1f}\", \"INFO\")\n1359:         \n1360:         # Visibility: V = (I_max - I_min) / (I_max + I_min)\n1361: >>>     def compute_visibility(intensity):\n1362:             if len(intensity) < 10:\n1363:                 return 0.0\n1364:             # Smooth to remove noise",
          "match": "def compute_visibility(intensity):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1374,
          "context": "1371:             return (I_max - I_min) / (I_max + I_min)\n1372:         \n1373:         # Alternative: count fringes (peaks) - more sensitive to interference\n1374: >>>     def count_fringes(intensity):\n1375:             from scipy.signal import find_peaks\n1376:             peaks, _ = find_peaks(intensity, prominence=0.1*np.max(intensity))\n1377:             return len(peaks)",
          "match": "def count_fringes(intensity):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1494,
          "context": "1491:     \n1492:     \n1493:     # --------------------------- Cavity spectroscopy ---------------------------\n1494: >>> def run_cavity_spectroscopy(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1495:         ensure_dirs(out_dir)\n1496:         test_id = test['test_id']\n1497:         desc = test['description']",
          "match": "def run_cavity_spectroscopy(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1581,
          "context": "1578:         spec = np.max(np.abs(np.fft.rfft(mode_amplitudes, axis=0)), axis=1)  # For plotting\n1579:         \n1580:         # Theoretical mode frequencies: ω_n^2 = (nπ/L)^2 + χ^2\n1581: >>>     def mode_omega(n):\n1582:             k_n = n * np.pi / L\n1583:             return np.sqrt(k_n**2 + chi**2)\n1584:         ",
          "match": "def mode_omega(n):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1640,
          "context": "1637:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n1638:     \n1639:     # --------------------------- Threshold test --------------------------------\n1640: >>> def run_threshold_test(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1641:         ensure_dirs(out_dir)\n1642:         test_id = test['test_id']\n1643:         desc = test['description']",
          "match": "def run_threshold_test(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1764,
          "context": "1761:     \n1762:     # --------------------------- Famous equation test --------------------------\n1763:     # --------------------------- QUAN-10: Bound State Quantization ---------------------------\n1764: >>> def run_bound_state_quantization(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1765:         \"\"\"\n1766:         CRITICAL QUANTUM TEST: Prove discrete energy eigenvalues emerge from boundary conditions.\n1767:         ",
          "match": "def run_bound_state_quantization(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 1985,
          "context": "1982:     \n1983:     \n1984:     # --------------------------- QUAN-12: Quantum Tunneling ---------------------------\n1985: >>> def run_tunneling_test(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1986:         \"\"\"\n1987:         CRITICAL QUANTUM TEST: Wave packet penetrates classically forbidden barrier.\n1988:         ",
          "match": "def run_tunneling_test(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2211,
          "context": "2208:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n2209:     \n2210:     \n2211: >>> def run_uncertainty_test(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n2212:         ensure_dirs(out_dir)\n2213:         test_id = test['test_id']\n2214:         desc = test['description']",
          "match": "def run_uncertainty_test(params, tol, test, out_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 2304,
          "context": "2301:         return TestResult(test_id, desc, passed, summary[\"metrics\"], 0.0)\n2302:     \n2303:     # ------------------------------- Main runner -------------------------------\n2304: >>> def main():\n2305:         import argparse\n2306:         parser = argparse.ArgumentParser(description='Tier-4 Quantization & Spectra Suite')\n2307:         parser.add_argument('--test', type=str, default=None, help='Run single test by ID (e.g., QUAN-09)')",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 60,
          "context": "  57:     def energy_total(E, E_prev, dt, dx, c, chi, xp=None):\n  58:         \"\"\"\n  59:         Compute total Klein-Gordon energy: H = ½ ∫ [(∂E/∂t)² + c²(∇E)² + χ²E²] dV\n  60: >>>     Works with both NumPy and CuPy arrays.\n  61:         \"\"\"\n  62:         if xp is None:\n  63:             xp = get_array_module(E)",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 95,
          "context": "  92:         return float(xp.sum(energy_density) * dV)\n  93:     \n  94:     # ----------------------- Energy Transfer Tests (QUAN-01, 02) --------------------------\n  95: >>> def run_energy_transfer(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n  96:         \"\"\"\n  97:         Test energy conservation during mode exchange.\n  98:         Initialize two modes with different amplitudes, evolve, verify total energy constant.",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 215,
          "context": " 212:             \"test_id\": test_id,\n 213:             \"description\": desc,\n 214:             \"timestamp\": time.time(),\n 215: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 216:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"mode_1\": mode_1, \"mode_2\": mode_2},\n 217:             \"metrics\": {\n 218:                 \"max_energy_drift\": float(max_drift),",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 215,
          "context": " 212:             \"test_id\": test_id,\n 213:             \"description\": desc,\n 214:             \"timestamp\": time.time(),\n 215: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 216:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"mode_1\": mode_1, \"mode_2\": mode_2},\n 217:             \"metrics\": {\n 218:                 \"max_energy_drift\": float(max_drift),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 232,
          "context": " 229:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 230:     \n 231:     # ----------------------- Spectral Linearity Tests (QUAN-03, 04) --------------------------\n 232: >>> def run_spectral_linearity(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 233:         \"\"\"\n 234:         Test that spectral response scales linearly with amplitude.\n 235:         For linear system: E(2A) should have 4x energy of E(A).",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 324,
          "context": " 321:             \"test_id\": test_id,\n 322:             \"description\": desc,\n 323:             \"timestamp\": time.time(),\n 324: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 325:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"num_modes\": num_modes},\n 326:             \"metrics\": {\n 327:                 \"max_linearity_error\": float(max_error),",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 324,
          "context": " 321:             \"test_id\": test_id,\n 322:             \"description\": desc,\n 323:             \"timestamp\": time.time(),\n 324: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 325:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"num_modes\": num_modes},\n 326:             \"metrics\": {\n 327:                 \"max_linearity_error\": float(max_error),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 342,
          "context": " 339:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 340:     \n 341:     # ----------------------- Linearity Tests (QUAN-05, 06) --------------------------\n 342: >>> def run_phase_amplitude_coupling(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 343:         \"\"\"\n 344:         Test linearity via superposition principle.\n 345:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 480,
          "context": " 477:             \"test_id\": test_id,\n 478:             \"description\": desc,\n 479:             \"timestamp\": time.time(),\n 480: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 481:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"modes\": [mode1, mode2], \"noise_level\": noise_level},\n 482:             \"metrics\": {\n 483:                 \"scaling_error_percent\": float(scaling_error * 100),",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 480,
          "context": " 477:             \"test_id\": test_id,\n 478:             \"description\": desc,\n 479:             \"timestamp\": time.time(),\n 480: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 481:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"modes\": [mode1, mode2], \"noise_level\": noise_level},\n 482:             \"metrics\": {\n 483:                 \"scaling_error_percent\": float(scaling_error * 100),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 498,
          "context": " 495:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 496:     \n 497:     # ----------------------- Wavefront Stability Test (QUAN-07) --------------------------\n 498: >>> def run_wavefront_stability(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 499:         \"\"\"\n 500:         Test that large-amplitude wavepackets maintain shape (no nonlinear steepening).\n 501:         For linear system, Gaussian packet should disperse but not steepen.",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 610,
          "context": " 607:             \"test_id\": test_id,\n 608:             \"description\": desc,\n 609:             \"timestamp\": time.time(),\n 610: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 611:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"amplitude\": packet_amplitude},\n 612:             \"metrics\": {\n 613:                 \"initial_gradient\": float(initial_grad),",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 610,
          "context": " 607:             \"test_id\": test_id,\n 608:             \"description\": desc,\n 609:             \"timestamp\": time.time(),\n 610: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 611:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"amplitude\": packet_amplitude},\n 612:             \"metrics\": {\n 613:                 \"initial_gradient\": float(initial_grad),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 628,
          "context": " 625:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 626:     \n 627:     # ----------------------- Lattice Blowout Test (QUAN-08) --------------------------\n 628: >>> def run_lattice_blowout(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 629:         \"\"\"\n 630:         Test numerical stability at high energy near CFL limit.\n 631:         Should not blow up (fields stay finite).",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 732,
          "context": " 729:             \"test_id\": test_id,\n 730:             \"description\": desc,\n 731:             \"timestamp\": time.time(),\n 732: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 733:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"cfl_fraction\": cfl_fraction, \"amplitude\": packet_amplitude},\n 734:             \"metrics\": {\n 735:                 \"final_energy\": float(final_energy),",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 732,
          "context": " 729:             \"test_id\": test_id,\n 730:             \"description\": desc,\n 731:             \"timestamp\": time.time(),\n 732: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 733:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"cfl_fraction\": cfl_fraction, \"amplitude\": packet_amplitude},\n 734:             \"metrics\": {\n 735:                 \"final_energy\": float(final_energy),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 750,
          "context": " 747:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 748:     \n 749:     # ----------------------- Planck distribution test --------------------------\n 750: >>> def run_planck_distribution(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 751:         \"\"\"\n 752:         QUAN-14: Non-thermalization test (conservation check)\n 753:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 972,
          "context": " 969:             \"test_id\": test_id,\n 970:             \"description\": desc,\n 971:             \"timestamp\": time.time(),\n 972: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n 973:             \"parameters\": {\n 974:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi,\n 975:                 \"temperature\": temperature, \"num_modes\": num_modes,",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 972,
          "context": " 969:             \"test_id\": test_id,\n 970:             \"description\": desc,\n 971:             \"timestamp\": time.time(),\n 972: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n 973:             \"parameters\": {\n 974:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi,\n 975:                 \"temperature\": temperature, \"num_modes\": num_modes,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 999,
          "context": " 996:     \n 997:     \n 998:     # ------------------------- Zero-point energy test --------------------------\n 999: >>> def run_zero_point_energy(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1000:         \"\"\"\n1001:         QUAN-11: Zero-point energy - quantum ground state E₀ = ½ℏω ≠ 0\n1002:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1197,
          "context": "1194:             \"test_id\": test_id,\n1195:             \"description\": desc,\n1196:             \"timestamp\": time.time(),\n1197: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n1198:             \"parameters\": {\n1199:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi,\n1200:                 \"num_modes\": num_modes, \"steps\": steps",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1197,
          "context": "1194:             \"test_id\": test_id,\n1195:             \"description\": desc,\n1196:             \"timestamp\": time.time(),\n1197: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n1198:             \"parameters\": {\n1199:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi,\n1200:                 \"num_modes\": num_modes, \"steps\": steps",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1224,
          "context": "1221:     \n1222:     \n1223:     # ----------------------- Wave-particle duality test ------------------------\n1224: >>> def run_wave_particle_duality(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1225:         \"\"\"\n1226:         QUAN-13: Wave-particle duality - which-way information destroys interference\n1227:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1464,
          "context": "1461:             \"test_id\": test_id,\n1462:             \"description\": desc,\n1463:             \"timestamp\": time.time(),\n1464: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n1465:             \"parameters\": {\n1466:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi,\n1467:                 \"slit_separation\": slit_separation, \"slit_width\": slit_width,",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1464,
          "context": "1461:             \"test_id\": test_id,\n1462:             \"description\": desc,\n1463:             \"timestamp\": time.time(),\n1464: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n1465:             \"parameters\": {\n1466:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi,\n1467:                 \"slit_separation\": slit_separation, \"slit_width\": slit_width,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1494,
          "context": "1491:     \n1492:     \n1493:     # --------------------------- Cavity spectroscopy ---------------------------\n1494: >>> def run_cavity_spectroscopy(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1495:         ensure_dirs(out_dir)\n1496:         test_id = test['test_id']\n1497:         desc = test['description']",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1628,
          "context": "1625:             \"test_id\": test_id,\n1626:             \"description\": desc,\n1627:             \"timestamp\": time.time(),\n1628: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n1629:             \"parameters\": {\"N\":N,\"dx\":dx,\"dt\":dt,\"chi\":chi,\"L\":L},\n1630:             \"metrics\": {\"mean_mode_error\": float(mean_err), \"num_modes\": len(measured_modes)},\n1631:             \"status\": \"Passed\" if passed else \"Failed\"",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1628,
          "context": "1625:             \"test_id\": test_id,\n1626:             \"description\": desc,\n1627:             \"timestamp\": time.time(),\n1628: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n1629:             \"parameters\": {\"N\":N,\"dx\":dx,\"dt\":dt,\"chi\":chi,\"L\":L},\n1630:             \"metrics\": {\"mean_mode_error\": float(mean_err), \"num_modes\": len(measured_modes)},\n1631:             \"status\": \"Passed\" if passed else \"Failed\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1640,
          "context": "1637:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n1638:     \n1639:     # --------------------------- Threshold test --------------------------------\n1640: >>> def run_threshold_test(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1641:         ensure_dirs(out_dir)\n1642:         test_id = test['test_id']\n1643:         desc = test['description']",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1751,
          "context": "1748:             \"test_id\": test_id,\n1749:             \"description\": desc,\n1750:             \"timestamp\": time.time(),\n1751: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n1752:             \"parameters\": {\"N\":N,\"dx\":dx,\"dt\":dt,\"chi\":chi},\n1753:             \"metrics\": {\"omega_th_theory\": omega_th_theory, \"omega_th_measured\": float(omega_th_measured), \"rel_error\": float(err)},\n1754:             \"status\": \"Passed\" if passed else \"Failed\"",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1751,
          "context": "1748:             \"test_id\": test_id,\n1749:             \"description\": desc,\n1750:             \"timestamp\": time.time(),\n1751: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n1752:             \"parameters\": {\"N\":N,\"dx\":dx,\"dt\":dt,\"chi\":chi},\n1753:             \"metrics\": {\"omega_th_theory\": omega_th_theory, \"omega_th_measured\": float(omega_th_measured), \"rel_error\": float(err)},\n1754:             \"status\": \"Passed\" if passed else \"Failed\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1764,
          "context": "1761:     \n1762:     # --------------------------- Famous equation test --------------------------\n1763:     # --------------------------- QUAN-10: Bound State Quantization ---------------------------\n1764: >>> def run_bound_state_quantization(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1765:         \"\"\"\n1766:         CRITICAL QUANTUM TEST: Prove discrete energy eigenvalues emerge from boundary conditions.\n1767:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1964,
          "context": "1961:             \"description\": desc,\n1962:             \"passed\": passed,\n1963:             \"timestamp\": time.time(),\n1964: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n1965:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"L\": L, \"num_modes\": num_modes},\n1966:             \"metrics\": {\n1967:                 \"mean_error\": float(mean_error),",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1964,
          "context": "1961:             \"description\": desc,\n1962:             \"passed\": passed,\n1963:             \"timestamp\": time.time(),\n1964: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n1965:             \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"chi\": chi, \"L\": L, \"num_modes\": num_modes},\n1966:             \"metrics\": {\n1967:                 \"mean_error\": float(mean_error),",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 1985,
          "context": "1982:     \n1983:     \n1984:     # --------------------------- QUAN-12: Quantum Tunneling ---------------------------\n1985: >>> def run_tunneling_test(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1986:         \"\"\"\n1987:         CRITICAL QUANTUM TEST: Wave packet penetrates classically forbidden barrier.\n1988:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2182,
          "context": "2179:             \"description\": desc,\n2180:             \"passed\": passed,\n2181:             \"timestamp\": time.time(),\n2182: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n2183:             \"parameters\": {\n2184:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"L\": L,\n2185:                 \"packet_omega\": packet_omega,",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2182,
          "context": "2179:             \"description\": desc,\n2180:             \"passed\": passed,\n2181:             \"timestamp\": time.time(),\n2182: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n2183:             \"parameters\": {\n2184:                 \"N\": N, \"dx\": dx, \"dt\": dt, \"L\": L,\n2185:                 \"packet_omega\": packet_omega,",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2211,
          "context": "2208:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n2209:     \n2210:     \n2211: >>> def run_uncertainty_test(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n2212:         ensure_dirs(out_dir)\n2213:         test_id = test['test_id']\n2214:         desc = test['description']",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2292,
          "context": "2289:             \"test_id\": test_id,\n2290:             \"description\": desc,\n2291:             \"timestamp\": time.time(),\n2292: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n2293:             \"parameters\": {\"N\":N,\"dx\":dx,\"dt\":dt,\"chi\":chi},\n2294:             \"metrics\": {\"mean_product\": float(products.mean()), \"target\": 0.5, \"rel_error\": err},\n2295:             \"status\": \"Passed\" if passed else \"Failed\"",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2292,
          "context": "2289:             \"test_id\": test_id,\n2290:             \"description\": desc,\n2291:             \"timestamp\": time.time(),\n2292: >>>         \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\", \"python\": platform.python_version()},\n2293:             \"parameters\": {\"N\":N,\"dx\":dx,\"dt\":dt,\"chi\":chi},\n2294:             \"metrics\": {\"mean_product\": float(products.mean()), \"target\": 0.5, \"rel_error\": err},\n2295:             \"status\": \"Passed\" if passed else \"Failed\"",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2326,
          "context": "2323:         p, tol, tests = cfg['parameters'], cfg['tolerances'], cfg['tests']\n2324:     \n2325:         from lfm_backend import pick_backend\n2326: >>>     xp, on_gpu = pick_backend(cfg.get('hardware', {}).get('gpu_enabled', True))\n2327:         dtype = xp.float64 if cfg.get('hardware', {}).get('precision', 'float64') == 'float64' else xp.float32\n2328:     \n2329:         # Prepare output and logger",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2326,
          "context": "2323:         p, tol, tests = cfg['parameters'], cfg['tolerances'], cfg['tests']\n2324:     \n2325:         from lfm_backend import pick_backend\n2326: >>>     xp, on_gpu = pick_backend(cfg.get('hardware', {}).get('gpu_enabled', True))\n2327:         dtype = xp.float64 if cfg.get('hardware', {}).get('precision', 'float64') == 'float64' else xp.float32\n2328:     \n2329:         # Prepare output and logger",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2384,
          "context": "2381:             \n2382:             # Run test based on mode\n2383:             if mode == 'uncertainty':\n2384: >>>             result = run_uncertainty_test(p, tol, t, out_dir, xp, on_gpu)\n2385:             elif mode == 'energy_transfer':\n2386:                 result = run_energy_transfer(p, tol, t, out_dir, xp, on_gpu)\n2387:             elif mode == 'spectral_linearity':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2386,
          "context": "2383:             if mode == 'uncertainty':\n2384:                 result = run_uncertainty_test(p, tol, t, out_dir, xp, on_gpu)\n2385:             elif mode == 'energy_transfer':\n2386: >>>             result = run_energy_transfer(p, tol, t, out_dir, xp, on_gpu)\n2387:             elif mode == 'spectral_linearity':\n2388:                 result = run_spectral_linearity(p, tol, t, out_dir, xp, on_gpu)\n2389:             elif mode == 'phase_amplitude_coupling':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2388,
          "context": "2385:             elif mode == 'energy_transfer':\n2386:                 result = run_energy_transfer(p, tol, t, out_dir, xp, on_gpu)\n2387:             elif mode == 'spectral_linearity':\n2388: >>>             result = run_spectral_linearity(p, tol, t, out_dir, xp, on_gpu)\n2389:             elif mode == 'phase_amplitude_coupling':\n2390:                 result = run_phase_amplitude_coupling(p, tol, t, out_dir, xp, on_gpu)\n2391:             elif mode == 'wavefront_stability':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2390,
          "context": "2387:             elif mode == 'spectral_linearity':\n2388:                 result = run_spectral_linearity(p, tol, t, out_dir, xp, on_gpu)\n2389:             elif mode == 'phase_amplitude_coupling':\n2390: >>>             result = run_phase_amplitude_coupling(p, tol, t, out_dir, xp, on_gpu)\n2391:             elif mode == 'wavefront_stability':\n2392:                 result = run_wavefront_stability(p, tol, t, out_dir, xp, on_gpu)\n2393:             elif mode == 'lattice_blowout':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2392,
          "context": "2389:             elif mode == 'phase_amplitude_coupling':\n2390:                 result = run_phase_amplitude_coupling(p, tol, t, out_dir, xp, on_gpu)\n2391:             elif mode == 'wavefront_stability':\n2392: >>>             result = run_wavefront_stability(p, tol, t, out_dir, xp, on_gpu)\n2393:             elif mode == 'lattice_blowout':\n2394:                 result = run_lattice_blowout(p, tol, t, out_dir, xp, on_gpu)\n2395:             elif mode == 'cavity_spectroscopy':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2394,
          "context": "2391:             elif mode == 'wavefront_stability':\n2392:                 result = run_wavefront_stability(p, tol, t, out_dir, xp, on_gpu)\n2393:             elif mode == 'lattice_blowout':\n2394: >>>             result = run_lattice_blowout(p, tol, t, out_dir, xp, on_gpu)\n2395:             elif mode == 'cavity_spectroscopy':\n2396:                 result = run_cavity_spectroscopy(p, tol, t, out_dir, xp, on_gpu)\n2397:             elif mode == 'threshold':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2396,
          "context": "2393:             elif mode == 'lattice_blowout':\n2394:                 result = run_lattice_blowout(p, tol, t, out_dir, xp, on_gpu)\n2395:             elif mode == 'cavity_spectroscopy':\n2396: >>>             result = run_cavity_spectroscopy(p, tol, t, out_dir, xp, on_gpu)\n2397:             elif mode == 'threshold':\n2398:                 result = run_threshold_test(p, tol, t, out_dir, xp, on_gpu)\n2399:             elif mode == 'bound_state_quantization':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2398,
          "context": "2395:             elif mode == 'cavity_spectroscopy':\n2396:                 result = run_cavity_spectroscopy(p, tol, t, out_dir, xp, on_gpu)\n2397:             elif mode == 'threshold':\n2398: >>>             result = run_threshold_test(p, tol, t, out_dir, xp, on_gpu)\n2399:             elif mode == 'bound_state_quantization':\n2400:                 result = run_bound_state_quantization(p, tol, t, out_dir, xp, on_gpu)\n2401:             elif mode == 'tunneling':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2400,
          "context": "2397:             elif mode == 'threshold':\n2398:                 result = run_threshold_test(p, tol, t, out_dir, xp, on_gpu)\n2399:             elif mode == 'bound_state_quantization':\n2400: >>>             result = run_bound_state_quantization(p, tol, t, out_dir, xp, on_gpu)\n2401:             elif mode == 'tunneling':\n2402:                 result = run_tunneling_test(p, tol, t, out_dir, xp, on_gpu)\n2403:             elif mode == 'planck_distribution':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2402,
          "context": "2399:             elif mode == 'bound_state_quantization':\n2400:                 result = run_bound_state_quantization(p, tol, t, out_dir, xp, on_gpu)\n2401:             elif mode == 'tunneling':\n2402: >>>             result = run_tunneling_test(p, tol, t, out_dir, xp, on_gpu)\n2403:             elif mode == 'planck_distribution':\n2404:                 result = run_planck_distribution(p, tol, t, out_dir, xp, on_gpu)\n2405:             elif mode == 'zero_point_energy':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2404,
          "context": "2401:             elif mode == 'tunneling':\n2402:                 result = run_tunneling_test(p, tol, t, out_dir, xp, on_gpu)\n2403:             elif mode == 'planck_distribution':\n2404: >>>             result = run_planck_distribution(p, tol, t, out_dir, xp, on_gpu)\n2405:             elif mode == 'zero_point_energy':\n2406:                 result = run_zero_point_energy(p, tol, t, out_dir, xp, on_gpu)\n2407:             elif mode == 'wave_particle_duality':",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2406,
          "context": "2403:             elif mode == 'planck_distribution':\n2404:                 result = run_planck_distribution(p, tol, t, out_dir, xp, on_gpu)\n2405:             elif mode == 'zero_point_energy':\n2406: >>>             result = run_zero_point_energy(p, tol, t, out_dir, xp, on_gpu)\n2407:             elif mode == 'wave_particle_duality':\n2408:                 result = run_wave_particle_duality(p, tol, t, out_dir, xp, on_gpu)\n2409:             else:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2408,
          "context": "2405:             elif mode == 'zero_point_energy':\n2406:                 result = run_zero_point_energy(p, tol, t, out_dir, xp, on_gpu)\n2407:             elif mode == 'wave_particle_duality':\n2408: >>>             result = run_wave_particle_duality(p, tol, t, out_dir, xp, on_gpu)\n2409:             else:\n2410:                 log(f\"[{t.get('test_id')}] Mode '{mode}' not yet implemented; mark skip or implement.\", \"WARN\")\n2411:                 tracker.stop()",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2422,
          "context": "2419:             result.metrics.update({\n2420:                 \"peak_cpu_percent\": metrics[\"peak_cpu_percent\"],\n2421:                 \"peak_memory_mb\": metrics[\"peak_memory_mb\"],\n2422: >>>             \"peak_gpu_memory_mb\": metrics[\"peak_gpu_memory_mb\"]\n2423:             })\n2424:             result.runtime_sec = metrics[\"runtime_sec\"]\n2425:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2422,
          "context": "2419:             result.metrics.update({\n2420:                 \"peak_cpu_percent\": metrics[\"peak_cpu_percent\"],\n2421:                 \"peak_memory_mb\": metrics[\"peak_memory_mb\"],\n2422: >>>             \"peak_gpu_memory_mb\": metrics[\"peak_gpu_memory_mb\"]\n2423:             })\n2424:             result.runtime_sec = metrics[\"runtime_sec\"]\n2425:             ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2439,
          "context": "2436:                 \"runtime_sec\": r.runtime_sec,\n2437:                 \"peak_cpu_percent\": r.metrics.get(\"peak_cpu_percent\", 0.0),\n2438:                 \"peak_memory_mb\": r.metrics.get(\"peak_memory_mb\", 0.0),\n2439: >>>             \"peak_gpu_memory_mb\": r.metrics.get(\"peak_gpu_memory_mb\", 0.0),\n2440:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n2441:             }\n2442:             test_metrics.record_run(r.test_id, metrics_data)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 2439,
          "context": "2436:                 \"runtime_sec\": r.runtime_sec,\n2437:                 \"peak_cpu_percent\": r.metrics.get(\"peak_cpu_percent\", 0.0),\n2438:                 \"peak_memory_mb\": r.metrics.get(\"peak_memory_mb\", 0.0),\n2439: >>>             \"peak_gpu_memory_mb\": r.metrics.get(\"peak_gpu_memory_mb\", 0.0),\n2440:                 \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n2441:             }\n2442:             test_metrics.record_run(r.test_id, metrics_data)",
          "match": "gpu"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 497,
          "context": " 494:         \n 495:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 496:     \n 497: >>> # ----------------------- Wavefront Stability Test (QUAN-07) --------------------------\n 498:     def run_wavefront_stability(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 499:         \"\"\"\n 500:         Test that large-amplitude wavepackets maintain shape (no nonlinear steepening).",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 498,
          "context": " 495:         return TestResult(test_id, desc, passed, summary[\"metrics\"], runtime)\n 496:     \n 497:     # ----------------------- Wavefront Stability Test (QUAN-07) --------------------------\n 498: >>> def run_wavefront_stability(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 499:         \"\"\"\n 500:         Test that large-amplitude wavepackets maintain shape (no nonlinear steepening).\n 501:         For linear system, Gaussian packet should disperse but not steepen.",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 601,
          "context": " 598:         \n 599:         ensure_dirs(out_dir / \"plots\")\n 600:         plt.tight_layout()\n 601: >>>     plt.savefig(out_dir / \"plots\" / \"wavefront_stability.png\", dpi=150)\n 602:         plt.close()\n 603:         \n 604:         summary = {",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 630,
          "context": " 627:     # ----------------------- Lattice Blowout Test (QUAN-08) --------------------------\n 628:     def run_lattice_blowout(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 629:         \"\"\"\n 630: >>>     Test numerical stability at high energy near CFL limit.\n 631:         Should not blow up (fields stay finite).\n 632:         \"\"\"\n 633:         ensure_dirs(out_dir)",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 630,
          "context": " 627:     # ----------------------- Lattice Blowout Test (QUAN-08) --------------------------\n 628:     def run_lattice_blowout(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n 629:         \"\"\"\n 630: >>>     Test numerical stability at high energy near CFL limit.\n 631:         Should not blow up (fields stay finite).\n 632:         \"\"\"\n 633:         ensure_dirs(out_dir)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 640,
          "context": " 637:         N = int(test.get('N', 512))\n 638:         dx = float(test.get('dx', 0.1))\n 639:         chi = float(test.get('chi_uniform', 0.20))\n 640: >>>     cfl_fraction = float(test.get('dt_cfl_fraction', 0.99))\n 641:         steps = int(test.get('steps', 2000))\n 642:         \n 643:         packet_amplitude = float(test.get('packet_amplitude', 2.0))",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 640,
          "context": " 637:         N = int(test.get('N', 512))\n 638:         dx = float(test.get('dx', 0.1))\n 639:         chi = float(test.get('chi_uniform', 0.20))\n 640: >>>     cfl_fraction = float(test.get('dt_cfl_fraction', 0.99))\n 641:         steps = int(test.get('steps', 2000))\n 642:         \n 643:         packet_amplitude = float(test.get('packet_amplitude', 2.0))",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 646,
          "context": " 643:         packet_amplitude = float(test.get('packet_amplitude', 2.0))\n 644:         packet_k = float(test.get('packet_k', 3.0))\n 645:         \n 646: >>>     # CFL condition: dt < dx / sqrt(2) for stability\n 647:         dt_cfl = dx / np.sqrt(2.0)\n 648:         dt = cfl_fraction * dt_cfl\n 649:         ",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 646,
          "context": " 643:         packet_amplitude = float(test.get('packet_amplitude', 2.0))\n 644:         packet_k = float(test.get('packet_k', 3.0))\n 645:         \n 646: >>>     # CFL condition: dt < dx / sqrt(2) for stability\n 647:         dt_cfl = dx / np.sqrt(2.0)\n 648:         dt = cfl_fraction * dt_cfl\n 649:         ",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 647,
          "context": " 644:         packet_k = float(test.get('packet_k', 3.0))\n 645:         \n 646:         # CFL condition: dt < dx / sqrt(2) for stability\n 647: >>>     dt_cfl = dx / np.sqrt(2.0)\n 648:         dt = cfl_fraction * dt_cfl\n 649:         \n 650:         L = N * dx",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 648,
          "context": " 645:         \n 646:         # CFL condition: dt < dx / sqrt(2) for stability\n 647:         dt_cfl = dx / np.sqrt(2.0)\n 648: >>>     dt = cfl_fraction * dt_cfl\n 649:         \n 650:         L = N * dx\n 651:         x = xp.arange(N, dtype=xp.float64) * dx",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 648,
          "context": " 645:         \n 646:         # CFL condition: dt < dx / sqrt(2) for stability\n 647:         dt_cfl = dx / np.sqrt(2.0)\n 648: >>>     dt = cfl_fraction * dt_cfl\n 649:         \n 650:         L = N * dx\n 651:         x = xp.arange(N, dtype=xp.float64) * dx",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 705,
          "context": " 702:         # Save data\n 703:         times = np.arange(len(energy_log)) * 10 * dt\n 704:         rows = [(float(t), float(e), float(m)) for t, e, m in zip(times, energy_log, max_field_log)]\n 705: >>>     write_csv(out_dir / \"stability_test.csv\", rows, [\"time\", \"energy\", \"max_field\"])\n 706:         \n 707:         # Plot\n 708:         fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 712,
          "context": " 709:         \n 710:         ax1.plot(times, energy_log, 'b-', linewidth=2)\n 711:         ax1.set_ylabel('Energy', fontsize=12)\n 712: >>>     ax1.set_title(f'{test_id}: High-Energy Stability (CFL={cfl_fraction:.2f})', fontsize=14)\n 713:         ax1.grid(True, alpha=0.3)\n 714:         \n 715:         ax2.plot(times, max_field_log, 'r-', linewidth=2)",
          "match": "Stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 712,
          "context": " 709:         \n 710:         ax1.plot(times, energy_log, 'b-', linewidth=2)\n 711:         ax1.set_ylabel('Energy', fontsize=12)\n 712: >>>     ax1.set_title(f'{test_id}: High-Energy Stability (CFL={cfl_fraction:.2f})', fontsize=14)\n 713:         ax1.grid(True, alpha=0.3)\n 714:         \n 715:         ax2.plot(times, max_field_log, 'r-', linewidth=2)",
          "match": "CFL"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 712,
          "context": " 709:         \n 710:         ax1.plot(times, energy_log, 'b-', linewidth=2)\n 711:         ax1.set_ylabel('Energy', fontsize=12)\n 712: >>>     ax1.set_title(f'{test_id}: High-Energy Stability (CFL={cfl_fraction:.2f})', fontsize=14)\n 713:         ax1.grid(True, alpha=0.3)\n 714:         \n 715:         ax2.plot(times, max_field_log, 'r-', linewidth=2)",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 723,
          "context": " 720:         \n 721:         ensure_dirs(out_dir / \"plots\")\n 722:         plt.tight_layout()\n 723: >>>     plt.savefig(out_dir / \"plots\" / \"stability_test.png\", dpi=150)\n 724:         plt.close()\n 725:         \n 726:         summary = {",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 733,
          "context": " 730:             \"description\": desc,\n 731:             \"timestamp\": time.time(),\n 732:             \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 733: >>>         \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"cfl_fraction\": cfl_fraction, \"amplitude\": packet_amplitude},\n 734:             \"metrics\": {\n 735:                 \"final_energy\": float(final_energy),\n 736:                 \"max_energy\": float(max_energy),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 733,
          "context": " 730:             \"description\": desc,\n 731:             \"timestamp\": time.time(),\n 732:             \"hardware\": {\"backend\": \"CuPy\" if on_gpu else \"NumPy\"},\n 733: >>>         \"parameters\": {\"N\": N, \"dx\": dx, \"dt\": dt, \"cfl_fraction\": cfl_fraction, \"amplitude\": packet_amplitude},\n 734:             \"metrics\": {\n 735:                 \"final_energy\": float(final_energy),\n 736:                 \"max_energy\": float(max_energy),",
          "match": "cfl"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 2391,
          "context": "2388:                 result = run_spectral_linearity(p, tol, t, out_dir, xp, on_gpu)\n2389:             elif mode == 'phase_amplitude_coupling':\n2390:                 result = run_phase_amplitude_coupling(p, tol, t, out_dir, xp, on_gpu)\n2391: >>>         elif mode == 'wavefront_stability':\n2392:                 result = run_wavefront_stability(p, tol, t, out_dir, xp, on_gpu)\n2393:             elif mode == 'lattice_blowout':\n2394:                 result = run_lattice_blowout(p, tol, t, out_dir, xp, on_gpu)",
          "match": "stability"
        },
        {
          "type": "Numerical stability technique",
          "pattern": "stability|CFL|convergence",
          "line": 2392,
          "context": "2389:             elif mode == 'phase_amplitude_coupling':\n2390:                 result = run_phase_amplitude_coupling(p, tol, t, out_dir, xp, on_gpu)\n2391:             elif mode == 'wavefront_stability':\n2392: >>>             result = run_wavefront_stability(p, tol, t, out_dir, xp, on_gpu)\n2393:             elif mode == 'lattice_blowout':\n2394:                 result = run_lattice_blowout(p, tol, t, out_dir, xp, on_gpu)\n2395:             elif mode == 'cavity_spectroscopy':",
          "match": "stability"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 42,
          "context": "  39:     \n  40:     # ------------------------------- 1D helpers --------------------------------\n  41:     def laplacian_1d(E, dx, order=2, xp=None):\n  42: >>>     \"\"\"1D Laplacian with periodic boundaries (will be overridden by apply_dirichlet if needed)\"\"\"\n  43:         if xp is None:\n  44:             xp = get_array_module(E)\n  45:         if order == 2:",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 68,
          "context": "  65:         # Time derivative approximation\n  66:         Et = (E - E_prev) / dt\n  67:         \n  68: >>>     # Spatial gradient (finite difference, periodic boundaries assumed in general case)\n  69:         # For 1D:\n  70:         if E.ndim == 1:\n  71:             gx = (xp.roll(E, -1) - xp.roll(E, 1)) / (2 * dx)",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1661,
          "context": "1658:         freqs_sweep = np.linspace(freq_start, freq_end, freq_steps)\n1659:         transmissions = []\n1660:         \n1661: >>>     # Drive source at left side, detect at right side (periodic boundaries allow transmission)\n1662:         source_idx = int(0.1 * N)  # 10% from left\n1663:         detector_idx = int(0.9 * N)  # 90% from left\n1664:         ",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1693,
          "context": "1690:             detector_window = slice(detector_idx-5, detector_idx+5)\n1691:             rms_series = []\n1692:             for t in range(steps_per_freq):\n1693: >>>             # Advance with periodic boundaries\n1694:                 lap = laplacian_1d(E, dx, order=2, xp=xp)\n1695:                 E_next = 2*E - E_prev + (dt*dt) * (lap - (chi*chi)*E)\n1696:                 E_prev, E = E, E_next",
          "match": "periodic"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1766,
          "context": "1763:     # --------------------------- QUAN-10: Bound State Quantization ---------------------------\n1764:     def run_bound_state_quantization(params, tol, test, out_dir: Path, xp, on_gpu) -> TestResult:\n1765:         \"\"\"\n1766: >>>     CRITICAL QUANTUM TEST: Prove discrete energy eigenvalues emerge from boundary conditions.\n1767:         \n1768:         Method:\n1769:         - 1D infinite square well (Dirichlet boundaries): E=0 at x=0, x=L",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 1972,
          "context": "1969:                 \"num_modes_measured\": num_modes,\n1970:                 \"quantization_demonstrated\": passed\n1971:             },\n1972: >>>         \"notes\": \"Discrete energy eigenvalues emerge from boundary conditions - fundamental quantum signature\"\n1973:         }\n1974:         save_summary(out_dir, test_id, summary)\n1975:         ",
          "match": "boundary"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 155,
          "context": " 152:                 mode1_energy_log.append(E_mode1)\n 153:                 mode2_energy_log.append(E_mode2)\n 154:             \n 155: >>>         # Leapfrog\n 156:             lap = laplacian_1d(E, dx, order=4, xp=xp)\n 157:             E_next = 2*E - E_prev + (dt*dt) * (lap - (chi*chi)*E)\n 158:             apply_dirichlet(E_next)",
          "match": "Leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1535,
          "context": "1532:                 snapshots.append(to_numpy(E.copy()))\n1533:                 snapshot_times.append(t * dt)\n1534:             \n1535: >>>         # Advance leapfrog\n1536:             lap = laplacian_1d(E, dx, order=2, xp=xp)\n1537:             E_next = 2*E - E_prev + (dt*dt) * (lap - (chi*chi)*E)\n1538:             apply_dirichlet(E_next)",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1807,
          "context": "1804:             phase = 0.0 if n % 2 == 1 else np.pi/4  # Alternate phases\n1805:             mode_shape = xp.sin(k_n * x)\n1806:             E += amp * mode_shape * xp.cos(phase)\n1807: >>>         E_prev += amp * mode_shape * xp.cos(phase + k_n * dt)  # Time-shifted for leapfrog\n1808:             mode_amplitudes_init[n] = amp\n1809:         \n1810:         apply_dirichlet(E)",
          "match": "leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1824,
          "context": "1821:                 snapshots.append(to_numpy(E.copy()))\n1822:                 snapshot_times.append(step * dt)\n1823:             \n1824: >>>         # Leapfrog integration\n1825:             lap = laplacian_1d(E, dx, order=4, xp=xp)\n1826:             E_next = 2*E - E_prev + (dt*dt) * (lap - (chi*chi)*E)\n1827:             apply_dirichlet(E_next)",
          "match": "Leapfrog"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 1824,
          "context": "1821:                 snapshots.append(to_numpy(E.copy()))\n1822:                 snapshot_times.append(step * dt)\n1823:             \n1824: >>>         # Leapfrog integration\n1825:             lap = laplacian_1d(E, dx, order=4, xp=xp)\n1826:             E_next = 2*E - E_prev + (dt*dt) * (lap - (chi*chi)*E)\n1827:             apply_dirichlet(E_next)",
          "match": "integration"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 2078,
          "context": "2075:                 energy_right.append(np.sum(E_np[to_numpy(right_region)]**2) * dx)\n2076:                 times.append(step * dt)\n2077:             \n2078: >>>         # Leapfrog with spatially-varying χ\n2079:             lap = laplacian_1d(E, dx, order=4, xp=xp)\n2080:             E_next = 2*E - E_prev + (dt*dt) * (lap - (chi*chi)*E)\n2081:             E_prev, E = E, E_next",
          "match": "Leapfrog"
        }
      ],
      "line_count": 2496,
      "docstring": "Tier-4 — Quantization & Spectra Tests\n- Famous-equation test implemented: Heisenberg uncertainty Δx·Δk ≈ 1/2 (natural units)\n- Additional tests scaffolded (cavity spectroscopy, threshold), initially skipped\n\nOutputs under results/Quantization/<TEST_ID>/"
    },
    {
      "filepath": "setup_lfm.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "83a153f58f4443c6",
      "file_size": 10038,
      "modified": "2025-11-03T13:19:47.563317",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 21,
          "context": "  18:     import os\n  19:     from pathlib import Path\n  20:     \n  21: >>> def print_header():\n  22:         \"\"\"Print setup banner\"\"\"\n  23:         print(\"=\" * 60)\n  24:         print(\"  LFM SETUP - Lattice Field Medium Installation\")",
          "match": "def print_header():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 29,
          "context": "  26:         print(\"=\" * 60)\n  27:         print()\n  28:     \n  29: >>> def check_python_version():\n  30:         \"\"\"Check if Python version is compatible\"\"\"\n  31:         version = sys.version_info\n  32:         print(f\"🐍 Python version: {version.major}.{version.minor}.{version.micro}\")",
          "match": "def check_python_version():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 42,
          "context": "  39:         print(\"✅ Python version compatible\")\n  40:         return True\n  41:     \n  42: >>> def check_tkinter():\n  43:         \"\"\"Check if tkinter is available for GUI\"\"\"\n  44:         try:\n  45:             import tkinter as tk",
          "match": "def check_tkinter():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 54,
          "context": "  51:             print(\"   On macOS: Tkinter should be included with Python\")\n  52:             return False\n  53:     \n  54: >>> def install_dependencies():\n  55:         \"\"\"Install required Python packages\"\"\"\n  56:         print(\"\\n📦 Installing Python dependencies...\")\n  57:         ",
          "match": "def install_dependencies():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:         \n  78:         return True\n  79:     \n  80: >>> def check_gpu_support():\n  81:         \"\"\"Check for NVIDIA GPU and offer CuPy installation\"\"\"\n  82:         print(\"\\n🚀 Checking GPU support...\")\n  83:         ",
          "match": "def check_gpu_support():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 121,
          "context": " 118:             print(\"   💻 Unable to check GPU - using CPU only\")\n 119:             return False\n 120:     \n 121: >>> def run_quick_test():\n 122:         \"\"\"Run a quick validation test\"\"\"\n 123:         print(\"\\n🧪 Running quick validation test...\")\n 124:         ",
          "match": "def run_quick_test():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 160,
          "context": " 157:             print(f\"   ❌ Test failed: {e}\")\n 158:             return False\n 159:     \n 160: >>> def create_desktop_shortcuts():\n 161:         \"\"\"Create shortcuts for easy access\"\"\"\n 162:         print(\"\\n🔗 Creating convenient shortcuts...\")\n 163:         ",
          "match": "def create_desktop_shortcuts():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 200,
          "context": " 197:             \n 198:             print(\"   ✅ Shell scripts created (run_lfm_console.sh, run_lfm_gui.sh)\")\n 199:     \n 200: >>> def print_usage_instructions():\n 201:         \"\"\"Print how to use LFM after installation\"\"\"\n 202:         print(\"\\n\" + \"=\" * 60)\n 203:         print(\"  🎉 LFM INSTALLATION COMPLETE!\")",
          "match": "def print_usage_instructions():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 242,
          "context": " 239:         print(\"   ORCID: https://orcid.org/0009-0004-0327-6528\")\n 240:         print()\n 241:     \n 242: >>> def main():\n 243:         \"\"\"Main installation process\"\"\"\n 244:         print_header()\n 245:         ",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 80,
          "context": "  77:         \n  78:         return True\n  79:     \n  80: >>> def check_gpu_support():\n  81:         \"\"\"Check for NVIDIA GPU and offer CuPy installation\"\"\"\n  82:         print(\"\\n🚀 Checking GPU support...\")\n  83:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 81,
          "context": "  78:         return True\n  79:     \n  80:     def check_gpu_support():\n  81: >>>     \"\"\"Check for NVIDIA GPU and offer CuPy installation\"\"\"\n  82:         print(\"\\n🚀 Checking GPU support...\")\n  83:         \n  84:         try:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 81,
          "context": "  78:         return True\n  79:     \n  80:     def check_gpu_support():\n  81: >>>     \"\"\"Check for NVIDIA GPU and offer CuPy installation\"\"\"\n  82:         print(\"\\n🚀 Checking GPU support...\")\n  83:         \n  84:         try:",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 82,
          "context": "  79:     \n  80:     def check_gpu_support():\n  81:         \"\"\"Check for NVIDIA GPU and offer CuPy installation\"\"\"\n  82: >>>     print(\"\\n🚀 Checking GPU support...\")\n  83:         \n  84:         try:\n  85:             # Try to detect NVIDIA GPU",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 85,
          "context": "  82:         print(\"\\n🚀 Checking GPU support...\")\n  83:         \n  84:         try:\n  85: >>>         # Try to detect NVIDIA GPU\n  86:             result = subprocess.run([\n  87:                 \"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"\n  88:             ], capture_output=True, text=True, timeout=5)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 87,
          "context": "  84:         try:\n  85:             # Try to detect NVIDIA GPU\n  86:             result = subprocess.run([\n  87: >>>             \"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"\n  88:             ], capture_output=True, text=True, timeout=5)\n  89:             \n  90:             if result.returncode == 0 and result.stdout.strip():",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 91,
          "context": "  88:             ], capture_output=True, text=True, timeout=5)\n  89:             \n  90:             if result.returncode == 0 and result.stdout.strip():\n  91: >>>             gpu_name = result.stdout.strip()\n  92:                 print(f\"   🎮 NVIDIA GPU detected: {gpu_name}\")\n  93:                 \n  94:                 # Ask user if they want GPU acceleration",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 92,
          "context": "  89:             \n  90:             if result.returncode == 0 and result.stdout.strip():\n  91:                 gpu_name = result.stdout.strip()\n  92: >>>             print(f\"   🎮 NVIDIA GPU detected: {gpu_name}\")\n  93:                 \n  94:                 # Ask user if they want GPU acceleration\n  95:                 while True:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 92,
          "context": "  89:             \n  90:             if result.returncode == 0 and result.stdout.strip():\n  91:                 gpu_name = result.stdout.strip()\n  92: >>>             print(f\"   🎮 NVIDIA GPU detected: {gpu_name}\")\n  93:                 \n  94:                 # Ask user if they want GPU acceleration\n  95:                 while True:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 94,
          "context": "  91:                 gpu_name = result.stdout.strip()\n  92:                 print(f\"   🎮 NVIDIA GPU detected: {gpu_name}\")\n  93:                 \n  94: >>>             # Ask user if they want GPU acceleration\n  95:                 while True:\n  96:                     response = input(\"   Install GPU acceleration (CuPy)? [y/N]: \").lower()\n  97:                     if response in ['y', 'yes']:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 96,
          "context": "  93:                 \n  94:                 # Ask user if they want GPU acceleration\n  95:                 while True:\n  96: >>>                 response = input(\"   Install GPU acceleration (CuPy)? [y/N]: \").lower()\n  97:                     if response in ['y', 'yes']:\n  98:                         print(\"   Installing CuPy for GPU acceleration...\")\n  99:                         try:",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 96,
          "context": "  93:                 \n  94:                 # Ask user if they want GPU acceleration\n  95:                 while True:\n  96: >>>                 response = input(\"   Install GPU acceleration (CuPy)? [y/N]: \").lower()\n  97:                     if response in ['y', 'yes']:\n  98:                         print(\"   Installing CuPy for GPU acceleration...\")\n  99:                         try:",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 98,
          "context": "  95:                 while True:\n  96:                     response = input(\"   Install GPU acceleration (CuPy)? [y/N]: \").lower()\n  97:                     if response in ['y', 'yes']:\n  98: >>>                     print(\"   Installing CuPy for GPU acceleration...\")\n  99:                         try:\n 100:                             subprocess.check_call([\n 101:                                 sys.executable, \"-m\", \"pip\", \"install\", \"cupy-cuda12x\"",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 98,
          "context": "  95:                 while True:\n  96:                     response = input(\"   Install GPU acceleration (CuPy)? [y/N]: \").lower()\n  97:                     if response in ['y', 'yes']:\n  98: >>>                     print(\"   Installing CuPy for GPU acceleration...\")\n  99:                         try:\n 100:                             subprocess.check_call([\n 101:                                 sys.executable, \"-m\", \"pip\", \"install\", \"cupy-cuda12x\"",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 101,
          "context": "  98:                         print(\"   Installing CuPy for GPU acceleration...\")\n  99:                         try:\n 100:                             subprocess.check_call([\n 101: >>>                             sys.executable, \"-m\", \"pip\", \"install\", \"cupy-cuda12x\"\n 102:                             ], stdout=subprocess.DEVNULL)\n 103:                             print(\"   ✅ GPU acceleration installed\")\n 104:                             return True",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 101,
          "context": "  98:                         print(\"   Installing CuPy for GPU acceleration...\")\n  99:                         try:\n 100:                             subprocess.check_call([\n 101: >>>                             sys.executable, \"-m\", \"pip\", \"install\", \"cupy-cuda12x\"\n 102:                             ], stdout=subprocess.DEVNULL)\n 103:                             print(\"   ✅ GPU acceleration installed\")\n 104:                             return True",
          "match": "cuda"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 103,
          "context": " 100:                             subprocess.check_call([\n 101:                                 sys.executable, \"-m\", \"pip\", \"install\", \"cupy-cuda12x\"\n 102:                             ], stdout=subprocess.DEVNULL)\n 103: >>>                         print(\"   ✅ GPU acceleration installed\")\n 104:                             return True\n 105:                         except subprocess.CalledProcessError:\n 106:                             print(\"   ❌ GPU installation failed - continuing with CPU\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 106,
          "context": " 103:                             print(\"   ✅ GPU acceleration installed\")\n 104:                             return True\n 105:                         except subprocess.CalledProcessError:\n 106: >>>                         print(\"   ❌ GPU installation failed - continuing with CPU\")\n 107:                             return False\n 108:                     elif response in ['n', 'no', '']:\n 109:                         print(\"   ⏭️  Skipping GPU acceleration\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 109,
          "context": " 106:                             print(\"   ❌ GPU installation failed - continuing with CPU\")\n 107:                             return False\n 108:                     elif response in ['n', 'no', '']:\n 109: >>>                     print(\"   ⏭️  Skipping GPU acceleration\")\n 110:                         return False\n 111:                     else:\n 112:                         print(\"   Please enter 'y' or 'n'\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 114,
          "context": " 111:                     else:\n 112:                         print(\"   Please enter 'y' or 'n'\")\n 113:             else:\n 114: >>>             print(\"   💻 No NVIDIA GPU detected - using CPU only\")\n 115:                 return False\n 116:                 \n 117:         except (subprocess.TimeoutExpired, FileNotFoundError):",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 118,
          "context": " 115:                 return False\n 116:                 \n 117:         except (subprocess.TimeoutExpired, FileNotFoundError):\n 118: >>>         print(\"   💻 Unable to check GPU - using CPU only\")\n 119:             return False\n 120:     \n 121:     def run_quick_test():",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 146,
          "context": " 143:             equation = LFMEquation(\n 144:                 nx=32, dx=0.1, dt=0.01, \n 145:                 alpha=1.0, beta=1.0, chi=0.1,\n 146: >>>             boundary='periodic', use_gpu=False\n 147:             )\n 148:             \n 149:             # Run 10 steps",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 265,
          "context": " 262:         \n 263:         print(\"✅ All dependencies installed successfully!\")\n 264:         \n 265: >>>     # Check GPU support\n 266:         check_gpu_support()\n 267:         \n 268:         # Run validation test",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 266,
          "context": " 263:         print(\"✅ All dependencies installed successfully!\")\n 264:         \n 265:         # Check GPU support\n 266: >>>     check_gpu_support()\n 267:         \n 268:         # Run validation test\n 269:         if not run_quick_test():",
          "match": "gpu"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 146,
          "context": " 143:             equation = LFMEquation(\n 144:                 nx=32, dx=0.1, dt=0.01, \n 145:                 alpha=1.0, beta=1.0, chi=0.1,\n 146: >>>             boundary='periodic', use_gpu=False\n 147:             )\n 148:             \n 149:             # Run 10 steps",
          "match": "boundary"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 146,
          "context": " 143:             equation = LFMEquation(\n 144:                 nx=32, dx=0.1, dt=0.01, \n 145:                 alpha=1.0, beta=1.0, chi=0.1,\n 146: >>>             boundary='periodic', use_gpu=False\n 147:             )\n 148:             \n 149:             # Run 10 steps",
          "match": "periodic"
        },
        {
          "type": "Numerical integration method",
          "pattern": "leapfrog|integration|solver",
          "line": 139,
          "context": " 136:             import pytest\n 137:             \n 138:             # Test LFM equation module\n 139: >>>         print(\"   Testing LFM equation solver...\")\n 140:             from lfm_equation import LFMEquation\n 141:             \n 142:             # Quick 1D test",
          "match": "solver"
        }
      ],
      "line_count": 279,
      "docstring": "LFM Installation & Setup Script\n===============================\nAutomated setup for the Lattice Field Medium framework on all platforms.\nDetects your system and installs everything needed to run LFM."
    },
    {
      "filepath": "tools\\build_comprehensive_pdf.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "3be3e9a848d23299",
      "file_size": 10203,
      "modified": "2025-11-03T13:12:11.543479",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:     OUT_BASENAME = f'LFM_Comprehensive_Report_{TODAY}'\n  35:     \n  36:     \n  37: >>> def find_pandoc() -> Path | None:\n  38:         exe = shutil.which('pandoc')\n  39:         if exe:\n  40:             return Path(exe)",
          "match": "def find_pandoc() -> Path | None:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 51,
          "context": "  48:         return None\n  49:     \n  50:     \n  51: >>> def read_master_status() -> str:\n  52:         \"\"\"Read and format the master test status CSV.\"\"\"\n  53:         csv_path = RESULTS / 'MASTER_TEST_STATUS.csv'\n  54:         if not csv_path.exists():",
          "match": "def read_master_status() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 64,
          "context": "  61:         return '\\n'.join(lines)\n  62:     \n  63:     \n  64: >>> def read_tier_descriptions() -> str:\n  65:         \"\"\"Read tier and per-test descriptions from results directories.\"\"\"\n  66:         lines = ['# Tier and Test Descriptions', '']\n  67:         # Presentation overrides (optional): tests to be shown as SKIP and extra notes",
          "match": "def read_tier_descriptions() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 158,
          "context": " 155:         return '\\n'.join(lines)\n 156:     \n 157:     \n 158: >>> def convert_docx_to_md(docx_path: Path, pandoc_exe: Path) -> str:\n 159:         \"\"\"Convert a DOCX to Markdown text using Pandoc.\"\"\"\n 160:         try:\n 161:             result = subprocess.run(",
          "match": "def convert_docx_to_md(docx_path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 173,
          "context": " 170:             return f'> Error converting {docx_path.name}: {e}\\n'\n 171:     \n 172:     \n 173: >>> def build_combined_markdown(pandoc_exe: Path) -> Path:\n 174:         \"\"\"Build a comprehensive Markdown combining all sources.\"\"\"\n 175:         UPLOAD.mkdir(parents=True, exist_ok=True)\n 176:         parts = []",
          "match": "def build_combined_markdown(pandoc_exe:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 226,
          "context": " 223:         return out_md\n 224:     \n 225:     \n 226: >>> def main():\n 227:         pandoc_exe = find_pandoc()\n 228:         if pandoc_exe is None:\n 229:             print('ERROR: Pandoc not found. Install from https://pandoc.org/install.html')",
          "match": "def main():"
        }
      ],
      "line_count": 272,
      "docstring": "Build a comprehensive PDF combining:\n- All governing DOCX contents (Executive Summary, Master, Core Equations, Phase 1 Test Design)\n- Test results rollup from MASTER_TEST_STATUS.csv\n- Tier descriptions\n- Per-test descriptions with pass/fail status\n\nUsage:\n  python tools/build_comprehensive_pdf.py\n\nOutput: docs/upload/LFM_Comprehensive_Report_<YYYYMMDD>.pdf"
    },
    {
      "filepath": "tools\\build_master_docs.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "3e8a3b144ec64a4d",
      "file_size": 6129,
      "modified": "2025-11-03T13:12:11.543479",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 37,
          "context": "  34:     # Deterministic build controls\n  35:     DETERMINISTIC = os.environ.get('LFM_DETERMINISTIC', '0') == '1'\n  36:     \n  37: >>> def _deterministic_date_str() -> str:\n  38:         sde = os.environ.get('SOURCE_DATE_EPOCH')\n  39:         if sde and sde.isdigit():\n  40:             try:",
          "match": "def _deterministic_date_str() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 64,
          "context": "  61:     RESULTS_REPORT = UPLOAD / 'RESULTS_REPORT.md'\n  62:     \n  63:     \n  64: >>> def read_text_if_exists(p: Path) -> str:\n  65:         return p.read_text(encoding='utf-8') if p.exists() else ''\n  66:     \n  67:     ",
          "match": "def read_text_if_exists(p:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 68,
          "context": "  65:         return p.read_text(encoding='utf-8') if p.exists() else ''\n  66:     \n  67:     \n  68: >>> def build_combined_markdown() -> Path:\n  69:         UPLOAD.mkdir(parents=True, exist_ok=True)\n  70:         parts = []\n  71:         # Cover",
          "match": "def build_combined_markdown() -> Path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 107,
          "context": " 104:         return out_md\n 105:     \n 106:     \n 107: >>> def find_pandoc() -> Path | None:\n 108:         \"\"\"Return path to pandoc executable if found on PATH or default install location.\"\"\"\n 109:         # First try PATH\n 110:         exe = shutil.which('pandoc')",
          "match": "def find_pandoc() -> Path | None:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 124,
          "context": " 121:         return None\n 122:     \n 123:     \n 124: >>> def run_pandoc(pandoc_exe: Path, md_in: Path, out_path: Path):\n 125:         args = [\n 126:             str(pandoc_exe), str(md_in), '-o', str(out_path),\n 127:             '--from', 'markdown', '--toc', '--standalone'",
          "match": "def run_pandoc(pandoc_exe:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 132,
          "context": " 129:         subprocess.run(args, check=True)\n 130:     \n 131:     \n 132: >>> def main():\n 133:         md = build_combined_markdown()\n 134:         pandoc_exe = find_pandoc()\n 135:         if pandoc_exe is None:",
          "match": "def main():"
        }
      ],
      "line_count": 169,
      "docstring": "Build the Master document (DOCX/PDF) for upload from canonical Markdown sources.\n- Concatenate docs/Executive_Summary.md, LFM_Master.md, LFM_Core_Equations.md, LFM_Phase1_Test_Design.md\n- Append docs/upload/RESULTS_REPORT.md (if present)\n- Produce docs/upload/LFM_Master_<YYYYMMDD>_v1.docx and .pdf via pandoc when available\n- Always write docs/upload/_LFM_Master_combined.md as the canonical combined source\n\nUsage:\n  python tools/build_master_docs.py\n\nNotes:\n- Requires Pandoc on PATH to produce DOCX/PDF. If absent, only the combined .md is produced.\n- You can install Pandoc from https://pandoc.org/install.html"
    },
    {
      "filepath": "tools\\build_upload_package.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "f2a57c67f37f8577",
      "file_size": 33904,
      "modified": "2025-11-03T13:12:11.543479",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 65,
          "context": "  62:     ]\n  63:     \n  64:     \n  65: >>> def sha256_file(path: Path) -> str:\n  66:         h = hashlib.sha256()\n  67:         with open(path, 'rb') as f:\n  68:             for chunk in iter(lambda: f.read(8192), b''):",
          "match": "def sha256_file(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 73,
          "context": "  70:         return h.hexdigest()\n  71:     \n  72:     \n  73: >>> def _deterministic_now_str() -> str:\n  74:         sde = os.environ.get('SOURCE_DATE_EPOCH')\n  75:         if sde and sde.isdigit():\n  76:             try:",
          "match": "def _deterministic_now_str() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 83,
          "context": "  80:         return '1970-01-01 00:00:00'\n  81:     \n  82:     \n  83: >>> def _deterministic_date_stamp() -> str:\n  84:         \"\"\"Return YYYYMMDD from SOURCE_DATE_EPOCH or 19700101 as fallback.\"\"\"\n  85:         sde = os.environ.get('SOURCE_DATE_EPOCH')\n  86:         if sde and sde.isdigit():",
          "match": "def _deterministic_date_stamp() -> str:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 94,
          "context": "  91:         return '19700101'\n  92:     \n  93:     \n  94: >>> def _collect_provenance(deterministic: bool = False) -> list[str]:\n  95:         \"\"\"Collect provenance: git SHA, Python, NumPy/CuPy, OS, deterministic flag.\"\"\"\n  96:         lines: list[str] = []\n  97:         # Git SHA",
          "match": "def _collect_provenance(deterministic:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 126,
          "context": " 123:         return lines\n 124:     \n 125:     \n 126: >>> def refresh_results_artifacts(deterministic: bool = False, build_master: bool = False):\n 127:         # Always rebuild master docs before staging, so DOCX/PDF are current\n 128:         master_builder = ROOT / 'tools' / 'build_master_docs.py'\n 129:         if build_master and master_builder.exists():",
          "match": "def refresh_results_artifacts(deterministic:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 189,
          "context": " 186:         # Note: We no longer stage canonical txt sources; .txt will be derived from evidence DOCX\n 187:     \n 188:     \n 189: >>> def stage_evidence_docx(include: bool = False) -> List[str]:\n 190:         \"\"\"Optionally stage original source DOCX files under upload/evidence_docx.\n 191:     \n 192:         Returns list of relative paths staged.",
          "match": "def stage_evidence_docx(include:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 221,
          "context": " 218:         return staged\n 219:     \n 220:     \n 221: >>> def export_txt_from_evidence(include: bool = True) -> List[str]:\n 222:         \"\"\"Export .txt versions of key DOCX sources for archival (Executive_Summary, LFM_*).\n 223:     \n 224:         Writes to upload/txt/*.txt and returns relative paths added.",
          "match": "def export_txt_from_evidence(include:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 251,
          "context": " 248:                 print(f\"[WARN] TXT export failed for {p.name}: {e}\")\n 249:                 continue\n 250:         return emitted\n 251: >>> def _convert_docx_to_md(src: Path, dst: Path):\n 252:         dst.parent.mkdir(parents=True, exist_ok=True)\n 253:         pandoc = _find_pandoc()\n 254:         if pandoc:",
          "match": "def _convert_docx_to_md(src:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 269,
          "context": " 266:             pass\n 267:     \n 268:     \n 269: >>> def export_md_from_evidence() -> List[str]:\n 270:         \"\"\"Export .md versions of governing DOCX into upload/md and create a top-level Executive_Summary.md.\"\"\"\n 271:         emitted: List[str] = []\n 272:         src_dir = UPLOAD / 'evidence_docx'",
          "match": "def export_md_from_evidence() -> List[str]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 306,
          "context": " 303:         return emitted\n 304:     \n 305:     \n 306: >>> def stage_legal_docs() -> List[str]:\n 307:         \"\"\"Copy legal/IP docs from repo (./ or ./docs) into upload.\n 308:     \n 309:         Returns list of relative paths staged.",
          "match": "def stage_legal_docs() -> List[str]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 333,
          "context": " 330:         return staged\n 331:     \n 332:     \n 333: >>> def _stage_canonical_txt_sources() -> List[str]:\n 334:         \"\"\"Copy canonical docs/text/*.txt into docs/upload/txt/.\n 335:     \n 336:         Returns list of relative paths staged.",
          "match": "def _stage_canonical_txt_sources() -> List[str]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 353,
          "context": " 350:         return out\n 351:     \n 352:     \n 353: >>> def validate_core_docs(strict: bool = False, deterministic: bool = False, build_master: bool = False) -> List[str]:\n 354:         \"\"\"Validate presence and basic integrity of critical documents.\n 355:     \n 356:         Returns a list of warnings/errors. In strict mode, raises on errors.",
          "match": "def validate_core_docs(strict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 388,
          "context": " 385:     \n 386:     \n 387:     # ---------------------------- Converters (Pandoc-first) ----------------------------\n 388: >>> def _find_pandoc() -> Path | None:\n 389:         import shutil as _sh\n 390:         exe = _sh.which('pandoc')\n 391:         if exe:",
          "match": "def _find_pandoc() -> Path | None:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 404,
          "context": " 401:         return None\n 402:     \n 403:     \n 404: >>> def _convert_docx_to_txt(src: Path, dst: Path):\n 405:         dst.parent.mkdir(parents=True, exist_ok=True)\n 406:         pandoc = _find_pandoc()\n 407:         if pandoc:",
          "match": "def _convert_docx_to_txt(src:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 423,
          "context": " 420:             raise RuntimeError(f\"Cannot convert {src.name} to txt: {e}\")\n 421:     \n 422:     \n 423: >>> def _convert_md_to_txt(src: Path, dst: Path):\n 424:         dst.parent.mkdir(parents=True, exist_ok=True)\n 425:         pandoc = _find_pandoc()\n 426:         if pandoc:",
          "match": "def _convert_md_to_txt(src:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 440,
          "context": " 437:         dst.write_text(txt, encoding='utf-8')\n 438:     \n 439:     \n 440: >>> def stage_and_list_files() -> List[Tuple[str, int, str]]:\n 441:         \"\"\"Return list of (relative_path_under_upload, size, sha256).\"\"\"\n 442:         entries: List[Tuple[str, int, str]] = []\n 443:     ",
          "match": "def stage_and_list_files() -> List[Tuple[str, int, str]]:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 509,
          "context": " 506:         return sorted(entries, key=lambda x: x[0].lower())\n 507:     \n 508:     \n 509: >>> def write_manifest(entries: List[Tuple[str, int, str]], deterministic: bool = False):\n 510:         now = _deterministic_now_str() if deterministic else datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n 511:         lines: List[str] = []\n 512:         lines.append('# Upload Manifest')",
          "match": "def write_manifest(entries:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 532,
          "context": " 529:         (UPLOAD / 'MANIFEST.md').write_text('\\n'.join(lines), encoding='utf-8')\n 530:     \n 531:     \n 532: >>> def write_zenodo_metadata(entries: List[Tuple[str, int, str]], deterministic: bool = False):\n 533:         pub_date = _deterministic_now_str().split(' ')[0] if deterministic else datetime.now().strftime('%Y-%m-%d')\n 534:         meta = {\n 535:             \"title\": \"Lorentzian Field Model (LFM) — Results Package\",",
          "match": "def write_zenodo_metadata(entries:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 557,
          "context": " 554:         (UPLOAD / 'zenodo_metadata.json').write_text(json.dumps(meta, indent=2, sort_keys=True), encoding='utf-8')\n 555:     \n 556:     \n 557: >>> def write_osf_metadata(entries: List[Tuple[str, int, str]]):\n 558:         # OSF often done manually; include a helper JSON + MD overview.\n 559:         meta = {\n 560:             \"title\": \"LFM Results Package (dry-run)\",",
          "match": "def write_osf_metadata(entries:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 581,
          "context": " 578:         (UPLOAD / 'OSF_UPLOAD_OVERVIEW.md').write_text('\\n'.join(md), encoding='utf-8')\n 579:     \n 580:     \n 581: >>> def stage_result_plots(limit_per_dir: int = 6) -> List[str]:\n 582:         \"\"\"Collect .png plots from results/**/plots and stage to upload/plots mirroring substructure.\n 583:     \n 584:         limit_per_dir limits the number of PNGs per source plot directory to keep package concise.",
          "match": "def stage_result_plots(limit_per_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 620,
          "context": " 617:         return staged\n 618:     \n 619:     \n 620: >>> def create_zip_bundle(entries: List[Tuple[str, int, str]], label: str | None = None, deterministic: bool = False) -> Tuple[str, int, str]:\n 621:         \"\"\"Create a ZIP bundle containing the payload entries only.\n 622:     \n 623:         Returns (relative_path_under_upload, size, sha256) for the created zip.",
          "match": "def create_zip_bundle(entries:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 654,
          "context": " 651:         return (zip_rel, size, digest)\n 652:     \n 653:     \n 654: >>> def generate_comprehensive_pdf() -> str | None:\n 655:         \"\"\"Generate comprehensive PDF combining all governing docs and test results.\n 656:         \n 657:         Returns the relative path to the PDF under upload/ if successful, None otherwise.",
          "match": "def generate_comprehensive_pdf() -> str | None:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 688,
          "context": " 685:             return None\n 686:     \n 687:     \n 688: >>> def verify_manifest(strict: bool = False) -> tuple[int, int]:\n 689:         \"\"\"Verify MANIFEST.md hashes against current files in docs/upload.\n 690:     \n 691:         Returns (checked, mismatched). In strict mode, raises on mismatches.",
          "match": "def verify_manifest(strict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 739,
          "context": " 736:         return (checked, mismatched)\n 737:     \n 738:     \n 739: >>> def main():\n 740:         parser = argparse.ArgumentParser(description='Build OSF/Zenodo upload package (dry-run)')\n 741:         parser.add_argument('--no-zip', action='store_true', help='Do not create a ZIP bundle of payload files')\n 742:         parser.add_argument('--label', type=str, default=None, help='Custom label prefix for the ZIP bundle name')",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 95,
          "context": "  92:     \n  93:     \n  94:     def _collect_provenance(deterministic: bool = False) -> list[str]:\n  95: >>>     \"\"\"Collect provenance: git SHA, Python, NumPy/CuPy, OS, deterministic flag.\"\"\"\n  96:         lines: list[str] = []\n  97:         # Git SHA\n  98:         sha = None",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 115,
          "context": " 112:         except Exception:\n 113:             lines.append(\"- NumPy: unavailable\")\n 114:         try:\n 115: >>>         import cupy as _cp  # type: ignore\n 116:             _ = _cp.__version__\n 117:             lines.append(f\"- CuPy: {_cp.__version__}\")\n 118:         except Exception:",
          "match": "cupy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 117,
          "context": " 114:         try:\n 115:             import cupy as _cp  # type: ignore\n 116:             _ = _cp.__version__\n 117: >>>         lines.append(f\"- CuPy: {_cp.__version__}\")\n 118:         except Exception:\n 119:             lines.append(\"- CuPy: unavailable\")\n 120:         # OS",
          "match": "CuPy"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 119,
          "context": " 116:             _ = _cp.__version__\n 117:             lines.append(f\"- CuPy: {_cp.__version__}\")\n 118:         except Exception:\n 119: >>>         lines.append(\"- CuPy: unavailable\")\n 120:         # OS\n 121:         lines.append(f\"- OS: {platform.system()} {platform.release()} ({platform.version()})\")\n 122:         lines.append(f\"- Deterministic mode: {'on' if deterministic else 'off'}\")",
          "match": "CuPy"
        }
      ],
      "line_count": 833,
      "docstring": "Build OSF/Zenodo upload package (dry-run)\n- Refresh results artifacts (MASTER_TEST_STATUS.csv, RESULTS_REPORT.md)\n- Stage required documents into docs/upload/\n- Compute SHA256 checksums and sizes\n- Generate MANIFEST.md (overwrites)\n- Emit simple metadata templates for Zenodo/OSF (JSON/MD)\n\nUsage (from repo root):\n  python tools/build_upload_package.py\n\nThis is a dry-run: no network calls; outputs are staged under docs/upload/."
    },
    {
      "filepath": "tools\\check_contact_email.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "4d7fe90b5907425d",
      "file_size": 2972,
      "modified": "2025-11-03T13:12:11.543479",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 39,
          "context": "  36:     ]\n  37:     \n  38:     \n  39: >>> def is_allowed(path: Path) -> bool:\n  40:         rel = path.as_posix()\n  41:         for p in ALLOWED_PREFIXES:\n  42:             if rel.startswith(p):",
          "match": "def is_allowed(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:         return False\n  45:     \n  46:     \n  47: >>> def main() -> int:\n  48:         root = Path(__file__).resolve().parents[1]\n  49:         violations = []\n  50:         scanned = 0",
          "match": "def main() -> int:"
        },
        {
          "type": "Boundary condition handling",
          "pattern": "boundary|periodic|absorbing",
          "line": 29,
          "context": "  26:     \n  27:     # Allowed paths (prefix match) where old email may legitimately persist (snapshots, evidence, outputs)\n  28:     ALLOWED_PREFIXES = [\n  29: >>>     \"docs/upload/\",            # current upload staging (regenerated periodically)\n  30:         \"docs/upload_backup_\",     # immutable backups\n  31:         \"docs/upload_ref\",         # immutable references\n  32:         \"docs/evidence/\",          # extracted evidence and templates",
          "match": "periodic"
        }
      ],
      "line_count": 86,
      "docstring": "check_contact_email.py — Guardrail to prevent old contact email from reappearing in source.\n\nScans the repository for occurrences of the old contact email and fails if any are found\noutside of explicitly allowed generated/snapshot directories.\n\nExit codes:\n- 0: No violations found\n- 1: Violations detected"
    },
    {
      "filepath": "tools\\compile_results_report.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "ad61cfef702865c5",
      "file_size": 3479,
      "modified": "2025-11-03T13:12:11.549897",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 28,
          "context": "  25:     OUTPUT_MD = Path(sys.argv[2]) if len(sys.argv) > 2 else Path('docs/upload/RESULTS_REPORT.md')\n  26:     \n  27:     \n  28: >>> def gather_entries(root: Path):\n  29:         entries = []\n  30:         for dirpath, dirnames, filenames in os.walk(root):\n  31:             d = Path(dirpath)",
          "match": "def gather_entries(root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 59,
          "context": "  56:         return entries\n  57:     \n  58:     \n  59: >>> def render_report(entries):\n  60:         lines = []\n  61:         lines.append('# LFM Results Report')\n  62:         lines.append('')",
          "match": "def render_report(entries):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 79,
          "context": "  76:         return \"\\n\".join(lines) + \"\\n\"\n  77:     \n  78:     \n  79: >>> def main():\n  80:         entries = gather_entries(RESULTS_ROOT)\n  81:         OUTPUT_MD.parent.mkdir(parents=True, exist_ok=True)\n  82:         OUTPUT_MD.write_text(render_report(entries), encoding='utf-8')",
          "match": "def main():"
        }
      ],
      "line_count": 87,
      "docstring": "Compile an aggregate results report from results/* readme.txt and summary.json\ninto docs/upload/RESULTS_REPORT.md.\n\nUsage:\n  python tools/compile_results_report.py [results_root] [output_md]\n\nDefaults:\n  results_root = ./results\n  output_md = ./docs/upload/RESULTS_REPORT.md"
    },
    {
      "filepath": "tools\\diagnostics_policy.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "73317201a7da7d6d",
      "file_size": 3909,
      "modified": "2025-11-03T13:12:11.550947",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 23,
          "context": "  20:     from typing import Dict, List, Tuple\n  21:     \n  22:     \n  23: >>> def enforce_for_cfg(cfg: Dict) -> Tuple[Dict, List[str]]:\n  24:         notes: List[str] = []\n  25:         if not isinstance(cfg, dict):\n  26:             return cfg, notes",
          "match": "def enforce_for_cfg(cfg:"
        }
      ],
      "line_count": 80,
      "docstring": "Diagnostics policy enforcement for LFM test configurations.\n\nThis enforces minimal diagnostics required for troubleshooting per the repo policy:\n- Time dilation: ensure diagnostics.save_time_series = true\n- Time delay: ensure diagnostics.track_packet = true, diagnostics.log_packet_stride set\n              enable energy monitoring and debug diagnostics at reasonable cadence\n\nBehavior: Non-destructive and conservative. It updates the in-memory cfg dict (no file I/O).\nIt returns the modified cfg and a list of human-readable notes describing changes."
    },
    {
      "filepath": "tools\\dirhash_compare.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "38b5c697c71a6fb8",
      "file_size": 2939,
      "modified": "2025-11-03T13:12:11.551946",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 25,
          "context": "  22:     from typing import Dict, Tuple\n  23:     \n  24:     \n  25: >>> def sha256_file(p: Path) -> str:\n  26:         h = hashlib.sha256()\n  27:         with p.open('rb') as f:\n  28:             for chunk in iter(lambda: f.read(8192), b''):",
          "match": "def sha256_file(p:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 33,
          "context": "  30:         return h.hexdigest()\n  31:     \n  32:     \n  33: >>> def walk_hashes(root: Path) -> Dict[str, Tuple[int, str]]:\n  34:         mapping: Dict[str, Tuple[int, str]] = {}\n  35:         for path in sorted(root.rglob('*')):\n  36:             if path.is_file():",
          "match": "def walk_hashes(root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 42,
          "context": "  39:         return mapping\n  40:     \n  41:     \n  42: >>> def main() -> int:\n  43:         if len(sys.argv) != 3:\n  44:             print('Usage: python tools/dirhash_compare.py <dirA> <dirB>')\n  45:             return 2",
          "match": "def main() -> int:"
        }
      ],
      "line_count": 97,
      "docstring": "Compare two directories recursively using SHA256 per-file and print a summary.\nUsage:\n  python tools/dirhash_compare.py <dirA> <dirB>\nOutputs:\n  - Added (in B not in A)\n  - Removed (in A not in B)\n  - Modified (present in both but different SHA256)\n  - Unchanged count"
    },
    {
      "filepath": "tools\\docx_text_extract.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "af16093cf198b926",
      "file_size": 3468,
      "modified": "2025-11-03T13:12:11.552945",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 47,
          "context": "  44:     WHITESPACE_RE = re.compile(r'[\\t \\u00A0\\u2000-\\u200B]+')\n  45:     \n  46:     \n  47: >>> def extract_docx_text(path: str) -> str:\n  48:         with zipfile.ZipFile(path) as zf:\n  49:             try:\n  50:                 data = zf.read('word/document.xml').decode('utf-8', errors='ignore')",
          "match": "def extract_docx_text(path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 66,
          "context": "  63:         return text.strip()\n  64:     \n  65:     \n  66: >>> def main():\n  67:         in_dir = sys.argv[1] if len(sys.argv) > 1 else DEFAULT_INPUT\n  68:         out_dir = sys.argv[2] if len(sys.argv) > 2 else DEFAULT_OUTPUT\n  69:     ",
          "match": "def main():"
        }
      ],
      "line_count": 100,
      "docstring": "Batch-extract text from .docx files without external dependencies.\n\n- Recursively scans an input directory (default: ./documents) for .docx\n- Extracts text from word/document.xml and writes .txt files mirroring structure\n- Saves under docs/evidence/docx_text/<relative>.txt\n\nUsage (from repo root):\n  python tools/docx_text_extract.py [input_dir] [output_dir]\n\nExamples:\n  python tools/docx_text_extract.py documents docs/evidence/docx_text\n  python tools/docx_text_extract.py . docs/evidence/docx_text\n\nNote: This is a simple XML-stripper for docx; formatting is minimal by design."
    },
    {
      "filepath": "tools\\docx_to_pdf.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "213d2a43d82630a4",
      "file_size": 971,
      "modified": "2025-11-03T13:12:11.554040",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 20,
          "context": "  17:     import os\n  18:     from docx2pdf import convert\n  19:     \n  20: >>> def main():\n  21:         in_dir = sys.argv[1] if len(sys.argv) > 1 else 'documents'\n  22:         out_dir = sys.argv[2] if len(sys.argv) > 2 else 'docs/evidence/pdf'\n  23:         os.makedirs(out_dir, exist_ok=True)",
          "match": "def main():"
        }
      ],
      "line_count": 29,
      "docstring": "Batch-convert .docx files to PDF using docx2pdf.\n\nUsage (from repo root):\n  python tools/docx_to_pdf.py documents docs/evidence/pdf\n\nRequires: docx2pdf (pip install docx2pdf)"
    },
    {
      "filepath": "tools\\generate_results_readmes.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "532bd6cc33c81bd1",
      "file_size": 4273,
      "modified": "2025-11-03T13:12:11.554040",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 31,
          "context": "  28:     CSV_EXTS = {'.csv', '.tsv'}\n  29:     \n  30:     \n  31: >>> def format_metrics(summary_path: Path) -> str:\n  32:         if not summary_path.exists():\n  33:             return \"- (no summary.json found)\\n\"\n  34:         try:",
          "match": "def format_metrics(summary_path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 55,
          "context": "  52:         return \"\\n\".join(lines) + \"\\n\"\n  53:     \n  54:     \n  55: >>> def list_files(root: Path) -> str:\n  56:         lines = []\n  57:         for p in sorted(root.iterdir(), key=lambda x: (x.is_dir(), x.name.lower())):\n  58:             try:",
          "match": "def list_files(root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 70,
          "context": "  67:         return \"\\n\".join(lines) + \"\\n\"\n  68:     \n  69:     \n  70: >>> def main():\n  71:         template = TEMPLATE_PATH.read_text(encoding='utf-8') if TEMPLATE_PATH.exists() else None\n  72:         now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n  73:     ",
          "match": "def main():"
        }
      ],
      "line_count": 120,
      "docstring": "Generate readme.txt files within each results directory, summarizing available\nsummary.json, CSVs, and plot images.\n\nUsage:\n  python tools/generate_results_readmes.py [results_root]\n\nDefaults to ./results"
    },
    {
      "filepath": "tools\\post_run_hooks.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "2d989a3caba693c1",
      "file_size": 3037,
      "modified": "2025-11-03T13:12:11.555651",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 18,
          "context": "  15:     from typing import Iterable, Optional\n  16:     \n  17:     \n  18: >>> def run_validation(scope: str, *, tiers: Optional[Iterable[int]] = None, strict: bool = False, quiet: bool = False) -> int:\n  19:         \"\"\"Run validation based on scope.\n  20:     \n  21:         scope: 'all' | 'tiers' | 'tier'",
          "match": "def run_validation(scope:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 52,
          "context": "  49:         return code if code != 0 else (0 if ok else 1)\n  50:     \n  51:     \n  52: >>> def rebuild_upload(*, deterministic: bool = False) -> bool:\n  53:         \"\"\"Rebuild docs/upload package with deterministic options as desired.\n  54:     \n  55:         Returns True on (best-effort) success.",
          "match": "def rebuild_upload(*, deterministic:"
        },
        {
          "type": "Parallel processing method",
          "pattern": "parallel|threading|multiprocess",
          "line": 11,
          "context": "   8:     \"\"\"\n   9:     Shared post-run hooks for validators and upload package staging.\n  10:     \n  11: >>> Use these helpers from tier runners and the parallel orchestrator to avoid duplication.\n  12:     \"\"\"\n  13:     from __future__ import annotations\n  14:     from pathlib import Path",
          "match": "parallel"
        }
      ],
      "line_count": 77,
      "docstring": "Shared post-run hooks for validators and upload package staging.\n\nUse these helpers from tier runners and the parallel orchestrator to avoid duplication."
    },
    {
      "filepath": "tools\\validate_results_pipeline.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "40e03f005c2eacda",
      "file_size": 27217,
      "modified": "2025-11-03T13:12:11.556509",
      "git_info": {
        "first_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 67,
          "context": "  64:             return None\n  65:     \n  66:     \n  67: >>> class ValidationError(Exception):\n  68:         \"\"\"Raised when validation fails in strict mode.\"\"\"\n  69:         pass\n  70:     ",
          "match": "class ValidationError(Exception):"
        },
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 72,
          "context": "  69:         pass\n  70:     \n  71:     \n  72: >>> class PipelineValidator:\n  73:         \"\"\"Validates the entire results → upload pipeline.\"\"\"\n  74:         \n  75:         def __init__(self, strict: bool = False, verbose: bool = True):",
          "match": "class PipelineValidator:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 53,
          "context": "  50:         from lfm_tiers import get_tiers, get_tier_by_number\n  51:     except Exception:\n  52:         # Fallback if registry unavailable\n  53: >>>     def get_tiers():\n  54:             return [\n  55:                 {\"tier\": 1, \"name\": \"Relativistic\", \"category_name\": \"Relativistic\", \"dir\": \"Relativistic\", \"prefix\": \"REL\"},\n  56:                 {\"tier\": 2, \"name\": \"Gravity\", \"category_name\": \"Gravity Analogue\", \"dir\": \"Gravity\", \"prefix\": \"GRAV\"},",
          "match": "def get_tiers():"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 60,
          "context": "  57:                 {\"tier\": 3, \"name\": \"Energy\", \"category_name\": \"Energy Conservation\", \"dir\": \"Energy\", \"prefix\": \"ENER\"},\n  58:                 {\"tier\": 4, \"name\": \"Quantization\", \"category_name\": \"Quantization\", \"dir\": \"Quantization\", \"prefix\": \"QUAN\"},\n  59:             ]\n  60: >>>     def get_tier_by_number(n: int):\n  61:             for t in get_tiers():\n  62:                 if int(t[\"tier\"]) == int(n):\n  63:                     return t",
          "match": "def get_tier_by_number(n:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 75,
          "context": "  72:     class PipelineValidator:\n  73:         \"\"\"Validates the entire results → upload pipeline.\"\"\"\n  74:         \n  75: >>>     def __init__(self, strict: bool = False, verbose: bool = True):\n  76:             self.strict = strict\n  77:             self.verbose = verbose\n  78:             self.errors: List[str] = []",
          "match": "def __init__(self, strict:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 82,
          "context": "  79:             self.warnings: List[str] = []\n  80:             self.info: List[str] = []\n  81:             \n  82: >>>     def log(self, msg: str, level: str = 'info'):\n  83:             \"\"\"Log a message at specified level.\"\"\"\n  84:             if level == 'error':\n  85:                 self.errors.append(msg)",
          "match": "def log(self, msg:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 97,
          "context": "  94:                 if self.verbose:\n  95:                     print(f\"ℹ️  {msg}\")\n  96:                     \n  97: >>>     def validate_test_result(self, test_id: str, tier_dir: Path) -> bool:\n  98:             \"\"\"\n  99:             Validate that a single test result has all required artifacts.\n 100:             ",
          "match": "def validate_test_result(self, test_id:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 166,
          "context": " 163:             \n 164:             return valid\n 165:         \n 166: >>>     def validate_tier_results(self, tier_num: int) -> bool:\n 167:             \"\"\"Validate all test results in a tier.\"\"\"\n 168:             tier_def = get_tier_by_number(tier_num)\n 169:             if not tier_def:",
          "match": "def validate_tier_results(self, tier_num:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 192,
          "context": " 189:             \n 190:             return valid\n 191:         \n 192: >>>     def validate_master_status_integrity(self) -> bool:\n 193:             \"\"\"\n 194:             Validate MASTER_TEST_STATUS.csv integrity.\n 195:             ",
          "match": "def validate_master_status_integrity(self) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 269,
          "context": " 266:             \n 267:             return valid\n 268:         \n 269: >>>     def validate_upload_package(self) -> bool:\n 270:             \"\"\"\n 271:             Validate upload package completeness and integrity.\n 272:             ",
          "match": "def validate_upload_package(self) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 368,
          "context": " 365:             \n 366:             return valid\n 367:         \n 368: >>>     def validate_end_to_end(self) -> bool:\n 369:             \"\"\"\n 370:             Validate the entire pipeline end-to-end.\n 371:             ",
          "match": "def validate_end_to_end(self) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 422,
          "context": " 419:     \n 420:             return valid\n 421:     \n 422: >>>     def validate_resource_metrics(self) -> bool:\n 423:             \"\"\"Validate resource tracking metrics from test_metrics_history.json and results/ structure.\n 424:     \n 425:             Rules:",
          "match": "def validate_resource_metrics(self) -> bool:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 518,
          "context": " 515:                     ok = False\n 516:             return ok\n 517:         \n 518: >>>     def _sha256_file(self, path: Path) -> str:\n 519:             \"\"\"Compute SHA256 hash of a file.\"\"\"\n 520:             h = hashlib.sha256()\n 521:             with open(path, 'rb') as f:",
          "match": "def _sha256_file(self, path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 526,
          "context": " 523:                     h.update(chunk)\n 524:             return h.hexdigest()\n 525:     \n 526: >>>     def _sha256_file_normalized(self, path: Path, *, ignore_generated_line: bool = True) -> str:\n 527:             \"\"\"Compute SHA256 of a text file with optional normalization.\n 528:     \n 529:             Normalizations applied when ignore_generated_line is True:",
          "match": "def _sha256_file_normalized(self, path:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 549,
          "context": " 546:                 return self._sha256_file(path)\n 547:             return h.hexdigest()\n 548:         \n 549: >>>     def report(self) -> int:\n 550:             \"\"\"\n 551:             Print validation report and return exit code.\n 552:             ",
          "match": "def report(self) -> int:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 586,
          "context": " 583:                 return 0\n 584:     \n 585:     \n 586: >>> def main():\n 587:         parser = argparse.ArgumentParser(\n 588:             description='Validate LFM results and upload pipeline integrity',\n 589:             formatter_class=argparse.RawDescriptionHelpFormatter,",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 427,
          "context": " 424:     \n 425:             Rules:\n 426:             - Every test under results/<Tier>/<TEST_ID>/ should have an entry in metrics history.\n 427: >>>         - Last run metrics must include runtime_sec>0 and non-negative CPU/RAM/GPU values.\n 428:             \"\"\"\n 429:             history_path = RESULTS / 'test_metrics_history.json'\n 430:             if not history_path.exists():",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 493,
          "context": " 490:                     continue\n 491:                 last = runs[-1]\n 492:                 # Required keys\n 493: >>>             req = ['runtime_sec', 'peak_cpu_percent', 'peak_memory_mb', 'peak_gpu_memory_mb']\n 494:                 missing = [k for k in req if k not in last]\n 495:                 if missing:\n 496:                     self.log(f\"{tid}: missing resource keys in last run: {', '.join(missing)}\", 'error')",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 503,
          "context": " 500:                 rt = float(last.get('runtime_sec', 0.0) or 0.0)\n 501:                 cpu = float(last.get('peak_cpu_percent', 0.0) or 0.0)\n 502:                 mem = float(last.get('peak_memory_mb', 0.0) or 0.0)\n 503: >>>             gpu = float(last.get('peak_gpu_memory_mb', 0.0) or 0.0)\n 504:                 if rt <= 0:\n 505:                     self.log(f\"{tid}: runtime_sec <= 0 ({rt})\", 'error')\n 506:                     ok = False",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 503,
          "context": " 500:                 rt = float(last.get('runtime_sec', 0.0) or 0.0)\n 501:                 cpu = float(last.get('peak_cpu_percent', 0.0) or 0.0)\n 502:                 mem = float(last.get('peak_memory_mb', 0.0) or 0.0)\n 503: >>>             gpu = float(last.get('peak_gpu_memory_mb', 0.0) or 0.0)\n 504:                 if rt <= 0:\n 505:                     self.log(f\"{tid}: runtime_sec <= 0 ({rt})\", 'error')\n 506:                     ok = False",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 513,
          "context": " 510:                 if mem < 0:\n 511:                     self.log(f\"{tid}: peak_memory_mb < 0 ({mem})\", 'error')\n 512:                     ok = False\n 513: >>>             if gpu < 0:\n 514:                     self.log(f\"{tid}: peak_gpu_memory_mb < 0 ({gpu})\", 'error')\n 515:                     ok = False\n 516:             return ok",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 514,
          "context": " 511:                     self.log(f\"{tid}: peak_memory_mb < 0 ({mem})\", 'error')\n 512:                     ok = False\n 513:                 if gpu < 0:\n 514: >>>                 self.log(f\"{tid}: peak_gpu_memory_mb < 0 ({gpu})\", 'error')\n 515:                     ok = False\n 516:             return ok\n 517:         ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 514,
          "context": " 511:                     self.log(f\"{tid}: peak_memory_mb < 0 ({mem})\", 'error')\n 512:                     ok = False\n 513:                 if gpu < 0:\n 514: >>>                 self.log(f\"{tid}: peak_gpu_memory_mb < 0 ({gpu})\", 'error')\n 515:                     ok = False\n 516:             return ok\n 517:         ",
          "match": "gpu"
        }
      ],
      "line_count": 644,
      "docstring": "Comprehensive validation framework for LFM results generation and upload pipeline.\n\nThis validator ensures data integrity across the entire chain:\n  Test Execution → Results Artifacts → Master Status CSV → Upload Package → Manifest\n\nUsage:\n  # Validate a single test result\n  python tools/validate_results_pipeline.py --test REL-01\n  \n  # Validate an entire tier\n  python tools/validate_results_pipeline.py --tier 1\n  \n  # Validate master status integrity\n  python tools/validate_results_pipeline.py --master-status\n  \n  # Validate upload package completeness\n  python tools/validate_results_pipeline.py --upload-package\n  \n  # Validate entire pipeline (end-to-end)\n  python tools/validate_results_pipeline.py --all\n  \n  # Run with strict mode (fail on warnings)\n  python tools/validate_results_pipeline.py --all --strict"
    },
    {
      "filepath": "validate_headers.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "026669b5a6bb9a58",
      "file_size": 6231,
      "modified": "2025-11-03T13:19:47.727672",
      "git_info": {
        "first_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        },
        "latest_commit": {
          "hash": "66d7142a",
          "date": "2025-11-03 13:20:52 -0800",
          "message": "Documentation update, console app."
        }
      },
      "innovations": [
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 19,
          "context": "  16:     import sys\n  17:     from pathlib import Path\n  18:     \n  19: >>> def check_python_header(filepath):\n  20:         \"\"\"Check if Python file has proper copyright header\"\"\"\n  21:         try:\n  22:             with open(filepath, 'r', encoding='utf-8') as f:",
          "match": "def check_python_header(filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 46,
          "context": "  43:         except Exception as e:\n  44:             return [f\"Error reading file: {e}\"]\n  45:     \n  46: >>> def check_markdown_header(filepath):\n  47:         \"\"\"Check if Markdown file has proper copyright notice\"\"\"\n  48:         try:\n  49:             with open(filepath, 'r', encoding='utf-8') as f:",
          "match": "def check_markdown_header(filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 63,
          "context": "  60:         except Exception as e:\n  61:             return [f\"Error reading file: {e}\"]\n  62:     \n  63: >>> def check_script_header(filepath):\n  64:         \"\"\"Check if batch/shell script has proper copyright header\"\"\"\n  65:         try:\n  66:             with open(filepath, 'r', encoding='utf-8') as f:",
          "match": "def check_script_header(filepath):"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 80,
          "context": "  77:         except Exception as e:\n  78:             return [f\"Error reading file: {e}\"]\n  79:     \n  80: >>> def main():\n  81:         \"\"\"Main header validation\"\"\"\n  82:         print(\"=\" * 60)\n  83:         print(\"  LFM COPYRIGHT HEADER VALIDATION\")",
          "match": "def main():"
        }
      ],
      "line_count": 179,
      "docstring": "Header Validation Script\n========================\nChecks that all LFM source files have proper copyright headers and license information.\nEnsures IP protection compliance across the entire codebase."
    },
    {
      "filepath": "validate_resource_tracking.py",
      "category": "UTILITY",
      "priority": 5,
      "file_hash": "171bf15900c53944",
      "file_size": 15978,
      "modified": "2025-11-02T21:26:21.592713",
      "git_info": {
        "first_commit": {
          "hash": "ef0dcb6b",
          "date": "2025-11-01 09:54:35 -0700",
          "message": "Testing framework improvements"
        },
        "latest_commit": {
          "hash": "54222bfd",
          "date": "2025-11-02 21:26:49 -0800",
          "message": "Upload report process, change license, change email, other changes."
        }
      },
      "innovations": [
        {
          "type": "Novel class/algorithm",
          "pattern": "class\\s+(\\w+).*?:",
          "line": 44,
          "context": "  41:     from datetime import datetime\n  42:     \n  43:     \n  44: >>> class Colors:\n  45:         \"\"\"ANSI color codes for terminal output.\"\"\"\n  46:         HEADER = '\\033[95m'\n  47:         OKBLUE = '\\033[94m'",
          "match": "class Colors:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 57,
          "context": "  54:         UNDERLINE = '\\033[4m'\n  55:     \n  56:     \n  57: >>> def load_metrics_history(project_root: Path) -> Dict:\n  58:         \"\"\"Load test metrics history JSON.\"\"\"\n  59:         metrics_file = project_root / \"results\" / \"test_metrics_history.json\"\n  60:         if not metrics_file.exists():",
          "match": "def load_metrics_history(project_root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 68,
          "context": "  65:             return json.load(f)\n  66:     \n  67:     \n  68: >>> def load_master_status(project_root: Path) -> Dict[str, str]:\n  69:         \"\"\"Parse MASTER_TEST_STATUS.csv and return {test_id: status} (e.g., PASS/FAIL/SKIP).\"\"\"\n  70:         status_csv = project_root / \"results\" / \"MASTER_TEST_STATUS.csv\"\n  71:         status_map: Dict[str, str] = {}",
          "match": "def load_master_status(project_root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 99,
          "context": "  96:         return status_map\n  97:     \n  98:     \n  99: >>> def load_test_summary(test_dir: Path) -> Optional[Dict]:\n 100:         \"\"\"Load individual test summary.json.\"\"\"\n 101:         summary_file = test_dir / \"summary.json\"\n 102:         if not summary_file.exists():",
          "match": "def load_test_summary(test_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 109,
          "context": " 106:             return json.load(f)\n 107:     \n 108:     \n 109: >>> def validate_metrics(metrics: Dict, test_id: str, source: str) -> List[str]:\n 110:         \"\"\"\n 111:         Validate resource metrics for a single test.\n 112:         ",
          "match": "def validate_metrics(metrics:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 160,
          "context": " 157:         return errors\n 158:     \n 159:     \n 160: >>> def get_tier_prefix(tier: int) -> str:\n 161:         \"\"\"Get test ID prefix for tier via central registry (fallback to legacy).\"\"\"\n 162:         try:\n 163:             from lfm_tiers import get_tier_by_number",
          "match": "def get_tier_prefix(tier:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 171,
          "context": " 168:             return prefixes.get(tier, \"\")\n 169:     \n 170:     \n 171: >>> def find_tier_results_dirs(project_root: Path, tier: Optional[int] = None) -> List[Path]:\n 172:         \"\"\"Find all tier result directories using central registry.\"\"\"\n 173:         results_dir = project_root / \"results\"\n 174:         if not results_dir.exists():",
          "match": "def find_tier_results_dirs(project_root:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 205,
          "context": " 202:                 return [p for p in (results_dir / \"Relativistic\", results_dir / \"Gravity\", results_dir / \"Energy\", results_dir / \"Quantization\") if p.exists()]\n 203:     \n 204:     \n 205: >>> def inspect_test_from_history(metrics_history: Dict, test_id: str) -> Dict:\n 206:         \"\"\"Inspect test from metrics history.\"\"\"\n 207:         if test_id not in metrics_history:\n 208:             return {",
          "match": "def inspect_test_from_history(metrics_history:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 238,
          "context": " 235:         }\n 236:     \n 237:     \n 238: >>> def inspect_test_from_summary(test_dir: Path, test_id: str) -> Dict:\n 239:         \"\"\"Inspect test from summary.json.\"\"\"\n 240:         summary = load_test_summary(test_dir)\n 241:         if not summary:",
          "match": "def inspect_test_from_summary(test_dir:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 280,
          "context": " 277:         }\n 278:     \n 279:     \n 280: >>> def print_test_inspection(inspection: Dict):\n 281:         \"\"\"Print inspection results for a single test.\"\"\"\n 282:         test_id = inspection[\"test_id\"]\n 283:         ",
          "match": "def print_test_inspection(inspection:"
        },
        {
          "type": "Method implementation",
          "pattern": "def\\s+(\\w+).*?:",
          "line": 305,
          "context": " 302:                 print(f\"    - {error}\")\n 303:     \n 304:     \n 305: >>> def main():\n 306:         parser = argparse.ArgumentParser(\n 307:             description=\"Validate resource tracking metrics across all tier runners\"\n 308:         )",
          "match": "def main():"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 13,
          "context": "  10:     --------------------------------------------------------------------------\n  11:     Purpose:\n  12:         Validate that all 4 tier runners correctly populate resource metrics\n  13: >>>     (CPU, RAM, GPU, runtime) after test execution.\n  14:     \n  15:     Inspection Points:\n  16:         1. Test metrics history JSON (test_metrics_history.json)",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 23,
          "context": "  20:     Expected Behavior:\n  21:         - peak_cpu_percent > 0 (unless psutil unavailable)\n  22:         - peak_memory_mb > 0 (unless psutil unavailable)\n  23: >>>     - peak_gpu_memory_mb >= 0 (0 if no GPU or nvidia-smi unavailable)\n  24:         - runtime_sec > 0\n  25:         - All metrics present (no missing keys)\n  26:     ",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 23,
          "context": "  20:     Expected Behavior:\n  21:         - peak_cpu_percent > 0 (unless psutil unavailable)\n  22:         - peak_memory_mb > 0 (unless psutil unavailable)\n  23: >>>     - peak_gpu_memory_mb >= 0 (0 if no GPU or nvidia-smi unavailable)\n  24:         - runtime_sec > 0\n  25:         - All metrics present (no missing keys)\n  26:     ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 119,
          "context": " 116:         errors = []\n 117:         \n 118:         # Check required keys\n 119: >>>     required_keys = [\"peak_cpu_percent\", \"peak_memory_mb\", \"peak_gpu_memory_mb\", \"runtime_sec\"]\n 120:         for key in required_keys:\n 121:             if key not in metrics:\n 122:                 errors.append(f\"Missing key: {key}\")",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 130,
          "context": " 127:         # Extract values\n 128:         cpu = metrics[\"peak_cpu_percent\"]\n 129:         mem = metrics[\"peak_memory_mb\"]\n 130: >>>     gpu = metrics[\"peak_gpu_memory_mb\"]\n 131:         runtime = metrics[\"runtime_sec\"]\n 132:         \n 133:         # Validate runtime (must be > 0)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 130,
          "context": " 127:         # Extract values\n 128:         cpu = metrics[\"peak_cpu_percent\"]\n 129:         mem = metrics[\"peak_memory_mb\"]\n 130: >>>     gpu = metrics[\"peak_gpu_memory_mb\"]\n 131:         runtime = metrics[\"runtime_sec\"]\n 132:         \n 133:         # Validate runtime (must be > 0)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 149,
          "context": " 146:         elif mem < 0:\n 147:             errors.append(f\"peak_memory_mb is negative: {mem}\")\n 148:         \n 149: >>>     # Validate GPU (>= 0, can be 0 if no GPU)\n 150:         if gpu < 0:\n 151:             errors.append(f\"peak_gpu_memory_mb is negative: {gpu}\")\n 152:         ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 149,
          "context": " 146:         elif mem < 0:\n 147:             errors.append(f\"peak_memory_mb is negative: {mem}\")\n 148:         \n 149: >>>     # Validate GPU (>= 0, can be 0 if no GPU)\n 150:         if gpu < 0:\n 151:             errors.append(f\"peak_gpu_memory_mb is negative: {gpu}\")\n 152:         ",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 150,
          "context": " 147:             errors.append(f\"peak_memory_mb is negative: {mem}\")\n 148:         \n 149:         # Validate GPU (>= 0, can be 0 if no GPU)\n 150: >>>     if gpu < 0:\n 151:             errors.append(f\"peak_gpu_memory_mb is negative: {gpu}\")\n 152:         \n 153:         # Check for placeholder values (exactly 0.0 for all)",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 151,
          "context": " 148:         \n 149:         # Validate GPU (>= 0, can be 0 if no GPU)\n 150:         if gpu < 0:\n 151: >>>         errors.append(f\"peak_gpu_memory_mb is negative: {gpu}\")\n 152:         \n 153:         # Check for placeholder values (exactly 0.0 for all)\n 154:         if cpu == 0.0 and mem == 0.0 and gpu == 0.0 and runtime > 0:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 151,
          "context": " 148:         \n 149:         # Validate GPU (>= 0, can be 0 if no GPU)\n 150:         if gpu < 0:\n 151: >>>         errors.append(f\"peak_gpu_memory_mb is negative: {gpu}\")\n 152:         \n 153:         # Check for placeholder values (exactly 0.0 for all)\n 154:         if cpu == 0.0 and mem == 0.0 and gpu == 0.0 and runtime > 0:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 154,
          "context": " 151:             errors.append(f\"peak_gpu_memory_mb is negative: {gpu}\")\n 152:         \n 153:         # Check for placeholder values (exactly 0.0 for all)\n 154: >>>     if cpu == 0.0 and mem == 0.0 and gpu == 0.0 and runtime > 0:\n 155:             errors.append(\"PLACEHOLDER VALUES DETECTED (all zeros except runtime)\")\n 156:         \n 157:         return errors",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 255,
          "context": " 252:             metrics = {\n 253:                 \"peak_cpu_percent\": summary[\"metrics\"].get(\"peak_cpu_percent\", 0.0),\n 254:                 \"peak_memory_mb\": summary[\"metrics\"].get(\"peak_memory_mb\", 0.0),\n 255: >>>             \"peak_gpu_memory_mb\": summary[\"metrics\"].get(\"peak_gpu_memory_mb\", 0.0),\n 256:                 \"runtime_sec\": summary.get(\"runtime_sec\", 0.0)\n 257:             }\n 258:         else:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 255,
          "context": " 252:             metrics = {\n 253:                 \"peak_cpu_percent\": summary[\"metrics\"].get(\"peak_cpu_percent\", 0.0),\n 254:                 \"peak_memory_mb\": summary[\"metrics\"].get(\"peak_memory_mb\", 0.0),\n 255: >>>             \"peak_gpu_memory_mb\": summary[\"metrics\"].get(\"peak_gpu_memory_mb\", 0.0),\n 256:                 \"runtime_sec\": summary.get(\"runtime_sec\", 0.0)\n 257:             }\n 258:         else:",
          "match": "gpu"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 297,
          "context": " 294:             print(f\"  {Colors.OKGREEN}✓ {test_id}{Colors.ENDC}: \"\n 295:                   f\"CPU={metrics['peak_cpu_percent']:.1f}%, \"\n 296:                   f\"RAM={metrics['peak_memory_mb']:.1f}MB, \"\n 297: >>>               f\"GPU={metrics['peak_gpu_memory_mb']:.1f}MB, \"\n 298:                   f\"Runtime={metrics['runtime_sec']:.2f}s\")\n 299:         else:\n 300:             print(f\"  {Colors.FAIL}✗ {test_id}{Colors.ENDC}:\")",
          "match": "GPU"
        },
        {
          "type": "GPU acceleration technique",
          "pattern": "cupy|gpu|cuda",
          "line": 297,
          "context": " 294:             print(f\"  {Colors.OKGREEN}✓ {test_id}{Colors.ENDC}: \"\n 295:                   f\"CPU={metrics['peak_cpu_percent']:.1f}%, \"\n 296:                   f\"RAM={metrics['peak_memory_mb']:.1f}MB, \"\n 297: >>>               f\"GPU={metrics['peak_gpu_memory_mb']:.1f}MB, \"\n 298:                   f\"Runtime={metrics['runtime_sec']:.2f}s\")\n 299:         else:\n 300:             print(f\"  {Colors.FAIL}✗ {test_id}{Colors.ENDC}:\")",
          "match": "gpu"
        }
      ],
      "line_count": 436,
      "docstring": "validate_resource_tracking.py — Multi-Point Inspection for Resource Metrics\n--------------------------------------------------------------------------\nPurpose:\n    Validate that all 4 tier runners correctly populate resource metrics\n    (CPU, RAM, GPU, runtime) after test execution.\n\nInspection Points:\n    1. Test metrics history JSON (test_metrics_history.json)\n    2. Individual test summary.json files\n    3. Master test status CSV (MASTER_TEST_STATUS.csv)\n    \nExpected Behavior:\n    - peak_cpu_percent > 0 (unless psutil unavailable)\n    - peak_memory_mb > 0 (unless psutil unavailable)\n    - peak_gpu_memory_mb >= 0 (0 if no GPU or nvidia-smi unavailable)\n    - runtime_sec > 0\n    - All metrics present (no missing keys)\n\nUsage:\n    python validate_resource_tracking.py [--tier TIER] [--test TEST_ID]\n    \n    Examples:\n        python validate_resource_tracking.py --tier 1\n        python validate_resource_tracking.py --test REL-01\n        python validate_resource_tracking.py  # Check all"
    }
  ],
  "legal_notice": {
    "purpose": "Establish prior art for LFM innovations",
    "patent_prevention": "This documentation prevents third-party patent claims on disclosed methods",
    "copyright": "All innovations documented herein are copyrighted by Greg D. Partin",
    "disclosure_date": "2025-11-03",
    "public_repository": "https://github.com/gpartin/LFM"
  }
}